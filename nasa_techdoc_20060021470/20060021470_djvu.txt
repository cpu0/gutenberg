Source of Acquisition 
NASA Ames Research Center 



Annotation Inference for the Safety Certification 
of Automatically Generated Code 



Ewen Denney 

USRA/RIACS, NASA Ames 

edenney@email . arc . nasa . gov 



Bernd Fischer 
ECS, University of Southampton 

B . Fischer@ecs . soton . ac .uk 



Abstract 

Code generators for realistic application domains are 
not directly verifiable in practice. Certifiable code gen- 
eration is an alternative approach, where the the genera- 
tor is extended to generate logical annotations (i.e., pre- 
and postconditions and loop invariants) along with the pro- 
grams, allowing fully automated program safety proofs. 
However, it is difficult to implement and maintain because 
it requires access to the generator sources, and because the 
annotations are cross-cutting concerns, both on the object- 
level (i.e., in the generated code) and on the meta-level (i.e., 
in the generator). 

We describe a generic post-generation annotation infer- 
ence algorithm to circumvent these problems. It exploits the 
fact that the output of a code generator is highly idiomatic, 
so that patterns can be used to describe all code constructs 
that require annotations, in a way which is largely indepen- 
dent of the code generator. The algorithm then uses tech- 
niques similar to aspect-oriented programming to add the 
annotations to the generated code. The generic algorithm 
is implemented and instantiated for two generators; the in- 
stantiations are applied successfully to fully automatically 
certify initialization safety for the generated programs. 



1 Introduction 

Automated code generation is an enabling technology 
for model-based software development and has significant 
potential to improve the entire software development pro- 
cess. It promises many benefits, including higher produc- 
tivity, reduced tum-around times, increased portability, and 
eli minatio n of manual coding errors. However, the key to 
realizing these benefits is of course generator correctness — 
nothing is gained from replacing manual coding errors with 
automatic coding errors. 

Several ideas have been explored to ensure generator 
correctness', but none has been entirely "successful" yet. 



Approaches based on "correct-by-construction" techniques 
like deductive synthesis [23] or refinement [22] remain dif- 
ficult to implement and to scale up, and have not found 
widespread application. The direct verification of genera- 
tors is still a challenge for existing verification techniques 
and remains similarly elusive. Usually, generators are thus 
validated by. testing only, but this quickly becomes exces- 
sive and cannot guarantee the same level of assurance. 

Our work follows an alternative approach that is based 
on the observation that the correctness of the generator is ir- 
relevant if instead the correctness of the generated programs 
is shown individually. However, rather than showing full 
correctness of the generated programs as envisioned for a 
verifying compiler [15], we follow the more pragmatic cer- 
tifying compiler [19] used in the proof carrying code (PCC) 
approach and focus on the Hoare-style certification of spe- 
cific safety properties. 

Still, this leaves us with the task to construct the appro- 
priate logical annotations (i.e., pre- and postconditions and 
loop invariants), due to their central role in Hoare-style cer- 
tification. In previous work [5, 6, 7, 8, 25] wehave thus 
developed and evaluated an approach to certifiable program 
generation in which the code generator itself is extended in 
such a way that it produces all necessary annotations togeth- 
er with the code. This is achieved by embedding annotation 
templates into the code templates, which are then instanti- 
atedand refiwdin^parallelijy ^ the~generaforr ^~ 

We have successfully used this approach to certify a va- 
riety of safety properties for code generated by the AUTO- 
BAYES [11] and AUTOFlLTER [26] systems. However, it 
has two major disadvantages. First, it is difficult to im- 
plement and to maintain: the developers first need to an- 
alyze the generated code in order to identify the location 
and structure of the required annotations, then identify the 
templates that produce the respective code fragments; and 
finally formulate and integrate appropriate annotation tem- 
plates. This is compounded by the fact that annotations 
are cross-cutting concerns, both on the cJbject-level (i.e., the 
generated program) and the meta-level (i.e., the generator). 
Second, it requires access to the existing- sources: thedevel- 



opers need to modify the code generator in order to integrate 
the annotation generation. However, sources are often not 
accessible, in particular for commercial generators. 

In this paper we describe an alternative approach that us- 
es a generic post-generation annotation inference algorithm 
to circumvent these problems. It is based on three funda- 
mental insights: (i) the problem of certifying code can be 
split into two phases: an untrasted annotation generation 
where the creative insights are made, and a simpler trust- 
ed phase where verification conditions are generated and 
proven (ii) although "eureka" insights are required in gen- 
eral, in practice they are rarely required because certain 
common cases typically arise, and (iii) code patterns can 



be used to describe these cases. 

The algorithm can run completely separately from the 
code generator because it uses techniques similar to aspect- 
oriented programming to add the annotations to the gener- 
ated code: the patterns correspond to (static) point-cut de- 
scriptors, while the introduced annotations correspond to 
advice. It thus concentrates annotation generation in one 
location but, even more importantly, leaves the generator 
unchanged by exploiting the idiomatic structure of automat- 
ically generated code (i.e., the fact that it only constitutes a 
limited subset of all possible programs). 

The main contribution of this paper is a general approach 
to extending code generators with a certification capability, 
which has been validated on two code generators. We build 
on previous work on certifiable code generation to develop 
a generic certification system for code generators. Howev- 
er, our focus in this paper is on the annotation inference, 
rather than the subsequent generation and proof of verifica- 
tion conditions. 

2 Background 

Idiomatic Code Automatic code generators derive 
lower-level code from higher-level, declarative specifica- 
tions. Approaches range from deductive synthesis [23] to 
template meta-programming [4] but for our purposes nei- 
ther tfle specific approach nor me speclfic'atroii language " 
matter, and we build on a template-based approach. What 
does matter, however, is the fact that an automatic code gen- 
erator usually generates highly idiomatic code. Intuitively, 
idiomatic code exhibits some regular structure beyond the 
syntax of the programming language and uses similar con- 
structions for similar problems. Manually written code al- 
ready tends to be idiomatic, but the applied idioms vary with 
the programmer. Automatic generators eliminate this vari- 
ability because they essentially derive code by combining 
a finite number of building blocks — in- our case, templates. 
For example, AUTOFlLTER only uses three templates to ini- 
tialize a matrix, resulting in either straight-line code, or one 
of two doubly-nested loop versions (cf. Figure 1) 



A [1 , 1 ] : = ai,i ; for i : = 1 to n do for i : = 1 to n do 

for j : = 1 to m do for j : = 1 to m do 
A[l,m] := q.\,mi B[i,j] :=£>,- ifi=jthen 

A[2,l ] :=a 2 ,i; C[i, j] := c 

... else 

A [n, m] : = a„, m ; C [i , j ] : = d ; 

Figure 1. Idiomatic matrix initializations 

The idioms are essential to our approach because they 
(rather than the templates) determine the interface between 
the code generator and the inference algorithm. Note that 
~^riTdroms~cmije"Teco-girk^^ 
templates that produced the code, which allows us to apply 
our technique to black-box generators as well. However, 
identifying and formalizing the necessary idioms remains a 
manual step in the process. 

Safety Certification The purpose of safety certification 
is to demonstrate that a program does not violate certain 
conditions during its execution. A safety property is an ex- 
act characterization of these conditions based on the opera- 
tional semantics of the language. A safety policy is a set of 
Hoare rules designed to show that safe programs satisfy the 
safety property of interest. The rules can be formalized us- 
ing the usual Hoare triples P {c} Q, i.e., if the condition P 
holds before and the command c terminates, then Q holds 
afterwards (see [18] for more information about Hoare-style 
program proofs). 

For each notion of safety the appropriate safety proper- 
ty and corresponding policy must be formulated. This is 
usually straightforward; in particular, a safety policy can be 
constructed systematically by instantiating a generic rule set 
that is derived from the standard rules of the Hoare calculus 
[5]. The basic idea is to extend the standard environment of 
program variables with a "shadow" environment of safety 
variables which record safety information related to the cor- 
responding program variables. The rules are then responsi- 
ble for maintaining this environment and producing the ap- 
propriate- safety obligations. This is done -using a -family- of 
safety substitutions that are added to the normal substitu- 
tions, and a family of safety predicates that are added to the 
calculated weakest preconditions (WPCs). Safety certifica- 
tion then starts with the postcondition true and computes the 
weakest safety precondition (WSPC), i.e., the WPC togeth- 
er with all applied safety predicates and safety substitutions. - 
If the program is safe then the WSPC will be provable with- 
out any assumptions, i.e., true {c} true is derivable. 



We have defined" severaTsafety properties andTtnpleF" 
"mented the corresponding safety policies in AutoBayes 
and AutoFilter. Here, we focus on the initialization safe- 
ty policy, which ensures that each variable, or individual ar- 
ray element has been explicitly assigned a value before it 



{assign) 
(update) 

(if) 

(while) 

(for) 



Q[e/x, init/^J A safe.^Je) {x : = e}Q 



Q{upd(x, a , e 2 )/x, upd{x M „ e a , mn)/x Mt ] A safe^i) A safe.^(e 2 ) {x [ei ] : = e 2 }C 

Pi{ci}Q P 2 {c 2 }Q 

(b => Pi) A (-.6 => P 2 ) A safe. wi Xb) {if 6 then c x else c 2 } <3 

P{c}/ lA b=>P lA^b^Q 
I A safe. mit (b) {while 6 inv I doc} Q 

P {c} I[i + 1/i) I[mn/i mit } A ex < t < e 2 =» P J[e 2 -f 1/i] =» Q 
Ifa/i] A ra/e inil (ei) A 5afe init (e 2 ) {for i -. = d to e 2 inv J do c} Q 

-P-^-P— -P-{-4-QL_QL^i3L 



(comp) =-7 7-r (skip) 

P {ci ; c 2 } Q 



Q {skip} £ 



(assert) 



P' {pre P' c post Q'}Q 



Figure 2. Proof rules for initialization safety 



is used. The safety environment consists of shadow vari- 
ables £;„ it that contain the value, init after the variable x has 
been assigned a value. Arrays are represented by shadow 
arrays to capture the status of the individual elements. Fig- 
ure 2 shows the rules of the policy. Only statements ac- 
cessing assigning a value to a location affect the value of 
a shadow variable (cf. the assign-, update-, and/or-rules). 
However, all rules also produce the appropriate safety pred- 
icates safe^e) for all immediate subexpressions e of the- 
statements. Since the safety property defines an expression 
to he safe if all corresponding shadow variables have the 
value init, safe^X x W ) f° r example simply translates to 
[i] ) = INIT. 



im« = INIT A (x. 



VC Processing and Annotations As usual in Hoare- 
style verification, a verification condition generator (VCG) 
traTerses the annotated code and applies the rules of the 
calculus to produce verification conditions (VCs). These 
are then simplified, completed by an axiomatization of the 
background theory and passed to an off-the-shelf automat- 
e<i dieorem 'pr6ver(ATP)TTf airVCs are _ proven, the- pro- 
gram is safe wit safety property. Note that the ATP has no 
access to the program internals; hence, all pertinent infor- 
mation must be taken from the annotations, which become 
part of -the. VCs.- For full functional verification, annotations 
axe thus usually very detailed and, consequently, annotation 
inference remains intractable for this case. For safety cer- 
tification, on the other hand, the Hoare-rules have already 
rri«re_iiiternai_structure and the safety predicates are regu- 
lar and relatively small, so that the required annotations are 
a. bt simpler. In addition, the targeted safety property and 
policy are known at annotation inference time, which elim- 
inates the need for any logical reasoning in the style of the 
early inference approaches [24]: 



3 A Worked Example 

Figure 3(a) shows a simple example program that initial- 
izes two vectors A and B of size N with given but irrelevant 
values at and b (cf. lines 2.1-2.n and 3.1-3.2, resp.) and 
then computes and returns the sums s and t of their respec- 
tive elements as well as their dot-product d. It is derived 
from and representative of the code generated by AUTO Fil- 
ter; in particular it shows the same overall structure — -a se- 
ries of variable definitions followed by a loop with variable 
uses. AUTOFlXTER's target language is a simple imperative 
language with basic control constructs (i.e., if and for) and 
numeric scalars and arrays as the only datatypes. However, 
the language also supports domain-specific operations on 
entire vectors and matrices like matrix multiplication or as- 
signment, although these are not used in the example shown 
in Figure 3. 

Intuitively, the certification of initialization safety re- 
quires that the logical annotations entail at each use of a 
variable x that the corresponding shadow variable x Wl has 
-the -value-JWl— In-particular^ we need an invari ant forjthe 
loop at line 5.1 that ensures this for s, t, and d, as well as 
for the entire arrays A and B. 

The first step of the inference algorithm is to scan the 
program for relevant variables; for initialization safety all 
variables that are used on the right-hand side of assignments 
(more precisely, in rwzr-positions) are relevant but here we 
will restrict our attention to the two array variables .A and B, 
starting with B which is used inflines 5.3 and 5.4: Both uses 
are abstracted- mto-toe(rB-)v-ef:-Figure-3(-b)-^Tie--algorithin. . 
then follows all control flow paths backwards from the uses 
until it encounters either a cycle or a definition forme van- - 
able. Paths that do not end ; in a definition are discarded and 
the remaining paths are traversed node by node, while the 



1.1 COESt N: = 71; 


Const N : 


= 71; 


const N : = n ; Mod: ; 




const N : = n ; 


1.2 var i, s, t,d; 


var i , s 


,t,d; 


var i , s , t , d ; 




var i , s , t , d ,- 


1.3 varA[l:N] ,B[1 


:N]-?arA[l 


:N] ,B[1 


:N]\'arA[l:N] ,B[1 :N] ; 




varA[l:N] ,B[1:N] ; 


2.1 A[l] : = ai; 


A[l] : = 


ai; 


A[l] : = a i; . def(A[l 


■■N]); 


A[l] :=ai; 


l.n A [n] : = a n ; 


A[n] : = 


On,' 


A[n] : = a n ; 




A [n] : = a„ ; 

post Vj € { 1 : n} ■ Am. [ j] = INIT 


3.1 fori:=ltoNdo 


deffBll 


:N]); 


for i .- =1 to N barrier; 
inv Vj e {1 : i - 1} ■ B Mt [j] = INIT 
do 




fori:=ltoN 

inv Vj € {1 : n] ■ A,,, [j] - INIT 
A Vj € {1 :i - l}-B Mt [j] =INIT do 


3.2 B[i]:=6; 






B[i] : = 6; 
post Vj € {1 : N} ■ B ini ,[j} = INIT 




B[i] : = 6; 
post Vj €{ 1 : n} ■ A inil \j] = INIT 












A Vj £ { 1 : N] ■ B Mt [j] = INIT 


4.1 fc>:=0; 


a : - ; 




s : -u , yit/cA. , 




S-. - S-, 


4.2 t:=0; 


t:=0; 




t : =0 ; 




t:=0; 


4.3 d:=0; 


d:=0; 




d:=0; 




d — O;'"" 


5.1 for i : =1 toMdo 


for i :=l toNdo 


fori:=ltoN fori:=: 


I to N do 


fori :=1 toN 



inv Vj e { 1 : N} ■ B ink [j] = INIT 
do 



5.2 
5.3 
5.4 



S: 


= S+A[i] ; t:=t+A[i] ; 


S:=S+A[i] ; 


use (A) ; 


t : 


=t+B [i] ; use(B); 


t:=t+B[i] ; 


block ; 


d: 


=d+A[i]*B[i] ; use(B); 


d:=d+A[i] *B[i] ; 


use(A) ; 


etu 


irn s , t , d ; return s , t , d ; 


return s , t , d ; 


6Zocfc ; 



inv Vj e {1 : n} -A^ti] = INIT 
AVj€{l:N}-B ia «\j)=imT 
A s iniI = i ini , = (4 it = INIT do 
s :=s+A[i] ; 
t:=t+B[i] ; 
d:=d+A[i]*B[i] ; 

post Si„i, = £ in i. = di„i, = INIT 

return s , t , d ; 



(a) (b) (c) (d) (e) 

Figure 3. (a) Original program (b) Abstraction for B (c) Annotations for B (d) Abstraction for A (using 
Woc£-patterns) (e) Fully annotated program. 



annotations are added as required. 

Here, the only assignment to B is in line 3.2; howev- 
er, this is not the entire definition — the algorithm needs 
to identify the for-loop (lines 3.1-3.2) as the definition for 
the entire array B and abstract it into the definition node 
def(B [1 :N] ). The path search then starts at line 5.4 and 
goes straight back up to the for-loop at line 5.1, where it 
splits. One branch comes in from the bottom of the loop- 
body but this mimediately_ leads to a cycle and js_ therefore 
discarded. The other branch continues through lines 4.1- 
4.3 and terminates at the definition node at line 3.1. Since 
all branches have been exhausted,, there is only one path 
along which annotations: need to be added. The annotation 
process startswith the use and proceeds towards the def- 
inition terminating the path. The form of all annotations 
is fully determined by the known syntactic structure of the 
definition and by the safety property. Since the definition 
is-aIoop,Jn-tlTis^case,_it.rieeds_a_lQopJmi?ariant,js_j^eJQ.as^ 
a postcondition. Since the safety property is initialization 
safety, both invariant and postcondition need to formalize 
that the shadow variable B Ml corresponding to the current 
array variable B records the value init for the already ini- 



tialized entries. Note that the different upper bounds for 
the quantifiers can both be constructed from the loop. The 
postcondition is then pulled along the remaining path, i.e., 
added to all nodes that require it. Every node needs to be in- 
spected, but in this case only the for-loop at line 5.1 requires 
an invariant. Figure 3(c) shows the result of this pass. 

The next pass (cf. Figure 3(d)) adds the annotations for 
A. As before, its two uses in lines 5.2 and 5.4 are abstract- 
ed. A is initialized using a different idiom — a sequence of 
assignments* cf. lines 2.1-2.n— but this is again collapsed 
into a <ief -node; here, the initialized range is taken from the 
first and last assignment, respectively. The program is then 
collapsed further by the introduction of barrier- and block- 
nodes. These represent areas that do not need to be explored 
because they cannot contain relevant definitions, thus sub- 
stantially reducing the number of paths. However, the bar- 
rier-node s must b e re-expanded during the pat h traversal 
phase because they require annotations (cf. line 3.1) while 
block-nodes remain opaque. Except for this special han- 
dling, the algorithm proceeds as before, and Figure 3(e) 
shows the fully annotated example program. 



4 Inference Algorithm 

The previous section shows that the set of idiomatic cod- 
ing patterns which are used is the key knowledge that drives 
the annotation construction. However, this is not a gener- 
al program understanding problem: we are not concerned 
with identifying general-purpose coding patterns and clich- 
es [21] but only the relevant definitions and uses. These are 
specific to the given safety property, but the algorithm re- 
mains the same for each policy. In the case of initialization 
safety, the definitions are the different initialization blocks 
as shown in Figure 1, while the uses are statements which 
read a variable (i.e., contain an rvar). 



global SP: Property ; 

P -.AST; 
prov annjprog ( ) = 
var patterns : list Pattern,- 

var : Id ,- 

uses : list Position,- 

use . : Position; 

Cfg : CFG; 

path : Path 
begin 
patterns : = get_pattems (SP) ,- 
foreach (var, uses) in compute_hotvars ( ) do 
cfg := compute_cfg (patterns , var) ,- 
foreach use in uses do 
foreach path in compute_paths (cfg, use) do 
ann_path(path) ,- 
end 



The aim of the inference algorithm is to "get information 
from definitions to the uses", i.e., to annotate the program 
in such a way that the VCG will have the necessary infor- 
mation to show the program safe as it works its way back 
through the program. For each variable, the algorithm first 
computes each control flow path back from a use to a defini- 
tion and then traverses the paths, annotating the definitions 
and all intermediate nodes that otherwise constitute barriers 
to the information flow. The following subsections describe 
the various concepts and components. 

As in the certifiable code generation approach, we still 
split the certification problem into two phases— -first, we 
infer the logical annotations required to prove the code 
safe; second, we apply the standard machinery (i.e., VCG 
and ATP) to prove that the code complies with the anno- 
tations. As consequence of splitting annotation inference 
from checking annotation compliance we do not need to 
carry out any logical analysis during annotation. Moreover, 
the inference algorithm remains an untrusted component in 
the sense of the PCC model. 

4.1 Top-level Algorithm Structure 

The top-level structure of the algorithm (cf . Figure 4) 
closely follows the outline above. The safety property SP 
and the abstract syntax tree of the program P are used by all 
ranctions-andgivenas-global variablesT-Theoverall-Tesult-is 
returned by side-effects on P. ann_prog first accesses the 
property-specific patterns for definitions, uses and barriers. 
It then further reduces the inference efforts by limiting the 
analysis to certain program hot spots which are determined 
by the so-called "hot variables" described in the next sec- 
tion. 

4.2 Hot Variable Identification 

Proving a program safe requires annotations at the points 
where the VCG needs essential information about the def- 
inition of certain key variables. To see why some uses of 
variables are more critical than others, consider how a VCG 



Figure 4. Top-level Algorithm 

processes a program to generate VCs. The VCG works back 
through the program, gradually constructing a WPC and 
generating safety obligations whenever required by the use 
of a variable. The safety obligations will ultimately be dis- 
charged in the context of safety substitutions that accumu- 
late earlier in the program. If something is missing from that 
context, it must be supplemented by an annotation. There- 
fore, to figure out which annotations are required, we need 
to know at which points variables are used with "missing" 
information: we need a notion of availability. 

Informally, we say that a variable is available at some 
point in a program (wrt. a safety property) if it is within 
reach of its definition. For. example, immediately after a 
scalar assignment, the assigned variable is available but it 
becomes unavailable if there is an intervening loop. We say 
that a variable use is hot if it unavailable, and call a variable 
a "hot variable" (hotvar, for short) if at least one of its uses 
is hot. 

The algorithm can then pass through the program before 
the annotation phase, and collect hotvars and uses r since 
these are the only variables for which it needs to construct 
annotations: Limiting the analysis in this way is a crucial 
optimization-to cut down- the^number of graphs to be~eon- 
structed (cf. Section A A). .-■.-■ 

The function compute ihotvars maintains, a list of. 
available variables, initially set to empty, and scans forward 
through the program, deciding for each statement (and the 
given property) how it affects the availability of the vari- 
ables. For example, we assume that scalar assignments 
add to the available variables, but array assignments do not: 
because arrays are typically accessed indirectly usingloops 
and variable Indices, aTTuses should be treated ashot For" 
each statement that matches' the policy-specific use pattern', 
the algorithm also checks if the used variable is available;^ 
it is not, that use is tagged as being hot. • < 

Note that the hotvars are computed before the pattern 



P ::= 



X 




xeX 


/(Pi,-- 


■,Pn) 


/eS 


- 1 p ? 1 


P* | P + 




Pi II Pa 


1 Pi ; P 2 




Pi 6 P 2 


|Pi^P 2 





Figure 5. Pattern Grammar 

analysis, and in order to minimize the work in that and sub- 
sequent stages. The hot variables are therefore approximat- 
ed conservatively, i.e., we err on the side of designating uses 



(and coulcTeven treat all uses) as "Rot! 

4.3 Patterns and Pattern Matching 

The algorithm uses patterns to capture the idiomatic code 
structures and pattern matching to find the corresponding 
code locations. Each pattern specifies a class of fragments 
that are treated similarly by the algorithm, e.g., because they 
require a similar annotation. 

The pattern language is essentially a tree-based regular 
expression language similar to XML-based languages like 
XPath [3]; Figure 5 shows its grammar. The language sup- 
ports matching of tree literals /(Pi, . . . P„) (if the signature 
£ is given by the programming language to be analyzed, we 
will also use its concrete syntax to formulate example pat- 
terns), wildcards (_) and the usual regular operators for op- 
tional (?), list (*) and non-empty list (+) patterns, as well as 
alternation ( 1 1 ) and concatenation ( ; ) operators. It also sup- 
ports matching at arbitrary subterm positions (i.e., P x 6 P 2 
matches all terms that match P 2 and have at last one subterm 
that matches Pi; similarly, Pi £ P 2 matches all terms that 
match P 2 and have no subterm that matches Pi). Matching 
arbitrarily nested terms of the form /(• - • f(x) ■ ■ •)) is not 
required for our purposes. 

However, the main difference to XPath and similar lan- 
guages is that we use meta- variable patterns x to introduce 
alimitMT!e^ee~ofc0n^ 

uninstantiated meta- variable matches any term but, unlike a 
wildcard, it becomes instantiated with the matched term and 
thus subsequently only in other instances of the instantiat- 
ed pattern. For example, the pattern (_ [._]. :.= _)+ matches 
the entire statement list A [1] :=1;A[2] :=2,-B[l] :=l 
while'the pattern' (x [-_-] : = _)+ matches, after the instanti- 
ation of x. with A on the first statement, only the follow- 
in g seco nd assignment to A but not the final assignment to 
B. Further context-dependencies are introducecfby multiple 
occurrences of me same meta- variable in. a pattern. Hence, 
the pattern for x := _ to _inv_.do_[a:,a;] :- _ can be used 
to identify loops that access only the diagonal elements of 
any matrix. - . -., :, 



The match procedure traverses terms first top-down and 
then left-to-right over the direct subterms. Meta-variables 
are instantiated eagerly (i.e., as close to the root as possi- 
ble) but instantiations are undone if the enclosing pattern 
fails later on. List patterns follow the usual "longest match" 
strategy used in almost all traditional regular expression 
matchers. The match procedure returns as result a set of 
{Position x IV x Substitution)-tiiples where the first two ar- 
guments are the root position and length of the match of the 
top-level pattern. 

4.4 Abstracted Control Flow Graphs 



The algorithm follows the control flow paths from vari- 
able use nodes backwards to all corresponding definitions 
and annotates the statements along these paths as required 
(see the next two sections for details). However, it does not 
traverse the usual control flow graphs (CFGs) but abstracted 
versions, in which entire code fragments matching specific 
patterns are collapsed into individual nodes. Since the pat- 
terns can depend on the variables, separate abstracted CFGs 
must be constructed for each given hotvar. The construc- 
tion is based on a straightforward syntax-directed algorithm 
as for example described in [14]. 1 The only variation is 
that the algorithm first matches the program against the dif- 
ferent patterns, using the algorithm described in the section 
above, and in the case of a match constructs a single node of 
the class corresponding to the successful pattern, rather than 
using the standard construction and recursively descending 
into the statements subterms.- 

In addition to the syntactic classes representing the dif- 
ferent statement types of the programming language, the ab- 
stracted CFG can thus contain nodes of several different pat- 
tern classes. The algorithm requires use- and def '-nodes and 
uses barrier-, barrier-block- and Mocfc-nodes as optimiza- 
tions. All of these represent code chunks that the algorithm 
regards as opaque (to different degrees) because they con- 
tain no definition for the given variable. They can therefore 
be treated as atomic nodes for the purpose of path search, 
which -dFasti«all-y-FeduGes-the-number-.of paths-thatneed. be. 
explored. barrier-nodes represent any statements that re- 
quire annotations, i.e., principally loops. They must there- 
fore be re-expanded and traversed during the annbtation of 
the algorithm. In contrast, block-nodes are completely irrel- 
evant to the hotvar because they neither require annotations 
(i.e., contain no barriers) nor contribute to annotations (i.e., 
contain no occurrence of the hotvar in an Zvar-position). 
They can thus also remain atomic during the annotation 
phase, i.e., are not entered on path traversal. Flocks are typ- 



1 Since the generators only produce well-structured programs, a syntax- 
directed graph construction is sufficient. However, if necessary, we could 
replace the graph construction algorithm by a more general version that 
can handle ill-structured programs.. 



ically loop-free sequences of assignments and (nested) con- 
ditionals, barrier-blocks constitute a further optimization 
by combining the other two concepts: they are essentially 
barriers wrapped into larger blocks. Hence, they must be 
re-expanded during annotation, like normal barrier-nodes. 
The algorithm must further distinguish between reaching a 
(barrier) block from behind and from within. Coming from 
behind, it can treat the block opaquely, as described above. 
Coming from within (i.e., starting from the initial-use), the 
algorithm must ignore the block label, and regard the node 
as the underlying statement. This means it has to keep track 
of the previous location as it navigates along paths. 



proc annjpath (HotVar, Path, PrevLoc, Post, UseLoc) : 
case Path of 
[] -> done 

Node: :NodeList -> 
if node_yisible (NodeList) or NodeList = [] then 

done 
else 
Loc := get_node_location(Node) ,- 
NextNode := head (NodeList) ; 
NextLoc := get_node_location (NextNode) ; 
if is_annotated(Loc, Post, DseLoc, HotVar) then 

skip 
else 
if node_is_barrier_or_opaque (Node) then 
if within (PrevLoc, Loc) then 
if node_is_loop (Node) then 
if within (NextLoc, Loc) then 



4.5 Annotation of Paths 

For each use of a hotvar, the path computation in the pre- 
vious section returns a list of paths to putative definitions: 
although they have been identified by successful matches, 
there is no way to tell at this stage which, if any, of the def- 
initions are relevant. In fact, it may be that several separate 
definitions are needed to fully define a variable for a single 
use. In a sense, the paths are untrusted and their correct- 
ness is established by annotating all barriers between the 
uses and definitions. Since this must take control flow into 
account, the current annotation is computed as the weakest 
precondition of the previous annotation. 

Paths are then annotated in two stages. First, unless it has 
already been done (during a previous path), the definition at 
the end of the path is annotated, and the current annotation 
is set to its postcondition (cf. Section 4.6). If the use is 
contained within the definition then the path does not need 
to be continued because the definition will have been fully 
annotated "internally"; otherwise, we go on to the rest of 
the path. 

The path annotation (Figure 6) works back along the path 
from a use to a definition, computing weakest preconditions 
along the way, and annotating loops and barriers as appro- 
priate. Both the computation of preconditions and the in- 
sertion of annotations are done node by node rather than 
statement by -statement. 

At each point, we know the current weakest precondi- 
tion, the previous location, the original use location (i.e., the 
start of the current path) and the hotvar. The previous loca- 
tion is needed to compute the precondition, and the hotvar 
and use location are used to prevent duplicate annotations. 

It first checks whether the current node is visible 2 from 
the definition. If so, then we are finished since the VCG will 
have all the information it needs from this point onwards. 
Likewise, if this Is the last node (that is, the one before the 
def), then we're finished annotating. If not, we look to see 
if this node has already been annotated. 



ann_loop_node (Node, Post, UseLoc, HotVar) 
else 

arin_barrier_node(Node, Post, UseLoc, HotVar) 
else 
skip 
else ann_barrier_node (Node , Post, DseLoc, HotVar) 
else 
if node_is_loop(Node) then 
if within(NextLoc, Loc) then 

ann_loop_node(Node, Post, DseLoc, HotVar) 
else 
ann_barrier_node (Node , Post, DseLoc, HotVar) 
else skip; 
Pre := nodejprecondit ion (PrevLoc, Post, Node) ,• 
ann_path (HotVar, NodeList, Loc, Pre, DseLoc) 



2 A node is visible from another node if it comes after it in a path 
through the CFG and there are no barriers between the nodes. 



Figure 6. Path Annotation Algorithm 



If so, we skip to the next node. If not, we distinguish 
several cases, depending on whether it's a loop or a barrier 
or an opaque node (blocks and barrier blocks), whether the 
previous node is within the current node, and whether the 
next node is within the current node. Once we've dealt with 
a node, the weakest precondition of that node is calculated, 
and we move on to the next node. 

The WPC of a node is somewhat subtle and depends on 
whether of hot it is a barrier of opaque, the statement it- 
self (for basic blocks), and the previous location. In many 
cases the WPC does not change. For those cases where it 
does, the new WPC needs to be computed by looking at 
the statement We distinguish atomic and compound state- 
ments. Compound statements (series, if, for, while) can on- 
ly changethe WPC if the previous location is after a loop, 
in which case WPC(P, C) = end(C) => P, where P is the 
incoming postcondition, C is the statement andend(C) is 
the end condition for the loop, C. For while 6 do c, this is 
-i b, and for for i -.= e\ to e2 do c, this is i > e?. In other 
words, the WPC says "if the loop has terminated then P". 
For atomic statements we compute the weakest precondi- 
tion by calling the VCG and simplifying the result ■ 



4.6 Annotation of Nodes 

The path traversal described above calls the actual anno- 
tation routines when it needs to annotate a node. For an- 
notation, we distinguish three classes of nodes: definitions, 
barriers, and loops (i.e., basic nodes which are loops). 

The most important (and interesting) class is the defini- 
tions. This is really the core of the whole system, and where 
the annotation knowledge is represented in the form of an- 
notation schemas, which take a match (identifying the pat- 
tern and location), and use meta-programming to construct 
and insert the annotations. 

For example, each initialization block from Figure 1 is 
~ (lefmecTby a separate pattern ancThas a corresponding an- " 
notation schema. In each case, a final outer postcondition 
Vi" : 1 < I < n.VJ.l < J < m.X mil (L J)'= init (where 
X is the matrix) is inserted, while 1(b) and 1(c)' also get an 
inner postcondition, as well as inner and outer invariants. 

Note that even after a pattern has been successfully 
matched, an annotation schema might still fail its precon- 
ditions. For example, the binary assignment schema (Fig- 
ure 1(a)) simply matches against a sequence of assignments, 
but the schema further requires that the indices of the first 
and last assignments are the low and the high, respectively. 

The annotation schemas can handle more complicated 
examples than the "pure" definitions directly reflected by 
the patterns. A common situation is for a barrier to appear 
within a definition. Consider the following simple example: 

1 for i : =1 to N do 

2 a[i] :=0; 

3 for j :=1 toNdo... 

The definition pattern is a single nested initialization, but 
the for-loop at (3) means that an extra postcondition, a init [i] 
= init, is needed on (2) to push the initialization through 
the body. However, if the for-banier is before the assign- 
ment no extra annotation is needed. In general, the schemas 
are able to deal with such cases and maintain the "internal" 
flow of information within a definition. 

5 Experiences 

We have implemented the generic inference algorithm in 
about 4000 lines of documented Prolog code and instanti- 
ated it to certify initialization safety for code generated by 
AutoB AYES and AutoFilter. The "declarative content" 
was surprisingly small: it only required instantiations of the 
pattern library but no changes to the algorithm itself. 

5.1 AutoFilter 

For AutoFilter, the definitions are given by the id- 
ioms in Figure 1 (both for vectors and matrices), along with 



the direct vector/matrix assignment operation 
captured by the following pattern: 



This is 



def A p(x) :•:= x : =_ || X: : =_ 

II (xU :=_)+ II (£[.,_] :=.) + 

II fori :=_ to _ doxli] :=_ 
II fori :=_ to _ do 

for j :=_ to _ do x[i,j] :=_ 
II fori :=_ to _ do 

for j : =_ to _ do 
if _ thenx[i,j] :=_elsex[i,j] :=_ 

Like all patterns here, this is parametrized over a hotvar 
x, so ft"H - ^^p(iE) - i!ritar^ttenrx}^^ 
barrierix) (see below) is a barrier on a path from a use of 
x to its definition, and so on. Note that i and j are "free" 
meta- variables that get instantiated by the actual loop index 
variables. The patterns can also contain "junk", i.e., arbi- 
trary code that can be interspersed with the match. This is 
easily defined by a junk operator omitted here. 

Barriers are defined as for-loops without any occurrence 
of the hotvar. Loops with the hotvar are then simply treat- 
ed by the normal CFG-routines, i.e., not collapsed. Finally, 
blocks are conditionals whose branches are deemed "irrele- 
vant", which means they have no occurrence of a barrier or 
hotvar. 

barrier^p(x) ::= x t (for _ to _ do _) 

block^jp(x) ::= if (x £)- thenirr(x) else irr(x) 
II for _ to _ do irr(x) 

where irr{x) = (x II barrier ^p{x)) £ - is an auxiliary 
pattern blocking all occurrences of the hotvar or a barrier. 
We omit the easy pattern for uses. 

5.2 AutoB ayes . 

AutoBayes has similar patterns to AutoFilter, but 
Joes not need the : : = -pattern since it does not g enerate 
matrix operations, nor the assignment sequence pattern. It 
has two additional language constructs, abort, which ap- 
pears in. the definition pattern, and while-loops, which can 
form additional barriers. Blocks and uses are the same as 
for AutoFilter. 



de fAB( x ) 



barrier £g{x) :: 



fori :=_ to _ doxli] :=_ 
fori :=. to _ do 
_ Jor j_i = - to _ doxTi, j'J_:_ = 
fori :=_ to _ do 
if _ then abort else xli,j] 

x £ (for _ to _ do _ ) 
x i (while _ do _ ) 



Spec. \P\ 


\A\ N T gen T ATP 


\A\ N T M T ATF 


dsl 235 


439 22/ - 16 41 


494 19/- 22 46 


iss 523 


441 27/ - 29 52 


547 24/- 46 49 


segm 182 
178 


1278 105/ 6 22 628 
1332 114/10 24 903 


1584 109/- 54 202 
1643 108/5 54 556 



6 Related Work 



Table 1. Generated vs. Inferred Annotations 



5.3 Results 



Table 1 compares the results acfiievedTby the new algo- 
rithm to those previously achieved in the certifiable code 
generation approach. The first two examples are AUTOFlL- 
TER specifications, dsl is taken from the attitude control 
system of NASA's Deep Space One mission [26]. iss 
specifies a component in a simulation environment for the 
Space Shuttle docking procedure at the International Space 
Station, segm describes an image segmentation problem 
for planetary nebula images taken by the Hubble Space 
Telescope. For this, AutoBayes synthesizes two differ- 
ent versions of an iterative numerical clustering algorithm. 
For each example, the table lists the size of the generated 
program, and then, for each approach, the sizes of the gen- 
erated resp. inferred annotations, the numbers of generated 
and failed safety obligations, resp., as well as the runtimes 
and proof times in seconds. 

For the two AUTOFlLTER examples, both techniques 
prove to be very similar. The inferred annotations are slight- 
ly larger (by 15-25%) than the generated ones but, due to 
simplifications, they induce fewer VCs. For both approach- 
es, the programs are certifiable fully automatically: all VCs 
are proven by the ATP. For the AUTOBAYES example, the 
situation is more complicated. Here, annotation generation 
has not kept up with ongoing development and the anno- 
tations are insufficient to prove the programs safe — even 
though they are. With the patterns described above, anno- 
tation-inference can, m contrast, certify the first program 
but it too remains too weak for the second program, as a 
required code pattern is still missing. In both cases, the in- 
ferred annotations are again slightly larger, with fewer VCs 
induced. 

Since it needs to build and traverse the CFGs, the infer- 
ence approach is (substantially) slower thari the generation 
approach, which only needs to expand templates. Howev- 
§&. fhejntroductiqn of block- and terrier-nodes cuts down 
the size of the CFGs dramatically, and we expect further 
speed-up from an optimized implementation. Moreover, the 
limiting factors overall are the proof times which are com- 
parable (modulo failed VCs) in all cases, indicating that the 
inference does not introduce new complexity for the ATP. 



Logical annotations were recognized early on as one of 
the bottlenecks in program verification. Wegbreit [24] com- 
plained that "completely specifying the predicates on loops 
is tedious, error prone and redundant", and claimed that 
"loop predicates can be derived mechanically". Like oth- 
er early work [9, 16], his approach is based on predicate 
propagation. Such methods use inference rules similar to 
a strongest postcondition calculus to push an initial logical 
anno®tioTrfOTwaxd"through^e^rogramT~Lxi-ops-are-h'aiK- 
died by a combination of different heuristics like weaken- 
ing or strengthening and loop unrolling, until a fixpoint is 
achieved. However, these methods still need an initial an- 
notation, and unlike our approach, the loop handling still 
induces a search space at inference time. Moreover, the con- 
structed annotations are often only candidate invariants and 
need to be validated (or refuted) during inference, because 
they increase the search space. 

Abstract interpretation has been used to infer annotations 
in separation logic for pointer programs [17] although the 
techniques required there are fairly specialized and elabo- 
rate compared to our patterns. The Coverity static analyzer 
[1] can be customized by macros that are simple versions of 
our patterns. 

Finally, generate-and-test methods have been applied to 
our problem. Here, the generator phase uses a fixed pat- 
tern catalogue to construct candidate annotations while the 
test phase tries to validate (or refute) them, using dynamic 
or static methods. Daikon [10] is the best-known dynam- 
ic annotation inference tool in this category. Its tester ac- 
cepts all candidates that hold without falsification but with 
a sufficient degree of support over the test suite. In order 
to verify the candidates, Daikon has also been combined 
[20] with the ESC/Java static checker [13]. In some cas- 
es,Tois"c6rnbinatioh even resTaTtedlnMrsaTetjrpfOofrCwrt. 
the safety policy supported by ESC/Java). In general, how- 
ever, dynamic annotation generation techniques remain in- 
complete because they rely on a test suite to generate the 
candidates and can thus miss annotations on paths that are 
not executed often enough (or not at all). Houdini [12] is a 
static generate-and-test tool that uses ESC/Java to statical- 
ly refute invalid candidates. Since ESC/Java is a modular 
checker, Houdini has to start with a candidate set for the 
entire program and then iterate until a fixpoint is reached. 
This increases the computational effort required, and in or- 
der to keep the approach tractable, the pattern catalogue is 
deliberately kept small. Hence, Houdini is incomplete, and 
acts more as a debuggingtool than as a certification tool. 



7 Conclusions and Future Work 

The certification system based on annotation inference 
as described here is much more flexible and extensible than 
our previous certification architecture [6]. Over time, ex- 
tensions and modifications to our code generators had led 
to a situation of "entropic decay" where the generated an- 
notations had not kept pace with the generated code. The 
new inference mechanism was able to automatically certify 
the same programs as the original system, as well as some 
subsequent extensions. However, as Table 1 shows, the re- 
construction is not yet complete, and we continue to extend 
the new system. These system extensions req uire less ef- 
fort than before since the patterns and annotation schemas 
are expressed declaratively and in one place, in contrast to 
the previous decentralized architecture where certification 
information is distributed throughout the code generator. 

We have implemented several optimizations which cut 
down on redundant annotations. This is important since 
the same annotations can arise on multiple paths. Further- 
more, many computational optimizations could be achieved 
by merging several of the phases. 

Our approach offers a general framework for augment- 
ing code generators with a certification component, and we 
have started a project to apply it to Math Works Real-Time 
Workshop [2]. Our techniques could also be adapted to oth- 
er annotation languages. 

There is a strong interaction between the VCG and the 
annotations. It is possible to modify the VCG so that it does 
some analysis and requires less annotations. This would, 
however, mean that a greater part of the certification system 
must be trusted. Nevertheless, we would like have a "safe- 
ty dial" whereby users can trade off trustedness with speed 
(which depends, inter alia, on the number of annotations 
which must be checked). Further empirical studies will be 
required to determine the most effective balance. 

References 

[17 www . cover ity . com. 

[2] www . mathworks . com/product s / rtw/ 

[3] XML Path Language (XPath) Version 1.0, 1999. 
www . w3 . org/TR/xpath. 

[4] D. Abrahams and A. Gurtovoy. C++ Template Metapro- 
gramming. Addison- Wesley, 2005. 

[5] E. Denney and B. Fischer. Correctness of source-level safe- 
ty policies. In FM'03, LNCS 2805, pp. 894-913. Springer, 
2003. 

[6] E. Denney and B. Fischer. Certifiable program generation. 
.In GPCE'05, LNCS 3676, pp. 17-28. Springer, 2005. 

[7] E. Denney, B. Fischer, and J. Schumann. Adding assurance 
to automatically generated code. In 8th Intl. Symp. High- 



Assurance Systems Engineering, pp. 297-299. IEEE Press, 
2004. 
[8] E. Denney, B. Fischer, and J. Schumann. An empirical evalu- 
ation of automated theorem provers in software certification. 
Intl. J. of AI Tools, 15(1):81-107, 2006. 
[9] N. Dershowitz and Z. Manna. Inference rules for program 
annotation. ICSE-3, pp. 158-167. IEEE Press, 1978. 

[10] M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin. 
Dynamically discovering likely program invariants to sup- 
port program evolution. IEEE TSE, 27(2): 1-25, 2001. 

[11] B. Fischer and J. Schumann. AutoBayes: A system for gen- 
erating data analysis programs from statistical models. J. 
Functional Programming, 13(3):483-508, 2003. 
^2]~(^Managan - and-iKr-Rr-i*lr- fceino; — EEoudini7-an-annetatisri- 
assistant for ESC/Java. In FME'01, LNCS 2021, pp. 500- 
517. Springer, 2001. 

C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. B. 
Saxe, and R. Stata. Extended static checking for Java. In 
PLDI'02, pp. 234-245. ACM Press, 2002. 
MJ. Harrold and G. Rothermel. .Syntax-directed construc- 
tion of program dependence graphs. Technical Report OSU- 
CISRC-5/96-TR32, The Ohio State University, 1996. 
C. A. R. Hoare. The verifying compiler: A grand challenge 
for computing research. JACM, 50(l):63-69, 2003. 
S. Katz and Z. Manna. Logical analysis of programs. CACM, 
19(4): 188-206, 1976. 

O. Lee, H. Yang, and K. Yi. Automatic Verification of 
Pointer Programs Using Grammar-Based Shape Analysis. In 
ESOP'05, LNCS 3444, pp. 124-240. Springer, 2005. 
J. C. Mitchell. Foundations for Programming Languages. 
The MIT Press, 1996. 

G. C: Necula and P. Lee. The design and implementation of 
a certifying compiler. In PLDI'98, pp. 333-344. ACM Press, 
1998. 

J. W. Nimmer and M. D. Emst. Static verification of dynam- 
ically detected invariants: Integrating Daikon and ESC/Java. 
In First Workshop on Runtime Verification, Elec. Notes in 
Theoretical Computer Science, 55(2). Elsevier, 2001. 

C. Rich and L. M. Wills. Recognizing a programs's descrip- 
tion: A graph-parsing approach. IEEE Software, 7(l):82-89, 
-1990. 

D. R. Smith. KIDS: A semi-automatic program development 
system. IEEE TSE, 16(9): 1024-1 043, 1990. 
M. Sfickel et al. Deductive composition of astronomical soft- 
ware from subroutine libraries, rn CADE-12, LNAI 814, pp. 
341-355. Springer, 1994. 



[13] 

[14] 

[15] 
[16] 
[17] 

[18] 
[19] 

[20] 

[21] 

[22] 
[23] 

t^4j 
[25] 

[26] 



B. Wegbreit. The synthesis of loop predicates. CACM, 
17(2): 102-1 12, 1974. 

M, Whalen, J. Schumann, and B. Fischer. Synthesizing cer- 
tified code. In FME'02, LNCS 2391, pp. 431=450-. Springer; 
2002. 

J. Whittle and J. Schumann. Automating the implementa- 
tion of Kalman filter algorithms. ACM Trans. Mathematical 
Software, 30(4):434~453, 2004. " 



10 



