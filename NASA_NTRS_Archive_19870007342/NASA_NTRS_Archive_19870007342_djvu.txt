N87-16775 


1986 



NASA/ASEE SUMMER FACULTY FELLOWSHIP PROGRAM 


MARSHALL SPACE FLIGHT CENTER 
THE UNIVERSITY OF ALABAMA 


COMPUTER-AIDED ANALYSIS FOR THE 
MECHANICS OF GRANULAR MATERIALS (MGM) EXPERIMENT 


Prepared by: 

Academic Rank: 

University and Department: 

NASA/MSFC : 

Laboratory : 

Division: 

Branch : 

MSFC Colleague: 

Date: 

Contract No . : 


Joey K. Parker, Ph.D. 

Assistant Professor 

University of Alabama 
Mechanical Engineering 
Department 


Systems Dynamics 
Atmospheric Sciences 
Fluid Dynamics 

Nicholas c. Costes, Ph.D. 

July 18, 1986 

NGT 01-002-099 

The University of Alabama 


XXXIII 


Computer-aided Analysis for the 
Mechanics of Granular Materials (MGM) Experiment 

by 


Joey K. Parker 

Assistant Professor of Mechanical Engineering 
University of Alabama 
Tuscaloosa, Alabama 


Abstract 

The Mechanics of Granular Materials program is planned 
to provide experimental determinations of the mechanics of 
granular materials under very low gravity conditions. The 
initial experiments will use small glass beads as the 
granular material, and a precise "tracking" of individual 
beads during the test is desired. Real-time video images of 
the experimental specimen were taken with a television 
camera, and subsequently digitized by a "frame grabber" 
installed in a microcomputer. Easily identified red 
"tracer" beads were randomly scattered throughout the test 
specimen. 


A . set of Pascal programs was written for processing and 
analyzing the digitized images. Filtering the image with 
Laplacian, dilation, and blurring filters then using a 
threshold function produced a binary (black on white) image 
which clearly identified the red beads. The centroids and 
areas for each bead were then determined. Analyzing a 
series of the images determined individual red bead 
displacements throughout the experiment. The system can 
provide displacement accuracies on the order of 0.5 to 1 
pixel if the image is taken directly from the video camera. 
Digitizing an image from a video cassette recorder 
introduces an additional repeatability error of 0.5 to l 
pixel. other programs were written to provide "hardcopy" 
prints of the digitized images on a dot-matrix printer. 


XXXIII-i 


Introduction 


Experimental determinations of the mechanics of granular 
materials, such as powders, soils, grains, etc., have been 
conducted for many years . In these experiments a 
cylindrical specimen of granular materials is usually 
confined by a uniform pressure. Since the experiments are 
conducted on the earth, the test specimens are also 
subjected to 1 g of acceleration (due to gravity) . Gravity 
induced body forces prevent the testing of specimens at low 
confining pressures of less than 1-2 psi since the 
specimen's weight dominates the system response. 
Determining the mechanics of granular materials at low 
confining pressures would significantly improve our 
understanding of many geotechnical engineering and 
geological phenomena, such as the behavior of soils during 
earthquakes, sand storms, and planetology. 

The Mechanics of Granular Materials Experiment is 
currently planned for Space Shuttle flight in the next few 
years. In a series of experiments a variety of granular 
materials (initially small spherical glass beads) will be 
tested in the near-zero g (microgravity) environment of the 
Shuttle's orbit. The absence of gravitational forces will 
allow very low confining pressures (0.25 to 1 psi) which are 
not possible terrestrially. 

One of the desired goals of the MGM experiments is to 
determine constitutive relationships between specimen 
loading and deformation. Determination of rigid body 
displacements of individual particles within the test 
specimen as a function of time would aid the development of 
these constitutive relationships. One proposed method for 
determining displacements of particles on the specimen 
surface is to record visual images of the system during a 
test. These visual images can come from either individual 
"still" camera pictures, or from continuous recording via 
movie or television cameras. When continuous recording is 
used a tremendous amount of data can be generated. A 
standard television camera generates images at the rate of 
30 per second, which results in over 200,000 images during a 
single 2 hour test. Clearly, some type of computer-aided 
analysis would benefit researchers by reducing the amount of 
effort required to determine particle displacements from the 
visual recordings of the experiment. 


XXXIIl-1 


Obi eotives 


The overall goal of this project was to develop 
computer-aided analysis techniques for analyzing visual 
images of the MGM experiments. Within this broad goal are 
many specific objectives, such as: 

1) determine if additional commercially prepared image 
processing software is necessary, 

2) develop a means for generating "hardcopy" images on a 
variety of printers. 


3) develop computer software for acquiring images of the 
experiment and determining particle locations in an 
individual image, 

4) develop computer software for identifying and 
"tracking" individual particle displacements between 
successive images, and 

5) test and evaluate the developed computer-aided 
analysis package with actual experimental systems. 


XXXIII-2 


Hardware & Equipment 


The computer vision system uses an Imaging Technology 
PCVision Frame Grabber plug-in board. The frame grabber is 
mounted in an IBM PC AT microcomputer equipped with a 6 MHz 
Intel 90286 microprocessor. 640K of random access memory 
(RAM) , and a 20 megabyte hard disk for permanent storage. 
The board digitizes a standard RS-170 television signal into 
a 512 by 512 pixel (picture element) matrix with a 
resolution of 8 bits (2Â® = 256 gray levels) . The PCVision 
Frame Grabber can digitize images at the l/30th of a second 
rate of the RS-170 standard, although permanent storage of 
the digital images on a hard disk requires several seconds. 

A JVC model BY-110 color television camera is used for 
viewing the experimental setup. A VCR (video cassette 
recorder) is also available for recording images throughout 
the experiment. The PCVision Frame Grabber can digitize 
either the signal directly from the television camera or 
from the VCR. 

The experimental setup used in this work consists of a 4 
inch diameter by 6 inch tall ''cylinder'' of 0.3 mm diameter 
blue glass beads constrained by a thin latex membrane. The 
cylinder of beads is placed inside a rigid "plexiglass" 
or "Lexan" pressure chamber cylinder of approximately 6 
inches inside diameter. The annular region between the bead 
specimen and the clear outer cylinder is filled with water, 
which is externally pressurized to maintain a constant 
confining pressure. 

Several red glass beads (of the same size and weight) 
are dispersed among the blue beads. Since there are fewer 
red beads, it is possible to identify and track individual 
red bead motions from frame to frame as the experiment 
progresses. The specimen is mounted in a standard triaxial 
soil mechanics testing frame where it is subjected to a 
uniform confining pressure, see Figure 1. During the 
experiment the specimen is strained at a constant rate of 
approximately 1 inch per hour to a final value of 
approximately 30% strain. Additional experimental 
arrangements (such as different size beads, other strain 
rates, etc.) are planned for the actual flight experiment. 


XXXIII-3 


Printer ( Hardcopy 1 Outputs 


Two commercial software packages ("ImagePro" and 
"ImageAction") are available from Imaging Technology for 
use with the PCVision Frame Grabber. These packages provide 
menu-driven software for acquiring and manipulating video 
images. Both "ImagePro" and "ImageAction" were useful in 
early stages of the project for generating image processing 
steps that were later developed into dedicated programs. 
The general purpose nature of these packages limits their 
usefulness for the specific, application oriented analyses 
required in this project. 

"ImagePro" provides a hardcopy (printer) output that 
"ImageAction" does not, although the quality of the printed 
pictures is extremely poor. However, digitized images 
stored by "ImagePro" are in a run- length-encoded form that 
is difficult to manipulate with other software. 
"ImageAction" stores the data in the form of consecutive 
rows (of 512 one byte pixels) with a small amount of 
preliminary information. The "ImageAction" storage format 
was used for all software developed in this project. This 
means that "ImageAction" can be used to generate images for 
subsequent processing and analysis, or that "ImageAction" 
can be used to display images generated by the processing 
and analysis programs. 

Pascal programs were written to provide hardcopy 
printouts of "ImageAction" digital images on both the Epson 
LQ-1500 (black and white) and ACT II (color) printers. The 
Epson printer simulates 8 shades of gray, while the ACT II 
displays 16 different colors. The PCVision Frame Grabber 
generates pixels with "brightness" values ranging from 0 
(dark) to 255 (white) . The printed gray shade (or color) 
for a particular pixel brightness is found by dividing the 
pixel value by 32 (Epson) or 16 (ACT II) and truncating the 
fractional part. The program for the Epson printer is named 
"Aspect.com" since it generates an almost exactly true 
aspect ratio (height to width ratio) for the printed image. 
The program for the ACT II color printer is appropriately 
named "Color_Pr.com" and it trims 56 columns from both sides 
of the image in order to have an almost true aspect ratio. 

Two other printer programs were written for the Epson 
LQ-1500 printer. The program "Squish.com" prints a picture 
that is 1/4 the size of the one printed by "Aspect.com". 
This program prints only every other row and column, i.e. 
pixels with both even row and column numbers, so some 
resolution is lost. All images presented in this report 
were printed with "Squish.com". Another program 
("Contur8.com") was developed for generating contour plots 
at 8 gray levels. 


XXXIII-4 


Image Processing 

With only one exception (an assembly language routine) 
all software for this computer-aided image analysis project 
was written in Borland International ' s Turbo Pascal 
language* Turbo Pascal provides a convenient programming 
environment with the program editor, compiler, and error 
message generator integrated into a single package. One of 
Turbo Pascal's basic storage elements is an individual byte, 
and a single digital image generates over 240,000 bytes of 
data. Therefore, a considerable savings in storage is 
provided over languages such as BASIC or FORTRAN which 
typically use two bytes for integer storage. The only other 
logical choice for a programming language would be "C", but 
the programming environment is not nearly as "user-friendly" 
as Turbo Pascal. 

The Pascal program for acquiring and processing the 
digital image into a usable form is called "Process". This 
program consists of a set of procedures (similar to 
subroutines in FORTRAN) for performing the required 
operations. The Pascal procedure for "grabbing" image 
frames from the TV camera (or VCR) is called "Snap". This 
procedure initializes the PCVision Frame Grabber board then 
"grabs" a single frame and places it in the PCVision memory. 
A procedure called "Store_Picture_in_Memory" stores the 
digitized picture in a 480 row by 512 column matrix of 1 
byte values (in the IBM PC AT memory) for easy manipulation 
by other procedures. Although the PCVision system digitizes 
512 rows, only the first 480 are displayed on the monitor, 
so the other 32 are not used by any of the image analysis 
programs or procedures. Another procedure called 
" Save_Picture_to_Disk" is used for storing the picture array 
in an "ImageAction" file format (which use the filename 
extension ".img"). 

In the original images the red beads display a 
noticeable diffraction pattern, which appear as the 
"cross-hatched" areas in Figure 2. Figure 2 represents the 
upper left quadrant (240 rows by 256 columns) of an image 
taken of an experimental specimen. Since the specimen is 
covered with a latex membrane, the red beads are somewhat 
difficult to see without image processing. Also, the 
PCVision system generates a black and white picture which 
would make it virtually impossible to distinguish red from 
blue beads without the diffraction patterns. Note that the 
left side of Figure 2 appears generally darker than the 
right side. The right side is near the center of the test 
specimen and a considerable amount of "glare" is present 
in this part of the image. 


XXXIII-5 


One of the basic image processing techniques used in 
this software involves convolving or filtering the digitized 
image with "operator masks" of various types. These 
operator masks are usually 3x3 or 5x5 matrices that are 
superimposed on each pixel of the original frame. Each 
value in the mask is multiplied by the pixel "under" it, and 
the sum of the 9 (or 25) multiplications becomes the pixel 
value at the center of the mask in the new, convolved image. 
As an example, consider the 4x5 digital "image" below along 
with the 3x3 Laplacian operator. 


5 

Image : 6 

4 
7 


7 10 4 3 

9 8 2 4 

5 7 12 

6 6 2 8 


-1 

Laplacian: -l 

-1 


-1 -1 

8 -1 

-1 -1 


If we apply the operator mask to the image only where the 
mask completely covers part of the image, then the first 
pixel to be convolved is the 9 in row 2, column 2. Applying 
the operator to this first pixel gives: 


New Value = (-1) (5) + (-1) (7) + (-1) (10) + <- Row 1 

(-1) (6) + (8) (9) + (-1) (8) + <- Row 2 

(-1) (4) + (-1) (5) + (-1) (7) <- Row 3 


or New Value =20. If we apply the Laplacian operator to 
all usable points in the original image, the resulting 
convolved image is 


Convolved Image: 


5 7 10 43 

6 20 19 -23 4 

4 -13 17 -31 2 

7 6 6 2 8 


Notice that the pixels on the perimeter of the image are 
unchanged. Each time a convolution operator is applied to 
an image two rows and two columns of pixels are "lost" since 
their data is no longer meaningful. 

The Laplacian convolution is the first to be applied to 
the video images since it enhances the visibility of the red 
beads while eliminating the blue beads. Figure 3 shows the 
image that results from convolving the Laplacian operator 
with the image in Figure 2 . The cross-hatched areas of 
Figure 2 are replaced by vertical bands of alternating light 
an dark areas. This step is extremely important since the 
Laplacian convolution produces essentially the same pattern 
for all red beads, regardless of where they occur in the 
original image. The red beads located in the right hand 
side of Figure 3 are in the "glare" region of Figure 2, yet 
the convolved appearances are similar. 


XXXIII-6 



The next image processing step involves removing the 
dark bands from the Laplaced image. The operator here is 
called a "dilation" mask and it operates somewhat 
differently than the convolution mask. The dilation mask 
shown below is applied by the procedure "Dilate" to all 
pixels in the current image: 

0 10 
Dilation mask: 111 

0 10 

If any of the pixels "under" a 1 of the mask are greater 
than a predetermined threshold (150 is the currently used 
value) , then the center pixel is replaced by the largest 
value in the image under a 1 in the mask. If all 
surrounding pixels are less than the predetermined 
threshold, then the center pixel is left unchanged. This 
operation has the effect of thickening the light regions 
(greater than 150) of the banded areas by essentially 
eliminating the dark bands. Figure 4 shows the results of 
applying the dilation mask to the image of Figure 3. Notice 
that Figure 4 is similar to Figure 3 except in the red bead 
regions where there now appears a white "spot". 

The next operation on the digital image is applying a 
"blurring" convolution mask (procedure "Blur") . This mask 
is a 5x5 array with the values: 

11111 
1 2 2 2 1 
Blur mask: 12121 

1 2 2 2 1 
11111 

The resulting value is divided by 33, which is the sum of 
all values in the blur mask. Blurring is essentially a 
smoothing or averaging operation that has two main effects 
on the dilated image. First, it reduces the effect of small 
spots of white (usually "noise") by spreading the pixel 
value over a larger area. Secondly, it smooths the edges of 
the red bead areas by averaging the dilated pixel values 
with surrounding darker areas. Figure 5 shows the image of 
Figure 4 after the blurring operation. 

The three image processing operations of Laplacian, 
dilation, and blurring are provided in the ImageAction 
software. However, the Pascal routines written for this 
project run from 30% to 50% faster than the equivalent 
ImageAction routines. Also, the ImageAction convolution 
mask routines have a small "bug" in them. The result of an 
ImageAction convolution is placed one pixel to the left of 
where it is supposed to be. After three convolutions the 


XXXIII-7 


entire image has been shifted to the left by three pixels. 
Images processed by the ImageAction routines should not be 
compared to other images for measurement purposes since this 
shifting has taken place. 


After the image has been blurred, a "thresholding" 
operation is applied. All pixel values greater than a 
threshold value (currently 150) are set to 0 (black) . All 
other pixel values are set to 254 (white) . The thresholding 
operation results in a binary image which clearly identifies 
the red beads as dark spots on a light background. The 
subroutine for thresholding is written in Microsoft assembly 
language for fast operation, but could be written in Pascal 
with only a small penalty in execution speed. 


The resulting binary image is then "segmented" into 
non-touching objects or "blobs" by a set of Pascal routines. 
Although humans can automatically determine which ones of 
the approximately 240,000 pixels form an individual object, 
a computer has no intrinsic way of doing this. An algorithm 
for grouping neighboring pixels into unique "blobs" was 
developed after several trials, and is implemented in the 
procedure "Segment". The essential steps of this algorithm 
are: 


1 > T-n ifV 

^ V.L< 


Â» 1 1 fÂ» A 




â %T JL. Al 1 j_ v 

\ a e a u kjuj u ) 


uu x ana scan 


2) 


3 ) 


4 ) 

5 ) 

6 ) 


7 ) 


the first row of the image from left to right 
searching for pixel values of 0 (dark) . 

If a value of 0 is found and its left-hand neighbor 
pixel value is a 254, then replace the current pixel 
value with the value of Next_Object and increment 
Next_0b j ect . 

If the left-hand neighbor is less than 254 (which 
indicates that it used to be a 0) , then replace the 
current pixel value with the value of its left-hand 
neighbor. 

Continue steps 2-3 until the first row is finished. 
Scan the next row looking for pixel values of 0. 

If a value of 0 is found and the left-hand neighbor 
is a 254, check (in succession) the pixel values in 
the row above that touch the current pixel (to the 
left, straight up, then to the right) . Replace the 
current pixel value with the first one of these that 
is not a 254. 

If a value of 0 is found and the left-hand neighbor 
is less than 254, then replace the current pixel 
value with the value of its left-hand neighbor. 
Check (in succession) the pixel values in the row 
above that touch the current pixel (to the left, 
straight up, then to the right) . If any of these are 
less that 254 and are different from the current 
pixel value, replace all instances of the different 
value with the current pixel value. 


XXXIII-8 



8) If a value of 0 is found and none of the surrounding 
pixel values are less than 254, then replace the 
current pixel value with the value of Next_Object and 
increment Next_Object. 

9) Continue steps 4-8 until finished with all rows. 

After this algorithm is run, each individual "blob" will be 
identified by a set of pixels with a unique value between 1 
and 253. All pixels with the same value belong to the same 
object. Note that no more than 253 "blobs" can be found by 
this method (actually quite a few less) . 

Now that individual "blobs" have been identified, 
parameters such as area, "roundness", and height to width 
ratio can be calculated. These parameters are used to 
determine which "blobs" are actually legitimate red beads 
and which are simply "noise". The area of each individual 
"blob" is calculated and compared to predetermined 

thresholds. All areas smaller or larger than the target red 
bead area range can be automatically eliminated. The 
smaller areas usually come from noise in the picture, while 
the larger areas can result from "glare" in the original 
image or from two or more touching beads. 

"Roundness" or "circularity" of an object is defined to 
be the ratio between the perimeter length squared and the 
area. For a perfect circle the circularity ratio is 4 yt . 
In a procedure called "Circle" all "blobs" with a 
circularity greater than 15 are eliminated. Similarly, a 
procedure called "Ratio" eliminates all "blobs" with a 
height to width ratio greater than 1. 

All remaining "blobs" are considered to be valid "red 
beads" and are re-numbered starting with 1. A procedure 
called "Center" calculates the centroid of each bead. The X 
axis is assumed to be along column 0 while the Y axis is 
assumed to be along row 0 (Y is positive down) . The bead 

centroids and areas are written into a data file (with a 
user-specified name) along with the number of beads. 
The current software determines bead centroids to within 0.1 
pixel, although this has some aspects of "false accuracy". 
Determining centroids to any greater precision would be 
meaningless, which will be shown in a later section of the 
report . 


XXXIII-9 



Image Analysis 


After the original images of the experiment are 
processed and bead centers are located, the analysis shifts 
to determining individual bead displacements between 
successive images. The current software for performing this 
analysis treats all bead displacements as relative motions 
between a single pair of images. Displacements are 
calculated from the first to the second image in a sequence, 
then from the second to the third, then from the third to 
the fourth, etc. However, the bead motions from the first 
to fourth frames can easily be determined by simply adding 
the three relative displacements between these two images. 

The bead "tracking" algorithm is relatively simple, and 
is performed by a program called "Analysis". The user is 
prompted for the names of two bead center data files 
prepared by the "Process" program. The data from these 
files is read into arrays. Bead centers are displayed on 
the video monitor as "+" signs for the first image and as 
"x" signs for the second image. The user is then prompted 
for the X (horizontal) and Y (vertical) "pixel to inches" 
conversion factors. The bead center in the second frame 
"closest" (in a least squares fashion) to each bead center 
in the first frame is then identified. The distance between 
them is compared to a threshold value (which is currently 
0.1 inch). If the distance is less than this threshold, 
then a "match" is assumed and relative X and Y displacements 
can be calculated. The "matched" bead centers in the second 
frame are then discarded so that they cannot be used for 
subsequent processing. The displacement analysis continues 
until all beads in the first image have been checked. 

One important limitation of the algorithm outlined above 
must be remembered, displacements between successive frames 
must b e relatively small . Motions on the order of half a 
bead diameter would be approximately ideal since the 
matching algorithm would work well with little opportunity 
for mis-matching. Displacements larger than one bead 
diameter could easily lead to erroneous results, especially 
if two beads begin to approach each other. Very small 
relative motions should also be avoided since calculated 
displacements will be greatly contaminated by inherent 
measurement "noise" (discussed in the next section) . 

The bead "size" information is recorded in the data 
files along with the horizontal and vertical center 
locations. This information could also be used to help in 
the "tracking" analysis, but is not used currently. Bead 
sizes should not change greatly between successive frames, 
so a matching algorithm based on both size and distance 
criteria could be developed. 


XXXIII-lo 


The "Analysis" program also has another output. Bead 
centers from the second data file that "match" bead centers 
from the first file are written to a new data file. This 
new data file has the same name as the second data file, but 
the new extension is "upd" (for UPDated) . Each bead ID is 

Â« - j j -i_ a_i rn Â« â ? +â¢ T.ra e w? +"Vt fmiT) 

cnangea uu mauuu uno w*. w**w ~ " â â - 

the first data file. For example, assume that bead #6 of 
the second data file ("No2.dat") matches bead #4 from the 
first data file ("Nol.dat") . The centroid and area data for 
bead #6 of the second file is then written to the new data 
file ("No2 .upd") with a new identification as bead #4. 
Beads from the second data file that have no "match" from 
the first file are not written into the new file. 


With this scheme bead centers from the first image can be 
tracked throughout an entire series of images. Suppose that 
four data files (Nol.dat, No2.dat, No3.dat, and No4.dat) 
have been created by "Process" from four successive images. 
First use "Analysis" to determine displacements from 
"Nol.dat" to "No2.dat", which creates a new data file 
entitled Â»No2.upd". Next use "Analysis" to determine 
displacements from "No2.upd" to No3.dat", which creates a 
new data file entitled "No3.updÂ». All displacements 
determined for a given bead "i" from the second analysis 
refer to the same bead "i" from the first analysis. 
Finally, use "Analysis" with the files "No3.upd" and 
"No4.dat". Again, all displacements determined for a given 
bead "i" from this third analysis refer to the same bead "i" 
from the first analysis. 

Analyzing a series of images in this fashion does have 
some potential problems. If a bead "disappears" in one 
image of the sequence and then "reappears" in a later image, 
no connection between these two beads will be made. A given 
bead could "disappear" in one of two ways. If a bead begins 
to move radially toward the center of the specimen, then the 
"size" of the bead appears to decrease. If it decreases 
below the threshold size of the "Process" program, then it 
is removed from the set of possible bead centers. Also, if 
two red beads move together and touch, a single large "blob" 
is generated by the "Process" procedures and can be removed 
by the circularity or ratio criteria. 

An additional program which uses the data files written 
by the "Process" program is called "Sequence". This program 
prompts the user for the name of a data file, then displays 
small circles on the video monitor at each bead center 
location. The program can then display other sets of bead 
centers concurrently. This program can be used to "animate" 
the motion of beads at speeds several times that of the 
original experiment. 


XXXIII-11 


Experiments and Calibration 


A series of tests were conducted in order to establish 
the validity of using video digitization as an analysis 
technique for the MGM experiment. In the first test a set 
of 20 red beads (of 3 mm or 0.12 inch diameter) were rigidly 
attached (glued) to a test plate. The plate was mounted to 
the triaxial test machine, but it was not behind the water 
or the "plexiglass" pressure chamber cylinder. The plate 
was displaced vertically (as a rigid body) five times in 
0.100 inch increments. Digitized images were taken directly 
from the video camera at each increment. The digital images 
were then processed using the software discussed in the 
previous sections ("Process" and "Analysis"). The data from 
the first test (0.1 inch input displacement) is given in 
Table 1, while the data for the last test (0.5 inch input 
displacement) is given in Table 2. 


Table 1 

Experimental Measurements with 0.1 inch Input Displacement 



al 

TTz-v â¢Â»*â¢+â  4 

V CJ. U J. 

1 

iv e ? 

Bead 

Displacement 

Displacement 

Displ. 


(pixels) 

(inches) 

(pixels) 

(inches) 

(inches) 

1 

0.2 

0.003 

8.4 

0.099 

0.099 

2 

- 0.2 

- 0.003 

8.5 

0.100 

0.100 

3 

- 0.2 

- 0.003 

8.4 

0.099 

0.099 

4 

- 0.6 

- 0.009 

8.4 

0.099 

0.099 

5 

- 0.3 

-0.004 

7.7 

0.091 

n no i 

v â¢ w ^ 

6 

0.4 

0.006 

8.2 

0.097 

0.097 

7 

- 0.6 

- 0.009 

8.5 

0.100 

0.101 

8 

- 0.5 

- 0.007 

8.0 

0.094 

0.095 

9 

- 0.2 

- 0.003 

8.8 

0.104 

0.104 

10 

- 0.3 

- 0.004 

8.3 

0.098 

0.098 

11 

0.3 

0.004 

8.4 

0.099 

0.099 

12 

0.3 

0.004 

8.7 

0.103 

0.103 

13 

- 0.4 

- 0.006 

7.8 

0.092 

0.092 

14 

0.1 

0.001 

8.1 

0.096 

0.096 

15 

0.0 

0.000 

8.4 

0.099 

0.099 

16 

- 0.1 

- 0.001 

8.5 

0.100 

0.100 

17 

0.1 

0.001 

8.3 

0.098 

0.098 

18 

0.2 

0.003 

8.5 

0.100 

0.100 

19 

0.3 

0.004 

8.5 

0.100 

0.100 

20 

0.2 

0.003 

8.0 

0.094 

0.094 


Average bead displacement Â« 0.098 inches 

Standard deviation = 0.0033 inches 


XXXIII-12 


ORIGINAL page is 

<* POOR quautV 


Table 2 


Experimental Measurements 

with 0.5 

inch Input 

Displacement 


Horizontal 

Vertical 

Net 

oead 

J â â t â 

UID^IQU 

(pixels) 


r> A 


nispi . 

(inches) 

(pixels) (inches) 

(inches) 

1 

1.2 

0.017 

42.0 

0.496 

0.496 

2 

1.5 

0.022 

42.4 

0.500 

0.501 

3 

1.1 

0.016 

42.5 

0.502 

0.502 

4 

0.5 

0.007 

41.8 

0.493 

0.493 

5 

2.0 

0.029 

42.1 

0.497 

0.498 

6 

1.2 

0.017 

41.8 

0.493 

0.494 

7 

1.5 

0.022 

42.7 

0.504 

0.504 

8 

0.5 

0.007 

42.1 

0.497 

0,497 

9 

1.7 

0.024 

42.9 

0.506 

0.507 

10 

1.0 

0.014 

42.2 

0.498 

0.498 

11 

1.6 

0.023 

42.9 

0.506 

0.507 

12 

1.8 

0.026 

42.7 

0.504 

0.505 

13 

1.2 

0.017 

41.4 

0.489 

0.489 

14 

1.2 

0.017 

41.0 

0.484 

0.484 

15 

1.4 

0.020 

42.5 

0.502 

0.502 

16 

1.4 

0.020 

42.5 

0.502 

0.502 

17 

1.3 

0.019 

41.6 

0.491 

0.491 

18 

1.4 

0.020 

42.1 

0.497 

0.497 

19 

1.9 

0.027 

42.4 

0.500 

0.501 

20 

0,7 

0.010 

41.5 

0.490 

0.490 


Average bead displacement = 0.498 inches 

Standard deviation = 0.0062 inches 


The 0.2, 0.3, and 0.4 inch input displacement cases 
showed average measured displacements of 0.199, 0.300, and 
0.400 inches respectively with standard deviations of 
0.0042, 0.0052, and 0.0059 inches respectively. The data 
indicate that the average measured displacements are quite 
accurate, but that individual beads may deviate somewhat 
from the average. The "worst-caseâ deviation for the 0.5 
inch input is 0.014 inches, which is approximately a full 
pixel height. 

One possible source of error can be seen by comparing 
individual bead displacements in Tables 1 and 2 to the 
average displacements. The displacements of beads 1, 2, 3, 
4, 7, 9, 11, 12, 15, 16, 18 and 19 in Table 2 are greater 
than the average of 0.098 inches. In Table 2 beads 2, 3, 7, 
9, 11, 12, 15, 16, and 19 have displacements greater than 
the average of 0.498 inches. These nine beads from Table 2 
also have greater than average displacements in Table 1. 
The displacements shown in both tables are measured with 


XXXIII-13 


respect to the same original image. Any errors in 
determining the starting bead centers from this image would 
tend to remain throughout the analysis of several images. 

In the second test of the imaging system, frames (or 
images) were captured from a video cassette recording of an 
experimental specimen. The specimen was mounted in the 
triaxial testing frame and the pressure chamber was filled 
with water. Several red beads were randomly scattered 
throughout the specimen. The specimen was not moved or 
strained during the video recording. Four different 
digitizations of the same "identicalâ image were made. 
Thirty-three (33) beads were correctly identified in each of 
the four images at essentially the same X and Y coordinates. 
However, four smaller beads were identified in some of the 
digitized images but not in others. Some of these beads 
were eliminated from the final analysis because they fell 
below the size or area threshold. 

Three sets of "displacements" were calculated for the 33 
beads common to all four images by subtracting the positions 
of the first image from the second, third, and fourth 
images. The average displacement calculated in this fashion 
was essentially zero in both the horizontal and vertical 
directions. However, the standard deviation was 0.57 pixels 
in the horizontal direction and 0.41 pixels in the vertical 
direction. Histograms for the horizontal and vertical 
displacements are shown in Figures 6 and 7 respectively. 
Gaussian distributions with the same standard deviations are 
also plotted for reference purposes. The data indicate that 
using the VCR for recording video images prior to 
digitization does contribute additional error in the form of 
reduced repeatability. This error is approximately one half 
to one full pixel in both the horizontal and vertical 
directions. 


XXXIII-14 



Results 


The extensive amount of data generated from the 
Mechanics of Granular Materials experiment will require 
computer assistance for effective data analysis. No 
commercial software packages are available for performing 
the specialized and specific analyses required. 

A set of Pascal programs for determining individual bead 
motions from digitized video pictures of the MGM experiment 
has been developed. The original image is passed through 
Laplacian, dilation, and blurring filters before 
thresholding creates a binary (black on white) image. Image 
segmentation separates the black pixels into contiguous sets 
or "blobs". Further processing eliminates some "blobs" on 
the basis of size, circularity, or height-to-width ratio. 
All remaining "blobs" are assumed to represent valid beads. 
This image processing for a single picture takes 
approximately 3-4 minutes after the digital image has been 
stored on the hard disk. The output of this software is a 
data file containing bead centroids measured from both the X 
and Y axes (top and left sides of the image respectively) . 

Testing of the video digitization equipment and image 
processing software indicated that measurements with average 
measurement errors of essentially zero can be made. However, 
standard deviations in the measurements made directly from 
the television camera indicate that the accuracy is on the 
order of one half a pixel. Also, images digitized from VCR 
recordings are of significantly lower quality than ones 
digitized directly from a television camera. Repeatability 
in measuring "identical" images from VCR recordings was 
within one half to one full pixel. 

Additional software was written to provide "hardcopy" 
output for the digitized images on a printer. Programs were 
developed for printing full size images on the Epson LQ-1500 
(black/white) and ACT II (color) printers. Other programs 
provide contouring and quarter size copies on the Epson 
LQ-1500. 


XXXIII-15 


Recommendations 


Several recommendations for further work on this project 
are given below. The recommendations are given in roughly 
the order of priority and/or practicality with highest 
priority first. 


The currently used JVC BY-110 color camera is too large 
and bulky for use in the actual shuttle experiments. Much 
smaller black and white cameras are available, but they must 
be checked to see if the "diffraction" pattern is generated 
for the red beads. The "diffraction" pattern is an critical 
requirement of the current analysis software. 

The use of special filters should be considered if other 
cameras do not generate the required "diffraction" patterns. 
â¢A filter that passed only red light could be used to give an 
image in which red beads could be easily identified. 


The experimental arrangement used in the test cases 
could not discriminate bead motion from relative motions 
between the camera and test specimens. Small stationary 
identifying points or "landmarks" should be added to the 
experimental system. Measurement of these "landmarks" in 
the image could then be used to correct for any "jitter" 
from the VCR or changes in angular orientation between the 
camera and test specimen. 


The water which fills the space between the specimen and 
the "plexiglass" pressure chamber magnifies the image to 
some degree. This magnification is difficult to determine 
and may change as the experiment progresses. The exact 
effect must be evaluated to determine the inchesâ perâ pixel 
ratios required for both the horizontal and vertical 
directions. 

Significantly more testing of the entire imaging system 
(hardware and software) is needed to conclusively prove the 
utility of this approach. The digitized images are of 
higher quality in the center 50 - 60% of the specimen image. 
This portion of the image is not significantly affected by 
the effects of projecting a three-dimensional scene (the 
specimen) onto a two-dimensional surface (the video frame). 
The outer portions of the test specimen image must be 
discarded or correction factors must be developed for 
generating valid information. 


The current 3 to 4 minutes required for processing each 
image can be reduced somewhat by different methods. The 
Turbo Pascal programs used in the current software are 
â¢ we ^f optimized for fast execution. Replacing the IBM 
PC-AT s standard 12 MHz clock crystal with a 16 MHz crystal 


XXXIII-16 


would Increase the AT's operating frequency from 6 to 8 MHz. 
Since disk access times would not be significantly improved, 
a 25% to 30% faster analysis could be expected. A more 
time-consuming option would be to convert the image 
processing routines to the "C" language for future porting 
to a faster microcomputer (such as the IBM RT-PC or a 
Motorola 68000 based system) . 

The PCVision frame grabber provides a useful resolution 
of 480 "rows" and 512 "columns". A 7% improvement in the 
imaging resolution could be easily obtained by turning the 
camera 90 degrees such that there are 512 "rows" and 480 
"columns". The current software would not be changed, 
except possibly to re-label the X and Y axes. This 
arrangement would also better use the full video screen, 
since the MGM test specimens usually have height-to-width 
ratios greater than one. 

The final recommendation is the most esoteric. Pattern 
matching and artificial intelligence techniques could be 
developed to identify red beads directly from the original 
or Laplaced images. These same techniques could also be 
used to accommodate the problems encountered with adjacent 
(touching) red beads. These beads are eliminated by the 
current algorithm, but could provide valuable information 
from the actual experiment. 


XXXIII-17 


References 


Baxes, G. A., Digital Image Processing. A Practical Primer . 
Prentice-Hall, Englewood Cliffs, New Jersey, 1982 

Castleman, K. R. , Digital Image Processing . Prentice-Hall, 
Englewood Cliffs, New Jersey, 1979 

Gonzalez, R. c. and P. Wintz, Digital Image Processing . 
Addison-Wesley, Reading, Massachusetts, 1977 

Haralick, R. M. , "Image Segmentation Survey", Fundamentals 
in Computer Vision , edited by 0. D. Faugeras, University 
Press, Cambridge, England, 1983 

ImageAction User's Guide . Imaging Technology Incorporated, 
Woburn, Massachusetts, 1985 

ImaqePro User * s Manual . Imaging Technology Incorporated, 

Woburn, Massachusetts, 1986 

Levialdi, S., "Basic Ideas for Image Segmentation". 
Fundamentals in Computer Vision , âeditedâ by 0. D*. 

Faugeras, University Press, Cambridge, England, 1983 

Rosenfeld, A., "Segmentation: Pixel-Based Methods", 

Fundamentals in Computer Vision , edited by 0. D. 
Faugeras, University Press, Cambridge, England, 1983 

Rosenfeld, A., "Digital Geometry: Geometric Properties of 

Subsets of Digital Images", Fundamentals in Computer 
Vision, edited by 0. D. Faugeras, University Press, 
Cambridge, England, 1983 


XXXIII-18 






Figure 2 - Original Digitized Image 



lirw 






Figure 3 - Digitized Image after Laplacian Filter 


XXXIII-2 0 





ORIGINAL PAGE is 
OF POOR QUALITY 








â  




I2z 


4#ggji 




















â u^cu y a wp p 






-**Â»-* â 


LcrS,i ,Â»t% 


â  




Figure 4 - Digitized Image after Dilation Filter 



Frequency Frequency 



Figure 6 - Histogram of Horizontal Displacements 



Experimental 


Vertical Deviation* (pixels) 

Sausalan Diet. 


Figure 7 - Histogram of Vertical Displacements 

XXXIII-22 


^rtHNAL PAGE -43 

OF POOR QUALfTY 



