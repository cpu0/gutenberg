AD-A264 730 

illlHi 


RL-TR-92-317 
Final Technical Report 

December 1992 



PROCEDURES FOR APPLYING 
ADA QUALITY PREDICTION 
MODELS 


The MITRE Corporation 

D.D. Murphy, W.M. Thomas, W.M. Evanco, W.W. Agresti 



APPROVED FOR PUBL /C RELEASE; DISTRIBUTION UNLIMITED. 


98 5 0 ? 05 4 



Rome Laboratory 
Air Force Materiel Command 
Griffiss Air Force Base, New York 











This report has been reviewed by the Rome Laboratory Public At fairs 0:iice 
(PA) and is releasable to the National Technical Information Service (NITS). At 
NTIS it will be releasable to the general public, including foreign nations. 

RL-TR-92-317 has been reviewed and is approved for publication. 


APPROVED: 



ANDREW J. CHRUSCICKI 
Project Engineer 


FOR THE COMMANDER 


' JOHN A. GRANIERO 
Chief Scientist for 


C3 


If your address has changed or if you wish to be removed from the Rome Laboratory 
mailing list, or if the addressee is no longer employed by your organization, 
please notify RL ( C3CB ) Griffiss AFB NY 13441. This will assist us in maintaining 
a current mailing list. 


Do not return copies of this report unless contractual obligations or notices on a 
specific document require that it be returned. 



R EPORT DOCUM ENT ATION PAGE 

•WJCitrxj CMdsn tCf ms o otoc o on c# r*or~n*our e> muraied roadway* > O/ fapr >Muy m - • •-»-» 'or t «** ££mr a »*><# ur * t, .s** *.*.*:.#* 

gan*r*} arc rnmrtmnrt) cW* naadad mo armrvwwriy src 'bv***^ si tlor-mx Sarc ucnt<wt» - mjt*■* t? «& :*j cm r ur «r v » «&***:* ur ", 

ccfcacn cf »*armancr\ f outJnQ stjggMcnna for laouang txjOar\ ta "«at;»jir>ar* ^wvm* O»»oc#** ’■» it r r *uf -y r mtmxx » **y .*r#*u 

Oavts *<<jrvrs* S-.^e i it54 A/inyort VA Z2?0? -OG2. *r« to 0 *c* c# Vtf«p-«art iro tf x%j» finm**** , <*m%jaur'- O' «p 


1 AGENCY use ONLY (Uavs Blank) 2, REPORT DAU 

: December I 

1 iITU AND SUB rim 

PROCEDURES FOR APPL Y I No ADA QUA!. I TV PKED I L"I I ON MODELS 

6. AUTHOR^) 

D. D. Murphy, W. M, Thomas, W. M. !.v.iiu>>, V. W. Ar:, t : 


3 report iYPt andoau a com A! r< 

•j I UNDING NUMBi ns 

t « }' I M * ‘* " ** ( f - 1 •* ; >i.! i 1 .! 


7 PERFORMING ORGANIZATION NAMt(S) AND ADDMI SSii S) 

The MITRE Corpora Cion 
Was hin g t on C 3 C e n c e r 
7>25 Colshire Drive 
McLean YA 22102-3481 

9 SPONSORING/MONITORING AGENC r NAME IS) AND ADDRESSES) 

Rome Laboratory (C3CB) 

535 Brooks Road 

Crit'l iss AKB NY l 54AI-45 n 5 


a PI HI OMM1NG ORGANIZATION 
Hi.PORI NUMBI M 

, Mi K V)i)uni..'\ 


10 SPONSORING MONl101 iiNG 
AGENCY Rf PORT NUMBI R 


KL-TH-y. 


U. SUPPLEMENTARY NOTES 

Rome Laboratory Project Engineer: Andrew .! . Chrusc iv'ki/C iCh/ ( i I 53 3 iO- 


12a DISTRIBUTION/AVA1 LABILITY STATEMENT 

Approved for public release; distribution unlimitu 


,12b DISTRIBUTION CODE 


13. ABS1RACT(Mwmjn 200 «aas| 

Procedures for applying Ada software quality prediction models for purposes of mode 1 
validation are described. The multivariate regression models predict metrics related 
to software reliability, maintainability, and flexibility. The procedures include 
the use of an Ada source code analysis tool and the Statistic''! Analys; . iiy.-ter, (GAS; 
to extract data from Ada source code and create data sets containing quantities 
needed for the models. 


14. SUBJECT TERMS 

Software Quality, Ada 

Reliability, Maintainability, Flexibility 

17. SECURITY CLASSIFICATION 

OF REPORT 

UNCLASSIFIED 

1 a SECURITY CLASSIFICATION i 
OF THIS PAGE 

UNCLASSIFIED 

19. SECURITY CLASSIFICATION 
OF ABSTRACT 

UNCLASSI FI ED 


16 PRICE CODE 


Standard f onT> 29R fP#v ;• {*& 
Pr#r*9rrt»ri by ANS* ita 
JW-l® 









EXECUTIVE SUMMARY 


This report describes procedures for applying Ada software quality prediction models for 
purposes of model validation. The multivariate regression models were developed under the 
Mission Oriented Investigation and Experimentation (MOIE) program of The MITRE 
Corporation. The models predict metrics related to software reliability, maintainability, and 
flexibility. The procedures include the use of an Ada source code analysis tool and the 
Statistical Analysis System (SAS) to extract data from Ada source code and create data sets 
containing quantities needed for the models. 

The quality prediction models have been developed in a research setting, based on software 
project data. The models are at a stage of development where they are ready for validation 
on additional software projects to refine the coefficients of the models. Validation of the 
models on diverse software projects will increase the confidence in subsequent application of 
the models. 

Readers are cautioned that the models were developed by analyzing source code and data 
from a particular set of Ada projects. The models in this report should not be expected to be 
universally applicable regardless of the size and nature of the project. Indeed, understanding 
the range of applicability of tb' models is part of the validation process, w hich the procedures 
in this report are intended to tat ilitate. 

This report is intended to support individuals who want to validate the models by apply ing 
them to Ada projects. The starting point for someone to use this report is the availability of 
Ada source code and an interest in obtaining a static analysis of the code or applying the 
quality prediction models. The models are of the form, 

q * f (aj * Xj) 

where q is a quality factor to be predicted; aj are coefficients resulting from the MOIE 
research and given in this report; and Xj are calculated quantities whose values depend on the 
Ada source code for the project. The values of Xj need to determined, so they can be 
combined with the coefficients a, to produce the predicted quality factor. Validation 
involves comparing the predicted values to actual data as they become available on projects. 

The models are based on static features of the Ada code, such as counts of declarations 
imported and exported across library units. To extract these data, a software tool, the Ada 
Source code Analyzer Program (ASAP), is used. An additional product of ASAP is the 
genc.atier o f a Project Summary Report, providing a profile of the source code. The 
extracted data proceed through several stages of processing before they are transformed into 
the Xj values needed for the quality prediction models. Because several processing steps are 
involved, an organization of directories and files has been established and described in this 
report to show where the Ada source code, software tools, intermediate data, models, and 


i 








calculated values reside during the process. The application of the models is now performed 
at the MITRE-Washington Software Engineering Center using a Sun computer, running the 
Unix operating system. This directory structure can serve as a model that can be duplicated 
if another computer system is used to apply the models. 

The report describes the series of steps invoking SAS programs that generate data tiles at the 
compilation unit, library unit, and subsystem levels. The library unit level tiles and 
subsystem level files will contain the quantities needed for calculating the values X, so the 
models can be applied. The models described can be categorized based on: the quality factor 
(reliability, maintainability, or flexibility) associated with the metric predicted using the 
model; the level of granularity of the software quality predicted for subsystems or library unit 
aggregations; and the testing activities over which the model is predicting the metric either 
unit, system, and acceptance test or system and acceptance test . The report includes the 
steps to invoke SAS programs, corresponding to the models, to compute predicted values for 
quality factors. 


ii 






ACKNOWLEDGMENTS 


The authors acknowledge the contributions of Bradford T. Ulery to the development of the 
procedures and file directories described in this report. 




□ □ 






TABLE OF CONTENTS 


SECTION PAGE 

1 Introduction 1 1 

1.1 Purpose 1 -1 

1.2 Background l-l 

1.3 Intended Audience 1-2 

1.4 Overview of the Procedures 1-2 

2 Extracted Data and Structural Metrics 2-! 

2.1 Declarations 2-1 

2.2 Expons 2-2 

2.3 Imports 2-4 

2.4 Statement Counts 2-5 

2.5 Quality Metrics 2-5 

3 Directories and File Organization 3-1 

4 Ada Source Code Analysis 4-1 

4.1 Overview of the Source Code Analysis Procedure 4-1 

4.2 Detailed Source Code Analysis Procedure 4-2 

5 Compilation Unit Level Analysis 5-1 

5.1 Overview of the Compilation Unit Level Analysis Procedure 5-1 

5.2 Detailed Compilation Unit Level Analysis Procedure 5-2 

6 Library Unit Level Analysis 6-1 

6.1 Overview of the Library Unit Level Analysis Procedure 6-1 

6.2 Detailed Library Unit Level Analysis Procedure 6-2 

7 Subsystem Level Analysis 7-1 

7.1 Overview of the Subsystem Level Analysis Procedure 7-1 

7.2 Detailed Subsystem Level Analysis Procedure 7-1 


V 






SECTION 


PACE 


8 Description and Use of the Quality Prediction Models 8-1 

8.1 Reliability Models 8-2 

8.2 Maintainability Models 8-5 

8.3 Flexibility Models 8-9 

List of References RE-1 

Appendix Example Of Project Summary Report A-1 

Glossary GL-1 

Distribution List DI-1 






LIST OF FIGURES 


FIGURE PAGE 

1- 1 Overview of Procedures and Report Sections 1.5 

2- 1 Example to Illustrate Exports and Imports 2-3 

3- 1 High Level Directories 3.2 

3-2 Project Directories 3.4 

3-3 Tools Directories 3.5 

3- 4 Template Directories 3.7 

4 - 1 Directories Used in Source Code Analysis Procedures 4-3 

5 - 1 Directories Used in CU-level Analysis Procedure 5-3 

6 - 1 Directories Used in LU-level Analysis Procedure 6-3 

7 - 1 Directories Used in Subsystem-level Analysis Procedure 7-3 


vii 





LIST OF TABLES 


TABLE 

PAGE 

2-1 Subsystem-level Quality Metrics 

2-6 

2-2 LUA-Ievei Quality Metrics 

2-7 

3-1 High Level Directories 

3-3 

3-2 Project Directories 

3-5 

3-3 Tools Directories 

3-6 

3-4 Template Directories 

3-8 


viii 








SECTION 1 


INTRODUCTION 


This report describes procedures for applying Ada software quality prediction models for 
purposes of model validation. The multivariate regression models were developed under the 
Mission Oriented Investigation and Experimentation (MOIE) program of The V1ITRE 
Corporation. The models predict metrics related to software reliabili v, maintainability, and 
flexibility. 

This section discusses the purpose of this report, background of the MOIE research that 
produced the models, the intended audience for this report, and an overview of the 
procedures to apply the models. 


1.1 PURPOSE 

This report is intended to support individuals who want to support in validating quality 
prediction models by applying them to Ada projects. The models have been developed in a 
research setting, bared on software project data. The models are at a stage of development 
where they are ready for validation on additional software projects to refine the coefficients 
of the models. Validation of the models on diverse software projects will increase the 
confidence in subsequent application of the models. 

The reader should be cautioned that the quality prediction models were developed using a 
particular set of Ada projects (described in [1]). The models should not be expected to be 
universally applicable regardless of the size and nature of the project. Indeed, understanding 
the range of applicability of the models is pan of the validation process, which the procedures 
in this report are intended to facilitate. 


1.2 BACKGROUND 

MITRE has been conducting a MOIE research project investigating software quality 
prediction from Ada designs. The research has focused on prediction of metrics related to the 
software quality factors of reliability, maintainability, and flexibility. The project team has 
developed multivariate models that use characteristics of the Ada design as the basis for 
predictions of quality. The approach and rationale for developing the models are described in 
separate reports and technical papers. [1,2, 4, 5] 

The development of the quality prediction models involved the analysis of data from 
software development projects. The data included Ada source code and information on the 
experiences implementing and testing the code to make the software pass acceptance testing. 


1-3 







This information included reports of defects found during testing and reports of the effort 
expended to repair defects and to make changes to the software. Details of the Ada software 
and corresponding project data are discussed in [ 1 ]. 

For the models to be used with confidence, they need to be validated. For val>dation, the 
models need to be atiplied to projects other than those which were the basis c r model 
development. This report describes the procedures for applying the models, sr individuals 
outside the MO IE research team can participate in validating the models. 


1.3 INTENDED AUDIENCE 

This report is written for individuals who want to validate the quality prediction models by 
applying them to Ada source code. Another possible user of these procedures is someone 
who wants to conduct a static analysis of Ada source code. For someone interested only in 
static analysis, sections 1 through 4 will be sufficient to explain how to use the Ada Source 
Analyzer Program (ASAP) to produce a Project Summary Report (PSR), a sample of which 
is included in the Appendix to this report. Reference 3 provides detailed description of the 
capabilities of ASAP. 

The procedures in this report assume a basic knowledge of Ada and familiarity with Unix 
commands. 


1.4 OVERVIEW OF THE PROCEDURES 

The starting point for someone to use this report is the availability of Ada source code and an 
interest in obtaining a static analysis of the code or applying the quality prediction models. 
The models are of the form 

q = f(aj*Xi), 

where q is a quality factor to be predicted; a, are coefficients resulting from the MOIE 
research and given in this report; and Xj are calculated quantities whose values depend on the 
Ada source code for the project. The values of Xj need to determined, so they can be 
combined with the coefficients aj to produce the predicted quality factor. Validation involves 
comparing the predicted values to actual data as they become available on projects. 

Sections 2 through 7 of this report describe the processing needed so that the values X, can 
be calculated for given Ada source code. Section 8 gives the models themselves; that is, the 
coefficients aj, and ways of combining ai and Xj to calculate the predicted quality factors. 
Section 8 also includes the commands to invoke programs that calculate the predicted values. 
Because the bulk of this report involves proceeding from Ada source code to the calculated 


1-2 






quantities X,, this process will be outlined in this section as an overview to Sections 2 
through 7. 

The models are based on static features of the Ada axle, such as counts of declarations 
Section 2 discusses the kinds of data on which the models depend The discussion in 
Section 2 should help the reader understand what data is being extracted from the Ada axle 
to use in later calculation of X,. To extract these dam. a software uxii, ASAP, ts used ASAP 
is a static Ada source code analysis program developed at the University of Maryland ASAP 
performs functions such as the following: presents profiles of compilation units, counts 
source lines and Ada statements, computes metrics based on Halstead software science 
analysis and McCabe cyclomatic complexity analysis, and prepares reports based on these 
analyses (3J. ASAP was developed as a stand-alone analysis tool Not all of the extracted 
and calculated quantities produced by ASAP are needed for applying the quality prediction 
models; for example, Halstead and McCabe metrics are not used. ASAP was found to extract 
static data needed for our models so it is being used for that purpose in these procedures. 
Section 2 also defines the quality metrics that are based on the extracted data. These metrics 
relate to design characteristics and are elements of the models presented in Section K 

Because several steps are involved in eventually calculating the X, values, an organization of 
directories and files has been established and described in Section 3 to show where the Ada 
source code, software tools, intermediate data, models, and calculated values reside during 
the process. The application of the models is now performed at the MITRE-Washington 
(SWEC) using a Sun computer, running the Unix operating system Section 3 discusses the 
directory organization on the SWEC computer. This directory structure can serve as a model 
that can be duplicated if another computer system is used to apply the models 

The steps involved in processing Ada source code, leading to the execution of the mcxlels. are 
depicted in Figure 1-1. The relationship of s^eps in the process to sections in this report is 
also shown in Figure 1-1. Section 4 describes the execution of ASAP to extract static data 
from the Ada source code. An additional product of this step is the production of the ASAP 
Project Summary Report, which provides a profile of the source code. An example of the 
ASAP Project Summary Report is included in the Appendix. For readers interested only in 
static analysis of their code. Section 4 contains the necessary commands leaning to the 
generation of the Project Summary Report. For readers who plan to apply the quality 
prediction models. Section 4 also includes steps to execute additional extraction programs 
which operate on the output of ASAP to produce data files in an appropriate form for use 
with the (SAS), the statistical software used in the analysis. 

As Figure 1-1 shows. Section 5 begins with all of the needed data available in SAS input 
files. The quantities needed for the quality prediction models refer to three different levels of 
structural granularity in the software. ASAP provides static data on Ada compilation units 
(as shown in Appendix A), so the first level of analysis is to calculate compilation-unit level 
measures. Section 5 discusses the steps involved in this pr<x:essing, invoking SAS programs 
to generate the compilation unit files, as shown in Figure 1 -1. 


1-3 









Compilation-unit level measures provide the needed data tor measures at two higher levels of 
granularity: library unit aggregations (LUAs) and subsystems. SAS programs at the LUA 
and subsystem levels are discussed in sections 6 and 7, respectively. Quality prediction 
models have been established at these two levels, so the products of the processing in 
sections 6 and 7 directly feed the quality prediction models. 

Unlike "compilation unit”, the terms "library unit aggregation" and "subsystem" are not 
defined in the Ada language. Both terms arose from the MOIE research because of a need to 
express structural relationships at intermediate points between compilation units and entire 
systems, which may be extremely large. Both LUA and subsystem have been useful for 
analysis and reporting purposes. An LUA is an Ada library unit (LU) and its descendent 
compilation units, if any [2]. An LUA ’ as become a structure of considerable interest in the 
research. The most interesting class of LUA examples consists of a package specification, a 
package body, and subunits. Such LUAs may include subunit structures which are nested at 
several levels. 

Subsystem is used to retain a degree of generality in the research, when referring to major 
functional areas or principal units of a complete system. If the system is developed under 
Department of Defense (DOD)-STD-2167A, a subsystem may be a computer software 
configuration item, or computer software component. But, because such terms are not 
universally used, subsystem is used in this research. 

At the conclusion of the steps described in sections 6 and 7. the library unit level files and 
subsystem level files will contain the quantities needed for calculating the values X,. Section 
8 represents the final stage of processing. The models described in Section 8 can be 
categorized based on: the quality factor (reliability, maintainability, or flexibility ) associated 
with the metric predicted using the model; the level of granularity of the software quality 
predicted for subsystems or library unit aggregations; and the testing activities over which the 
model is predicting the metric - either unit, system, and acceptance test (USA) or system and 
acceptance test (SA). For a detailed discussion of the background, motivation, rationale for 
the models, refer to references l, 2, and 4. Section 8 includes the steps to invoke SAS 
programs, corresponding to the models, to compute predicted values for quality factors. 


1-4 







Figure 1-1. Overview of Procedures and Report Sections 

















SECTION 2 


EXTRACTED DATA AND STRUCTURAL METRICS 


The purpose of this section is to describe the classes of data that will be extracted from the 
Ada source code and the structural metrics used in the models. The procedures in sections 4 
through 7 will refer to the data classes discussed in this section. The quality prediction 
models in Section 8 include factors based on the structural metrics. 

The MOIE research has shown that the number and kinds of declarations are significant 
factors in quality prediction. Also significant are the patterns of sharing information by 
making quantities declared in one place accessible elsewhere in the software. We refer to 
declarations in the visible part of a library unit as being exported to a compilation unit that 
imports them by using a context ("with") clause. Data on declarations, expons, impons, and 
statement counts are extracted from the Ada source code and combined to form structural 
metrics that are used in the quality prediction models. This section defines the declarations, 
exports, imports, statement counts, and resulting structural metrics. 


2.1 DECLARATIONS 

Extracted data from the Ada source code includes counts of declarations by the following 
semantic classes: constants, objects, types, subtypes, formal parameters, exceptions, 
subprograms, packages, and tasks. Also figuring in the quality prediction models are counts 
of the total number of declarations, the number of program unit declarations, and the number 
of non-program units declarations. 

The quality prediction models have also included factors that are sensitive to the possible use 
of the same identifier name in more than one way in the software. Data is extracted on the 
number of unique names declared, across the entire software and the number of unique 
names within a semantic class. 

The example below illustrates the possible differences in these counts of declarations when 
names are used more than once. 

Package P is 

procedure Q(A,B : in out integer, F: float); 
function F(X: integer) return integer; 
function F(X: character) return character; 
type T is new integer range 1..100; 


end P; 


2-1 










The number of unique names declared does not include multiple declarations of the same 
name. In the example, F is declared twice as a function and once as a formal parameter, 
representing only one unique name declared (F). In the example, there are seven names 
declared (P, Q, A, B, F, X, T). 

The number of unique names is also determined for each semantic class and then summed 
over all semantic classes. We call this count the number of unique declarations. In the 
example, F is declared twice as a function and once as a formal parameter, resulting in two 
unique declarations (i.e., a function F and a formal parameter F). The example has eight 
unique declarations: P, Q, A, B, F (function), F (formal parameter), X, T. Note that X is 
counted only once as a formal parameter. 

Our third count of declarations is the total number of declarations including all overloaded 
names. In the example, F is declared twice as a function and once as a formal parameter, 
resulting in three total declarations (i.e., two functions named F and one formal parameter F). 
The example has ten total declarations (°, Q, A, B, F (integer function), F (character 
function), F (formal parameter), X (integer formal parameter), X (character formal 
parameter), T). 

When declarations are divided into program unit and non-program unit declarations, the 
counts are not sensitive to the overloading. In the example, there are four program unit 
declarations (P, Q, F (integer function), F (character function)) and six non-program unit 
declarations made (A, B, F (formal parameter), X (integer formal parameter), X (character 
formal parameter), T). 


2.2 EXPORTS 

Exports are declarations made in the visible part of a library unit. Counts of exports are used 
in factors in various quality prediction models. Two counting rules for exports should be 
noted: (1) the name of a function or procedure implemented as a library unit is counted as a 
single declaration, since the declarations within the function or procedure are not visible, and 
(2) formal parameters to these subprograms, although visible, are not counted. 

Figure 2-1 shows sample Ada source code consisting of library units P, Q, R, and S, and their 
associated secondary units. In this example, P exports Five total declarations 
(P, Tl, T2 ,T3,c), Q exports four declarations (Q, Ql, x,y), R exports six declarations 
(R, Rl, R2, x, y, z), and S exports one declaration (S). 


2-2 





Package P is 
type T1 
type T2 
type T3 

c : constant = 10; 
end; 

with P; 

Package Q is 

procedure Ql(x,y ; in out integer); 
end; 

Package body Q is 

procedure Ql(x,y : integer) is 

end; 

end; 

with Q; 

Package Ris 

procedure Rl(x,y ; in out integer); 
procedure R2(z : in out integer); 
end; 

Package body R is 

procedure R1 is separate; 
procedure R2 is separate; 
end; 

with P; 
separate (R) 

procedure Rl(x,y : in out integer) is 

end; 

with P; 
separate (R) 

procedure R2(z : in out integer) is 
end; 

with P,R; 

procedure S(a,b,c: in out integer) is 
end; 


Figure 2-1. Example to Illustrate Exports and Imports 


2-3 






A second count, related to exports, is the count of users of the library units. We count this in 
two ways: the number of CUs that contain a "with" to the LU in question, and the number of 
LUAs that contain a "with" to the LU in question. In the above example, P is "withed" by 
four CUs (package specification Q, subunit R. Rl, subunit R. R2, procedure S), and thus 
three LUAs (Q, R, S); Q is withed by one CU (package spec R) and one LUA (R); R is 
withed by one Cl T (procedure S) and one LUA (S), and S is not withed at all. 


2,3 IMPORTS 

We associate a count of imports with each compilation unit based on the number of 
declarations in the visible part of the library units that are "withed in" to the CU (i.e., named 
in the CU’s context clause). For example, we see that the compilation unit S imports the 
visible declarations of P (P, T1, T2, T3, c) and R (R, Rl, R2, x, y, z). The other imports are 
as follows: package specification P imports nothing; package specification Q imports the 
five declarations from P (P, Tl, T2, T3, c); package body Q imports nothing; package 
specification R imports the four visible declarations of Q (Q, Ql, x, y); package body 
R imports nothing; and subunits R.R1 and R.R2 each imports the five declarations of 
P (P, Tl, T2, T3, c). 

These counts of imports to each CU are then aggregated to the LUA level for CUs 
comprising the LUA. Three import counts are defined: total imports, unique imports, and 
cascaded imports. 

Total imports is simply the sum of the imports for all CUs in the LUA. Thus, P imports 
nothing; Q imports five declarations; R imports 14 declarations; and S imports 11 
declarations. 

Unique imports is a count that is sensitive to multiple CUs importing the services of the same 
library unit. An example of this can be seen in the library unit aggregation R, where R.R1 
and R.R2 each import the services of P. Unique imports do not count this duplication. Thus, 
P has no unique imports; Q has five; R has nine; and S has 11. 

The. thud count of imports is the "cascaded imports" introduced in the MOIE research [1]. A 
declaration imported to one compilation unit will "cascade" through (i.e., be visible to) all 
descendent units of that compilation unit. For example, the five declarations imported to the 
package specification Q are also visible to the package body Q; thus, the library unit 
aggregation Q contains ten "cascaded imports:" the five directly imported to the 
specification, and the five cascaded to the body. P and S have no subunits, so the count of 
cascaded imports is the same as the count of total imports, namely, zero for P and 11 for S. 
Four declarations are imported to the package specification R; these are cascaded to the 
package body R and the subunits R.R1 and R.R2. Both R.R1 and R.R2 directly import five 
declarations, thus R has 26 cascaded imports. 


2-4 








2.4 STATEMENT COUNTS 


ASAP provides various counts of source lines of code, comment lines, blank lines, and 
counts of Ada executable and declarative statements. For the most part, these counts are not 
included in our analyses. However, as a proxy for measures of the extent and uniformity of 
control flow, we defined several measures based on the number of call statements (either 
subprogram "call" (i.e., invocation) or task entry call) in the compilation units. 


2.5 QUALITY METRICS 

Based on the extracted data on declarations, imports, and expons, we have defined various 
metrics that relate to design characteristics and quality factors studied in the MOIE research. 
These metrics are included in the quality prediction models in Section 8. The metrics are 
defined in Table 2-1 (for subsystem-level metrics) and Table 2-2 (for LUA-level metrics) and 
discussed in References 1, 2, and 4. 


2-5 







Table 2-1. Subsystem-level Quality Metrics 


Design Characteristic 

Quality Metric 

Context Coupling 

IMPEXP: Number of unique declarations imported 
divided by the number of unique declarations exported 


WITHPLU: Mean number of library units “withed” per 
library unit aggregation 


PUDPLU: Mean number of imported program unit 
declarations per library unit aggregation 

Control Coupling 

CALLPSUB: Mean number of subprogram invocation 
statements per subprogram in the subsystem 


CALLPEX: Mean number of subprogram invocation 
statements per executable unit in the subsystem 

Visibility 

CIMPIMP: Number of unique cases ed declarations 
imported divided by the number of unique declarations 
imported 


VISHPUD: Percentage of hidden program unit 
declarations (i.e., number of hidden program unit 
declarations divided by number of hidden and visible 
program unit declarations) 


VISXPUD: Mean number of exported program unit 
declarations per library unit aggregation 

Locality 

FINTPUD: Percentage of imported program unit 
declarations originating in the same subsystem as the 
importing unit 

Generality 

GENS: Percentage of generic and instantiated library 
units in the subsystem 

Parameterization 

PARVPUD: Mean number of parameters per visible 
program unit 




2-6 





















Table 2-2. LUA-level Quality Metrics 


Design Characteristic _ Quality Metric 


Context Coupling 

WITHS: Number of library units "withed" per 

LUA 

Functionality 

VIS PROG UNITS: Number of visible program 
units within the LUA 


i 


2-' 









SECTION 3 


DIRECTORIES AND FILE ORGANIZATION 


This section describes the directory structure that has been established to facilitate the 
application of the quality prediction models. This directory structure has been implemented 
on the SWEC Sun host computer named National under Unix. There are two purposes for 
describing the directories and files: (1) They are referenced in the processing steps as 
locations for intermediate data and results. Readers who are applying the quality prediction 
models in the MITRE SWEC will know where to look for those data or results; and, (2) The 
MODE research team has found this directory structure to be a useful way to organize the 
potentially confusing collection of programs and data. If the quality prediction models are 
implemented on a different host computer, this file structure may be helpful as a model. 

Figure 3-1 depicts the Unix directory structure. The "qmtop" directory is accessed through 
the "design 1” directory. The ”qm” of qmtop stands for quality metrics. The qmtop directory 
provides access to the projects, tools, and templates directories. Table 3-1 describes the 
directories shown in Figure 3-1. The projects directory provides access to directories for 
specific projects, while tools like ASAP and SAS are contained in the tools directory. 

Many of the SAS programs needed for application of the quality prediction models create 
files associated with the project to which the models are being applied. To retain flexibility 
in these procedures, so they can be applied to various projects, templates have been written 
by the MOIE team. The templates are generic programs that, when supplied with a project 
name, can produce specific instantiated programs to create files associated with the project 
name. 

Figures 3-2 through 3-4 and Tables 3-2 through 3-4 display and describe the directories for 
projects, tools, and templates. 


3-1 







Figure 3-1. High Level Directories 
















Table 3-1. High Level Directories 



Directory Name Directory Description 


design 1 

This directory is at the highest level on the Sun host 
called National and provides access to the qmtop 
directory. 

qmtop 

This directory is the highest directory for the quality 
metrics project. It incorporates directories that include 
programs and data input and data output for ASAP, SAS, 
and MITRE-developed quality prediction models. 

projects 

This directory contains directories for individual projects 
that are to be analyzed. 

project 

This directory incorporates directories that include 
project-specific data and programs. 

(Throughout the remainder 
of this report when the term 
project is underlined 
(oroiect) it should be 
interpreted as an actual 
project name) 

tools 

This directory incorporates directories that include 
executable programs and source code. These programs 
are used to perform ASAP and SAS analyses, and to 
apply the quality prediction models. 

templates 

This directory incorporates directories that include 
generic SAS programs that can be used to create project- 
specific programs. 


3-3 































Table 3*2. Project Directories 


Directory Name 

Directory Description 

asap_out 

Output files created when running ASAP 
are placed in this directory Trm directory 
contains one output file for each source 
input file to ASAP. 

data 

ASAP data output files are placed in this 
directory 

reports 

Files that include predictions and summary 
desorptions are placed in this directoiy. 

sas 

. . 

SAS programs obtained from the templates 
directory and modified to be project- 
specific are placed in this directory. 

source 

Ada source code files are contained in this 
directory'. 

ssd 

SAS data sets are placed in this directory 
when they are created by SAS programs. 

work 

General work files can be placed in this 
directory. 


3-5 

















Figure 3-3. Tools Directories 


Table 3-3. Tools Directories 


Directory Name _ Directory Description 


bin 

This directory contains executable 
programs. 

src 

This directory contains directories that 
contain source code associated with the 
executable programs included in the bin 
directory. 























Table 3-4. Template Directories 


Directory Name Directory Description 


parti 

This directory contains SAS programs that 
are used to create the project's SAS 
database. 

part2 

This directory contains SAS programs that 
are used to create data sets at the library 
unit level. 

part3 

This directory contains SAS programs that 
are used to create data sets at the 
subsystem level. 


models 


This directory contains programs that are 
used to produce results from the quality 
prediction models. 












SECTION 4 


ADA SOURCE CODE ANALYSIS 


This section describes the procedure f or using ASA? and other programs to extract data from 
Ada source code and create files that are in the proper format for use with SAS. ASAP also 
can generate a Project Summary Report. This section contains an overview of the procedure 
and the detailed steps required. 


4.1 OVERVIEW OF THE SOURCE CODE ANALYSIS PROCEDURE 

The starting point for using the procedure in this section is the presence of the Ada source 
code for a project. The steps in the procedure are as follows: 

- Step 1-1 Establish user path and directories 

- Step 1-2 Create the ASAP database 

- Step 1-3 Create the project summary file (and report) 

- Step 1-4 Create "withs by CU" file 

- Step 1-5 Create instantiations file 

- Step 1-6 Create declarations file 

- Step 1-7 Create filenames and CUs file 

- Step 1-8 Create CU call counts file 

- Step 1-9 Create filename/subsystem mapping file 

- Step 1-10 Change file data to uppercase 

Step 1-2 runs ASAP, creating output files used in subsequent steps. Step 1-3 uses the ASAP 
output files to create a project summary file that can be printed as a Project Summary Report 
(see the Appendix for an example). Steps 1-4 through 1-9 create files that are subsequently 
used to create SAS files. The final step changes data in the created files to uppercase so that 
the files are in the correct form for SAS processing. 

Figure 4-1 highlights the directories involved in the procedure, as follows: 

- bin: contains programs used in steps 1-2 through 1-10 

- source: contains source code used as input to step 1-2 

- asap_out: contains input data for steps 1-4, 1-5, 1-6, 1-7, 1-8, and 1-10; and files of 
output data from step 1-2 

- data: contains input data for step 1-3; and files of output data from steps 1-2 through 


After following this procedure, all needed data will be present in SAS input files, ready for 
compilation unit level analysis in Section 5. 


4 -! 







4.2 DETAILED SOURCE CODE ANALYSIS PROCEDURE 


Step 1-1 Establish user path and directories 

The procedures begin with steps to ensure that the Unix path and directories are established, 
so that commands in this section will execute correctly. 

The user path should be updated to include the following directory: 

/design 1/qmtop/tools/bin 

A new project directory must be created in the projects directory. As previously indicated 
(Table 3*1), the term project is used throughout this report to represent the name of a project. 
The following lower level directories must also be created in the newly created project 
directory: asap_out, data, reports, sas, source, ssd, and work. The Ada source code must be 
placed in the source directory located in the project directory. The remaining steps in this 
section assume the current directory is the project directory. 

Step 1-2 Create the ASAP database 

This step takes the Ada source code data located in the source directory and creates ASAP 
reports stored in the asap_out directory and also stored in the data directory. The ASAP 
database file reports are used in subsequent steps when extracting data to be used as input to 
SAS. The database file is used in the next step to create a file that can be used to produce the 
Project Summary Report. 

The command to initiate this process follows: 

datasap source asap_out data /project .db 

This command consists of four parts: the program name (datasap); the input directory name 
(source); an output directory name (asap_out); and a second output directory name along 
with the name of the file to be stored in the directory (data/ project .db). 


4-2 








qmtop 


tools 


projects 


crflkci 


Figure 4-1. Directories Used in Source Code Analysis Procedures 


Step 1-3 Create the project summary file and report 

This step uses the previously generated ASAP database file to create a project summary file, 
which is formatted for printing as the Project Summary Report( project .usumm). A sample 
of this report is shown in the Appendix. A second file is also packed, project .summ. which is 
used in the SAS processing described in Section 5. 

The command to initiate this process follows: 

projsumm data /proiect .db data/ proiect 

This command consists of three pans: the program name (projsumm); the input directory 
and file name (data/ project .dbV. and the output directory and file name (data /proiect ). 

Step 1-4 Create "withs by CU" file 

This step takes files created in step 1-2 and creates an output file ( proiect .withs) that is used 
during the SAS processing described in Section 5. 


4-3 











The command to initiate this process follows: 

withextr asap_out > data/ proiect .withs 

This command consists of four parts: the program name (withextr); the input directory name 
(asap_out); the Unix symbol directing outputs to a file (>); and the name of the output 
directory along with the output file stored in the directory (data/prpjfc£j.withs). 

Step 1-5 Create instantiations file 

This step takes files created in step 1-2 and creates an output file (project.insts) that is used 
during the SAS processing described in Section 5. 

The command to initiate this process follows: 

instextr asap_out > data/ proiect .insts 

This command consists of four parts: the program name (instextr); the input directory name 
(asap_out); the Unix symbol directing outputs to a file (>); and the name of the output 
directory along with the output file stored in the directory (data/projgct.insts). 

Step 1-6 Create declarations file 

This step takes files created in step 1-2 and creates an output file (project-decs) that is used 
during die SAS processing described in Section 5. 

The command to initiate this process follows: 

decsextr asap_out > data /project .decs 

This command consists of four parts: the program name (decsextr); the input directory name 
(asap_out); the Unix symbol directing outputs to a file (>); and the name of the output 
directory along with the output file stored in the directory (data/prgjg&.decs). 

Step 1-7 Create filenames and CUs file 

This step takes files created in step 1-2 and creates an output file (prfljgct-fnmap) that 
contains a mapping of filenames to compilation unit names. This output is used during the 
SAS processing described in Section 5. 

The command to initiate this process follows: 

fntocu asap_out > data/project.fnmap 


4-4 




This command consists of four pans: the program name (fntocu); the input directory name 
(asap_out); the Unix symbol directing outputs to a file (>); and the name of the output 
directory along with the output file stored in the directory (data/ proiect .fnmap). 

Step 1-8 Create CU call counts file 

This step takes files created in step 1-2 and creates an output file ( project -calls) that contains 
data concerning compilation unit counts. This output is used in during the SAS processing 
described in Section 5. 

The command to initiate this process follows: 

callextr asap_out > data/ project .calls 

This command consists of four pans: the program name (callextr); the input directory name 
(asap_out); the Unix symbol directing outputs to a file (>); and the name of th“ output 
directory along with the output file stored in the directory (data/project.calls). 

Step 1-9 Create filename!subsystem mapping file 

This step requires the user to create a file named project .ssmap that contains two columns. 
The first column containing the name of the Ada source file and the second the "subsystem " 
(as discussed in Section 1) to which the file belongs. After the file is created, it is placed in 
the data directory. In the event that subsystems have not been identified for the project, the 
user can map all files to a single subsystem. This will allow the user to continue with the 
processing described in the next section. 

Step 1-10 Change file data to uppercase 

This step takes the files created in steps 1-4 through 1-9 and changes data to impercase so 
that the files can be used to create SAS files. 

The command to initiate this process follows: 

uppercase project 

This command consists of two pans: the program name (uppercase); and the input directory 
name (project) . 


4-5 





SECTION 5 


COMPILATION UNIT LEVEL ANALYSIS 


This section describes a procedure for creating project SAS files at the compilation unit level. 
The procedure involves executing SAS programs that operate on the SAS input files created 
by the procedure in Section 4. This section contains an overview of the procedure and the 
detailed steps in the processing. 


5.1 OVERVIEW OF THE COMPILATION UNIT LEVEL ANALYSIS PROCEDURE 

The starting point is the completion of the procedure in Section 4, resulting in SAS input 
files. The steps in the procedure are as follows: 

- Step 2-1 Create SAS programs from templates 

- Step 2-2 Remove duplicate CU names 

- Step 2-3 Create CU file 

- Step 2-4 Create instantiations file 

- Step 2-5 Create declarations file 

- Step 2-6 Create declaration counts file 

- Step 2-7 Create "withed in” relationship file 

- Step 2-8 Create the SAS database file 

When running SAS from the UNIX command line (as we describe in this report), for each 
SAS program run (e.g., sas sasjjrogram) an output file sas_program.\og will be generated. 
This file contains a log of the executed SAS program, including any warnings and error 
messages. It is recommended that this file be examined after each step to ensure that no 
errors have been encountered. 

A second output is often produced, sas_program\si. This file contains the output from any 
SAS print procedures. Many of the steps produce intermediate reports that are contained in 
these files. While examining these reports is not necessary to obtain the predictive results, it 
can help to provide a better understanding of the system under analysis and help to resolve 
any errors that may have been encountered. 

The first step uses program templates to create project-specific programs that will be used 
during subsequent steps in this process. The next step examines previously generated files to 
determine whether duplicate compilation unit names exist. If duplicate names exist it is 
necessary to take steps to eliminate the duplicates. The remaining steps take either 
previously generated files or files created during this process to create SAS CU-level files. 

Figure 5-1 identifies the directories that are used during this procedure, as follows: 


5-1 








* templates: contains programs used as input to step 2-1 

- sas: contains programs that are the output of step 2-1 and used in steps 2-2 through 2-8 

- data: contains data used as input to steps 2-2 through 2-5, 2-7, and 2-8 

- ssd: contains data used as input to step 2-6 and data used as output from steps 2-3 
through 2-8 

- bin: contains the program used in step 2-1 

After following this procedure, all needed data is in CU-level files, to be used for library unit 
level analysis (Section 6) and subsystem level analysis (Section 7). 


5.2 DETAILED COMPILATION UNIT LEVEL ANALYSIS PROCEDURE 

Step 2-1 Create SAS programs from templates 

Prior to beginning the steps described in this section, it is assumed that the procedure 
described in Section 4 has been completed. Thus the data directory contains the SAS input 
files (e.g., project -decs, project .withs. and project .insts) that will be used during this 
procedure. It is further assumed that the current directory is any of the following: design 1, 
qmtop, tools, or bin. 

This step instantiates program templates that are stored in the templates directory to create 
programs specific to the project of interest. The resulting programs are stored in the sas 
directory. The templates must be instantiated so that the programs will be able to access files 
that include the project identification as part of the name (e.g., project .withs') and to store 
results in the proper location. 

The command to initiate this process follows: 

modifyjemplates project 


5-2 





Figure 5-1. Directories Used in CU-level Analysis Procedure 


This command contains the name of a program (modify_templates) and a parameter which is 
the name of the project that is being analyzed. The input template programs for this process 
are located in the parti, part2, part3, and models directories located in the qmtop/templates 
directory. The outputs from this process are stored in the parti, part2, part3, and models 
directories located in the sas directory. 

Step 2-2 Remove duplicate CU names 

For this step and remaining steps in this procedure, the current directory should be the parti 
directory in the sas directory. 

This step examines the previously generated project .withs file for duplicate compilation unit 
names. It produces an output file that the user must examine to determine if any compilation 
unit names occur more than once. If duplicate compilation units are discovered, the user 
must go back to the original code and eliminate the duplicate code and then restart the 
process with the steps described in Section 4. 


5-3 


















The command to initiate this process follows: 


sas dupdecsl.sas 

This command invoices a program that checks for duplicate compilation unit names f ir any 
project. The project , withs file is an input to this program. If duplicate compilation unit 
names exist, they are output to the sas_dupdecs 1.1st file. 

A second approach to detecting duplicates is to examine the previously generated 
project .decs file for duplicate compilation unit names. If duplicate compilation units are 
discovered, the user must go back to the original code and eliminate the duplicate code and 
then restart the process with the steps described in Section 4. 

The command to initiate this process follows: 

sas dupdecs2.sas 

This command invokes a program that also checks for duplicate compilation unit names for 
any project. The project -decs file is an input to this program. If duplicate compilation unit 
names exist they are output to the sas_dupdecs2.1st file. 

Step 2-3 Create CU file 

This step takes the previously generated project .withs file and creates a SAS file 
(culist.ssd01) that contains the names of compilation units and their types. 

The command to initiate this process follows: 

sas culistsas 

This command invokes a program that takes the proiect .withs file containing relationships 
between user compilation units and "withed in" library units and generates the culist.ssdOl 
file that contains the names of the compilation units and their types. The output file is 
contained in the ssd directory. 

Step 2-4 Create instantiations file 

This step takes the previously generated project .insts file and creates a SAS file 
(instssf.ssdOl) that contains the instantiations associated with each compilation unit The 
output from this step serves as an input to step 2-6. 

The command to initiate this process follows: 


5-4 







sas instssf.sas 


This command invokes a program that creates the instssf.ssdOl file. The input file to this 
program is the proiect .insts file. 

Step 2-5 Create declarations file 

This step takes the previously generated proiect .decs file and creates a SAS file 
(decssf.ssdOl) that contains information concerning declarations. The output from this step 
serves as an input to the following step. 

The command to initiate this process follows: 

sas decssf.sas 

This command invokes a program that creates the decssf.ssdOl file containing declarations 
information. 

Step 2-6 Create declaration counts file 

This step provides the additional processing needed to calculate counts that are sensitive to 
names being used more than once, as discussed in Section 2.1. This step takes the file 
generated by the previous step (decssf.ssdOl) and creates a SAS file (psdecnum.ssdOl) that 
contains the number of declaration names, the number of overloaded declaration names, and 
the number of unique declaration name/class combinations. 

The command to initiate this process follows: 

sas psdecnum.sas 

This command sends its results to the file, psdecnum.ssdOl. That file and the file produced 
by step 2-4 (instssf.ssdOl) are then input to another program, invoked by the command, 
psdecmod.sas, yielding the required declaration counts data in the psdecmod.ssdOl file. 

Step 2-7 Create "withed in" relationship file 

This step takes the previously generated project .withs file containing relationships between 
user compilation units and "withed in" library units and creates a SAS file (wither.ssdOl). 

The command to initiate this process follows: 

sas with 1.sas 


5-5 









This command invokes a program that takes the project , withs file and creates the 
wither.ssdOl file. 

Step 2-8 Create the SAS database file 

This step takes the previously generated project .summ file and creates the SAS database file 
(database.ssdOl). 

The command to initiate this process follows: 
sas database.sas 

This command contains the name of a program that takes the project .summ file and 
generates the database.ssdOl file. The procedure is now complete with the output file 
containing information on counts of declarations and "with's" at the compilation unit level. 


5-6 








SECTION 6 


LIBRARY UNIT LEVEL ANALYSIS 


This section describes a procedure for creating project SAS files at the library unit 
aggregation (LUA) level. The procedure involves executing SAS programs that operate on 
the SAS compilation unit level data created by the procedure in Section 5. This section 
contains an overview of the procedure and the detailed steps in the processing. 


6.1 OVERVIEW OF THE LIBRARY UNIT LEVEL ANALYSIS PROCEDURE 

The starting point is the completion of the procedure in Section 5, resulting in SAS 
compilation unit level data. To create library unit level files, the steps in the procedure are as 
follows: 

- Step 3-1 Create compilation unit mapping file 

- Step 3-2 Create counts of "withed in" declarations file 

- Step 3-3 Create imports file 

- Step 3-4 Create unique imports counts file 

- Step 3-5 Create the exports file 

- Step 3-6 Create cascaded imports (CU level) file 

- Step 3-7 Create cascaded imports (LU level) file 

- Step 3-8 Create "withed by" file 

- Step 3-9 Create program unit declarations file 

- Step 3-10 Combine previously generated files 

- Step 3-11 Create library unit files 

This section describes a procedure to create library unit level SAS files. The first step creates 
a file that maps compilation units to subsystem units. This step uses files created during the 
processing described in Section 4. Steps 3-2 through 3-9 use files created during processing 
described in Section 5 to create library unit files for various categories of data (e.g., "withed 
in" data, cascaded imports data, and unique imports data). Step 3-10 combines the files 
generated in steps 3-2 through 3-9. Step 3-11 takes the file generated in step 3-10 and creates 
SAS files at the library unit level. 

Figure 6-1 identifies the directories that are used during this procedure, as follows: 

- sas: contains the programs used in all steps 

- data: contains data used as input to step 3-1 

- ssd: contains data used as input to steps 3-2 through 3-1; and files used as output data 
from step 3-11 





After following this procedure, the library unit level files are complete. 


6.2 DETAILED LIBRARY UNIT LEVEL ANALYSIS PROCEDURE 

This section describes each step in the procedure by giving the commands used to invoke the 
necessary programs and the input and output. 

Step 3-1: Create Compilation Unit Mapping File 

The starting point for using the procedure in this section is the existence of the following 
specific project files: 

- in the data directory: proiect .fnmap (from step 1-7) and project. ssmap (from step 1 -9) 

- in the ssd directory: wither.ssdOl (from step 2-7) and psdecmod.ssdOl (from step 2-6). 

For this step and remaining steps in this procedure, the current directory should be the part2 
directory in the sas directory. 

This step takes a previously generated file that contains a mapping of filenames to 
compilation unit names and another previously generated file that contains the mapping of 
filenames to subsystems and creates a file that maps compilation units to subsystem units. 

The command to initiate this process follows: 

sas cumap.sas 

This command contains the name of a program that takes the proiect .fnmap and 
project .ssmap files and creates the cumap.ssdOl file. The output contains a mapping of 
compilation units to subsystem units. 


6-2 





qmtop 



Figure 6-1. Directories Used in LU-level Analysis Procedure 

Step 3-2: Create Counts of'Withed In" Declarations File 

This step takes previously generated files and creates a file that contains counts of "withed 
in" declarations for library units. The output file is used as an input to step 3-10. 

The command to initiate this process follows: 

sas lusswdec.sas 


6-3 










This command contains the name of a program that outputs counts of the declarations withed 
into the various compilation units and is ordered by subsystem. Note that the declarations 
from the standard library are not included in these counts. The input files are wither.ssdOl, 
cumap.ssdOl, and psdecmod.ssdOl. The output file is withdecs.ssdOl. 

Step 3-3: Create Imports File 

This step takes the file created in step 3-2 and creates a file that contains the counts of 
imports from external subsystems (i.e., subsystems other than the one containing the library 
unit in question) at the library unit level. Note that, in this step, if a library unit is "withed in" 
more than once into compilation units of a LUA, the imports will be counted more than once. 
The output file is used as an input to step 3-10. 

The command to initiate this process follows: 

sas luimp.sas 

This command contains the name of a program that uses the withdecs.ssdOl file to calculate 
the number of imports from external °ubsystems at the library unit level. The output files 
from this program are lusimp.ssdOl and Iunimp.ssdOl. 

Step 3-4: Create Unique Imports Counts File 

This step takes the file created in step 3-2 and creates a file that contains the counts of 
imports from external subsystems at the library unit level. Note that, in this step, if a library 
unit is "withed in" more than once into compilation units of a LUA, the imports will be 
counted only once. The output files are used as inputs to step 3-10. 

The command to initiate this process follows: 

sas luuimp.sas 

This command contains the name of a program that uses the withdecs.ssdOl file to calculate 
imports from external subsystems at the library unit. The output files from this program are 
luusimp.ssdOl (imports from the same subsystem) and luunimp.ssdOl (imports from external 
subsystems). 

Step 3-5: Create the Exports File 

This step takes the file created in step 3-2 and creates a file that contains counts of exports at 
the LUA level. The output file is used as an input to step 3-10. 

The command to initiate this process follows: 


6-4 






sas luexp.sas 

This command contains the name of a program that computes the expons at the LUA level. 
The input file to this program is withdecs.ssdOl. The output file from this program is 
luexps.ssdOl. 

Step 3-6: Create Cascaded Imports (Compilation Unit Level) File 

This step takes the files created in steps 3-1 and 3-2 and creates a file that contains cascaded 
import counts for compilation units. The output file is used as an input to step 3-7. 

The command to initiate this process follows; 

sas lucscd.sas 

This command contains the name of a program that uses the withdecs.ssdOl and cumap.ssdOl 
files to compute cascaded imports. The output file is lucscd.ssdOl 

Step 3-7: Create Cascaded Inputs (Library Unit Level) File 

This step takes the file created in step 3-3 and creates a file that contains counts of cascaded 
imports at the LUA level. The output file is used as an input to step 3-10. 

The command to initiate this process follows: 

sas lucimp.sas 

This command contains the name of a program that uses the lucscd.ssdOl file to compute the 
cascaded imports at the LUA level. The output file from this program is lucimp.ssdOl. 

Step 3-8: Create "Withed By" File 

This step takes the previously generated file containing "withed in" information and the 
previously generated compilation unit mapping file and creates a "withed by” file for library 
units. 

The command to initiate this process follows: 
sas luwithby.sas 

This command contains the name of a program that calculates the "withed by" relationships. 
The input files to this program are wither.ssdOl and cumap.ssdOl. The output file from this 
program is luwithby.ssdOl. 


6-5 







Step 3-9: Create Program Unit Declarations File 


This step takes the previously generated database file and the previously generated 
compilation unit mapping file and creates a file that contains information on parent-child 
relationships (e.g., package body-subunit [1]) and on the counts of various program unit 
declarations within a LUA. The output file is used as an input to step 3-10. 

The command to initiate this process follows: 

sas lupuds.sas 

This command contains the name of a program that takes as input the SAS data set contained 
in database.ssdOl and cumap.ssdOl and delivers as output the lupuds.ssdOl file. 

Step 3-10: Combine Previously Generated Files 

This step takes files created by steps 3-2 through 3-9 and combines this data into a single data 
file. The output from this step serves as input to step 3-11. 

The command to initiate this process follows: 

sas lusscmb.sas 

This command contains the name of a program that creates a SAS data set for the specified 
project at the library unit level. It combines the following filesrlunimp.ssdOl, lucimp.ssdOl, 
lusimp.ssdOl, luexp.ssdOl, luunimp.ssdOl, luusimp.ssdOl, lupuds.ssdOl, luwithby.ssdOl. 

The output file is lucmb.ssdOl. 

Step 3-11: Create Library Unit Data Sets 

This step takes the file generated by the previous step and generates a file, ludb.ssdOl, 
containing data on all LUAs and also creates four files that represent partitions of ludb.ssdOl 
according to characteristics of the LUAs. The first of these files, pkgs.ssdOl, contains 
information concerning LUAs that contain a library unit package and at least one executable 
line of code. A second file, pkgd.ssdOl, contains information concerning LUAs that contain 
a library unit package, but do not contain any executable lines of code. The third file, 
subs.ssdOl, contains information concerning LUAs that are subprograms. The fourth file, 
inst.ssdOl, contains information concerning LUAs that are instantiations of generics. 

The command to initiate this process follows: 

sas ludb.sas 


6-6 






This command contains the name of a program that creates SAS data sets at the LUA level. 
The input file to the program is lucmb.ssdOl. The output files from this program are 
ludb.ssdOl, pkgs.ssdOl, pkgd.ssd01, subs.ssdOl, and inst.ssdOl. 


6-7 







SECTION 7 


SUBSYSTEM LEVEL ANALYSIS 


This section describes a procedure for creating project SAS files at the subsystem level. The 
procedure involves executing SAS programs that operate on the SAS compilation unit level 
and library unit level data created by the procedures in section 5 and 6. This section contains 
an overview of the procedure and the detailed steps in the processing. 


| 7.1 OVERVIEW OF THE SUBSYSTEM LEVEL ANALYSIS PROCEDURE 

The starting point is the completion of the procedure in Section 6, resulting in SAS library 
[ unit level data. To create subsystem level files, the steps in the procedure are as follows: 

i 

l - Step 4-1 Create subsystem exports file 

i - Step 4-2 Create subsystem imports file 

Step 4-3 Create subsystem program unit declarations file 

- Step 4-4 Create subsystem level SAS file 

! 

I This section describes a procedure to create subsystem level file. The first three steps take 

previously generated files and create files containing data concerning exports, imports, and 
program unit declarations at the subsystem level. The last step takes the files created by the 
! previous steps and combines the data into a single file. 

i 

i Figure 7-1 identifies the directories that are used during this procedure, as follows: 

- sas: contains the programs used in all steps 

- data: contains data used as input and output for all steps 

After following this procedure, the subsystem level files are complete. 


7.2 DETAILED SUBSYSTEM LEVEL ANALYSIS PROCEDURE 

This section describes each step in the procedure by giving the commands used to invoke the 
necessary programs and the input and output. 

The starting point for this procedure is the existence of the files withdecs.ssdOl and 
database.ssdOl. 

Step 4-1 Create subsystem exports file 


7-1 







For this step and remaining steps in this procedure, the current directory should be the part3 
directory in the sas directory. 

This step takes the previously generated file containing information concerning "withed in" 
declarations at the LUA level and creates several files containing information concerning 
exports at the subsystem level. The outputs from this step serve as input to step 4-4. 

The command to initiate this process follows: 

sas ssexpts.sas 

This command contains the name of a program that creates SAS data sets at the subsystem 
level. The input file to the program is withdecs.ssdOl. The output files from this program 
are exports.ssdOl, exptsubs.ssdOl, ngenexsb.ssdOl, expdecs.ssdOl, and crssdecs.ssdOl. 

Step 4-2 Create subsystem imports file 

This step takes the previously generated file containing information concerning "withed in" 
declarations at the LUA level and creates several files containing information concerning 
imports at the subsystem level. The outputs from this step serve as input to step 4-4. 

The command to initiate this process follows: 

sas ssimpts.sas 

This command contains the name of a program that creates SAS data sets at the subsystem 
level. The input file to the program is withdecs.ssdOl. The output files from this program 
are impcus.ssdOl, impdecs.ssdOl, impcscd.ssdOl, and impcdec.ssdOl. 

Step 4-3 Create subsystem program unit declarations file 

This step takes the previously generated database file and creates two files that contain data 
concerning program unit declarations at the subsystem level. The outputs from this step 
serve as inputs to step 4-4. 

The command to initiate this process follows: 

sas sspuds.sas 





Figure 7-1. Directories Used in Subsystem-level Analysis Procedure 


This command contains the name of a program that creates SAS data sets at the subsystem 
level. The input file to this program is database.ssd. The output files from this program are 
puds.ssd and gtots.ssd. 

Step 4-4 Create subsystem level SAS file 

This step takes the files created by the previous three steps and creates a subsystem level data 
set file. 

The command to initiate this process follows: 
sas sscmb.sas 

This command contains the name of a program that creates a SAS data set that merges 
previously generated data sets. The output file from this program is sscmb.ssd. 


7-3 











SECTION 8 


DESCRIPTION AND USE OF THE QUALITY PREDICTION MODELS 

This section describes the quality prediction models and gives commands to invoke programs 
that apply the models using project data in files created by previous procedures in this report. 
The models described in this section were developed based on data provided by the Software 
Engineering Laboratory (SEL) of NASA's Goddard Space Flight Center. Data from four Ada 
projects consisting of 21 subsystems were used. Reference 1 provides detailed profiles of the 
data. These projects were concerned with the development of interactive, ground-based, 
scientific applications. 

These models have had only limited validation using different projects. The application of 
the models should be viewed as a part of the process of validating the models in different 
environments. A different environment may lead to more or less defects than those predicted 
by the models. However, initial validation efforts have indicated that there may be a high 
correlation between actual and predicted defects, implying a linear relationship. The 
coefficient of this relationship must be determined externally from the models. When 
interpreting the model predictions for projects from substantially different development 
enviroments than those used to calibrate the model, the quality predictions may be interpreted 
as measures of relative merit in that environment. 

The quality prediction models in this section may be classified according to the quality factor 
of interest, the time period over which a metric is predicted, and the level of granularity of 
the model. The models relate to the following quality factors: reliability, maintainability, and 
flexibility. For each of these quality factors, models are presented that predict metrics over 
two different time periods: (1) unit, system/integration, and acceptance (USA) testing, and 
(2) system/integration and acceptance (SA) testing. In the case of reliability, models are 
given at the subsystem level and the LUA level of granularity, while maintainability and 
flexibility models are presented only at the subsystem level. 

The models that are presented represent a subset of the models that have been developed. 
These models were selected because they have produced the best results thus far in their 
category. For additional information concerning models that have been developed see 
references 1 and 4. 

Prior to running any of the models, the user should enter the following command to change to 
the models directory: 

cd /design 1/qmtop/proiects /proiect/ sas/models 


8-1 






8.1 RELIABILITY MODELS 


Four models are described: two each for predictions at the subsystem and LUA levels. 
Within each level, models are given at both the USA and SA time intervals. Note that, 
although these models are identified for convenience as reliability models, the research team 
has not had access to data on software-induced system failures. Instead, software defect data 
was analyzed to develop the models. Consequently, the models are more accurately 
identified as "reliability-related", because of the strong connection between defects and 
failures [6], 

Reliability Model #1: SubsystemJUSA 

This model predicts the total number of defects per thousand lines of source code 
(TOTDEFSL) — where "total" is used to mean defects reported during the activities of unit, 
system/integration, and acceptance testing. TOTDEFSL is predicted at the subsystem level. 

The explanatory variables in the model are defined as follows: 


Design Characteristic Measure 


Context Coupling 

IMPEXP: number of unique declarations 
imported divided by the number of unique 
declarations exported 

Visibility 

CIMPIMP: number of unique cascaded 
declarations imported divided by the number of 
unique declarations imported 


The basic form of the model is: 

log(Y) = ao + aj * log ( Xj) + a 2 * log (X 2 ) 
where 

Y = dependent variable (TOTDEFSL) 

Xi= independent (explanatory) variables 

aj= coefficients determined by multivariate regression 

The calibrated model is as follows[l]: 

log (TOTDEFSL) = - 0.04 + 0.51*log (IMPEXP) + 0.26*log (CIMPIMP) 
This model can be run using the following command: 
sas rel_ss_usa.sas 


8-2 






The outputs from the model will be the predicted values of TOTDEFSL for all subsystems in 
the Ada system, where TOTDEFSL is the defects per thousand source lines of code reported 
during the activities of unit, system/integration, and acceptance testing. 

Reliability Model #2: SubsystemlSA 

This model is similar to Model #1, except it predicts the number of defects per thousand lines 
of source code that will occur during system/integration and acceptance testing only 
(SYACDEFSL). 

The explanatory variables in the model are identical to those in model #1. 

The calibrated model is [1]: 

log (SYACDEFSL) = -1.42 + 0.70 * log (IMPEXP) + 0.46 * log (CIMPIMP) 

This model can be run using the following command: 
sas rel_ss_sa.sas 

The outputs from the model will be the predicted values of SYACDEFSL for all subsystems 
in the Ada system, where SYACDEFSL is the defects per thousand source lines of code 
reported during the activities of system/integration, and acceptance testing. 

Reliability Model #3: LUA/USA 

This model predicts the probabilities that a library unit aggregation has 0, 1,2, 3,4, 5, or 
greater than 5 defects detected during the unit, system/integration and acceptance test 
activities [4], From these probabilities, the expected total number of defects can be predicted 
at the LUA level and any other higher levels of aggregation (e.g., subsystem or project) by 
rolling up the LUA results. 

The explanatory variables in the model are defined as follows: 


Design Characteristic _ Measure 


Context Coupling 

WITHS: number of library units "withed" per 

LUA 

Functionality 

VIS PROG UNITS: number of visible program 
units within the LUA 


The model can be described as follows: 


8-3 












p(X < i) = 1/(1 + cxp(Intercept l - model), i = 0,5 
p(X>5) - 1- p(X < 5) 


where p(X £ i) is the probability that the number of defects, X, in the LUA is less than or 
equal to i (for i=0,l,...5), and p(X > 5) is the probability that the number of defects is greater 
than five. The model is described in more detail in [4|. The model term is given by 

model = a, * (WTTHS) + a 2 * (VIS PROG UNITS) 


where the Intercept's and a/s are the model parameter values as indicated in the table beiow; 


Class 


Context Coupling 
Functionality 


Identifier 

Value 

Intercept 1 

0.41 

Intercept2 

0.83 

Intercept3 

1.13 

Intercept4 

1.37 

Intercepts 

1.53 

Interceptb 

1.69 

WITHS 

0.07 

VIS PROG UNITS 

0.0008 


(at) 

(a 2 ) 


This model can be run by entering the following command: 
sas rel_lu_usa.sas 

Several processing stems occur when the command is executed. The direct outputs from the 
model are the probabilities of defects, as previously described. Using these probabilities, 
expected numbers of defects are computed for all LUAs and printed. Next, the expected 
defects at the LUA level are rolled up and printed at the subsystem level. Note that step 1 -9 
in Section 4 provides for the case in which there is a single "subsystem" that actually is the 
entire system. 

Reliability Model # 4: LUA/SA 

This model is similar to Model #3, except that it predicts over the system/integration and 
acceptance test activities only [4J. The model parameters are as follows: 


8-4 








Class Identifier Value 

Interceptl 0.60 

Intercept 1.03 

Intercept3 1.35 

Intercept4 1.54 

Intercept5 1.74 

Intercept6 1.89 

Context Coupling WITHS 0.06 (ai) 

Functionality VIS PROG UNITS -0.007 (a 2 ) 


This model can be run by entering the following command: 


sas rel_lu_sa.sas 


The outputs from the model are similar to model #3, except the predictions apply to the more 
restricted interval of system/integration and acceptance testing. 


8.2 MAINTAINABILITY MODELS 

Two models are described: the first predicts over the unit, system/integration, and acceptance 
(USA) testing activities and the second predicts over system/integration, and acceptance (SA) 
testing only. Both models predict, for subsystems, the probability that a defect in the 
subsystem will require less than 1 hour, less than 1 day, and less than three days of defect 
isolation effort [1 ]. 

Maintainability Model #1: Subsystem! USA 

Model #1 is at the subsystem level, with coverage over unit, system/integration, and 
acceptance (USA) testing. 






The explanatory variables in the model are defined as follows: 


Design Characteristic Measure 


Context Coupling 

WITHPLU: Mean number of library units 
“withed” per library unit aggregation 

Visibility 

VISHPUD: Percentage of hidden program unit 
declarations (i.e., number of hidden program unit 
declarations divided by number of hidden and 
visible program unit declarations) 

Control Coupling 

CALLPSUB: Mean number of subprogram 
invocation statements per subprogram in the 
subsystem 


The model can be described as follows: 

p(Y< i) = 1/(1 + exp(Intercept; - model)), 
such that 

p(Y < i) is the probability that a defect in the subsystem will require isolation effort less 
than or equal to category i, (for three categories: 1 hour, 1 day, and three days), and 


model = ai * Xi + 32 * X 2 + 33 * X 3 


where the X;s represent the explanatory variables described above, and the Intercept;^ and 
afs are the model parameter values as indicated in the table below: 


Class 

Identifier 

Value 



Intercept 1 

0.147 



Intercept! 

2.244 



Intercept3 

3.525 


Context Coupling 

WITHPLU 

0.070 

(ai) 

Visibility 

VISHPUD 

-1.301 

(&2) 

Control Coupling 

CALLPSUB 

-0.029 

(a 3 ) 


This model can be run as follows: 
sas mnt_ss_usa.sas 


8-6 












Any anomalies occurring while running the model will be noted in the SAS log file 
mnt_ss_usa.log. The output will be contained in the file mnt_ss_usa.lst. Five columns of 
output are produced. The first and second columns contain the name of the project and 
subsystem, respectively. The third, fourth and fifth columns contains the predicted 
probabilities that a effort to isolate a defect will be less than one hour, less than 1 day, and 
less than three days. 

The outputs from the model will be the probabilities, for each subsystem, that the time to 
isolate defects in that subsystem will require less than 1 hour, less than 1 day, and less than 
three days. 

Maintainability Model #2: Subsystem!SA 

This maintainability model is similar to model #1 except that the prediction covers 
system/integration and acceptance (SA) testing only. The explanatory variables in the model 
are defined as follows: 


8-7 







Design Characteristic Measure 


Context Coupling 

WITHPLU: Mean number of library units 
“withed” per library unit aggregation 

Generality 

GENS: Percentage of generic and instantiated 
library units in the subsystem 

Control Coupling 

CALLPEX: Mean number of subprogram 
invocation statements per executable unit in the 
subsystem 

Locality 

FINTPUD: Percentage of imported program unit 
declarations originating in the same subsystem as 
the importing unit 


The model parameter values are indicated in the table below: 


Class 

Identifier 

Value 


Intercept 1 

-1.99 


Intercept2 

-0.15 


Intercept3 

1.33 

Context Coupling 

WITHPLU 

0.12 (a,) 

Generality 

GENS 

1.80 (a 2 ) 

Control Coupling 

CALLPEX 

-0.03 (a 3 ) 

Locality 

FINTPUD 

1.86 (a4) 


This model can be run as follows: 
sas mnt_ss_sa.sas 

Any anomalies occurring while running the model will be noted in the SAS log file 
mnt_ss_sa.log. The output will be contained in the file mnt_ss_sa.lst. Five columns of 
output are produced. The first and second columns contain the name of the project and 
subsystem, respectively. The third, fourth and fifth columns contains the predicted 
probabilities that a effort to isolate a defect will be less than one hour, less than 1 day, and 
less than three days. 


8-8 














8.3 FLEXIBILITY MODELS 


Two flexibility models are described: the first predicts over the unit, system/integration, and 
acceptance (USA) testing activities and the second predicts over system/imegration, and 
acceptance (SA) only. Both models predict, for subsystems, the probability that a non-defect 
change in the subsystem will require less than 1 hour, less than l day, and less than three 
days of isolation effort [1]. 

Flexibility Model #1: Subsystem/USA 

Model #1 is at the subsystem level, with coverage over unit, system/integration, and 
acceptance (USA) testing. The explanatory variables in the model are defined as follows: 


Design Characteristic Measure 


Context Coupling 

PUDPLU: Mean number of imported program 
unit declarations per library unit aggregation 

Generality 

GENS: Percentage of generic and instantiated 
library units in the subsystem 

Visibility 

VISHPUD: Percentage of hidden program unit 
declarations (i.e., number of hidden declarations 
divided by number of hidden and visible program 
unit declarations) 

Control Coupling 

CALLPSUB: Mean number of subprogram 
invocation statements per subprogram in the 
subsystem 


The model is similar to maintainability models in structure and results. The model parameter 
values are indicated in the table below; 


Class 

Identifier 

Yaly& 



Intercept 1 

0.599 



Intercept2 

2.385 



Intercept3 

3.229 


Context Coupling 

PUDPLU 

0.015 

(a,) 

Generality 

GENS 

2.462 

(a 2 ) 

Visibility 

VISHPUD 

-1.180 

(a 3 ) 

Control Coupling 

CALLPSUB 

-0.044 

(a4) 


8-9 










This model can be run as follows: 


sas flx_ss_usa 

Any anomalies occurring while running the model will be noted in the sas log file 
flx_ss_usa.log. The output will be contained in the file flx_ss_usa.lst. Five columns of 
output are produced. The first and second columns contain the name of the project and 
subsystem, respectively. The third, fourth and fifth columns contains the predicted 
probabilities that a effort to isolate a defect will be less than one hour, less than 1 day, and 
less than three days. 

Flexibility Model #2: SubsystemJSA 

This model is similar to flexibility model #1 except that the prediction covers 
system/integration and acceptance (SA) testing only. The explanatory variables in the model 
are defined as follows: 


Design Characteristic_Measure 


Context Coupling 

PUDPLU: Mean number of imported program 
unit declarations per library unit aggregation 

Generality 

GENS: Percentage of generic and instantiated 
library units in the subsystem 

Visibility 

VISXPUD: Mean number of exported program 
unit declarations per library unit aggregation 

Parameterization 

PARVPUD: Mean number of parameters per 
visible program unit 


The model parameter values 

Class 


Context Coupling 
Generality 
Visibility 
Parameterization 


indicated in the table below: 

Identifier 

Intercept 1 
Intercept2 
Intercept3 
PUDPLU 
GENS 
VISXPUD 
PARVPUD 


are 














This model can be run as follows: 


sas flx_ss_sa 

Any anomalies occurring while running the model will be noted in the sas log file 
flx_ss_sa.log. The output will be contained in the file tlx_ss_sa.lst. Five columns of output 
are produced. The first and second columns contain the name of the project and subsystem, 
respectively. The third, fourth and fifth columns contains the predicted probabilities that a 
effort to isolate a defect will be less than one hour, less than 1 day, and less than three days. 


8-11 




LIST OF REFERENCES 


1. Agresti, W. W., W. M. Evanco, M.C. Smith, D. R. Clarson, "An Approach to Software 
Quality Prediction from Ada Designs", MTR-90W00135, MITRE Corporation, 
September 1990. 

2. Agresti, W. W., W. M. Evanco, M. C. Smith, "Early Experiences Building a Software 
Quality Prediction Model", Proceedings of the Fifteenth Annual Software Engineering 
Workshop, November 1990. 

3. Doubleday, D. L., "ASAP: An Ada Static Source Code Analyzer Program", 

TR-1895, Department of Computer Science, University of Maryland, August 1987. 

4. Evanco, W. M., and W. W. Agresti, "Statistical Representations and Analyses of 
Software”, Proceedings of the 24th Symposium on the Interface of Computing Science 
and Statistics, College Station, Texas, 18-21 March 1992. 

5. Evanco, W. M., W. M. Thomas, W. W. Agresti, "Estimating Ada System Size During 
Development", MTR-91W00132, MITRE Corporation, December 1991. 

6 . Musa, J. D„ A. lannino, and K. Okumoto, Software Reliability, New York: 
McGraw-Hill, 1987. 

7. SAS Institute Inc., SAS Procedures Guide, Release 6.03 Edition. Cary, NC: SAS 
Institute Inc., 1988. 


RE-1 




APPENDIX 


EXAMPLE OF PROJECT SUMMARY REPORT 


A-l 







SOURCE LINES- ADA STATEMENTS NESTDEPTII DECLARATIONS- PACKAGE 5UIIPKOC TASK VIS 

UNIT MAKE AND TYPE T< 'TL CODE CMTS BLNK TOTL EXEC DECL MAX AVRGE CON OBJ TYP SP,T PAR EXC SP BD ST SP BD ST SP BO ST WI IN 


oooo 
0^00) 
oooo 
oooo 
oooo 
o o o 
n-ico 

m 

o o o i© 
oooo 
O O «-t o 

O O O ri 
OOOO 


O O O O n 

OOJOtDH 

O o o o o 
O O O o o 
o o o o o 

O O O O <N 


o o o o o 
«-* o o o 
O n O *h o 
o o o o -> 


nnoooooori 


0000000004 


ooooooooo 


oo — 000000 s 


oooooooo— 


C2 *■ © v*. s 
WOiONcor 


O 0 © 000000020 ~<ci*r ©0 — 0 

o ooooooooooooooooo 
o o o o o o o o o o o o o o o o o o 

c o o o o o o o o o o © o o o o o o 

O O O o O O O O O O' o o o o o o o o 

O 0rHC s 000Or-i0QC s Q'3''0O0^ 
—I <N 

oooooooo ooi^or-omo 
o o o o o o o o o o o o o o o o o o 

O -f o o •««* O O O -t O «H o r-T O — O O 

r- 00©~0-< — 00*i0r-<0ri0-<C s 
—( OOOfNOOOOOOOOOinOOO 


v© vo'D'CC'C'OONH^nMinoor) 

O* — -4 w~l rn 


000000^-*00400000000 

OOOf-OO^O^OO^OOOOO 

r«o«'-<Hoa'O>-(/ i roc0OTHO 


o ooooo^o 

O OOOHWMfl 

o ooooooo 

o ooooooo 

o ooooooo 

O O O o O C •: 

ci © O © O ro a> © 

— n 

OOOOOOO 
O O —* O ri n © 
-I n O n O O 
O O O OJ O O rr 


O O O O o o - 


O I*") O O O o *-* 


OOtN 
rO!*l 
o o o 
o o o 
o o o 
o o o 
-* r*t o 
O o <n 
O o o 

OhO 

o o -* 
o ~ a 


CO OOrrOOMO O n 03 C 


OO^OOOOrHW^OOOOO^OO *~< O n O © — O O 


m 0(Ncr>in-M<«j*oao*nr-*ao'^^ , oJorvr<. 
— OVr s >^W>OJ-«OC'OH^f4N»Cn< 


V) 

*J 

C if* OJ 
3 

3 

<-*<"■> o 

C *H 
£} 

0 


03 C — O ’ 

tn — i-n — «■ 


O MO-OhO^OINONhNhhoO 
«-« >Hnf\xr-rs-<o-iniNxroJnH-< 

'hno n nor^ooC'^<Nmr-«'nf^< , oc s o«<s^ 

} O 03 If n V •>"« 03 


m ««■ r*^ u* o u* 
o <n m o in C' ' 


f~< <N O PM (N C 

oj n* -< m oj 


* 03 o m O 0 s o o 


6- 

Tl 


m Ci r* 


S3 — 
- X) 

0 

o 

> jC 00 
to If* 


: (N o 
■ *?■ o; 


)«rOc2 
3 — l/l 


'Oni' fn c s inr**-ooc s *--4C s '^*Y-*o5' , nmc'fn(No 
> o- 03 os i , i(Nno>n-<v(NC'^c(NO’4'r<-i 


o. w vo io n « f 
w v n* o o 


0 m oj © in o < 

U 03 02 V 


I C*« © © — m Li 


3 ft) ■C C 
• E 

e 


> « £MO XC 03 03 

un h o v o 


pu->. 


© © r- r~, oj o m 

T3 n ^ ® n o 03 


CQCO'OOC'X' — 
•on«^nc. 

u —• 


J3(N« un 'CQ3l'lvCC'lNMOlt(NncOtf'PO^C 

o> v n «-03O03i00Jf^s0un^->aj-r^-o< , -<^' 

330303 rx ro — xr —i c 


• © o 
*TJ ^ 


•§ 


) i£) IVJ 
* m os *0 


0 03 03 ® 


r»-in«err^04—^c , ’03uno^oi^*'n-f^.o^ 
** ^ ^ oj —< oi <~-3 m 'n 


c n* 
0 


C 03 
0 •**■ 


03 © in O 03 CO c 
U3 O '/3 H o O 
O* O -« 03 n . 


c 

x 


— — t/J 
pi M -w 
CL u. 


c c 


S8 


|C3 W CC CO i 
>-c~ i.a£L( 


1 i * 


a 

<- 




— E 
' * E 


— 71 

*J c 

^'-'330 

CC V) 0 0 — 1 
Cu ac ix *j 
| ww j i- 

y> « u 

*J L <c 

OCJCC- 

^<3330 
^ 0 O '» 

V, 'J, »J a 

III 

Cu u. £L ia. CL 

< < < c < 

10 '-0 10 o s to 

< < < < < 


|to tt. 

u. fj *j tn 

< k> L( 'L 

^ S.2.2 

• a; c fj 

V. X X S 
1C 11^ 
OT CL u. 'TJ 

u < < c 

rs to to 

iL, < < CC 


CO CO r- U U 

C Cl W J 4j 

w 1/5 
CO to C I | 
^ ty. pa u. x: c c 

tflj(AC wwi > > 

Cu a Cl 
— I|D 

« «J< 

W C O CL 
C w O 
C L. I- O 
ue -l o 
H I I*j 
to 

a. u l, 


^ “ 
A 

ri< -fj 

a i 
^ w i 

c c < 

(3 •!) ( 
73 | 
V) c •• 


to CO ^ ^ 
a a a w 
‘- — a a v 

to 03 C C 
aa c c dd 

« U. j< 


C w W..-< .. 

o rH a a 

w 4J ( ICC 

c c c tj n co to 

w 'o e c w <t 
I I I ^ X5 - 
C L L E 6 O 4! 

to (J t! E £ *J *) 

c X -C o c 5 

O V 'J C C Q C 


E 

3 

to 


« 

a a m 

I 1*3 

x: jc lu 
a a c 

'C CL 
u l. c 
'L? G X 

? ! ?V 


- a < 


A-3 








IVito : 09/10/92 ASAP REPORTS Page 

Project Summary Report 
Project Complexities Summary 

Summary of ASAP Project iMLalviy.o: asap.db 


, 

i 

t/i 

C 

£ 

r 

ncM^’T'M^omn 




8 

J 

5 

2 

8 

2 

5 

r- 44 

44 © m r» © m fh 



© 

no cr. 

ro 

_ 

cy. 44 

OJ 


O' 

cr- 

- 

OS 

j 

; 


tNrtaDO'OOff'O)'' 


o 


(NOOOOCfNOINOOO'nCOOQ 


- 

OOINC 

© 03 

C 


- 

0 

c 

0 

i 

j 

w 




V 



lA^ooinrSHiy.icv 



© cr 

«* © <T- © © 


■«r 

© e 

n 



z 


©N“(om©n-©44CN 




r*» «-< © *-< © -4 

asmca'OmcoONCN 


ro 

goo 


in © 



-c- 

0 

•*r 

© 


a 





o 


-4 -4 <N © m © m 


omHior440o 


a* 

o r~ o. 


cr- -4, 

O 




*— 

© 

- Ed 

e 












. • 













j 

Oj-c'O'CfOOOSOro 


o 


•«?•©©© O © tn 

© 44 

© © O CN © © O 

© 


o 

0 

0 

ro 

O 

O CN 

O 


CN 

© 


0 


u 



\© 




4T 

















Q 























l U 

s- 


h^c^'C'O 


CO 


u cm m mo m u 

m n* 

cn © © <y. o © ci 

© 


© 

F-4 *~4 

© 

in 

© CN 

© 


© 

<0 

© 

—A 



a 


44Mi-<«r©rNmr'-©. 


<N 


m in o -r h o <■ 


© © © o «r © © 

in 



© © 

© 

wo 

—i «r 

-«• 


<0 

04 

OS 



X 



mwiT'WOHff'ifl-i 


in 


o m o crici C -4 

© -4 

m cn n* r» cn © © 

n 


I s - 

no «r 

cr- 

44 

4i rv 

O 


tr- 

V 

© 

V 


l 

U. 




m 


QMnmoTO 

cn in 

m © © © 44 

44 


o 

V O 

44 

44 

cn «r 

in 


© 

cr- 

© 

in 

i 

t 

u. 


co m- co o to -c- 




r*- •—« cn m 

r4 M 

cn © 4- 



© 

m 



© m 



m- 




1 

l 

hi 


^ OS r-« <N 




CN <7' 


44 





CN 


44 







! 


( 






CN 


















« 


—( ©. © ©. f-i ~4 * (N 


<N 


•h © o © cr. ie 

© © 

n- © <n © © 

© 


e- 

o in 

CN 

c 

cn e 

© 





© 

« 


z 


cn 


<N 


h r, C' iA « ^ © 

© NT 

n 4}“ C' CN 4j- CN 

<T‘ 


M 

© cr 


44, 

0 © 

© 


© 

»-4 

© 

CN 

t 

1 

<: 


<••••••* 




















1 




rv©-*?-.— «r«rir>* © 


ro 


a3COCN4-i^-.'crO©!Ncr. 4TC0©'*'. ^CNOJ 


© 

ro © in © 

in 0 0 


© 




[ 

*3 

i 


*h r-* in ©. © in * ^ 




CN CN ro CN 

in «■ 

^ (N H <• T H f4 




CN 




-4 



44 



< U 

i 


»i *h ?o a> * 




















I u 

z 




O 


-4«r®o©©©oe'©©05<Nin©M<N 


CN 

CO © 

r*» o os C 



© 

in 

c © 


-2 

oc 


OMnoa«rN»ro 


m* 


-4n®lO^AliNO(N(OtOOU5" r l v<' 

•*r 


© 

m 4- 

© 

fO 

ro © cr- 


© 

0 * 

4- 

© 

1 


o 


Lrv©ie«j*©»-ir-©^- 


© 


m©'4r*«03OMacsff'«r'i)r.f»i(r 

CN 


4T 

i— in cn cr 

v «r 

ro 


ro 

© 

c 

©• 

1 


o 

cc 

a 


OOOrOO^r^m© 


© 


OhhhhhQ 

-1 o 

«T © 44 © 44 44 44 

44 


O 

44 © o 

44 

O C 

44 


O 

0 


© 

1 



oooooooo© 


© 


©OOOOOOOO 

oooooooo 


© 

© © o 

e 

a c 

Q 


© 

© 

© 

O 

1 


z 


r** r, ro v in c r*> co 


m 


HrimNiAinoN'fNMnoir.co^ 




m in e- 

4 

© f- 

© 


© 

0 

© 

ro 



Q 


■*rn(T-«ror'-Hinff' 


m 


© 30 a- cn r*v ^ cn 

<r -4 

e V <n IA CM (N X N 


Tf 

40 44 , 

e- 

«T 


C- 


© 

© cr 

n 

J 


f- 


ro n »r m tc <r ti 




CN r~i -+ CN »-t 

«n in 

cn 44 r-» ~n 



44 

f4 44 

44 


«4 0 : 



44 

44 



» 

W 

j= 

£ 


--S <* “0 




















w 

D 























esc 

-J 

Z 


mccfnJO'NfnHC' 


CN 


©^4mux©o©CN-4 

in <?•' in © © 4t- © 

CO 


in 

© © 

r* 


in «j- 

4T 


m 

O CN 

—1 





r^r~r*'C’-'(Nvirio 




Q CO (N cn M 4T O’- 


f 4 <?, m <n x in cn 

<7. 


CN 

© © 

<• 

CN 

©0-0 


© 

© 

f>- 

-r- 

> 

§ 


or-Or, <N—*.-<eDco 


n 


v>©xnMnciN 

tN <«• O' O v (J> r*. 

-4 


cr- 

r**- © 

cr- 

CN © 44 

0 . 


0 

O © 

in 

fS 

t 



O « 'Ll o (J> 




CD -4 CN m* CN © 

CN -4 (N 



CN 

CN 

© 


CN © 



in 

CN 






H(N (N OJ 




















z 

1 

a 






















G 

l 

a 


inMorNina)©-*-'©' 


CN 


O lA H IN O (MO 

'©tn©OMCN»CN 


cr- 

n» 44 , 

p* 

(N <7- © 

44 


e- 

O' 

— 


< 

t 

hi 


ro r- o ©. co co © m ©- 


© 


in cr> r*» cr h y*. i-i 

CN M 

o> m m © © © »-< 

o* 



oj n cn cr- 

>4 © 

OJ 


CO 

fO CN 

© 


jg 

CC 


vo5v*03©«rr-©<o 


•—< 


0«-4rnT-4r*-.mm-4 

m CN © N* CN — 



no 

4 - o« 





OJ 

in os 

44 

fc- 


a 


/1W *o <N 44 44 




pn 











,— 





w o 



a—* 















E 





_ 

Z 



G 















W 





< w 

V 


w 05 in a- r, v h n tr. m 


<N 


as r. m » a r>i -4 

F4, <y. 

cr.in © © cr cr- r- 



4T 

U"i JO Ol X U Os 

© 



0 - 

<■ 

F»S 

E 

-3 

G 


«** oo © co cn in ro © r*» 


rv 


«• 4T © rN © 

hCN'tOXiAMO^^- 


f*% 

s/~i IT- 

o 

T Ol x 

O) 


© 

c 

r- 

© 

1 

S 

cc 


o m m M ^ 4-< 33 CN 




H rl i\ r” n r4 O 


xr »-t in ^ 4-i 




—« «r 

-a 


N- X 

1-4 

V. c- 


4 - 

44 


1 

a 


w —• - 1 C") (N <o ^ 











4- 




aJ 





1 

1 



jJ 















c 





1 




c 















3 






J 

CC 


3©*rCNCN©©ooo 


CN 


CN CN ® 33 © © © 

2 

0 

8 

0 

6 

2 

0 

0 

2 


o 

Q © OJ © © © 

«• 

C <N 

CN © 

© 


< 

t- 


0 r- os oj o o *o 




•-4 ^4 pH ^4 »-< 

© 

4(Nf,0«T-HH 



CN 

OJ F- 

OJ 


*— 

*-l 

u 







a. 


U HHV«r 




















1 

i 


c 


*Z 















2 





1 


Q 


XimomcnctNco 


09 


m r- <r* a> —< o 

M 44 

m in o» © «r o> ■© © 


C- 

© C 

© © <y- cr © C 


ro 

© © 

1 

- 

Z 


0 m <—< (N ro in 




rn ^4 —4 m 44 

in m 

OJ F4 <+ 4. -4 







F-4 05 



ro 

fO 





a 

















u 





1 

s, 


• 

G 















x: 





1 




_G 















V. 





1 

1 

CSC 


^©■'©CN^r^CNajoo* 


fv 


o^hctvmd 

M CO 

^ OnrOOi4«TN 


cr- 

ro © 

© 

*r 

0 os g 



-o 

47 - 


1 

1 

H 


"0 © «r o © moimn^ 




4 r. mo n c v 

P4- © 

<r x h run o *r os 


o 

F-4 O 

o 

4F, 

■w to 

© 

C V 1 ' 1 

«• 

© 

© 

1 

l 

a 


T>m©Q4H©ro(Na3r*> 




r* —4 <N »— rr 

44 4T 

CN F4 © OS 44 



ro 

44 F4, 

r*» 


OS IT 




OS 

— 



JL 

a 


< <N -» CN 






F~< 









u. 





i 

< 

C 

! 

JJ 















© 






5 

G 


l, ©. ©. ©. © crm cr cc 


in 


®rNCNcr v '-n n ai h 

© m in m r~- © -n 

c-* 


in 

oj cr 

© 


OJ C 

O 

U © 



04 

i 


2 


c--«4-cr>(NCN0J0J03CN 


CN 


n vn a' ri <• n m 

«r •«■ 

v in co os © o» 

—4 


© 

4r *r 

c- 


© "4 

V 

X 

N* 

© 

o- 

4J- 

i 

i 

CSC 


Cl VI CO CO C7- ©• tn 




V — 

— © 

— i/i- 



44 


-0 




LL 

<r 

FA 



i 

i 

a 


CO «-* 















Vi 





i 

t 

Q 


u 















aJ 





i 



! 

c 















C 






i 

CC 


3 Tf fi IN ", rOC(NM^ 


—4 


a co v ir o n -f 

r-i © © «r r- cr* m r*- 

m 


c- 

OJ 

4~ m 

C- r 

“4 

3 -w 

4T 

r> 

© 



H 


Cr>»r<f*"rC'r^fNC^ 


•^4 


lOl -i 4 1 0» 4P fM >4 

ns © 

44 -c* -o r- xr os 4 - 

F—< 


4J- 

OJ 44, 

<n 

44 

.0 ■© 

(N 

0 


<- 

04 



d 

iL 


V *o oj o: 




















CD 

yj 


*j 














































c 


cot’^it^ m m. ir. v 


© 


•-4 '© CD 33 © vn © 

*-« 4 - m © ^ nn 

G 


|4\ 

cr- o 

m 

o 

© O- 

—* 

c © 

04 

F- 

©• 



z 






O CN CN r-4 C<n f4 © 

-4 

CN OS in 4T CN 44 



CN 

os 

CN 

4— 

-tf- © 

CN 


ro 

M -1 

05 

—* 


© 



TJ *-4 —4 •—. 




fh m 

~4 










TJ 

















G 


V. 





—. 

F— 
















CL 


CL 





■ — 

CC. 




Li- 


_ 


3INf^!\CinC^OO 


© 


-4 #-« m © r»> © © 

44 <J~ 

O un o cr o © © 


.— 

*C 

L O 

7- 

o 

v CC 

© 

3 

ro VJ 

4T 


O 

n 




S - C O VO © rn 




4T ^4 —i 

nj 




OJ 


T~ 


1-4 4F 



A_- 

04 



< u 

1. 


■ " (N 








C 


C 










o 

s~ 

r - / 










G 


G 





aJ 

aJ 




i. 

; 

G 










i/. 


SI, 





La 









G 

03 


e 







— 





~ 

c 








a. 

G 


2- 





L. 


L. 





_ 

z 









*- 


— 





X 


T 





c 

L. 








v 








Cm 


Cl 






cc 








>. 



Ci 




s 

fc 


E 





>- 

r~ 








U 

u 




CZ 


L"3 



Q 





La 

V, 









X 


■g 


V. 











--A 








E G 

« 


■4—< 

X ir. 











L 

c 








E Vj 

u 


U 

G Z*. 



cr 

o 







E 

- — 








3 



c 

*—. v *—* »— 

G 



C 


C 






J, 








CT, 



AJ 

cC ir, 


4— 


















*J V, 

c 


c 

in •/) v, a. 

— 



U 


L. 





aJ 

V. 














Cl Cl 

vs 









c 






W 


0 




c c 



V! 

V, 


Ci. 





.; 

G 


z~ 

v2 



a 

i 


<v 


c 

4_J — — 1/1 

-- -- 

G W 

v 



| 



44 


■-' 

— 


... 

CL 



p- 


j -> 

c 


c 

fj -> aJ c 

©GW — 3 s r- G G 


t- 




Vi 

G 


3 . 

aJ 


4—- 

w 





u 

■’-t 



V. r-. 3 3 0 

••4 Q. 

G G W -«C lc -- 


> 


> 


CL 

0 . rO 


La 









G. — 

l—i 



r+ 2 W 0 0 ,H 

c ■— 

— G. £. G u, 

> 



■ — 


^-r 

.—• l_ 

__ 

CL 



O 

O' 





133 CO fl W 33 W 




uo G. G- esc a: u 


W W | ( 




iJ 4 s 

4 


— 






,j£ 



z 


% >*G- ClQ.CuQ.1 

T3 


T5 

I--' S IX 

IW 

V, V5 v, U _C 

aJ 



•— t/i 

d 

v/ 

C 


V. 

> 


CL 

L. 



< 


*J --I -w» '-• W --• W 

C 


c 

CL t/; V. L, 

G © 

© VS w 4." CL CL CL 

• -« 

V. 


Ci, CL 

CL 

C 

c r 


AJ 




! 






fC 


X 

x< u 

)- t 1 O 8f 

VS 

c 


C — 

•S-F 

-«4 

•4* -L 

5* 

La 

CL 


-CC 

■C 






fc 


E 

W O O C C »-4 

W 0 0 5? t u u o o 

c 

1- 


c 


44 

—< CL 

*7, 

p 

CL 






X 


a 

fc 


t 

< D t 3 3 C)< tau ^ t 


‘•J, 


Vi aJ 



1 ; 

... 




r 

■j 



< 


'v ■ ^ — -4* •- .*4 ~1 C/5 

0 


W 

1 O *) o 0 L' 

« 4* 


IF. 

c 


C C 

L 

T". 

O’ v 

'.0 




Ia 

La 



2 


a i. j j jv 

0 


u 

o. W W L' O Ci 

i- DC 

X >4>4>i >*V) V. 

c: 

.M 


— V. 

Ci: 

U 

C 77 

-* 

,x 

La 


* 






l 0 3 3 3 3 3 3 




C Jill 

4 

i U u U U LC Lt. 

■—> 



I 






L 






C-. 






Vi El g. £~ Cl g. 


CL X " X X C’ L 


■V 


a v, 

U 

t; 

V. X 

X 

d. 

v. 


Y 

Y 



»— 


< 

X 


T 

!-<<<<< 

i_ >' 

< c c c c C J 

v: 

l/, 


J. T 

f? 

fc 

E 

-J 

< 

L 


, ‘ 

,' 



Z 


*.*'. — 'i. r.. r. r.. £. ji. :/; 

5f, 


1/. 

X VJ V3 V3 V3 V. 

X V3 


-r> 

T 


X JZ 

/: 



"7 


O 


— 






< L. O C <5 C C t< 

X 


X 

G < < < < < 

© < 

< 3 S 33 - 3 X 

'-J 

G 


L 

L 

G 

'- ►_ 

© 

< 

L. 


j- 



A-4 










0‘>/l O/vU ASAP REPORTS 

Project Summary Report 
Project Olobd) Summary 


o © o o o o 


© c o o c o 


fNvcrs. «r © ©CO ©Co 


o c o o c © 


COO COO CO: 


© © c. <«r fn oo in in r-. rv >• 

O (N m r— C- O X 03 cn «r (7- oo —> 


© «-* — <N 


COT-t\*> rn rs OttO ©• xr m O O) V 
cn 03 CN Or^>» <i) S 3 v O fNJ CN (N « o 

CO «T m f\ CN ©• © « f. ^ **, 

O <N <7- _4 m xr 


E; *i- *; C c^c F- c n c c C cC 

_ ^ 3 w- 3 3 ZJ 2 3 ^3C3 3Z3 

v. w'vr's.iojcs. s. s: v — 'v t: 
“■ z cEt; c. a c e a cb£ t6f-z i 6* c. a :- -.a 

r- ,. -_■ ~ J ~ 3 C'az ?5C t- 3 Z i: C- 3 ~ Z 3 - ~ 3 Z r:i 

-f> (i.iO«l-hl,,j«l.. u — X < - >-— — 

<i ->-;S : “ J ' :e S; ,J 36i;eT:szw'ra*tW'rEc: .JTEtvTi; - j-TEjS-j-jEf-- 


I 


«ivf>r.jf^‘/un 11 






ASAP KKPORTS Page 10 

Project Summary Report 
Project Global Summary 



I/(JbH.'j/tft l/00H.V/8 r > 47!>. 1 .)j9 0.0000 2*6.)',0‘> 0.0000 0.06/8 0.0000 














GLOSSARY 


ASAP Ada Source Analyzer Program 

CU Compilation Unit 

DoD Department of Defence 

LU Library Unit 

LUA Library Unit Aggregations 

MOIE Mission Oriented Investigation and Experimentation 

PSR Project Summary Report 

SWEC Software Engineering Center 

SA System and Acceptance Test 

SAS Statistical Analysis System 

SEL Software Engineering Lab 

USA Unit, System and Acceptance Test 


*U.S. GOVERNMENT PRINTING OFFICE 1993-710-3? 


GL-1 




