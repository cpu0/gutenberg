UNCLASSIFIED 



AD NUMBER 


ADB222369 


NEW LIMITATION CHANGE 
TO 

Approved for public release, distribution 
unlimited 


FROM 

Distribution: Further dissemination only 
as directed by U.S. Army Strategic Defense 
Command, Attn: SCCD-IM-PA, P.0. Box 1500, 
Huntsville, AL 35807-3801, Jan 97 or 
higher DoD authority. 


AUTHORITY 


Phillips Lab. [AFMC] Kirtland AFB, NM ltr 
dtd 30 Jul 97 


THIS PAGE IS UNCLASSIFIED 













PL-TR-96-1126, Pt. 1 


PL-TR- 
96-1126, 
Pt 1 


ADVANCED HARD REAL-TIME OPERATING SYSTEM, 
THE MARUTI PROJECT 

Part 1 of 2 

Ashok K. Agrawala 
Satish K. Tripathi 

Department of Computer Science 
University of Maryland 
College Park, MD 20742 

January 1997 

Final Report 


Further dissemination only as directed by the U.S. Army 
Strategic Defense Command, ATTN: SCCD-IM-PA, P.O. 
Box 1500, Huntsville, AL 35807-3801, January 1997, or 
higher DoD authority. 


WARNING - This document contains technical data whose 
export is restricted by the Arms Export Control Act (Title 22, 
U.S.C., Sec 2751 et scq .) or The Export Administration Act 
of 1979, as amended (Title 50, U.S.C., App. 2401, et sea.) . 
Violations of these export laws are subject to severe criminal 
penalties. Disseminate IAW the provisions of DoD Directive 
5230.25 and AFI61-204. 


DESTRUCTION NOTICE - For classified documents, follow the procedures in DoD 5200.22-M, Industrial Security Manual, 
Section II-19 or DoD 5200.1-R, Information Security Program Regulation, Chapter IX. For unclassified, limited documents, destroy 
by any method that will prevent disclosure of contents or reconstruction of the document. 


JDSSC QUALITY IHSI 


3CESB P 



PHILLIPS LABORATORY 


19970415 061 


Space Technology Directorate 

AIR FORCE MATERIEL COMMAND 

KIRTLAND AIR FORCE BASE, NM 87117-5776 













PL-TR-96-1126 


Using Government drawings, specifications, or other data included in this document for 
any purpose other than Government procurement does not in any way obligate the U.S. 
Government. The fact that the Government formulated or supplied the drawings, 
specifications, or other data, does not license the holder or any other person or 
corporation; or convey any rights or permission to manufacture, use, or sell any patented 
invention that may relate to them. 


If you change your address, wish to be removed from this mailing list, or your organization 
no longer employs the addressee, please notify PL/VTS, 3550 Aberdeen Ave SE, Kirtland 
AFB, NM 87117-5776. 

Do not return copies of this report unless contractual obligations or notice on a specific 
document requires its return. 

This report has been approved for publication. 




Chief, Satellite Control and Simulation 
Division 


FOR THE COMMANDER 



CHRISTINE M. ANDERSON, SES 
Director, Space Technology 





DRAFT SF 298 


1. Report Date (dd-mm-yy) 2. Report Type 

January 1997 Final 


4. Title & subtitle 

Advanced Hard Real-Time Operating System, The Maruti 
Project 


6. Author(s) 

Ashok K. Agrawaia 
Satish K. Tripathi 


3. Dates covered (from... to ) 
4/92 to 10/96 


5a. Contract or Grant # 

DASG-60-92-C-0055 


5b. Program Element # 62301E 


5c. Project # DRPB 


5d. Task # TB 


5e. Work Unit# AT 


7. Performing Organization Name & Address 
Department of Computer Science 
University of Maryland 
College Park, MD 20742 


8. Performing Organization Report # 


9. Sponsoring/Monitoring Agency Name & Address 
Phillips Laboratory 
3550 Aberdeen Ave. SE 
Kirtland, AFB, NM 87117-5776 


10. Monitor Acronym 


11. Monitor Report # 
PL-TR-96-1126, Parti 


12. Distribution/Availability Statement 

Further dissemination only as directed by the U.S. Army Strategic Defense Command, ATTN: SCCD-IM-PA, P.O. 
Box 1500, Huntsville, AL 35807-3801, January 1997, or higher DoD authority. 


13. Supplementary Notes 


14. Abstract System correctness for real-time systems relies on both functional and temporal correctness of 
the system components. In order to allow creation and deployment of critical applications with hard real-time 
constraints in a reactive environment, we have developed the Maruti environment, which consists of the Maruti 
operating system and runtime environment, and an application development and environment that uses the 
Maruti Programming Language (MPL), an extension of ANSI C; the Maruti Configuration language (MCL), which 
specifies how MPL modules are to be connected and any environmental constraints; and various analysis and 
debugging tools. The core of the Maruti runtime system is the Elemental Unit (EU) and calendar. An EU is an 
atomic entity triggered by incoming data/signals, that produces data/signals. A calendar specifies the 
execution order and time for each EU. Calendars are static entities created during application design and 
development, thus allowing temporal debugging of applications before they are executed on the machine. A 
given application may have more than one calendar to allow contingency or degraded operation. 


15. Subject Terms 

Real-Time operating systems, fault tolerance, concurrency, embedded systems, environments 


Security Classification of 

16. Report 
Unclassified 

17. Abstract 
Unclassified 

18. This Page 
Unclassified 


19. Limitation 20. # of 
of Abstract Pages 

Limited 220 


21. Responsible Person 
(Name and Telephone #) 

Capt Jim Russell 
(505) 846-8986 ext 352 


i / i i 
































TABLE OF CONTENTS 


1. Executive Summary i-iii 

2. “Optima] Replication of Series-Graphs for Computation-Intensive 1-37 

Applications” 

By: A. K. Agrawala and S.-T. Cheng 

3. “Designing Temporal Controls” 39-61 

By: A. K. Agrawala, S. Choi, and L. Shi. 

4. “Scheduling an Overloaded Real-Time System” 63-92 

By: S.-I. Hwang, C.-M. Chen, and A. K. Agrawala 

5. “Notes on Symbol Dynamics” 93-104 

By: A. K. Agrawala and C. A. Landauer 

6. “Allocation and Scheduling of Real-Time Periodic 105-127 

Tasks with Relative Timing Constraints” 

By: S.-T. Cheng and A. K. Agrawala 

7. “Scheduling of Periodic Tasks with Relative Timing Contraints” 129-150 

By: S.-T. Cheng and A. K. Agrawala 

8. “A Scalable Virtual Circuit Routing Scheme for ATM Networks” 151-175 

By: C. Alaettinoglu, I. Matta, and A. U. Shankar 

9. “Hierarchical Inter-Domain Routing Protocol with 177-212 

On-Demand ToS and Policy Resolution” 

By: C. Alaettinoglu and A. U. Shankar 

10. “Optimization in Non-Preemptive Scheduling for a pPriodic Tasks” 213-257 

By: S.-I. Hwang, S.-T. Cheng, and A. K. Agrawala 

11. “A Decomposition Approach to Non-Preemptive Real-Time Scheduling” 259-279 

By: A. K. Agrawala, X. Yuan, and M. Saksena 

12. “Viewserver Hierarchy: a Scalable and Adaptive 281-314 

Inter-Domain Routing Protocol.” 

By: C. Alaettinoglu and A. U. Shankar 

13. ‘Temporal Analysis for Hard Real-Time Scheduling” 315-322 

By: M. Saksena and A. K. Agrawala 

14. “Implementation of the MPL Compiler” 323-340 

By: J. M. Rizzuto and J. da Silva 

15. “Maruti 3.1 Programmers’s Manual, First Edition” 341-380 

By: Systems Design and Anlysis Group, 

Department of Computer Science, UMCP 

16. “Maruti 3.1 Design Overview, First Edition” 381-406 

By: Systems Design and Anlysis Group, 

Department of Computer Science, UMCP 






Executive Summary 


Introduction: 

This is the final report on the work done under contract DASG-60-92-C-0055 from Phillips 
Labs and ARPA to the Department of Computer Science at the University of Maryland. 
The work started 04/28/92. The goal of this project was to create an environment for 
development and deployment of critical applications with hard real-time constraints in a 
reactive environment. We have redesigned Maruti system to address these issues. In this 
report we highlight the achievements of this contract. A publications list and a copy of each 
of the publications is also attached. 

Application Development Environment: 

To support applications in a real-time system, conventional application development 
techniques and tools must be augmented with support for specification and extraction of 
resource requirements and timing constraints, The application development system 
provides a set of programming tools to support and facilitate the development of real-time 
applications with diverse requirements. The Maruti Programming Language (MPL) is used 
to develop induvidual program modules. The Maruti Configuration Language (MCL) is 
used to specify how individual program modules are to be connected together to form an 
application and the details of the hardware of which the application is to be executed. 

In the current version, the base programming language used is ANSI C. MPL adds 
modules, shared memory blocks, critical regions, typed message passing, periodic 
functions, and message-invoked functions to the C language. To make analyzing the 
resource usage of programs feasible, certain C idioms are not allowed in MPL; in 
particular, recursive function calls are not allowed nor are unbounded loops containing 
externally visible events, such as message passing and critical region transition. 

MPL Modules are brought together into as an executable application by a specification file 
written in the Maruti Configuration Language (MCL). The MCL specification determines 
the application’s hard real-time constraints, the allocation of tasks, threads, and shared 
memory blocks, and all message-passing connections. MCL is an interpreted C-like 
language rather than a declarative language, allowing the instantiation of complicated 
subsystems using loops and subroutines in the specification. 


Analysis and Resource Allocations: 

The basic building block of the Maruti computation model is the elemental unit (EU). In 
general an elemental unit is an executable entity which is triggered by incoming data and 
signals, operates on the input data, and produces some output data and signals. The 
behavior of an EU is atomic with respect to its environment. Specifically: 

• All resources needed by an elemental unit are assumed to be required for the entire 
length of its execution. 

• The interaction of an EU with other entities of the system occurs either before it starts 
executing or after it finishes execution. 


XV 







In order to define complex executions , the EUs may be composed together and properties 
specified on the composition. Elemental units are composed by connecting an output port 
of an EU with an input port of another EU. A valid connection requires that the input and 
output of port types are compatible, i.e., they carry the same message type. Such a 
connection marks a one-way flow of data or control, depending on the nature of the ports. 
A composition of EUs can be viewed as a directed acyclic graph, called an elemental unit 
graph (EUG), in which the nodes are the EUs, and the edges are the connections between 
EUs. An incompletely specified EUG in which all input and output ports are not connected 
is termed as a partial EUG (PEUG). A partial EUG may be viewed as a higher level EU. 
In a complete EUG, all input and output ports are connected and there are no cycles in the 
graph. The acyclic requirements come from the required time determinacy of execution. A 
program with unbounded cycles or recursions may not have a temporally determinate 
execution time. Bounded cycles in an EUG are converted into a acyclic graph by loop 
unrolling. 

Program modules are independently compiled. In addition to the generation of the object 
code, compilation also results in the creation of partial EUGs for the modules, i.e., for the 
services and entries in the module, as well as the extraction of resource requirements such 
as stack sizes or threads, memory requirements, and the logical resource requirements. 

Given an application specification in the Maruti Configuration Language and the component 
application modules, the integration tools are responsible for creating a complete application 
program and extracting out the resource and timin g information for scheduling and 
resource allocation. The input of the integration process are the program modules, the 
partial EUGs corresponding to the modules, the application configuration specification, and 
the hardware specifications. The outputs of the integration process are: a specification for 
the loader for creating tasks, populating their address space, creating the threads and 
channels, and initializing the task; loadable executables of the program; and the complete 
application EUG along with the resource description for the resource allocation and the 
scheduling subsystem. 

After the application program has been analyzed and its resource requirements and 
execution constraints identified, it can be allocated and scheduled for a runtime system. 

We consider the static allocation and sched ulin g in which a task is the finest granularity 
object of allocation and an EU instance is the unit of scheduling. In order to make the 
execution of instances satisfy the specification and meet the timing constraints, we consider 
a scheduling frame whose length is the least co mm on multiple of all tasks’ periods. As 
long as one instance of each EU is scheduled in each period within the scheduling frame 
and these executions meet the timing constraints, a feasible schedule is ob tain ed 


Maruti Runtime System: 

The runtime system provides the conventional functionality of an operating system in a 
manner that supports the timely dispatching of jobs. There are two major components of 
the runtime system - the Maruti core, which is the operating system code that implements 
scheduling, message passing, process control, thread control, and low level hardware 
control, and the runtime dispatcher, which performs resource allocation and scheduling or 
dynamic arrivals. 



The core of the Maruti hard real-time runtime system consists of three data structures: 

• The calendars are created and loaded by the dispatcher. Kernel memory is reserved for 
each calendar at the time it is created. Several system calls serve to create, delete, 
modify, activate, and deactivate calendars. 

• The results table holds timing and status results for the execution of each elemental 
unit; The maruti_calandar_results system call reports these results back up to the user 
level, usually the dispatcher. The dispatcher can then keep statistics or write a trace 
file. 

• The pending activation table holds all outstanding calendar activation and deactivation 
requests. Since the requests can come from before the switch time, the kernel must 
track the requests and execute them at the correct time in the correct order. 

The Maruti design includes the concept of scenarios, implemented at runtime as sets of 
alternative calendars that can be switched quickly to handle an emergency or a change in 
operating mode. These calendars are pre-scheduled and able to begin execution without 
having to invoke any user-level machinery. The dispatcher loads the initial scenarios 
specified by the application and activates one of them to begin normal execution. 


VI 


Optimal Replication of Series-Parallel Graphs for 
Computation-Intensive Applications* 


Sheng-Tzong Cheng 
Ashot K. Agrawala 

Institute for Advanced Computer Studies 
Systems Design and Analysis Group 
Department of Computer Science 
University of Maryland, College Park, MD 20742 
{stcheng,agrawala}@cs.umd.edu 


‘This work is supported in part by Honeywell under N00D14-91-C-P195 and Army/Phillips under DASG-60-92- 
G-0055. The views, opinions, and/or findings contained in ibis report are those of the anther(s) and should not be 
interpreted as representing the official policies, either expressed or implied, of Honeywell or Army/Phillips. 


1 






Optimal Replication of SP Graphs for Computation-Intensive Applications 


I 


Prof. Ashok K. Agrawala 
Department of Computer Science 
University of Maryland at College Park 
A.V. Williams Building 
College Park, Maryland 20742 
(Tel): (301) 405-2525 

Abstract 

We consider the replication problem of series-parallel (SP) task graphs where each task may 
run on more than one processor. The objective of the problem is to minimi?. * the total cost 
of task execution and interprocessor communication. We call it, the minimum cost replication 
problem for SP graphs (MCRP-SP). In this paper, we adopt a new communication model where 
the purpose of replication is to reduce the total cost. The class of applications we consider 
is computation-intensive applications in which the execution cost of a task is greater than 
its communication cost. The complexity of MCRP-SP for such applications is proved to be 
NP-complete. We present a branch-and-bound method to find an optimal solution as well as 
an approximation approach for suboptimal solution. The numerical results show that such 
replication may lead to a lower cost than the optimal assignment problem (in which each task 
is assigned to only one processor) does. The proposed optimal solution has the complexity of 
0{Ti 7 2 n M). while the approximation solution has 0(n*M 7 ), where n is the number of processors 
in the system and M is the number of tasks in the graph. 


I 


2 


1 




1 Introduction 


Distributed computer systems have often resulted in improved reliability, flexibility, throughput, 
fault tolerance and resource sharing. In order to use the processors available in a distributed 
system, the tasks have to be allocated to the processors. The allocation problem is one of the 
basic problems of distributed computing whose solution has a far reaching impact on the usability 
and efficiency of a distributed system. Clearly, the tasks of an application have to be executed 
satisfying the precedence and other synchronization constraints among them. (Such constraints are 
often specified in the form of a task graph.) 

In executing an application, defined by its task graph, we have the option of restricting ourselves 
to having only one copy of each task. The allocation problem, in this case, is referred to as 
assignment problem. IS, on the other hand, a task may be replicated multiple times, the general 
problem is called the replication problem. In this paper, we consider the replication problem and 
present an algorithm to find the optimal replication of series-parallel graphs for computation¬ 
intensive applications. 

For distributed processing applications, the objective of the allocation problem may be the 
minimum completion time, processor load balancing, or total cost of execution and communication, 
etc. For the assignment problem where the objective is to minimize the total cost of execution and 
interprocessor communication, Stone [11] and Towsley [12] presented 0(n z M) algorithms for tree- 
structure and series-parallel graphs, respectively, of M tasks and n processors. For general task 
graphs, the assignment problem has been proven [9] to be NP-complete. Many papers [8][9][10] 
presented brancib-and-bonnd methods which yielded an optimal result. Other heuristic methods 
have been considered by Lo [7] and Price and Krishnaprasad [5]. All these works focused on the 
assignment problem. 

Traditionally, the main purpose of replicating a task on multiple processors is to increase the 
degree of fault tolerance [2][6], If some processors in the distributed system fail, the application may 
still survive using other copies. In such a communication model, a task has to communicate with 
multiple copies of other tasks. As a consequence, the total cost of execution and communication 
of the replication problem will be bigger than that of the assignment problem. In this paper, we 
adopt another communication model in which the replication of a task is not for the sake of fault 
tolerance but for decreasing of the total cost. In our model, each task may have more than one copy 


3 







and it may start its execution after receiving necessary data from one copy of each preceding task. 
Clearly, in a heterogeneous environment the cost of execution of a task depends on the processor on 
which it executes, and the communication costs depend on the topology, communication medium, 
protocols used, etc. When a task i is allowed to have only one copy in the system, the sum 
of the interprocessor communication costs between i and other tasks may be large. Sometimes 
it will be more beneficial if we replicate t onto multiple processors to reduce the inter-processor 
communication, and to fully utilize the available processors in the systems. Such replication may 
lead to a lower total cost than the optimal assignment problem does. An example illustrating this 
point is presented in Section 3. 

In the assignment problem, polynomial-time algorithms exist for special cases, such as tree- 
structure [11] and series-parallel [12] task graphs. This paper represents one of the first few attempts 
at finding special cases for the replication problem. The class of applications we consider in this 
paper is computation-intensive applications in which the execution cost of a task is greater than its 
communication cost. Such applications can be found in an enormous number of fields, such as digital 
signal processing, weather forecasting, game searching, etc. We formally define a computation¬ 
intensive application in Section 2.2. In this paper, we prove that for the computation-intensive 
applications, the replication problem is NP-complete, and we present a branch-and-bound algorithm 
to solve it. The worst-case complexity of the solution is 0(v. 7 2 n M). Note that the algorithm is 
able to solve the problem in the complexity of the linear function of M. 

We also develop an approximation approach to solve the problem in polynomial time. Given a 
forker task s with K successors in the SP graph, the method tries to allocate s to processors based 
on iterative selection. The complexity of the iterative selection for a forker is 0{n 7 K 7 ), while the 
overall solution for an SP graph is 0(n 4 M 7 ). 

In the remainder of this paper, the series-parallel graph model and the computation model are 
described in section 2. In section 3, the replication problem is formulated as the TniniTnnm cost 
0-1 integer programming problem and the proof of NP completeness is given. A branch-and-bound 
algorithm and numerical results are given in section 4, while the approximation methods and results 
are given in section 5. The overall algorithm is presented and conclusion remark is drawn in section 
6 . 


4 




2 


Definitions 


2.1 Graph Model 

A series-parallel (SP) graph, G = (V, E), is a directed graph of type p, where p 6 {r umt , Tchain, 
T an d, Ter] and G has a source node (of indegree 0) and a sixth node (of outdegree 0). An SP graph 
can be constructed by applying the following rules recursively. 


1. A graph G — ( V,E ) = ({«}, 4>) is an SP graph of type r u m t . (Node v is the source and the 
sink of G.) 

2. If Gi = (Vi ,E{) and G 2 = {V 2 ,E^) are SP graphs then G’ — (V', E') is an SP graph of type 
Tchain, where V' = V 1 u V 2 and E 1 = £j U E 2 U {<sini of Gi, source of G 2 >}. 

3. If each graph Gi = (K,£.-) with source-sink pair ($,•,<,•), where s, is of outdegree 1, is an SP 

graph, V i = 1,2,.. .,n, and new nodes s' # Vi and t' £ K’, V i are given then G' = (V', £') is 
an SP graph of type T an d(or type TV), where V' = Vj U V 2 U ... U V n U {s', f } and E' = Ei 
U E 2 U ... U En U {< s',Si > I V i = 1,2,.. .,n } U {< t„t / > | V i = 1,2,.. .,n }. The source 

of G', s', is called the Jorker of G'. The sink of G', t', is called the joiner of G'. G' is an SP 

graph of type T on rf(or type TV) if there exists a parallel-and (or parallel-or ) relation among 
G, 5 s. 

A convenient way of representing the structure of an SP graph is via a parsing tree [4]. The 
transformation of an SP graph to a parsing tree can be done in a recursive way. There are four 
kinds of internal nodes in a parsing tree: TVut, Tchain, T an d and TV nodes. A TViit node has only 
one child, while a Tchain node has more than one child. Every internal node x, along with all its 
descendant nodes induces a subtree S z which describes an SP subgraph G r of G. Each leaf node 
in S s corresponds to an SP graph of type T w i t . A T an d(oT Tor) node y consists of its type T an d(or 
Tor ) along with the forker and joiner nodes of G y . We give an example of an SP graph G, and its 
parsing tree T’(G) in Figure 1. 


5 





2.2 Computational Model 

An application program consists of M tasks labeled m = 1 . 2, .. M. Its behavior is represented 
by an SP graph with the tasks correspond to the Dodes. Each task may be replicated onto more 
than one processor. A task instance t l>p is a replication of task t on processor p. A directed edge < 
j > between nodes i and j exists if the execution of task j follows that of task i. Associated with 
each edge < :, j > is the communication cost incurred by the application. We are concerned with 
types of applications where the cost of execution of a task is always greater than the communication 
overhead it needs. The model is stated as follows. 

Given a distributed system 5 with n processors connected by a communication network, an 
application is computation-intensive if its associated SP graph G = (V, E) on S satisfies the 
following conditions: 

1 - > 0 , 

2 . £ 9=1 ?) < nunp( >€ E , and 1 < p < n, where 

• ?) Is the communication cost between tasks i and j when they axe assigned to processors 
p and q respectively, and 

• ei tP is the execution cost when task i is assigned to processor p. 

The first condition states that the communication cost between any two task instances (e.g. 
and tj.9) is not negative. The second one depicts that for every edge < i,j >, the worst-case 
communication cost between any task instance and all its successor task instances (i.e. V 
q) is less than the minimum execution cost of task i. 

2.3 Communication Model 

The communication model we considered is different from that of reliability-oriented replication. 
In reliability-oriented replication problem, the objective is to increase the degree of fault tolerance. 
To detect fault and maintain data consistency, each task has to receive multiple copies of data from 
several task instances if its predecessor is replicated in more than one place. 


6 





The purpose of the replication problem considered in this paper is to decrease the sum of 
execution and communication costs. Under such consideration, there is no need to enforce plural 
communication between any two task instances. Hence, we propose the 1-out-oJ-n communication 
model. In the model, for each edge < i, j > £ £, a task instance may start its execution if it 
receives the data from any one task instance of its predecessor, task i. 


3 Problem Formulation and Complexity 


Based on the computational model presented in Section 2.2, the problem of minimizing the total 
sum of execution and communication costs for an SP task graph can be approached by replication 
of tasks. An example where the replication may lead to a lower sum of execution costs and 
communication costs is given in Figure 2, where the number of processors in the system is two, and 
the execution costs and communication costs are listed in e table and p table respectively. If each 
task is allowed to run on at most one processor, then the optimal allocation will be to assign task 
a to processor 1 , b to 1 , c to 1 , d to 2, e to 2, and / to 1. The minimum cost is 68 . However, if 
each task is allowed to be replicated more than one copies, (i.e. to replicate task a to processors 1 
and 2), then the cost is 67. 

We introduce integer variable Af.^’s, VI < i < M and 1 < p < n, to formulate the problem 
where each X l<r> = 1 if task i is replicated on processor p; and = 0, otherwise. We define a binary 
function 6(z). If x > 0 then 6(x) = 1 else S(x) = 0. We also associate an allocated flag F(w) with 
each node to in the parsing tree, where F(w ) = 1 if the allocation for tasks in the subtree S w is 
valid; and = 0, otherwise. A valid allocation for the tasks in S w is an allocation that follows the 
semantics of TeAain, T an i, and ZV subgraphs. A valid allocation is not necessarily the allocation in 
which each task in S w is allocated to at least one processor. Some tasks in subgraphs may be 
neglected without effecting the successful execution of an SP graph. 

Given an SP graph C, its parsing tree T(G) and any internal node tc in T(G), allocated flag 
F(w) can be recursively computed: 


7 







1. if tu is a T unt - f node with a child i, then 


F(w) = F{i) = 6(£X ij> ) 

p=: 


2. if w is a Tchain node with c children, F(w) = F(child{) x F(child 2 ) x ... x F(child c ). 

3. if tr is aT otu f node with forker s, joiner t and c children, then -F(ttf) = F(s ) x F(t) x F(childi) 
x J ? (ch:'/d 2 ) x ... x F(ckild c ). 

4. if u) is a IV node with forker s, joiner t and c children, then F(w) = F(s ) x F(t) x 6(F(childi) 
+ r(chiid 2 ) + ...+ J’(chiW e )). 

The minimum cost replication problem for SP graphs, MC&P-SP, can be formulated as 0-1 
integer programming problem, i.e: 

Z = Minimize [£ Xi 9 * ^j> + £ min (jHjfa q) * Xj,,) ] 

ij> <iJ>£E, ,J> “ 

subject to F(r) = 1, where r is the root of T(G) and Xi tT> = 0 or l,Vi,p. (1) 

The restricted problem which allows each task to ran on at most one processor has the following 
formulation. 

Z — Minimize ] Xi^ * tij, 4- } ' Mij * X% t p * A] 

»,P <»0>6£,p,9 

n 

subject to ^2 Xi tP < 1 and F(r) = 1, 
p=i 

where r is the root of T{G) and A,-, = 0 or 1, Vi,p. (2) 

The task assignment problem (2) for SP graphs of M tasks onto n processors, has been solved 
in 0(n z M) time [12]. However,the multiprocessor task assignment for general types of task graphs 
without replication has been reported to be NP-complete [9]. As for the MCRP-SP problem, it 
can be shown to be NP-complete. In this paper, we are able to solve the problem and present a 
linear-time algorithm that is linear in the number of tasks when the number of processors is fixed 
for computation-intensive applications. 


8 


3.1 Assignment Graph 


Bokhan [1] introduced the assignment graph to soive the task assignment problem (2). To prove 
the NP completeness of problem (1) and solve the problem, we also adopt the concept of the 
assignment graph of an SP graph. The assignment graph of an SP graph can be defined similarly. 
The following definitions apply to the assignment graph. And we draw up an assignment graph for 
an SP graph in Figure 3. 

1. It is a directed graph with weighted nodes and edges. 

2. It has M x n nodes. Each weighted node is labeled with a task instance, t,- >p . 

3. A layer i is the collection of n weighted nodes U, 2 , • ••, and U, n )- Each layer of the 
graph corresponds to a node in the SP graph. The layer corresponding to the source (sink) 
is called source (sink) layer. 

4. A part of the assignment graph corresponds to an SP subgraph of type T^n, T an d or T or is 
called a T^in , T an d or limb respectively. 

5. Communication costs are accounted for by giving the weight Wj(p, q) to the edge going from 

to tj, 9 - 

6. Execution costs are assigned to the corresponding weighted nodes. 

Given an assignment graph, Bokhari [1] solves Problem (2) by selecting one weighted node 
from each layer and including the weighted edges between any two selected nodes. This resulting 
subgraph is called an allocation graph. To solve Problem (1), more than one weighted node from 
each layer may be chosen. Similarly, a replication graph for Problem (1) cap be constructed from 
an assignment graph by including all selected nodes and edges between these nodes. Examples of 
an allocation graph and a replication graph are shown in Figure 4 for an assi gnm ent graph shown 
in Figure 3. Note that for each node x in the replication graph there is only one edge incident to 
it from each predecessor layer of x. 

In a replication graph, each layer may have more than one selected node. Let Variable Xi 
— i, Xi, 2, ..., Xi, n ) be a replication vector for layer l in a replication graph. We define the 


9 








minimum activation cost of vector A, for layer : , A,(A t ), to be the minimum sum of the weights 
of all possible nodes and edges leading to the selected nodes of layer i in a replication graph. 
Then the goal of Problem (1) can be achieved by computing the minimal value of {A.;„t,(A«;tu) + 
Hp=i r * Csiak,?} over all possible values of A.i„v. 

3.2 Complexity 

In this section, we can show that Problem ( 1 ) for a computation-intensive application is NP* 
complete provided we prove the following: 

Lemma 1 : For any layer 1 in the replication graph, the minimum activation cost for two selected 
nodes t/ iP and tj >9 will be always greater than that for either node tij, or t ; i9 only. 

Proof: The Lemma can be proven by contradiction. Let A\ be the the minimum activation cost for 
two nodes l/ iP and tj, 9 , and A^ and A 3 be the minimum costs for t/ (P and l ; i9 respectively. Assume 
that A\ < A 2 and A x < A 3 . Since Aj includes the activation cost of node tj >p , an activation cost 
for only can be obtained from Aj. The obtained value c is not necessarily the minimum value 
for t; iP , hence A 2 < c. The value c is obtained by removing some weighted nodes and edges from 
replication graph. This implies that c < Aj. From above, we find that A 2 < Ai, which contradicts 
the assumption. The same reasoning can be applied to A 3 and reaches a contradiction. Therefore, 
the assumptions are incorrect and Lemma 1 holds. 


□ 

Lemma 1 can be further extended to the cases where more than two weighted nodes axe chosen. 
The conclusion we can draw is that the more nodes are selected from a layer, the bigger the 
activation cost is. 

Lemma 2 : Given a computation-intensive application with its SP task graph G = (V, E) and its 
assignment graph, if node : has outdegree one and edge < i,j > € A, then for any vector A,-, the 
minimal activation cost Aj(Xj) can be obtained by choosing only one weighted node from layer i. 
(i.e. = 1 ) 

Proof: The Lemma can be proven by contradiction. Since node i has outdegree one and edge 


10 





< M*, 9 ) + S X lv * e «'.* + 52 ( X i.i * ?)) = m - 

P=1 5 = 1 ■*! J. 15 * 

The result, m' < m, contradicts our assumption. It means that the assumption is wrong and 
Lemma 2 holds. 

D 

Lemma 3: Given a computation-intensive application with its SP task graph G, the objective of 
the minimum cost can be achieved by considering only the replication of the forkers. 

Proof: We proceed to prove the lemma by contradiction. Let the tninirnmn cost for task replication 
problem be zo if only the forkers(i.e. outdegree > 1) are allowed to run on more than one processor. 
Assume the total cost can be reduced further by replicating some task i which is not a forker. Then 
there are two possible cases for i: 

1 . : has outdegree 0- 

2. i has outdegree 

In case 1, : is the sink of the whole graph. Also i may be the joiner of some SP subgraphs. If i is 
allowed to run on an extra processor b, which is different from the one which i is initially assigned 
to (when z 0 is obtained), then the new cost will be jfc + e,,j, -f Y^<d,i > eE Pd, i- Apparently, the new 
cos: is greater than no- This contradicts our assumption that the total cost can be reduced further 
by replicating task 

In case 2, i has one successor. Let < i,j > € E. From the assumption, we know that the 
replication of i can reduce the total cost. Bence, the minimum activation cost for task instances 
in layer j, Aj(Xj), is obtained when task i is replicated onto more than one processor. This 
contradicts Lemma 2. Hence, the assumption is incorrect and the objective of the minimum cost 
can be achieved by considering only the replication of the forkers. 

D 

Lemma 3 tells that, given an SP graph, if we can find out the optimal replication foi the forkers, 
Problem (1) for computation-intensive applications can be solved. Now, we show that the problem 


11 







< i,j > € E, we know that 




■ 


n n 

A j{Xj) = aMn{Af(Xi) 4 E A >'.» * c ‘.?> + E * KjiP* ?)))• 

A> 7=1 9 =1 A, >- 1 

Let us assume that the above equation reaches a minimal value m when more than one node 
from layer i is selected and the optimal replication vector is Xf. Since A’, tP > 1 for Xf, we 
may remove one selected node from layer : and obtain a new vector X-. Without loss of generality, 
let us remove I,-,,. By removing node U >T , a new value m' is obtained. Since m is the minimum 
value for layer i, it implies that m < m'. 

From Lemma 1, we obtain that A,-(X/) < A;(Xf). And for a computation-intensive application, 
the following holds that £?=i Mi j(?> ?) < min p (e l(P ), V 1 < p < n. Then, 


m' = A : {X-) 4 E X' <p . e,-, 4 E (■*** * W jfa f)) 

7=1 5=1 

< AC*?) + E * «.> + E =i» (X,., * ?)) 

7=1 9=1 

< - M + E ““(*«•*■>(?.!)) 

7=1 9=1 

= Ai(X,°) 4 ^ X?„ * e, iP 4 E min (X Jt? « Mi j(p, ?))] - e», r 

t=i 9=: a *^ =: 

< Ai(X, D ) 4 £ X? (P * ei,„ 4 E JP 11 , (■ x m * Wj (?. 5))) ~ =un(ei,) 

7=1 9=1 F 

< mx ?)+£ 1i: “i,(^ * ?») - i; >■*&>, s) 


7=1 

n 


9=1 


9=1 


< x,(x»)+E^-^ 

7=1 


12 


1 





< MX?) + £ X Ip * e *> + S C-^i.9 * MijOb 9)) = m. 

T= 1 9=J 

The result, m' < m, contradicts our assumption.. It means that the assumption is wrong and 
Lemma 2 holds. 

□ 

Lemma 3: Given a computation-intensive application with its SP task graph G, the objective of 
the minimum cost can be achieved by considering only the replication of the forkers. 

Proof: We proceed to prove the lemma by contradiction. Let the minimum cost for task replication 
problem be zo if only the forkers(i.e. outdegree >1) are allowed to run on more than one processor. 
Assume the total cost can be reduced further by replicating some task t which is not a forker. Then 
there are two possible cases for i: 

1 . i has outdegree 0. 

2 . i has outdegree 1. 

In case 1, i is the sink of the whole graph. Also t may be the joiner of some SP subgraphs. If i is 
allowed to run on an extra processor b, which is different from the one which i is initially assigned 
to (when z 0 is obtained), then the new cost will be zo -f Cjj. 4- Z)<d,«‘>e£ Apparently, the new 
cost is greater than zo- This contradicts our assumption that the total cost can be reduced further 
by replicating task i. 

In case 2, : has one successor. Let < i,j > € E. From the assumption, we know that the 
replication of : can reduce the total cost. Hence, the minimum activation cost for task instances 
in layer j, Aj(Xj ), is obtained when task i is replicated onto more than one processor. This 
contradicts Lemma 2. Hence, the assumption is incorrect and the objective of the minimum cost 
can be achieved by considering only the replication of the forkers. 


D 

Lemma 3 tells that, given an SP graph, if we can find out the optimal replication for the forkers, 
Problem (1) for computation-intensive applications can be solved. Kow, we show that the problem 


13 


of finding an optima] replication for the forkers in an SP graph is NP-complete. First, a special 
form of the replication problem is introduced. 

Uni-Cost Task Replication (UCTR) problem is stated as follows: 

INSTANCE: Graph G' = (V',E'), V ' = V{ U V 2 \ where | VJ | = n and | | = m. If x £ V{ and 

y £ Vj then edge < x,y > £ E' (i.e. | E' | = m x n). For each x £ VJ, there is an activation cost 
m. Associated with each edge < x,y > £ E\ there is a communication cost cL iV = n x m or 0. A 
positive integer K < n x m is also given. 

QUESTION: Is there a feasible subset 14 Q such that, we have 

I £>+£ (3) 

[Theorem l]: Uni-Cost Task Replication problem is NP-Complete. 

[Proof]: The problem is in NP because a subset 14, if it exists, can be checked to see if the sum 
of activation costs and communication costs is less than or equal to K. We shall now transform 
the VERTEX COVER [3] problem to this problem. Given any graph G - (V,£) and an integer C 
< | V |, we shall construct a new graph G' = (V\E r ) and V' = V{ u VJ, such that there exists a 
VERTEX COVER of size C or less in G if and only if there is a feasible subset of in G'. Lex 
| V | = n and j E j = m. To construct G (1) we create a vertex t,- for each node in V, (2) we 
number the edges in E, and (3) we create a vertex bj for each edge < u,r > € E where u, v € V. 
We define K = m x C, V{ = {t>j, t> 2 , r„}, Vj = {bj, b?, ..., *>„} and E' = {< v-.b v > \ v. £ 

Vj', b v £ }. Let = 0, if v. is an end point of the corresponding edge of vertex b v \ and = 

n x m, otherwise. An illustration, where n = 7 and m = 9, is shown in Figure 5. 

Let us now argue that there exists a vertex cover of size C or less in G if and only if there is 
a feasible subset of Vf in G' to satisfy that the sum of activation cost and communication cost is 
m x C or less. Suppose there is a vertex cover of size C, then for each vertex b v (= < u,v >) in V 2 ', 
at least one of v and v belongs to the vertex cover. By selecting all the vertices in the vertex cover 
into the subset of Vj, we know that the sum in Eq. (3) will be m x C. Since C < n, it implies that 
m x C < n x 77i. 

Conversely, for any feasible subset 14 £ VJ such that the total cost is equal to or less than 


14 





mC, we can see that the second term of Eq. (3) (i.e. the sum of communication cost) must be 
zero. Suppose, for some g y € the minimum communication cost between g y and vertices in V' 
is nonzero, then the communication cost will be at least mxn. Since C < n, it implies that mxn 
> mxC. The total cost in Eq. (3) will be greater than m x C, which is a contradiction. Thus the 
minimum communication cost between any vertex in V£ and any vertex in 14 is zero. It means that 
at least one of two end points of each edge in E belongs to V*. Since, there is at most C vertices in 
14 (the activation cost for each vertex is m), and by selecting the vertices in 14 , we obtain a vertex 
cover of size C or less in G. 


D 

[Theorem 2]: The problem, MCRP-SP for compvtation~inicnsive applications, is NP-complete. 

[Proofj: From L emm a 3, we know that only the forker in an SP graph of type T om f needs to run on 
more than one processor. Consider the following recognition version of Problem (1) for SP graphs 
Of type Ta-nJ- 

Given a distributed system of n processors, an SP graph G D — (V c ,E a ) of type T an d, its 
assignment graph E and two positive integers m and r. Let r be a multiple of m, V c = {s, t, 
1,2,...,r} and = {< s,i > | i = 1,2,...,r} U {< i,t > | : = 1,2,...,r}. Task s (l) is the forker 
(joiner) of G a . Execution cost and communication cost Pij(p,q) are defined in E, V < ij > 
£ JE? C and V 1 < p,g < n. Integer variable Xi# = 1 if task i is assigned to processor p\ and = 0, 
otherwise. W r hen a positive integer K < r is given, is there an assignment of X^ s, such that 

l 22 ■*.> * «»> + J2 “in (nj(p, q ) * Xj, f )}<K1 

1# <ij>iE, l<f<n ' j '~ 

where 22 = 1, Vi ?£ s, and 22 X w > 1» if * = *• ( 4 ) 

if 

We shall transform the UCTE. problem to this problem. Given any graph G' — (V{ U Vj ,£') 
considered in UCTR problem, we construct an SP graph of type T an d, G c = (V® JE°), and its 
assignment graph E, such that G' has a feasible subset of Vj to allow the sum in Eq. (3) is K or 
less if and only if there is an assignment of Xi^s for G° and E to satisfy Eq. (4). Let | | = rz, 


15 






I 


| V 2 ' | = m, then the unit cost / = n x m. Assign r = m x / (= n x m?) and K = n x m. The 
forker and joiner of G a are s and t respectively. Then V 6, = {s, t, 1,2,... ,r) and £ c = {< s,i > \ i 
= 1,2,.. .,r} U {< t,l > | i = 1,2,. We assign the execution costs and communication costs in 
E as follows. An illustration, where m = 2 and n = 3, is shown in Figure 7. 

• V 1 < p < n, e, iP = m. 

• V 1 < i < r, V 1 < p < n, if p = 1 then e l|? = 0 else e, tP = r. | 

• Vl<p<n, ifp=l then e tJ> = 0 else e tiP = r. 

• V 1 < i < r, V 1 < p < n, let q = (i — 1) div (m x n), where div is the integral division. If 

d vr,t'+> t 0 tbeD l ) = 1 ^ = 0. 

• V 1 < i < r, V 1 < p < n, V q # 1, /x,,,-(p,g) =0. 

• V 1 < : < r, V 1 < p,? < n, = 0. 

It is easy to verify that the SP graph constructed by the the above rules is of type T an £ and 
computation-intensive. For each node in of G', we create / nodes in <7°, where the communica¬ 
tion cost between each node and source s is either one or zero. 

Let us now argue that there exists a feasible subset of VJ for UCTR problem if and only if there 1 

exists a valid assignment of A liP ’s such that the total sum in Eq. (4) is K or less. Suppose a feasible 
subset 14 of V{ exists such that the sum in Eq. (3) is C (< K) . Let be Then we 

can obtain a valid assignment by letting A,-.i = 1, A »,2 = 0, X = 0, V 1 < t < r, and A:.j = 

1, A : ,j = 0, ..., A'.,* = 0, and X tyP = 1 , if v p € V*; and X ltP = 0, if v p £ V'*, V 1 < p < n. Since 

each node 2 in V{ corresponds to / nodes in G°, it is sure that the communication cost between 

node x and any node (v p ) in Vj is equal to the total communication costs between these / nodes I 

and any task instance of source (l,, p ) in G a . By summing up all the costs, we can obtain that the 

total sum is C. Since C<K<nxm<T, this is a valid assignment. 

Conversely, if there exists an assignment of such that the sum in Eq. (4) is K or less, 
then the following must be true that A^ = 1, X{,i - 0,.. A,> = 0, V 1 < » < r, and AT-,: = 1, 

A ;,2 = 0 ,..., At,* = 0. it is because for some p 5 * 1 , if A tJ) = 1 then the sum must be greater than „ 


16 


1 



r, which causes a conflict. Hence the second term in Eq. (4) must be zero. Thus, we may obtain a 
subset of V 3 for UCTR problem by selecting node x € Vj if X JiS equals 1 . Since the first term in 
Eq. (3) is equivalent to the first term in Eq. (4), the total sum for UCTR problem will be also K 
or less then. 

O 


4 Optimal Replication for SP Graphs of Type T an d 

In this section, we develop the branch-and-bound algorithm to And an optimal solution for T aru j 
subgraphs. The non-forker nodes only need to run on one processor. Hence, an optima] assignment 
of non-forker nodes can be done after an optimal replication for forkers is obtained. 

4.1 A Branch-and-Bound Method for Optimal Replication 

Consider a T an e SP graph with forker-joiner pair (s,h) shown in Figure 6 . There are B subgraphs 
connected by s and h. These B subgraphs have a parallel-and relationship. Since the joiner h has 
only one copy in optimal solution (i.e. ]££=) = 1 )> we decompose the minimum cost replication 

problem T for a T an d SP graph into n subproblems T g , q = 1, 2, ..., n, where is to And the 
TninimTiffl cost when the joiner is assigned to processor q (i.e. Xh,q = 1 )- 

Given a joiner instance t^ t9 , subgraphs Gt's, b * 1, 2, ..., B, and the minimum costs C£ >? s 
between each forker instance l tJ , and joiner instance , V 1 < p < n and 1 < b < B. we further 
decompose problem V' 1 into n subproblems ?J,fcsl,2,...,n, where k is the number of replicated 
copies that the forker s has. Basically; means the problem of finding an optimal replication for 
k copies of forker s where the joiner K is assigned to processor q. Since the problem of finding an 
optimal replication for forker s is NP-complete, we propose a branch-and-bound algorithm for each 
subproblem V\. 

We sort the forker instances according to their execution costs e^’s into non-decreasing order. 
Without loss of generality, we assume e,,i < e ,,2 < ...< e,,„. We represent all the possible 
combinations that s may be replicated by a combination tree with (") leaf nodes. To make the 
solution efficient, we shall not consider all combinations since it is time-consuming. We apply a 


17 






least-cost branch-and-bound algorithm to find an optimal solution by traversing a small portion of 
the combination tree. 

During the search, we maintain a variable i to record the minimum value known so far. The 
search is done by the expansion of intermediate nodes. Each intermediate node t? at level y repre¬ 
sents a combination of y out of n forker instances. The expansion of node v generates at most n — y 
child nodes, while each child node inherits y forker instances from v and adds one distinct forker 
instance to itself. For example, if node v is represented by -< t 4( ;,, l 4t ,-j, ..., t 4i ,- >-, where i 3 < t 2 
< ... < t' y> then -< l 4ft - 1 , t 4<1 -,, ..., tj^+y >- represents a possible child node of v, V 1 < j < 
n — i y . A combination tree, where k = 4 and n = 6, is shown in Figure 8. At any intermediate node 
of a combination tree, we apply an estimation function to compute the least cost this node can 
achieve. If the estimated cost is greater than i, then we prime the node and the further expansion 
of the node is not necessary. Otherwise, we insert this node along with its estimated cost into a 
queue. The nodes in the queue are sorted into non-decreasing order of their estimated costs, where 
the first node of the queue is always the next one to be expanded. When the expansion reaches 
a leaf node, the actual cost of this leaf is computed. If the cost is less than i, we update z. The 
algorithm terminates when the queue is empty. 


4.1.1 The Estimation Function 

The proposed branch-and-bound algorithm is characterized by the estimation function. Let node v 
be at level y of the combination tree associated with subproblem V\ and be represented by -< X 4t ,,, 
..., >-, where : 3 < t '2 < ... < iy Any leaf node that can be reached from node r needs 

k - y more forker instances. Let t = ■< j \, jz, - - • , jk-y >- be a tuple of k — y instances chosen from 
the remaining n - i v instances, where jj < 37 < • • • < jk-y Let L be the set of all possible Vs. Let 
p(v) be the smallest cost among all leaf nodes that can be reached from node v. 

y B 

s(v) = ]£ c 4ti . + e, j4 + £ . . min (Cj ) ] + e H<v . 

tZL tel ° r 


18 





Since the complexity involved in computing g(v) is (*!**), we nse the following estimation function 
esf(v) to approximate g{v): 


V iy +k— y B 

est(v)= £e a , ; . + e ‘J + E • min . (C{ t ,) + e h< „. 

o ssi p=si 


iy+k-y 


E * E e-o, £ imn (O < E (O • 

;=,„+) 3 ,et i=i ? , -‘v+ 1 -‘»+ 2 . n tei *€« 


it is easy to see that est(v) < p(v). Hence, we use est(v) as the lower bound of the objective 
function at node v. 


4.1.2 The Proposed Algorithm 

Three parameters of the branch-and-bound algorithm axe joiner instance (t^), the number of 
processors that forker s is allowed to run ( k ). and the up-to-date minimum cost (z). The algorithm 
BB(k , q f z) is shown in Table 1. 

The MCHP-SP problem can be solved by invoking BB(k,q,z) n 2 times with parameters set to 
different values. BB(k,q.z) solves the problem P*, while the whole procedure, shown in Table 2, 
solves V. 


4.2 Performance Evaluation 

The essence of the branch-and-bound algorithm is the expansion of the intermediate nodes. Upon 
the removal of a node from the queue its children are generated and their estimated values are 
computed. If the estimation function performs well and gives a tight lower bound of objective 
function, the number of expanded nodes should be small. Then an optimal solution can be found 
out as soon as possible. 

We conduct two sets of experiments to evaluate the performance of the proposed solution. The 
performance indices we consider are the number of enqueued intermediate nodes (EIM) and the 
number of visited leaf nodes (VLF) during the search. We calculate EIM and VLF by inserting one 


19 






counter for each index at lines 13 and 8 of Table 1 respectively. Each time the execution reaches 
line 13 (8), EIM (VLF) is incremented by 1. 

The first set of experiments is on SP graphs of type T aru i where the communication cost between 
any two task instances is arbitrary and is generated by random number generator within the range 
[1,50]. The execution cost for each task instance is also randomly generated within the same range. 
The second set of experiments is on SP gTaphs of type T an i with the constrain of computation¬ 
intensive applications. We vary the size of the problem by assigning different values to the number 
of processors in the system (n) and the number of parallel-and subgraphs connected by forker and 
joiner (B). For each size of the problem (n, H), we randomly generate 50 problem instances and 
solve them. The results, including the average values of EIM and VLF over the solutions of 50 
problem instances, are summarized in Table 3. 

From Table 3, we find out that the proposed method significantly reduces the number of ex¬ 
pansions for intermediate nodes and leaf nodes. For example, for problem size (n, B) = ( 20, 40), 
the total number of leaf nodes is 2 20 (= 1,048,576) if an exhaustive search is applied. However, 
our algorithm only generates 16,857 nodes on the average, because we apply est(r), i, and the 
branch-and-bound approach. 

The branch-and-bound approach and the estimation function even perform better for the 
computation-intensive applications. We can see that EIM and VLF values are much more smaller 
in Set H than those in Set I. It is because that in the computation-intensive applications an optimal 
number of replications for the forker is smaller than that in general applications. The z value in 
function OPT () is able to refiect this fart and avoid the unnecessary expansions. 


5 Sub-Optimal Replication for SP Graphs of Type T on d 


The branch-and-bound algorithm in section 4.1 yields an optimal solution for T an t subgraphs. 
However, the complexity involved is in exponential time in the worst case. Hence, we also consider 
to find a near-optimal solution in polynomial time. 


20 


5.1 Approximation Method 

For the problem V\ defined in section 4.1, we exploit an approximation approach to solve it in 
polynomial time. The approach is based on iterative selection in a dynamic programming fashion. 
Given a joiner instance and subgraphs Gk, 5 = 1, 2,..., B, and minimum costs C Pif between 
*A t! and t StP , p = 1, 2 , ..., n, and 5 = 1, 2, ..., S. we define 5u5(p,5) to be the sub-optimal 
solution for replication of forker s where forker instances f 4> i, i Jt i ,..., t iyP and subgraphs G\ , G 2 , 

..., Gk axe taken into consideration. 

Strategy’ 1: 

Sub{p,b ) can be obtained from Sub(p- 1 ,b) by considering one more forker instance t 3tP . Strategy 
1 consists of two steps. The first step is to initialize 5u5(p,5) to be Svb(j>— 1,5) and to determine 
if t }yP is to be included into Sub(p, b) or not. If yes, then add t i<p in. The second step is to examine 
if any instances in Sub(p — 1,5) should be removed or not. Due to the possible inclusion of i 3tP in 
the first step, we may obtain a lower cost if we remove some instances 1,/s, i < p, and reassign the 
communications for some graphs Gj's from 1,/s to l SyP . 

Strategy 2: 

Sub[p y b ) can also be obtained from Su5(p, 5 - 1) by taking one more subgraph Gt into account. 
Initially, 5u5(p, 5) is set to be Svb(p,b— 1). The first step is to choose the best forker instance from 
tj,:, i iy 2 ,.... i iyP for Gk- Let the best instance be i ta . The second step is to see if t tyi is in Sub{p. 5) 
or not. If not, a condition is checked to decide whether l tyZ should be added in or not. Upon the 
addition of t 4fI , we may remove some instances and reassign the communications to achieve a lower 
cost. 

We compare two possible results obtained from the above two strategies and assign the one with 
lower cost to actual 5v5(p,5). Bence by computing in a dynamic programming fashion, Sv.b(n,B ) 
can be obtained. The algorithm and its graphical interpretation are shown in Figure 9. 

5.2 Performance Evaluation 

The complexity’ involved in each strategy described in section 5.1 is 0(nB). Since the solving 
of 5«5(n, B) needs to invoke n x B times of strategies 1 and 2, the total complexity of solving 


21 







I 


Sub(n,B ) by the approximation method is 0(n 7 B 2 ). 

We conduct a set of experiments to evaluate the performance of the approximation method. For 
each problem size (n, B), we randomly generate 50 instances and solve them by using approximation 
method and exhaustive searching. The data for computation and communication in the experiments 
are based on the uniform distribution over the range [1,50]. We compare the minimum cost obtained 
from exhaustive searching (EXHAUST) with those from from approximation (APPROX) and single | 

assignment solution (SINGLE). The optimal single assignment solution is the one in which only one 
forker instance is allowed. Note that the solutions from SINGLE are obtained from the shortest 
path algorithm [1]. The results are su mm arized in Table 4. From the table, we find out that the 
approximation method yields a tight approximation of the minimum cost. On the contrary, the 
error range for single copy solution is at least 20%. This again justifies that the replication can 
lead to a lower cost than an optimal assignment does. 

6 Solution of MCRP-SP for computation-intensive applications 

6.1 The Solution 

Given a computation-intensive application with its SP graph, we generate its parsing tree and 
assignment graph first. The algorithm finds the minimum weight replication graph from the as- * 

signment graph. Then the optimal solution is obtained from the minimum weight replication graph. 

The algorithm traverses the parsing tree in the postfix order. Namely', during the traversal, an 
optimal solution of the subtree S-, induced by an intermediate node x along with all x's descendant 
nodes, can be found only after the optimal solutions of s ! s descendant nodes are found. Given an 
SP graph G and a distributed system 5, we know that there is a one-to-one correspondence between 
each subtree S z in a parsing tree T(G) and a limb in the assignment graph of G on S. 'Whenever a J 

child node b of x is visited, the corresponding limb in the assignment graph will be replaced with a 
a two-layer limb if b is a or Ik,-type node; and a one-layer T m it limb if b is a Tom'-type 

node. The algorithm is shown in Table 5. A graphical demonstration of how the algorithm solves 
the problem is shown in Figure 10. 

Before the replacement of a Tgnain limb is performed (i.e. a is a T,j, 0 ,„-type node), each con¬ 
stituent child limb has been replaced with a T *™ t or two-layer Tc^oin limb. Hence, the shortest 


22 


path algorithm [1] can be used to compute the weights of the new edges between each node in the 
source layer and each node in the sink layer of the new Tchain limb. The complexity, from lines 05 
to 08 of Table 5, in transformation of the limb, corresponding to an intermediate node x with M 
children, into a two-layer TeUin limb is 0(M n 3 ). An example of illustrating the replacement of a 
Tchain limb is shown from parts (b) to (c) and parts (d) to (e) in Figure 10. 

For the replacement of a T an d limb, we have to compute C£ t9 ’s. The values can also be computed 
by the shortest path algorithm. Hence, the complexity involved in lines 16 and 17 is 0(Bn 3 ). 
According to the computational model in section 2.2, each task instance s may start its execution 
if it receives the necessary data from any task instance of its predecessor d. And, from Lemma 
2, we know that the minimum sum of initialization costs of multiple task instances of s will be 
always from only one task instance of d. Therefore, the initialization of task instance t, %p depends 
on which task instance of d it communicates with. That is why ,in line 19, the communication 
cost At< 2 ,,(:,p) is added to the the execution cost of t tJ , before OPTQ is invoked. And the most 
significant part of the replacement is to compute the weights on the new edges from the source 
layer to sink layer. The complexity is n 2 x 0(0 PT()), which in the worst case is n 7 T n . However, in 
the average, our OPT function performs pretty well and reduces the complexity significantly. An 
example of illustrating the replacement of a T an d limb is shown from parts (c) to (d) in Figure 10. 

We also consider to use the approximation method to find the sub-optimal replacement of a 
T un d limb. In that case, function OPTQ in line 21 is replaced with Svb(n,B). The total complexity 
involved is 0(n*B 2 ) then. 

Finally, for the replacement of a T'or limb, if there are B subgraphs connected between the forker 
and the joiner, then the complexity will be 0(Bn 7 ) for the new edges and 0(1?n 3 ) for C^’s. An 
example of illustrating the replacement of a 2V limb is shown from parts (a) to (b) in Figure 10. 

When the traversal reaches the root node of the parsing tree, the result of FINDQ will give 
us either one single layer or two layers, depending on the type of root node. All we have to do is 
to select the lightest of these n (in single layer) or n 7 (in two layers) shortest path combinations. 
An optimal replication graph itself is found by combining the shortest paths between the selected 


23 


1 


nodes that were saved earlier. The whole algorithm has the complexity of 

0 (aJ 2") + Ban 3 ) + £(C.n 3 ) 

2 » 

where A is the number of T an d limbs, Ri is the number of subgraphs in the.ith 2V limb, and C, is 
the number of layers in the *th Tchain limb. This is not greater than 0(M n 2 2 n ), where M is the 
total number of tasks in the SP graph. The complexity of the algorithm is a linear function of M 
if the number of processors, n, is iixed. 

6.2 Conclusion Remark 

This paper has focused on MCEJP-SP, the optimal replication problem of SP task graphs for 
computation-intensive applications. The purpose of replication is to reduce inter-processor commu¬ 
nication, and to fully utilize the processor power in the distributed systems. The SP graph model, 
which is extensively used in modeling applications in distributed systems, is used. The applications 
considered in this paper are computation-intensive in which the execution cost of a task is greater 
than its communication cost. We prove that MCHP-SP is NP-complete. We present branch-and- 
bound and approximation methods for SP graphs of type T a ni- The numerical results show that 
the algorithm performs very well and avoids a lot of unnecessary searching. Finally, we present an 
algorithm to solve the MCEP-SP problem for computation-intensive applications. The proposed 
optimal solution has the complexity of 0 (n 2 2 n M ) in the worst case, while the approximation solu¬ 
tion is in the complexity’ of 0(n 4 M 2 ), where tj is the number of processors in the system and M is 
the number of tasks in the graph. 

For the applications in which the communication cost between two tasks is greater than the 
execution cost of a task, the replication can still be used to reduce the total cost. However, in the 
extreme case where the execution cost of each task is zero, the optimal allocation will be to assign 
each task to one processor. We are studying the optimal replication for the general case. 

References 

[1] S.H. Bokhari, Assignment Problems in Parallel and Distributed Computing , Kluwer Academic 
Publisheds, MA, 1987. 


24 


1 




[2] Y. Chen and T. Chen, “Implemeating Fault-Tolerance via Modular Redundancy with Com¬ 
parison,” IEEE Trans. Reliability , Vol. 39, pp 217-225, June, 1990. 

[3] . M.R. Garey and D.S. Johnson, Computers and Intractability: A Guide to Theory of NP- 

Completeness , San Fhancisco: W.H. Freeman & Company, Publishers, 1979. 

[4] R. Jan, D. Liang and S.K. Tripathi, “A Linear-Time Algorithm for Computing Distributed 
Task Reliability in Pseudo Two-Terminal Series-Parallel Graphs,” submitted for publication 
to Journal of Parallel and Distributed Computing. 

[5] C.C. Price and S. Krishnaprasad, “Software Allocation Models for Distributed Computing 
Systems,” in Proc. 4th International Conference on Distributed Computing Systems, pp 40-48, 
May 1984. 

[6] D. Liang, A.K. Agrawala, D. Mosse, and Y. Shi, “Designing Fault Tolerant Applications in 
Marutif Proc. 3rd International Symposium on Software Reliability Engineering, pp. 264-273, 
Research Triangle Park, NC, Oct. 1992. 

[7] V.M. Lo, “Heuristic Algorithms for Task Assignment in Distributed Systems,” in Proc. 4th 
International Conference on Distributed Computing Systems, pp 30-39, May 1984. 

[8] P.R. Ma, E.Y.S. Lee and M. Tsuchiya, “A Task Allocation Model for Distributed Computing 
Systems,” IEEE Trans. Computers , Vol. C-31, pp 41-47, Jan. 1982. 

[9] V.F. Magirou and J.Z. Milis, “An Algorithm for the Multiprocessor Assignment Problem,” 
Operations Research Letters, Vol. 8, pp 351-356, Dec. 1989. 

[10] C.C. Price and U.W. Pooch, “Search Techniques for a Nonlinear Multiprocessor Scheduling 
Problem,” Naval Res. Logist. Quart., Vol 29, pp 213-233, June 1982. 

[11] H.S. Stone, “Multiprocessor Scheduling with the Aid of Network Flow Algorithm,” IEEE 
Trans. Soft. Eng. Vol 3, pp 85*93, Jan. 1977. 

[12] D. Towsley, “Allocating Programs Containing Branches and Loops Within a Multiple Pro¬ 
cessor System,” IEEE Trans. Software Eng., Vol. SE-12, pp. 1018-1024, Oct, 1986. 


25 










Optimal Assignment: 

e c ,3 -r Atc.fcCl, 1) + Ma,c(l»l)-r Mo,rf(li2) + /i a , e (l,2) + e*,i 4- e^j 
+ e O + e ti2 4 + ^c,/(l,3) + Mi./(2,1) + At e j(2,l)+ e/.i = 68 


Optimal Replication: 

Cc.i t eo + 1)+ ^ c , e (l,l)+ /i c ^(2,2)-f p e , e (2,2)-f e*, 3 

*r£c,i *r Co + Ct.2 + Wj(l? 1) + A^,/(2> 1) + A4,/(2,1)4 e/,i = 67 

Figure 2: An example to show how the replication can reduce the total cost 


26 
























: d v„i„ = mxn=2x3 = 6 




IKED 


BHi 

fi table 

IKED 

BE 

P = 3 

pea 

1 2 

2 

2 

^.i(7U) = 

IHHl 

0 

1 

BIS 

(■HI 

12 

12 

^ 4 .2(P,1) = 

0 

0 

1 

IMM 

0 

12 

12 


0 

0 

1 

IMfU 


12 

i—aii 

iwssssm 

0 

0 

1 



12 

12 

mssssm 

0 

0 

1 

! e S,T> = 

_L 

12 

12 

K532SES: 

0 

0 

1 

! «6.* = 


12 

12 

A*..r(p, 2) — | 

1 1 

0 

0 


1 o 

12 

12 

ESSSIESi 

1 

0 

0 

MUD 

gggjgij 

12 

12 


1 

0 

0 

! <** = 1 

o 

12 

■a 


1 

0 

0 

! e :o,v = 

HI 

12 

Mail 

ftjlfol) = 

HD 

0 

0 


H 

12 

12 

j M,.12(p,l) = 


0 

0 


■KX 

12 

12 

i AW(p,ff) = o, 

V 1 < i 

< 12, v 

= 1.2.3 and o = 2.3 

1 C:,p= 1 

0 1 

12 

12 

MMMMM 


iimiiiMM 


Figure 7: An illustration about how to transform a TJCTR instance to a T arui SP graph 




















































































Table 1: Function BB(k,q,z): branch-and-bound algorithm for solving problem P* 

01 Initialize the queue to be empty; 

02 Insert root node vo into the queue; 

03 While the queue is not empty do begin 
04 Remove the first node tz from the queue; 

05 Generate all child nodes of tz ; 

06 For each generated child node v do begin 

07 If v is a leaf node (i.e. v is at level k) then 

OS Compute g(v ) by setting L to be 4 ; 

09 Set i = min ( f, g(v )); 

10 else begin /* v is an intermediate node */ 

11 Compute est(v) by (5) ; 

12 If est(v) < i then 

13 Insert v into the queue according to est(v) ; 

14 end; 

15 end; 

16 end; 

17 Return(f). 

Table 2: Function OPT(CpJs, e StT> 's): the optimal solution of MCRP-SP of type T aru i when 
Cp i? ’s and e 3 ys are given 

01 Sort tj.p’s into a non-decreasing order by values of e aj ,’s ; 

02 For c = 1 to n do begin 

03 Let node v be a leaf node at level 1; 

04 Set r to be t 4 ,i and k to be 1; 

05 Compute g(v ) by setting L to be q> ; 

06 Initialize i to be g(v) ; 

07 For k = 1 to n do 

08 z=BB(k,q,z) ; 

09 Set c(g) = i ; 

10 end; 

11 Output the combination with the minimum value among c(l), c(2),c(n). 


31 






Figure 9: Pseudo code, graphical demonstration, and dynamic programming 
table for approximation methods 


Sub(p- l,b) —► Sub'(p,b): 

Sitb(p,b — 1) —♦ 5u6"(p,6): 


Let be the one satisfys mini<,< p (C , 1 t i? ) . 

begin 

If 1,,* € Su6(p,6- 1) then 

Sub'(p,b ) = Sub(p- 1,6) © l 4iP 

5u6"(p,6) = 5«6(p,6— 1) 

ReassigniiRemove(St:6'(p, 6)) 

Else 

end 

if Ci^ < DLi(l^jeSttiCp.s-i)(C},9)) - C z, v ) 

Else Sub'(p, b) = 5ii6(p- 1,6) 

begin 


5u6"(p,6) = 5u6(p- 1,6) © l Jt j 

Legend: 

ReassignitRjemove(5ti6"(p, 6)) 

(i) + = x, if 2 > 0. 

end 

(z) + = 0, if 2 < 0. 

Else Svb M (p,b)= Sub(p,b- 1) 



Sub(p, b) = M in.Cosi(Sub'(p, b), Sub"(p , b )) 





Table 3: Computation Results for branch-and-bound approach 


n 

B 

Set I 

EIM* VLF* 

Set n 

EIM* VLF* 

Total Number of 
leaves (2 n ) 

■ 

20 

2 


4 

7 

16 

■ 

24 

3 

6 

3 

6 

16 

■ 

28 

4 

im 


6 

16 

m 

32 

4 

HO 

3 

6 

16 

I 

36 

4 

HID 

■Q 

7 

16 

■ 

40 

_ 

3 

6 

3 

6 

16 


20 

36 

74 

16 

51 

256 


24 

40 

75 

21 

62 

256 


28 

50 

86 

26 

68 

256 

8 

32 

63 

94 

37 

78 

256 


36 

73 

96 

47 

84 

256 


40 

81 


50 

86 

256 


~W 

186 

558 

81 

340 

4,096 


24 

231 

639 

102 

398 

4,096 


28 

349 

839 

167 

543 

4,096 

12 

32 

| 451 

967 

204 

Ha 

| 4,096 


36 

K23 

984 

269 

720 

| 4,096 | 


40 

i 636 

1,186 

301 

780 

! 4,096 


20 

I 758 

3.216 

j 203 


i 65,536 


24 

| 1,065 

4,161 

329 

1,711 

j 65.536 


28 

1,335 

4,862 

546 

mm-im 

i 65,536 

16 

32 

1,884 

6,250 

726 

E&a 

mmmam 


36 

| 2,322 

74227 

839 

Wtmi 

65,536 


40 

| 2,880 

8,511 

1,179 

4,51C 

65,536 


20 

2,026 

12,042 

389 

3,079 

1,048,576 


24 

3,579 

18,866 

761 

5,280 

1,048,576 


28 

5,551 

OO 
1—I 

0 

r- 

C* 

1,227 

7,905 

! 1,048,576 

20 

32 

6,405 

30,521 

1,709 

10,357 

| 1,048,576 


36 

9,517 


1EM1 

15,032 

1,048,576 


40 

11,651 

48,087 

3,086 

16,857 

■■B&sisaH 


^: Each value shown is the average value over 50 runs. 


33 

























































































































































































Table 4: Simulation Results for Approximation Method 


h 

B 

SINGLE* 



single error % 

approx error % 

1 

20 

2876 

2407 

2400 

20 

0.28 

24 

3463 

2835 

2831 

22 

0.16 

28 

4032 

3264 

3259 

24 

0.18 

32 

4606 

3678 

3673 

25 

0.11 

36 

5198 

4084 

4082 

27 

0.05 

40 

5790 

4514 

4514 

28 

0.00 

8 

20 

2794 

2282 

2250 

24 

1.46 

24 

3356 

2672 

2636 

27 

1.38 

28 

3931 

3060 

3028 

30 

1.05 

32 

4540 

3443 

3413 

33 

0.88 

36 

5127 

3831 

3800 

35 

0.80 

40 

5683 

4215 

4192 

36 

0.55 

12 

20 

2767 

2213 

2161 

28 

2.42 

24 

3359 

2592 

2542 

32 

1.99 

28 

3912 

2996 

2941 

33 

. 1.88 

32 

4491 

3364 

3299 

| 36 

1.97 

36 

5063 

3736 

3676 

36 

1.62 

40 

5610 

4101 

4043 

! 39 

1.43 

16 

20 

2733 

2167 

2111 

29 

2.66 

24 

! 3287 

2558 

2492 

32 

2.66 

28 

| 3844 

2932 

2865 

I 34 

2.31 

32 

| 4393 

3315 

3240 

| 36 

2.32 

36 

| 4991 

3659 

3584 

39 

2.10 

40 

5558 

4045 

3970 

! 40 

1.89 


^: Each value shown is the average value over 50 runs. 


single error% = 


SINGLE - EXHAUST 
EXHAUST 


x 100%. 


approx error% = 


APPROX - EXHAUST 
EXHAUST 


x 100%. 


34 









































































































































































I 


Table 5: Algorithm FIN D(S s ): the algorithm for finding the shortest path combinations from the 
limb which corresponds to the subtree S x induced by an intermediate node x and all a’s descendant 
nodes in a parsing tree 

01 Case of the type of intermediate node x: 

02 Type 2TVat n • 

03 For b — the first child node of x to the last one do 
04 FIND(Sk); /* Now the limb corresponding to St is replaced */ 

05 Replace the limb corresponding to S s with a two-layer 7^;* limb where 
06 the source (sink) layer of the old limb is the source (sink) layer of new 2 -layer limb; 

07 Put weights on the edges between source and sink layers equal to the shortest path 

08 between the corresponding nodes; 

09 

10 Type T and : /* Let x = [ T andi forker s, joiner h.]*/ 

11 Let d be the predecessor of forker s in G (i.e. < d,s > € V); 

12 Let B be the number of child nodes of x in the parsing tree; 

13 /* I.e. there are B subgraphs connected by s and h *f 

14 For b = the first child node of x to the 5-th child of x do 

15 FIND(Sb)\ /* Now the limb corresponding to St is replaced */ 

16 For p = 1 to n, 9 = 1 to u and b — 1 to B do 

17 Compute the minimum replication cost C Pi! from t,, p to w.r.t. child b : 

18 For :' = 1 to n do begin 

19 For p = 1 to n do + e,, p ; 

20 /* E 3 ~, accounts for initialization by t d j and execution cost itself. “/ 

21 For g = 1 to n do m.k{i,q) = OFT(C^ >? 's,F,/s) ; 

22 /* Create new edges from td/'s to l^’s */ 

23 end; 

24 Replace the T and limb with a T vn i t limb, where source layer = sink layer = layer h, 

25 and there are new edges from layer d to layer h; 

26 

27 Type Ter : /* Let x = [ Tar , forker s, joiner h ] */ 

28 Use the same method described above from lines 12 to 17 to compute C p>9 ’s ; 

29 Replace the T^ limb with a two-layer T^in limb, where 

30 the source (sink) layer of 2V limb is the source (sink) layer of IVa.* limb and 

31 = xninj,(C£ 9 ), Vp and g ; 

32 end case; 

33 Save the shortest paths between any node in source layer and any node 
in sink layer ior future reference. 


35 








(C) 




(e) 


Figure 10. A graphical demostration of how to find an optimal solution for MCRP-SP 


36 


I 







REPORT DOCUMENTATION PAGE 


f-orm Approved 
OMB HO 0704-0188 


i 


•wD*»( •roe'***: Ok'jr* 1 *©' I* *3 ’ “vw' pr 'ruxy»r. iimr *7 r«m"*9 ©*i* v>w*<n, 

;r* * *0 *• •’ :*w 'r"0« •'•c * * •'-c **.•'«•*« •wn.pw f s»*o • »-o a r 01 »nq im) bw'Of n ni*"**tf O' Vf* o< i**v 

“.*wo ■*>*;* ••iv “*c r !•. >***»cr\ D''rc;o»*ie *0' «*r*o **roon\. 

•>*** — <•» ')C* -»••** )‘Z m *. #- 222Z! **:*.: " •* ."o Hmc-jp 1 *88) * ***•*©! o*\ DC JCSO) 

1. AGENCY USE ONLY (Lfjwf bunt) 2. REPORT DATE 3. REPORT TYPE AND DATES COVERED 

10/12/94 Technical 

4 . title and subtitle 

Optimal Replication of Series-Parallel Graphs for 

Computation-Intensive Applications _ , „ 

Revised Version 

S. FUNDING NUMBERS 

N00014-9l-C-0195 
DASG-60-92-C-0055 

6. AUTHOR(S) 

Sheng-Tzong Cheng and Ashok K. Agrawala 

7 . PERFORMING ORGANIZATION NAM£(S) AND ADDRESS(ES) 

Department of Computer Science 

A. V. Williams Building 

University of Maryland 

College Park, MD 20742 

8. PERFORMING ORGANIZATION 

REPORT NUMBER 

Revised Version 

CS-TR-3020.1 

UMIACS-TR-93-4.1 

9 . SPONSORING/MONITORING AGENCY NAMEIS) AND ADDRESS(ES) 

Honeywell, Inc. Phillips Laboratory 

3600 Technology Drive Directorate of Contracting 

Minneapolis, MN 55418 3651 Lowry Avenue SE 

Kirtland APB NM 87117-5777 

10. SPONSORING/MONITORING 

AGENCY REPORT NUMBER 

11. SUPPLEMENTARY NOTES 

This version supercedes the previous version. 

T2a. DISTRIBUTION/AVAILABILITY STATEMENT 

12b. DISTRIBUTION CODE 


13. ABSTRACT (Miximurr. ZQOtvorci) 


We consider the replication problem of series-parallel(S?) task graphs where 
each task may run on more than one processor. The objective of the problem is to 
minimi ze r'ne total cost of task execution and interprocessor communication. We call 
it, the minimum cost replication problem for SP graphs (MCRP-SP). In this paper, we 
adopt a new communication model where the purpose of replication is to reduce the 
total cost. The class of applications we consider is computation-intensive applicati* 
in which the execution cost of a task is greater than its communication cost. The 
complexity of MCRP-SP for such applications is proved to be NP-complete. We present 
a branch-and-bound method to find an optimal solution as well as an approximation 
approach for suboptimal solution. The numerical results show that such replication 
may lead to a lower cost than the optimal assignment problem (in which each task is 
assigned to onlv one processor) does. The proposed optimal solution has the complexi 
of O(nVM), while the approximation solution has 0(r.4 m2), where n is the number of 
processors in the system and M is the number of tasks in the graph. 


14. SUBJECT TERMS - _ . r 

Operating Systems 

Storage Management, Communications Management 

IS. NUMEER OF PAGES 

35 pages 

16. PRICE CODE 

; 17. SECURITY CLASSIFICATION 

IE. SECURITY CLASSIFICATION 

IS. SECURITY CLASSIFICATION 

20. LIMITATION OF ABSTRACT 

| OF REPORT 

OF THIS PAGE 

OF ABSTRACT 


| Unclasssified 

Unclassified 

Unclassified 

Unlimited 


"SN “S-'-O-O' -2SO-5SQO 


37 

























1 


I 


1 


38 


1 



Designing Temporal Controls 


Ashok K. Agrawala Seonho Choi 
Institute for Advanced Computer Studies 
Department of Computer Science 
University of Maryland 
College Park, MD 20742 
{agrawala. seonho}@cs.umd.edu 


Leyuan Shi 

Department of Industrial Engineering 
University of Wisconsin 
Madison, WI 53706 
leyuan@ie.engr.wisc.edu 


Abstract 

Traditional control systems have been designed to exercise control at regularly spaced time 
instants. When a discrete version of the system dynamics is used, a constant sampling interval is 
assumed and a new control value is calculated and exercised at each time instant. In this paper 
we formulate a new control scheme, temporal control , in which we not only calculate the control 
value but also decide the time instants when the new values are to be used. Taking a discrete, 
linear, time-invariant system, and a cost function which reflects a cost for computation of the 
control values, as an example, we show the feasibility of using this scheme. We formulate the 
temporal control scheme as a feedback scheme and, through a numerical example, demonstrate 
the significant reduction in cost through the use of temporal control. 


'This work is supported in pan by ONR and DARPA tinder contract N00014-91-C-019S to Honeywell and Com¬ 
puter Science Depanment at the University of Maryland. The views, opinions, and/or findings contained in this 
report are those of the author(s) and should not be interpreted as representing the official policies, either expressed 
or implied, of the Defense Advanced Research Projects Agency, ONR., the U.S. Government or Honeywell. Computer 
facilities were provided in part by NSF grant CCR-8811954. 

’This work is supported in part by ARP A and Philips Labs under contract DASG-60-92-C-0055 to Department of 
Computer Science, University of Maryland. The views, opinions, and/or findings contained in this report are those 
of the author(s) and should not be interpreted as representing the official policies, either expressed or implied, of the 
Advanced Research Projects Agency, PL, or the U.S. Government. 


39 







1 Introduction 


Control systems have been used for the control of dynamic systems by generating and exercising 
control signals. Traditional approach for feedback controls has been to define the control signals, 
u(t), as a function of the current state of the system, x(t). ‘As the state of the system changes 
continuously the controls change continuously, i.e. they are defined as functions of time, t, such 
that time is treated as a continuous variable. When computers are used for implementing the 
control systems, due to the discrete nature of computations, time is treated as a discrete variable 
obtained by regularly spaced sampling of the time axis at A seconds. Many standard control 
formulations are defined for the discrete version of the system, with system dynamics expressed at 
discrete time instants. In these formulations the system dynamics and the control are expressed as 
sequences, x(k ) and u(k). 

Most of the traditional control systems were designed for dedicated controllers which had only 
one function, to accept the state values, x(k ) and generate the control, u(k). However, when a 
general purpose computer is used as a controller, it has the capabilities, and may, therefore, be 
used for other functions. Thus, it may be desirable to take into account the cost of computations 
and consider control laws which do not compute the new value of the control at every instant. 
When no control is to be exercised, the computer may be used for other functions. In this paper 
we formulate such a control law and show how it can be used for control of systems, achieving the 
same degree of control as traditional control systems while reducing computation costs by changing 
the control at a few, specific time instants. We term this temporal control 

To the best of our knowledge this approach to the design and implementation of controls has not 
been studied in the past. However, taking computation time delay into consideration for real-time 
computer control has been studied in several research papers [1, 5, 6, 9, 11, 13]. But, all of these 
papers concentrated on examining computation time delay effects and compensating them while 
maintaining the assumption of exercising controls at regularly spaced time instants. 

The basic idea of temporal control is to determine not only the values for u but also the time 
instants at which the values are to be calculated and changed. The control values are assumed 
to remain constant between changes. By exercising control over the time instants of changes the 
designer has an additional degree of freedom for optimization. In this paper we present the idea and 
demonstrate its feasibility through an example using a discrete, linear, and time invariant system. 
Clearly, the same idea can be extended to continuous time as well as non-linear system. 

The paper is organized as follows. In Section 2, we formulate the temporal control problem and 
introduce computation cost into performance index function. The solution approach for temporal 
control scheme is discussed in Section 3. In Section 4, implementation issues are addressed. We 


40 







provide an example of controlling rigid body satellite in Section 5 . In this example, an optimal 
temporal controller is designed. Results show that the temporal control approach performs better 
than the traditional sampled data control approach with the same number of control exercises. 
Section 6 deals with the application of temporal controls,to the design of real-time control systems. 
Finally, Section 7, we present our conclusions. 

2 Problem Formulation 

In temporal control, the number of control changes and their exercising time instants within the 
controlling interval [0, Tj] is decided to minimize a cost function. To formulate the temporal control 
problem for a discrete, linear time-invariant system, we first discretize the time interval [0,7/] into 
M subintervals of length A = Tj/M. Let Dm = {0, A, 2A,..., (M - 1)A} which denote M time 
instants which are regularly spaced. Here, control exercising time instants are restricted within 
Dm for the purpose of simplicity. The linear time-invariant controlled process is described by the 
difference equation: 

x(k + l) = Ax{k) -r Bu(k) (l) 

y{k) — Cx(k ) 

where k is the time index. One unit of time represents the subinterval A, whereas x £ 7Z n and 
u £ 7Z 1 are the state and input vectors respectively. 

It is well known that there exists an optimal control law [4] 

n°(i') = /[*(:)] * = 0,1,..., M- 1 (2) 

that minimizes the quadratic performance index function (Cost) 

M—1 

Jm= J2 I x r (k)Qx(k) 4- u T {k)Ru(k)) + x t (M)Ox{M) (3) 

less0 

where Q £ 72 nx " is positive semi-definite and R £ 7Z lxl is positive definite. 

As we can see, traditional controller exercises control at every time instant in Dm- However, 
in temporal control, we are no longer constrained to exercise control at every time instant in Dm- 
Therefore, we want to find an optimal control law, 6 and g for i = 0,1 - 1: 

u°(i) = u°(i — 1) if <5(t) = 0 (4) 

«°(0 = ^[ 2 ( 0 ] *7 < 5(0 = i 


41 









(5) 


that minimizes a new performance index function 

A/-1 m-i 

Jm = E [x r {k)Qx{k) + v x {k)Ru(k)) + x J {M)Qx{M) + 6{k)fi 

k=0 lc =0 

= Jm + Cm 

Hena, fi is the computation cost of getting a new control value at a time instant, and Cm = 
Eft;’ 6(k)fi denotes the total computation cost. Is'ote that v = Ylh=o l ^e number of 

control changes. Also, let D v = {to,*i,* 2 ) • • -, } consist of control changing time instants where 

to = 0, t\ — TiiA, • •i „-1 = n^A. That is, no,ni,n 2 ,...,n„_i are the indices for control 
changing time instants and <5(n,) = 1 for i = 0, 1 , 2 ,.. .v — 1 . 

With this new setting we need to choose v, D u , and control input values to find an optimal 
controller which minimizes j' M . This new cost function is different from Jm in two aspects. First, 
the concept of computational cost is introduced in j' M as Cm term to regulate the number of control 
changes chosen. If we do not take this computation cost into consideration v is likely to become 
M. If computation cost is high (i.e., /i has a large value) then v is likely to be small in order to 
minimize the total cost function. Second, in temporal control, not only do we seek optimal control 
law u(z(t)), but also the control exercising time instants and the number of control changes. In the 
next section, we present in detail specific techniques for finding an optimal temporal control law. 

3 Temporal Control 

We develop a three-step procedure for finding an optimal temporal controller. 

Step 1. Find an optimal control law given v and B v 
Step 2. Find best D u given v 
Step 3. Find best v 

First, in the following two subsections(3.1 and 3.2) we derive a temporal control law which 
minimizes the cost function J' M when D u is given, i.e., both time instants and number of controls 
are fixed. Since v and D v are fixed we can use Jm defined in ( 5) as a cost function instead of 
4- Secondly, assume that v is fixed but D v can vary. Then we present an algorithm in section 
3.3 to find a D° v such that Jm (and J' M ) is minimized. Finally, we will vary v from 1 to v max 
to search an optimal at which temporal control should be exercised. Section 3.4 presents this 
iteration procedure. Section 3.5 explains how to incorporate terminal state constraints into the 
above procedure of getting an optimal temporal control law. And a complete algorithm of the 


42 





above procedure is described in Section 3.6. Finally, in Section 3.7 we explain how to get optimal 
temporal controllers over an initial state space. 

3.1 Closed-loop Temporal Control with D v Given 

Assume that v and D u are given. Then a new control input calculated at U will be applied to the 
actuator for the next time interval from U to t,- +J . Our objective here is to determine the optimal 
control law 

u°(n,-) = s{ar(n,)) i = 0,1 ,v - 1 (6) 

that minimizes the quadratic performance index function (Cost) Jm which is defined in ( 5). 

State Cost 



Control Input Cost 


Figure 1: Decomposition of Jm into J). 

The principle of optimality, developed by Richard BeUman[2, 3] is the approach used here. That 
is, if a closed loop control u°(n;) = p[z(n,-)] is optimal over the interval t 0 < 1 < t v , then it is also 
optimal over any sub-interval t m < t < t„, where 0 < m < v. As it can be seen from Figure 1, the 


43 









( 7 ) 


total cost Jm can be decomposed into F;s for 0 < i < v where 

F; = z r (ni)Qx(rii) -f x T (n t - + l)Qx(n,- + 1) 

+ x T (ni + 2)Qx(ni + 2) + ... + z T (n,- + i - l)Qx(n, +1 - 1) 

+ (n, +1 - n;)u T (n,-)Ru(n ; ) 

That is-, from ( 1), 

Ji = i T (ni)(5x(n,-) + (Az(n,-) + 5ti(n,-)) T Q(Ai(ni) + £u(7t,-)) (8) 

+ (A 2 x(n,-) + ABu(n<) + Bu(ni)) T Q(A 2 x(ni) -f ABu(n;) -f Bu(n,-)) 

■f ••• + (j4 n ' +,-n ’~ 1 z(n l ) + A n, * ) ~ n '- 7 Bu(ni) + ... -f ABu(n{) + j9u(n,-)) r Q 
( j4 n, +J -n,-l a .( n .) + A n -+'- n '- 7 Bu(m) + ... + ABu(ni) + Bu(m)) 

+ (n,+i - n,)u T (n,-)Jlu(n,) 

This can be rewritten as 

n,+] -n, -l 

Fi = x T (m)Qx(ni)+ [Ajx(ni) +Bjuin^fQlAjxin^A Bju(ni)] (9) 

i=i 

+ {n i+ 1 - n,)ii T (n,).Ru(n l ) 

where A: = A : and Bj = A k B. 

Then Jm can be expressed as 


Jm = Fo + Fy -r Fi -r ... + F),. (10) 

Let S m be the cost from i = v - m 1 to = v: 

Brr. -Ti.—m + 1 "7" F i/—T7i4*2 "T" ... * -FJ * T i /. 1 ^ 77Z ^ V 1. (11) 

These cost terms are well illustrated in the above Figure 1. 

Therefore, by applying the principle of optimality, we can first minimize 5j = F u , then choose 
F„~i to minimize 5 2 = ,F„_i -r F v — Sf -I- F v -\ where 5f is the optimal cost occurred at t„. We 
can continue choosing -F „_2 to minimize 53 = F „-1 -f F v - 1 -f F„ = iZ -2 t Sf so OD 
S„ + i = is minimized. Note that S\ = F u =■ r7"(rc.„)Q2(n„) is determined only from x{n u ) which 
is independent of any other control inputs. 




3.2 Inductive Construction of an Optimal Control Law with D„ Given 

We inductively derive an optimal controller which changes its control at v time instants 
. . t u - j. As we showed in the previous section, the inductive procedure goes backwards in time 
from 5® to 5° +1 . Since S\ — F u =■ x 7 (n„)Qz(n„) -f v T (n l/ )Ru(n u ) and 2 ( 77 ^) is independent of 
u(7i„), we can let ti°(n„) = u°(M) = 0 and 5f = 2 - r (n„)Q 2 (n 1/ ) where Q is symmetric and positive 
semi-definite. 

Induction Basis: 5f = i T (n 1/ )(2i(n„) where Q is symmetric. 

Inductive Assumption: Suppose that 

S£ = z T (n 1/ _ m+: )P(t/ - m + ) 

holds for some m where 1 < m < v and P(u — m- f 1) is symmetric. 


We can write as 

Sm = [-^•(n v _ rn 4 j-n v _ m ) :c ( n *'-in) + P(n„_ m+] P(v — 771 + 1) 

[•^.(n„_ m+ 3 -r.„_ rT1 ) a: ( 7l *'-m) + 5(r.,_ m+ j ) u ()] 

From the definition of 5 TO and (9), 


( 12 ) 


•Sm-i-l 


F£ + - T (^-Tn)Q2(n J/ _ Tn ) (13) 

^ ^ it(rn )j [j4yx( ft*,—m ) t in )] 

j=i 

m-rl m )u tn ) 


And the above equation becomes 




[^■n v _ m+ :-n. v _ Tn 2 ( 71 K-Tji) . _ n „_ m tl(n t/ _ Tn )]‘^P(j/ 77J-f l) (14) 

i^r. 1/ _ IB+ 3-n^_ m s ( n v-ir. ) + -Sn„_ m+5 — ji„_„ t^Ti^-m)] 

2 (t 1 1/ _ 7JI )£?2 (n.i/_rr. ) 

m+J *” F* fc'—m 1 

-r Pju(n t/ _ TO )] r ClAy2(n l ,_ TO ) 4- 
i=l 

(tii*—m-fi (rt^_j t; )Pn(n i ._37;) 


45 








If we differentiate S m4 i with respect to then 

_™ + -- — n- A^-m) 

( A L-™ + l-n_ A( V ~ m + - ,) T l(Vm) 

'T* __ . . _ . 


9u(n„_ m ) 


(15) 




—tt» 43 ”■•***'—m “" 1 


(16) 


f- J I**'—m i 

[2£jQi4ji(n v _ m ) -f 2SjQ£jii(n t/ _ m )] 
i=i 

4” Tl l/ _ rn _|.2 71^—m )-^'^’(^•1/—m ) 

= 2 {- B J,_ m4J -n,_ m - F> (^-”l+ l)V™ +1 -n- m 

—tti4' 

+ Y BfQAj}x(n v - m ) 

l=i 

ff" 2{i? ni/ _ m+ j _ n „_„ •^ > (t / — rn + 1 )-B TIi/ _ tti+3 _m,_ m 

Ti u-m 4 ] 

+ S BfQBj + (n^.jn+a - 

Note that P{ v - m + 1) is symmetric and the following three rules are applied to differentiate S m +i 
above. 

J^(x r Qx) = 2Qx 
■~(* T Qy) = Qv 

j- y (z TQy) = qTx 


Let 


P ^ 

- "-'S = 0. from Lemma 1 and Lemma 2 given later we can obtain ^{nu-A which 

CU\T*i,—Tn) ' 


minimizes 5 m +i sJid thus obtain 5£, 4l 


i-i 


U (n*/-rr. ) — P { v m ' 3 )-®r.^_ m4 j -T^- m 

"T B j Q B j T (itj/—m-fj n„_ m )il} 

1=1 

m+3 to —I 

~ ™ + 1M„- 43 -r_ + 51 CT 

1=1 

= — K(v - m)x(7i„_ m ) 

where K{v - m) is denned in ( 17). 


(!') 


£j<5Aj}x(Ti„_ Tn ) 


46 


1 




Therefore, we can write 


-n„_ m -n^_ m V ( n u-m) — (IS) 

(^n v _ m+) -n^_m _ -n„_ m 71 { v ~ m )] 2: ( n i/-in ) 

If we use ( 17) and ( 18), we have 

S c m +1 = {[Awm+ 1 —- B n „_ m ^-n^ m K(v- m)]z(n„_ m )} T P(i/- m+ 1) (19) 

{[^n^-m+i-ni~m ~ A (l/ - m)]z(n 1/ _ TO )} 

"h z ) Qx{rii/—Tn ) 

+ ^ {(^4; - BjK(L> - r7i)]z(n 1/ _ m )} r <?{[Aj - BjK{y - m)]s(n„_ m )} 

j=i 

+ (n^_ m+1 - n„_ tn )[j£'(i/ - m)x(n t ,_ m )] T P[A'(x'- m)x{n v - m )} 

This equation can be rewritten as 

‘S’m+l = 2 " r ( 71 »'-i 7 i){[-^n„_ m+ ) -n„_ m — K{v — m)] 7 'P(l/ — 771+1) (20) 

[^l»i,_m+l — fn -®7l v _ m 4 j — 7!v-m (^ m )j 

+ Q 

+ * m+ E^ " 14> - £;*(* - m)f Q[A,- - J5,-JT(v - m)] 

i=i 

*?“ (^t^—m-ft — 71 ^—^)^ (rtj/—77J) P.K[y m)}x(n t ,_ 771 ). 

= x r (n 1/ _ m )P(i/- m)x(n 1/ _ m ) 

where P(i/ - m) is obtained from K{v — m) and P(i v - m -f 1) as in ( 20). Also note that knowing 
P[y - m + 1) is enough to compute K(u — m) because other terms of ( 17) are known a priori. 

Therefore, we find a symmetric matrix P(i/-m) satisfying 5£, +1 = x- r (n )/ _ Tn )P(z/-7n)x(n l ,_ 7n ). 
From ( 17) and ( 20), we have the following recursive equations for obtaining P{v — m) from 
P(i/ - m + 1) where m - 1,2, v. 


i>-m) = {B?_ 


m-f 2 m 


P(v - m + l)P^_ m+: -n,. m 


5"*^ — TT>-fl — T*i/—fr. } 

22 - 7l 1/ _ m )P}‘ 

J=] 




{^_ ra+3 -n,_ ra -P(^ - "*+ l)A n _ m ^ 3 _ n _ m + 22 £ JQ A j) 

J=J 


47 





P( u — m) 


(22) 


I 


- [•4n„_ m+ ,-n„_ m - Br^_ m ^ n ^ m K{v - m)) T P(v - m + 1) 

—m-f 1 —m —m+1 —flu— m ^ ^0] 

+ Q 

Hv — m«f 3 ~— m ”“1 

r XI \ A i ~ B i K ( v - m )) T Ql A : - - m)) 

j=i 

+ (n„_ m+ i - n„- m )K T (v - m)RK{v - m ) 


Also, we know that at each time instant A 


u°(n^_ m ) = -K(y - m) 


(23) 


Hence, with P(i/) = <2, we can obtain K(i) and P(i) for i = v - 1, v - 2,...,0 recursively using 
( 21) and ( 22). At each time instant n,-A, i = 0,1,2,...,!/— 1 the new control input value will be 
obtained using ( 23) by multiplying K(i) by x(n,-) where x(n,-) is the estimate of the system state 
at n,-A. .Also, note that the optimal control cost is J° M = = x T (0)P(0)x(0) where P(0) is 

found from the above procedure. 

To prove the optimality of this control law we need the following lemmas. 

Lemma 1 If Q is positive semi-definite and R is positive definite, then P(i), i = v, v—1, v-2. .... 0, 
matrices are positive semi-definite. Hence, P(i)s are symmetric from the definition of a vositive 
semi-definite matrix. 


Proof Since P( u) = Q , from assumption P(j/) is positive semi-definite. Assume that for 
k = i- r 1, P(k) is positive semi-definite. We use induction to prove that P(i) is semi-definite. Note 
that Q is positive semi-definite and R is positive definite. From ( 22) we have 

P( 0 = K. +s -n.-Pn. +J -n,iir(i)] T -P(i+l) (24) 

[/4. n , +3 -r.,- — Pj-., +J -n,■■&"(*)] 

-r Q 

+ [Aj - BjKWfQlAj - B. -A'(i)3 

J=1 

+ (n, +1 - n,)P T (i)PP(f) 


48 


I 






Since P(i + 1) and Q are positive semi-definite, R is positive definite, and (n t+1 - n,) > 0, it 
is easy to verify that for Vy £ R m : y T P(i)y > 0. This means that P(i) is positive semi-definite. 
This inductive procedure proves the lemma. 

Lemma 2 Given Dthe inverse matrix in (21) always exists. 


Proof Let V = - m + 1 B ?QB, + 

- n v „ m )R. From Lemma 1, P(v — m-f 1) is positive semi-definite. Therefore, Vy £ R m : 
y T Vy > 0 because Q is positive semi-definite, R is positive definite and — n v _ m > 0. This 

implies that V is positive definite. Hence the inverse matrix exists. 


Theorem 1 Given D u , Ji'(i) (i = 0,1,2, — l ) obtained from the above procedure are the optimal 

feedback gains which minimize the cost function Jm (and j' M ) on [0, MA). 


Proof Note that given D„, Jm is a convex function of u(n,-),i = 0,1,..., v— 1. Thus the 
above feedback control law is optimal. 

Lemma 3 If p < q and D v C D q , then > J^ where J° M ^ and are the optimal costs of 
controls which change controls at time instants in D P and D q respectively. 

Proof Suppose that J° M ^ < Jj^. then, in controlling the system with D q , if we do not 
change controls at time instants in D q - D v and change controls at time instants in D v to the same 
control inputs that were exercised to get with D v , we obtain Jm, which is equal to Jy . This 
contradicts the fact that Jy is the minimum cost obtainable with D n since we have found Jm, 
which is equal to Jy and therefore less than Jm,- Hence, Jfc > J%' 4 . 

This lemma implies that if we do not take computation cost, yt, into consideration, then the 
more control exercising points, the better the controller is (less cost). With the computation cost 
being included in the cost function, the statement above is no longer true. Therefore we need to 
search for an optimal D u which minimizes the cost function J' M . The following sections provide a 
detailed discussion on searching for such an optimal solution. Note that if we let D„ = Dm then 
the optimal temporal control law is the same as the traditional linear feedback optimal control law. 


49 





3.3 Optima! Temporal Control Law over D„ Space with v Given 

^'hen the number of control changing points, v, and an initial system state x(0) are given, we I 

search over a set of possible D v s and u[D u )s such that the cost function Jm is minimized. This 

can be done by varying v - 1 control changing time instants, t,-, i = l,2,...,v— 1 (since t 0 = 0) 

over the discrete set, Dm = {0, A,2A,. .., (M - 1)A} and applying the technique developed in the 

previous section for each given D„. Let us denote such a D v which minimizes Jm a-s D° v . Note 

that when v is given, minimizing Jm Is equivalent to minimizing J M . Since both D u and u{D u ) 

are control variates, to be able to find a global optimal solution, either an exhaustive search or J 

some global search methods like Genetic Algorithm or Simulated Annealing should be considered. 

liter we-pfWent & numeric*! example, m which an exhaustive search with Steepest Descent Starch 

method is used. Searching for a globally optimal solution for a temporal controller calls for further 

research. 

3.4 Optimal Temporal Control Law 

Assume that a maximum number of control changing points, is given. By varying u from 

1 to i/ ma _ we can find D°. to obtain a globally optimal temporal controller which minimizes 4- 

This can be done by first searching for D° u for each given v and then comparing the cost function 

4 = Jm + vp at each v = 1,2,..., i/ mc _. That is, let = x r (0)P(0)r(0)-f vp where 

P(0) is calculated at D° as in the previous section. Then we can obtain a global minimum cost | 

J'm = mini<*<i, ma -{4„} ^ ^ optimal number of control changes, u°, at which j'fi^ = 

3.5 Terminal State Constraints 

The terminal state constraints may be used to check if the optimal temporal controller with D%. 
can drive the system state to a permissible final state within a given time. Let Xj be a set of j 

allowed terminal states, if x(n„) € Xj, then the control law is said to be stable in terms of the 
terminal state constraints and not stable if x(n„) £ Xj. If the globally optimal temporal controller 
obtained from the above procedure is not stable, v’ should be increased until a stable one is found. 

One way of specifying terminal state constraints for regulators might be | x(Af),- |< £,• where x(M){ 
is the ith element of x(M) state vector. 


50 


I 


3.6 Algorithm to Derive an Optimal Temporal Controller 

To summarize the above discussion, we provide in Figure 2 a complete algorithm to search for a 
globally optima] temporal controller under the assumption that the initial state x(D) is given. 

In the algorithm, a neighbor of D„ = {n 0 A, nj A, n 2 A,..., A} is defined to be any member 
of a set N(D V ) = {{n^A, n' A,..., A} | | n) - «,• | < 1, i ~ 1,2,.. .,v - 1}. 

3.7 Optimal Temporal Controllers over an Initial State Space 

Note that D° v might become different if a new initial system state x(0) is used instead of x(0) when 
the state vector is in P mXl where m > 2. This is because the cost function Jm = x r (0)P(0)x(0) 
depends on x(0) as well as P(0). Thus, D° v is dependent on the initial state x(0). However, when 
m — 1 it can be shown that D° v is independent of any initial state. To see this let x(0) = kx( 0) 6 
and P(0) and P(0) be the optimal matrices with initial states x(0) and x(0), respectively, i.e., 


J M (*(0)) = x(0)P(0)s(0) 
J M (i(0)) = x(0)P(0)x(0) 


From the optimality of P( 0) with respect to x(0), 

x r (0)P(0)x(0) > x r (0)P(0)x(0) 


Multiplying the above inequality by k~ we have 


/: 2 x T (0)P(0)x(0) = 
> 


x J (0)P(0)x(0) 

I- 2 x T (0)P(0)x(0) 

x T (0)P(0)x(0) 


(25) 


(26) 


On the other hand, due to the optimality of P(0) we have 

x T (0)P(0)x(0) > x r (0)P(0)x(0) (27) 

Therefore, P(0) = P(0). This implies the optimality of P(0) and D° u for any initial state 

x(o) € 

Generally speaking, the above result will not hold for m > 2 cases. However, using the same 
argument discussed above we can prove that for any initial state x(0) = ix(0), x(0) and x(0) will 
have the same Dl as well as the same P(0). 


51 





V° = 1 
~ 00 

for v = 1 to i i/ mex { 

/* Several different search starting points */ 
for i = 1 to N umlnitPtSv { 

D u = D” nii ' { 

I* Iterate until a local minimum is found - Steepest Descent Search */ 
while (MinimumFound 1= True) { 

Find optimal costs for neighboring points of D„ using theorem 1 
if ( j' M has a Local Minimum at D v ) 
then { 

MinimumFound = True 
~ Cost (J M ) at D„ } 

else 

B v — a neighbor of D„ with the smallest j' M 

} 

} 

if ( J'm.< J'm) 

then { 



Figure 2: Complete algorithm to find an optimal temporal controller. 


52 













4 Implementation 

To implement temporal control, we need to calculate and store matrices in ( 22) and use them 
when controlling the system utilizing ( 23). Note that in traditional optimal linear control a similar 
matrix is obtained and used at every time instant in Dm to generate control input value. While 
the feedback gain matrices for traditional linear optimal controller are independent of initial states, 
the number of control exercises, u, and K(i) matrices are dependent on initial states for temporal 
control systems. But, if the possible set of initial states is in 7S 1 they are independent of the initial 
states. Effective deployment of temporal control requires that we know the range of initial state 
values and generate L'(i) matrices for each group. A sensitivity analysis is required to determine 
how many distinct matrices need to be stored. 

In order to implement temporal control we require an operating system that supports scheduling 
control computations at specific time instants. The Maruti system developed at the University of 
Maryland is a suitable host for the implementation of temporal control [10, 8, 7]. In Maruti, all 
executions are scheduled in time and the time of execution can be modified dynamically, if so 
desired. This is in contrast with traditional cyclic executives often used in real-time systems, which 
have a fixed, cyclic operation and which are well suited only for the sampled data control systems 
operating in a static environment. It is the availability of the system such as Maruti that allows 
us to consider the notion of temporal control, in which time becomes an emergent property of the 
system. 


5 Example 

To illustrate the advantages of a lemporal control scheme let us consider a simple example of rigid 
body satellite control problem [12]. The system state equations are as follows: 


x{k~ 1) 


vi k ) 


0 1 

*(*) + 

0 

-1 2 

0.00125 

1 1 ] x(k) 



u{k) 


the discretized subinterval of length 
( 5) is used here with the following 


Q = 


i o 
0 1 


where k represents the time index and one unit of time is 
A = 0.05. The linear quadratic performance index J' M in 
parameters. 


53 






Figure 3: Optima] Linear Control with A = 0.05. 


R = 0.0001 

H = 0.02 & 0.01 

M = 40 
A = 0.05 


e; 

x(0) 


0.01, i = 1,2 



(28) 


The objective of the control is to drive the satellite to the zero position and the desired goal 
state is xj = [0, 0] 3 ". The terminal state constraint is | s,-(40) |< e, i = 1,2. With the equal 
sampling interval A = 0.05 and M = 40 the optimal linear feedback control of this system has cost 
function Jm = 0.984678 (without computational cost) and j' M = 1.784678 (with computational 
cost) and is shown in Figure 3. The terminal state constraint is satisfied at O.Ssec. 

If we apply the temporal control scheme presented above to this problem with p = 0.02 we find 
that the optimal number of control changes for this example is 3 and D§ = {0,2A, 10A} with a 
cost J M = 1.08388. Note that the 40 step optimal linear feedback controller given above has a cost 
j‘ M = 1.784678 when computation cost is considered. Table 1 shows how this optimal controller 
is obtained when we set y mc= = 7. Figure 4(a) shows the system trajectory when this three-step 
optimal temporal controller is used to control the system. This trajectory satisfies the terminal 
state constraint at 0.8sec as well. Also, the maximum control input magnitudes, | u j mcr , in both 


54 


71 

Dl 

Cost (J M ) with p = 0.02 

Cost(J M ) with p = 0.01 

1 

{0} 

4.630S9 + p = 4.65089 

4.63089 +p = 4.64089 

2 

{ 0 , 1 } 

1.44603+ 2p = 1.48603 

1.44603 + 2p = 1.46603 

3 

{0,2,10} 

1.02388+ 3p = 1.08388 

1.02388+ 3p = 1.05388 

4 

{0,2,9,11} 

1.02224 +4p = 1.10224 

1.02224+ 4p= 1.06224 

5 

{0,1,3,8,11} 

0.996968+ op = 1.096968 

0.996968+ 5p= 1.046968 


{0,1,3,8,11,24} 

0.996746+ 6p = 1.116746 

0.996746+ 6p = 1.056746 


{0,1,3,8,11,23,25} 

0.996745+ 7p = 1.136745 

0.996745+ 7p = 1.066745 


Table 1 : Calculating optimal temporal controllers. 

controllers lie within the same bound B = 50, which may be another constraint on control. 

The optimal temporal controller found with p = 0.01 has v = 5 and = {0, A, 3A, 8 A, 11A} 
with a cost Jm = 0.996968. Note that this cost is even less than 1.01269 which is obtained from 
the optimal controller with equal sampling period O.lsec and 20 control changes. 

If we change control values only at three time instants with equal sampling period, 13 M = 
0.65sec, the total cost incurred is 2.2823(wjthout computational cost) on the time interval [0,2], 
The cost is more than twice that of our optimal temporal controller and the terminal state constraint 
is not satisfied even at the end of the controlling interval of 2.0sec. Figure 4(b) clearly shows the 
advantages of using an optimal temporal controller over using an optimal controller of equidistant 
samplings. Their performances are noticeably different though both of them are changing controls 
at three time instants. It is clear that the optimal temporal control with three control changes 
performs almost the same as 40 step linear optimal controller does. This implies that enforcing the 
constant sampling rate throughout the entire controlling interval may simply waste computational 
power which otherwise could be used for other concurrent controlling tasks in critical systems. 

Obtaining I?| for this example was simple since J 4 o has only one minimum over the entire set 
of possible D 3 S on (0,40Aj. Figure 5(a) and Figure 5(b) show that J 4 0 has only one local(global) 
minimum at i?| = {0,2A, 10A}. We got this optimal D$ by doing steepest descent search with the 
starting point = {0, A, 10A} after searching for only three points, {0, A, 10A), {0,2A, 10A), 
{0,3A,10A}. Also, Figure 5(a) shows that choosing nj has greater influence on the total cost than 
7*2 since the cost varies more radically along the nj axis in the figure. This means that the initial 
stage of the control needs more attention than the later stage in this linear control problem. 

But, if we change one of the parameters of performance index function, R, from 0.0001 to 0.001 
we get two local minima at D\ = {0,A,2A} and D\ = {0,3A,19A}, among which D\ is the 


55 










1 


(b) 


Figure 4: Control trajectories with 3 control changes, (a)Optimal temporal control with D§ = 
{0.2A, 10A}. (b)Optimal linear control with 13A (O.Sosec) period. 


56 


1 













Figure 6: Costs near D\ and D\ with R = 0.001. 

optimal one with less cost. Figure 6 shows this fact. In this case we need to use steepest descent 
search method at least twice with different search starting points to get am optimal solution. We 
implemented this steepest descent search algorithm in Mathematica and used it to generate D° v for 
several examples by varying v. For our examples of linear time invariant system control problems 
the number of local minima was not so large that we could efficiently apply this search method 
just a few times with different initial D'™ 1 s to get a global minimum without doing an exhaustive 
search over the entire D v space. 

6 Discussion 

Employing the temporal control methodology in concurrent real-time embedded systems will have 
a significant impact on the way computational resources are utilized by control tasks. A minimal 
amount of control computations can be obtained for a given regulator by which we can achieve 
almost the same control performance compared to that of traditional controller with equal sampling 
period. This significantly reduces the CPU times for each controlling task and thus increases the 
number of real-time control functions which can be accommodated concurrently in one embedded 
system. Particularly, in a hierarchical control system if temporal controllers can be employed for 
lower level controllers the higher level controllers will have a great degree of flexibility in managing 
resource usages by adjusting computational requirements of each lower level controller. For example, 
in emergency situations the higher level controller may force the lower level controller to run as 


58 


















infrequently as they possibly can (thus freeing computational resources for handling the emergency). 
In contrast, during normal operations the temporal control tasks may run as necessary, and the 
additional computation time can be used for higher level functions such as monitoring and planning, 
etc. 

In addition, the method developed in Section 3.2, which calculates an optimal controller when 
control changing time instants are given, can be applied to the case in which the control computing 
time instants cannot be periodic. For example, when a small embedded controller is used to 
control several functions, it may be a lot better to design a temporal controller for each function 
such that the required computational resources are appropriately scheduled while retaining the 
required degree of control for each function. 

7 Conclusion 

In this paper we proposed a temporal control technique based on a new cost function which takes 
into account computational cost as well as state and input cost. In this scheme new control input 
values are defined at time instants which are not necessarily regularly spaced. For the linear 
control problem we showed that almost the same quality of control can be achieved while much less 
computations are used than in a traditional controller. 

The proposed formulation of temporal control is likely to have a significant impact on the 
way concurrent embedded real-time systems are designed. In hierarchical control environment, 
this approach is likely to result in designs which are significantly more efficient and flexible than 
Traditional control schemes. As it uses less computational resources, the lower level temporal 
controllers will make the resources available to the higher level controllers without compromising 
the quality of control. 

References 

[1] A. Belleisle. Stability of systems with nonlinear feedback through randomly time-varying 
delays. IEEE Transactions on Automatic Control, AC-20:67-75, February 1975. 

[2] R. Bellman. Adaptive Control Process: A Guided Tour. Princeton,NJ: Princeton University 
Press, 1961. 

[3] Bellman. Bellman special issue. IEEE Transactions on Automatic Control, AC-26, October 
1981. 


59 







[4] P. Dorato and A. Levis. Optimal linear regulators: The discrete time case. IEEE Transactions 
on Automatic Control, AC-16:613-620, December 1971. 

[5] A. Gosiewski and A. Olbrot. The effect of feedback delays on the performance of multivariable 
linear control systems. IEEE Transactions on Automatic Control, AC-25(4):729-734, August 
1980. 

[6] K. Hir’ai and Y. Satoh. Stability of a system with variable time delay. IEEE Transactions on 
Automatic Control , AC-25(3):552-554, June 1980. 

[7] S. T. Levi, Satish K. Tripathi, Scott Carson, and Ashok K. Agrawala. The MARUTI hard 
real-time operating system. ACM Symp. on Op. Syst. Principles, Op. Syst. Review, 23(3), 
July 1989. 

[8] Shem-Tov Levi and Ashok K. Agrawala. Real Time System Design. McGraw Hill, 1990. 

[9] Z. Rekasius. Stability of digital control with computer interruptions. IEEE Transactions on 
Automatic Control, AC-31:356-359, April 1986. 

[10] Manas Saksena, James da Silva, and Ashok K. Agrawala. Design and Implementation of 
Maruti-II , chapter 4. Prentice Hall, 1995. In Advances in Real-Time Systems, edited by Sang 
H. Son. 

[11] K. G. Shin and H. Kim. Derivation and application of hard deadlines for real-time control 
systems. IEEE Transactions on Systems. Man and Cybernetics, 22(6):1403-1413, November 
1992. 

[12] G.S. Virk. Digital Computer Control Systems, chapter 4. McGraw Hill, 1991. 

[13] K. Zahr and C. Slivinsky. Delay in multivariable computer controlled linear systems. IEEE 
Transactions on Automatic Control, pages 442-443, August 1974. 


60 





REPORT DOCUMENTATION PAGE 


form Approve 
QmB ho 07CK.Q18S 


•"•'■“C *; *.•**»*>*■ * **w' d<- 1»»r »«»y to* *»*>—■— »*«u«wnip^i, r«nt«^ o*«* KM'trt. 

“ e ’*••*“*•*■: * — *^*‘'*o~ •*■* •*•*••■'me** s«**o c —*»»■*■■ *>n '«~o*ro> M o »*n O' #*»v »tefn e 1 t^n 

“•v r <*C“' t\ .Vi»»«*ctpA ip*«a w .vi^t >r**nn l>»env»u i©' 'mo^^ho" Oof»»io"> ^roenj WU 
' " - M -* ?' <*>r' •*»»own«C" ►»Oi»*c» (0/0^*0'S8) A»»*w*^t<y OC 7D%03 


1. AGENCY USE ONLY (tfrfvf D.jn<; 2. REPORT DATE 

Julv 1995 


A. TITLE AND SUBTITLE 

Designing Temporal Controls 


6. AU.THOR(S) 

Ashok K. Agrawala, Seonho Choi & Leyuan Shi 


3. "REPORT TYPE AND DATES COVERED 

Technical Report 


S. FUNDING NUMBERS 


N00014-91-C-0195 and 
DSAG-60-92-C-0055 


7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 

University of Maryland 
A.V. Williams Building 
College Park, Maryland 20742 


9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES) 

Honeywell Phillips Labs 


3660 Technology Drive 
Minneapolis, MN 55418 


11. SUPPLEMENTARY NOTES 


3550 Aberdeen Ave. SE 
Kirtland APB, NM 

87117-5776 


8. PERFORMING ORGANIZATION 
REPORT NUMBER 

CS-TR-3504 

UMIACS-TR-95-81 


10. SPONSORING / MONITORING 
AGENCY REPORT NUMBER 



TZa. DISTRIBUTION /AVAILABILITY STATEMENT 


12b. DISTRIBUTION CODE 


13. ABSTRACT (Maximurr. 2CD worcJl 

Traditional control systems have oeen designed to exercise control at regularly 
spaced time instants. When a discrete version of the system dynamics is used, a 
constant sampling interval is assumed and a new control value is calculated and 
exercised at each time instant. In this paper we formulate a new control scheme, 
temporal control, in which we not only calculate the control value but also decide 
time instants when the new values are to be used. Taking a discrete, linear, time- 
invariant system, and a cost function which reflects a cost for computation of the 
control values, as an example, we show the feasibility of using this scheme."We 
formulate the temporal control scheme as a feedback scheme and, through a numerical 
example, demonstrate the significant reduction in cost through the use of temporal 
control. 


ia. $us;ect terms 


Computing Methodologies 


15. NUMBER OF PAGES 

22 pages 


15. PRICE CODE 


■IT. SECURITY CLASSIFICATION I IB. SECURITY CLASSIFICATION IS. SECURITY CLASSIFICATION 20. LIMITATION OF AESTRAC 


1 OF REPORT 

I Unclassified 


-\-SN 7SAC l -0i-2S0-5500 


OF THIS PAGE 

Unclassified 


of abstract 
Unclassified 


Unlimited 


S'.i^aa'O -orn 295 !Re« 2-89) 






















V 


1 


I 


1 


62 


I 






Scheduling an Overloaded Real-Time System * 


Shyh-In Hwang, Chia-Mei Chen, and Ashok K. Agrawala 


Institute for Advanced Computer Studies 
Department of Computer Science 
University of Maryland, College Park, MD 20742 


Abstract 

The real-time systems differ from the conventional systems in that every task in the real¬ 
time system has a timing constraint. Failure to execute the tasks under the timing constraints 
may result in fatal errors. Sometimes, it may be impossible to execute all the tasks in the task 
set under their timing constraints. Considering a system with limited resources, one solution 
to handle the overload problem is to reject some of the tasks in order to generate a feasible 
schedule for the rest. In this paper, we consider the problem of scheduling a set of tasks without 
preemption in which each task is assigned criticality and weight. The goal is to generate sin 
optima] schedule such that all of the critical tasks are scheduled and then the non-critical tasks 
are included so that the weight of rejected non-critical tasks is minimized. We consider the 
problem of finding the optimal schedule in two steps. First, we select a permutation sequence 
of the task set. Secondly, a pseudo-polynomial algorithm is proposed to generate an optimal 
schedule for the permutation sequence. If the global optimal is desired, all permutation sequences 
have to be considered. Instead, we propose to incorporate the simulated annealing technique to 
deal with the large search space. Our experimental results show that our algorithm is able to 
generate near optimal schedules for the task sets in most cases while considering only a limited 
number of permutations. 


’This work is supported in part by Honeywell under N00014-91-C-0195 and Army/Phillips under DASG-60-92- 
C-0055. The views, opinions, and/or findings contained in this report are those of the author(s) and should not be 
interpreted as representing the official policies, either expressed or implied, of Honeywell or Army/Phillips. 


63 








I 


1 Introduction 

Ilea]-time computer systems are essential for all embedded applications, such as robot control, flight 
control, and medical instrumentation. In such systems, the computer is required to support the 
execution of applications in which the timing constraints of the tasks are specified by the physical 
system being controlled. The correctness of the system depends on the temporal correctness as 
well as the functional correctness of the tasks. Failure to satisfy the timing constraints can incur 
fatal errors. How to schedule the tasks so that their timing constraints are met is crucial to the 
proper operation of a real-time system. 

As an example of an embedded system, let us consider the air defense system which monitors 
an air space continuously using radars. Whenever an intruder is identified, the embedded control 
system characterizes it and proceeds to initiate the responsive action in a timely manner. The 
temporal constraints for this phase of processing are different depending on the intruder, whether 
it is a missile, a fighter, a bomber, a d umm y, etc. Such a system is designed to handle a number of 
intruders concurrently. If the processing requests exceed the capacity of the system, we expect the 
system to handle a set of the most significant intruders, and not any arbitrary set of intruders. This 
involves rejecting the processing of some real-time tasks based on their importance. In this paper, 
we consider the problem of creating a schedule for a set of tasks such that all critical tasks are 
scheduled, and then, among the non-critical tasks we select those which can be scheduled feasibly 
while maximizing the sum of the weights of selected non-critical tasks. 

As all systems have finite resources, their ability to execute a set of tasks while meeting the 
temporal requirements is limited. Clearly, overload conditions may arise if more tasks have to be 
processed than the available set of resources can handle. Under such overload conditions, we have 
two choices. We may augment the resources available, or reject some tasks (or both). In [8]. a 
technique was presented to handle transient overloads by taking advantage of redundant computing 
resources. Another permissible solution to this problem is to reject some of the tasks in order to 
generate a feasible schedule for the rest. Once a task is accepted by the system, the system should 
be able to finish it under its timing constraint. Some algorithms may have been shown to perform 


64 


I 


well under low or moderate resource utilization. However, their performance degrades if the system 
is overloaded [2]. For example, the EDF algorithm has been shown to be optimal for a periodic task 
set {6] ; If there exists a feasible schedule for the task set, EDF can come up with one. However, 
if the task set is not feasible, EDF may perform unsatisfactorily. The reason is that a task with 
urgent deadline may not be able to finish before its deadline. But, due to its urgent deadline, the 
task has a high priority to use the processor and thus keeps wasting the CPU time until the task 
expires after its deadline. The waste of CPU time may further prevent other tasks from meeting 
their deadlines. The other problem is that there is little control over which tasks will meet their 
deadlines and which will not. 

For an overloaded system, how to select tasks for rejection on the basis of their importance 
becomes a significant issue. When the tasks have equal weight, an optimal schedule can be defined 
to be one in which the number of rejected tasks is minimized. In our previous study 13)., we used a 
super sequence based scheduling algorithm to compute the optimal schedule for the tasks. In this 
paper, the criticality of the tasks are taken into consideration. Basically, if a task can not meet 
its deadline, it is rejected so that the CPU time would not be wasted. Secondly, we would like to 
schedule tasks such that the less important tasks may be rejected in favor of the more important 
tasks. We classify tasks into two categories: critical and non-critical. The critical tasks are crucial 
to the system such that they must not be rejected. The non-critical tasks are given weights to 
reflect their importance, and are allowed to be rejected- A schedule is feasible if all critical tasks 
in the task set are accepted and are guaranteed to meet their timing constraints. If there exists 
no feasible schedule for the task set, the task set is considered infeasible. The loss of a schedule is 
defined, to be the sum of the weights of the rejected non-critical tasks. A schedule is optimal if it 
is feasible and the loss of the schedule is minimum. 

We first propose a Permutation Scheduling Algorithm (PSA) to generate an optimal schedule 
for a permutation, which is a well defined ordering of tasks. When it comes to scheduling a task set 
of n tasks, in the worst case there might be up to n! permutations to consider. We propose a Set 
Scheduling Algorithm (SSA) which incorporates the simulated annealing technique [9] to deal with 
the large search space of permutations. PSA is invoked by SSA to compute the optimal schedule for 


65 







1 


each permutation. Taking the feedback from the schedulability and loss of the schedule generated 
by PSA, SSA is able to control the progress of search for an optimal schedule for the task set. Our 
experimental results show that SSA is able to generate feasible schedules for task sets consisting of 
100 tasks with success ratios no less than 98% and loss ratios less than 10% for most cases while 
searching less than 5,000 permutations. For each permutation, the average number of schedules | 

computed to generate an optimal schedule by PSA, which is invoked by SSA, is usually less than 
500. The SSA algorithm can be considered efficient in dealing with the exponential search space 
for coming up with a satisfactorily near optima! schedule. 

In the following section, we define the scheduling problem. In section 3, we present the idea 
about how to schedule a permutation. In section 4, we incorporate the technique of simulated 
annealing and discuss how to schedule a task set. In section 5, the results of our experiments are 
presented, which is followed by our conclusion. 

2 The Problem 

A task set is represented as T = T 2 ,r n ). A task t, can be characterized as a record of | 

representing the ready time, computation time, deadline, and criticality of the :th 
task. Time is expressed as a real number. A task can not be started before its ready time. Once 
started, the task must use the processor without preemption for c, time units, and be finished 
by its deadline. If a task is very important for the system such that rejection of the task is not 
allowed, w; is set to be CRITICAL. Otherwise, te,- is assigned an integral value to indicate its 
importance, and is subject to rejection if necessary. A permutation sequence, or simply abbreviated 1 

to a permutation, is an ordered sequence of tasks in the task set. Scheduling is a process of binding 
starting times to the tasks such that each task executes according to the schedule. Note that a 
non-preemptive schedule on a single processor implies a sequence for the execution of tasks. For the 
convenience of our discussion, we hereafter use a sequence to represent the schedule in the context. 

A permutation is denoted by fj,= (ti,.. where -f/ is the ith task in the permutation. A prefix "'■ 

of a permutation is denoted by pk = {~i ,.. .,7k). 


66 


I 





To schedule a task set, we need to take into consideration the possible permutations in the task 
set. We first consider an algorithm for scheduling a permutation. The finish time of a schedule is 
the finish time of the last task in the schedule. Let 5jt(t) denote a schedule of pk with finish time 
no more than t. We use W(5*(0) to represent the weight of £*(*), which is the sum of the weights 
of non-critical tasks in the schedule. A feasible schedule of pk is defined as follows: 

Definition: Sjt(t), 1 < /c < n, is a feasible schedule of pk at 1, if and only if: 

1. Sk{l ) is a subsequence of pk, 

2. the finish time of Sk(t) is less than or equal to t , and 

3. all critical tasks in pk are included in Sjj(f). 

An optimal schedule of pk is defined as follows: 

Definition: Ck{t) is an optimal schedule of pk at t, if and only if: 

1. cr^(t) is a feasible schedule of pk, and 

2. for any feasible schedule Sk.(t ) of pk, H'(aA-(f)) > W'(S*(t)). 

In other words, an optimal schedule is a feasible schedule with minimum loss. There are possibly 
more than one optimal schedules for pk with finish time less than or equal to l. We donote by 
Ei(t) the set of all of the optimal schedules for pk at l. Hence, if Sjt(t) € Fjt(t), 5*(t) is an optimal 
schedule for pk at t. 

The scheduling problem considered here is NP-complete. To prove that, its related decision 
problem , which is defined to be computing a feasible schedule with loss no more than a given 
bound, can be easily shown to be NP-complete. This can be done by restricting to PARTITION 
problem [l] by setting r ; = 0, w< = c,-, d,- = | cj, for 1 < i < n. 

3 Scheduling a Permutation 

We consider the problem of finding an optimal schedule for the task set in two steps - select a 
permutation, and find an optimal schedule for the permutation. The methodology is preser. ted in 
Figure 1. 


67 







Loop l: Choose a. permutation pL of T 
Loop 2; for/t*, k s=-l,2,...,» 

Loop 3: compute Ofc(f) 

Figure 1: Methodology 

Clearly, to find the optimal schedule for the task set, all possible permutations have to be 
considered. How to search the permutations will be addressed in section 4. In Loop 3, optima] 
schedules for are computed at some time instants. Next, we discuss how to compute Ok(t) for a 
given 1 in the following, and then discuss how to determine the time instants for pk- 

3.1 Computing cr fc (i) 

We use dynamic programming to compute cr*(t) based on Ok-i (*'), with t' < i. The criticality of 
T k plays an important role in computing Ofc(t). 

If t* is a critical task, we have to schedule it, possibly at the cost of rejecting some of the 
non-critical tasks. Hence, ct*(1) = Sk-\{l r ) © t*, for some schedule where © means 

concatenation of the sequence and the task. The finish time of must be no more than 

t — c* in order to accommodate t*, which leads to f* < t — Ck- The best candidate could be 
Ok-\(t - c k ). Hence, 

a k {i) = Ci)©r*, (1) 

which can be seen in Figure 2. Note that a*(t) only exists for a proper range of i. That is, o*(t) is 
infeasible when t is beyond the proper range, e.g., t < r* -f c*, or if Ok-\{t — c*) is infeasible. The 
range would be considered in details later. 

If t k is non-critical, our concern is to obtain as large a weight for the schedule as possible, while 
the critical tasks accepted previously must be kept in the schedule. Computation of o*(t) is based 






Ok-\(l - Cfc) 





Figure 2: Scheduling for r* 


upon the choice between either including r* or not. 'Rlat is, 


°k{t) = 


- c k ) @ r k or 


( 2 ) 


which can be seen in Figure 2. The factors for making the choice axe the feasibility and the weights 
of the two candidate schedules. That is, the chosen schedule has to be feasible in the first place, 
and has a weight more than or equal to the other. 


3.2 Time Instants for Computing o fc (f) 


From Equations 1 and 2, the computation of is based on the results of and cjt). 

We do not need to look for all possible values for t. We can get the idea about howto determine the 
time instants l by a simple example in Figure 3. The. ready times, computation times, deadlines, 
and weights are given to the tasks in p 3 = ^Tt, r 2 , r 3 ). 

The following schedules for can be easily verified. 


o 3 (0 = INFEASIBLE 
*3(0 = <r 3 ) 

*3(0 = ( t 2,t 3 ) 

O3(0 = (ti,t 3 ) 


for6< 6 

W(<7 3 (0) = 0 for 6 < t < 7.5 

W{o 3 {i)) = 5 for 7.5 < 1 < 9 

W(o 3 {t)) =10 for 9 < t 








12 

J W} = 10 

tl>2 — 5 

u* = CRITICAL 

In general, there exist a number of subranges in each of which the schedules are exactly identical, 
which are illustrated in Figure 4. We only need to compute the schedules at the time instants 
which delimit the subranges, i.e., 6,7.5, and 9. We call these time instants scheduling points. The 
scheduling points can be determined by the timing characteristics of the tasks. 


0 6 7.5 9 12 



Figure 4: Identical subranges 


3.3 Definition of Scheduling Points 

We denote the jith scheduling point for pk by Aand call j the index of A kj. Hence, Ok(^kj) de¬ 
notes an optimal schedule for pk at the scheduling point Aij. Let Vk be the total number of schedul¬ 
ing points at which we need to schedule pk- For simplicity, A* denotes the set of A^, Aj^,..., A 
and Ok the set of a*(A* il ),crfc(Ai, 2 ),..., p*(A* il)Jt ). The scheduling points are defined as follows. 

Definition: The set of scheduling points, A*, is complete if and only if: 

1. for any t < A* tl , E*(t) is empty, 

2. for any A k j < 1 < A for j = - 1, o*(A*j) € X*(l), and 

3. for any t > \ k<Vt , o k {Xi, Vi ) € £*■(*). 

Note that £jt(i) being empty means that there is no feasible schedule with finish time less 
than or equal to 1. And also remember that o k {Xkj) € £jt(t) means that o fc (A fc j) is an optimal 



70 



schedule for fi k at t. The completeness of scheduling points indicates that all ef the optimal 
schedules at the positive real time domain can be represented by the optimal schedules computed 
at the scheduling points. In addition, the set of scheduling points, A*, is minimum, if and only if 
W(£7^(Ajt,j)) < ^(^(Ajcj+i)), for any 1 < j < v k - 1- This ensures that there does not exist any 
redundant scheduling point which, if removed, does not violate the completeness of the scheduling 
points. The sets of scheduling points that we will discuss are complete and minimum. 


3.4 An Example for Deriving Scheduling Points 


The values of A ^ depend on the temporal relations between r k and Ajt-i- The example in Figure 5 
is used to illustrate the relations. We only describe the idea of deriving scheduling points by the 
example, and will discuss in more detaib later. Assume that there are 5 scheduling points for [ik-\, 
and we consider to compute c k based On 0^-\- The current task, t*, may be critical or non-critical. 

scheduling points for 3 : 


^k~ i,2 Ajt— i,a Afc_ lt s 



scheduling points for fi k : T k + c k A*_ lt2 + c k Ai_ 1<3 + c k 


time 



Figure 5: Scheduling Points 


First, let us assume that r k is critical, which means that T k must be the last task in any feasible 
schedules for p. k . A schedule for fi k is thus a schedule for concatenated by r k . Hence, the 
optimal schedules for fi k can be computed by appending r k to j = One 

restriction is that r k must be able to execute during its time window, from T k to d k . Hence, the 
scheduling points are A*-ij + c k , j = subject to the timing constraint of r k . In the 

example, because r k > Ajt-i,:, the first scheduling point is A* f i = r k + c k . The first and the rest 
scheduling points are expressed in Equations 3-5. Notice that A k _ li4 -f c k > d k . Hence, there are 


71 


only 3 scheduling points for /x*. 


Afc.i - n + c fc and ffi(Ajb,i) = (3) 

Ai ,2 = A*_i, 2 + cjt and ajt(A^) = <r*-i(Afc-i. 2 ) © r fc (4) 

Aj .,3 = A t _ :>3 4- c k and cri(Ai, 3 ) = trjt-i (A*_ li3 ) © T k (5) 

On the other hand, let us assume that r* is non-critical. As a non-critical task, r* is not necessarily 
included in the schedule of p.k- Whether to include r* or not depends on how much weight may be 
gained by including t If ~k is included in the schedules, the new possible scheduling points for fik 
are expressed in Equations 6-8. 

A Jt,i= r t- + ct and *fc(Ajfe t ,) = c f ji-i(Ajfe> lt i)©T* (6) 

a 1,2 = A*-i ,2 + Ck and o' k {\' k 7 ) = ou- i(A*_i, 2 ) © r k (7) 

3 = A t— 1,3 t ct and c' k (X' k z ) = (Afc_i. 3 ) © r* (8) 

If T k is not included, the scheduling points for p* are A k-ij, j - 1,..., The scheduling points 
for /xjt can be derived by, first, merging and sorting A^ and X k -i, which gives 

A*-i,i, Ajc-i. 2, A , A*_ 1>3 , Afc_i i4 , A^ 2 , A^j, Ai_i,5. (9) 

Then, the resultant array of scheduling points should follow the rule that the weights of the optimal 
schedules at the scheduling points in the resultant array in Equation 9 should be strictly increasing. 
We remove any scheduling point if necessary. 

3.5 Deriving Scheduling Points 

By the example illustrated in Figure 5, A k can b«= derived from A*_i and t*. Note that a scheduling 
point indicates the finish time of a schedule. If we want to append Tk to o*_i(Ai_u), Tk raTi not be 
started before \k-\j- This implies that A k can be determined by the temporal relations between 
Ajc-i, the finish times of a*, and the start time of t*. Specifically, we need to explore the temporal 
relations between the earliest start time, r*, the latest start time, d k - c*, of r k , and the lower and 


72 






V , and the upper bound 

upper bounds to be defined below. We define the iower bound L,-, - **-u. 

U k i = X k -i v* r ln Particular, they have the following meanings. 

the time instant such th«.t there is no feasible schedule for W-r 

finish time less than L k - 1 - . , _ . « .. 

0m! the least time instant such that the optimal schedule for »,th ^sh 

greater than U k -\ can be 

The six possible temporal relations in Equations 10-15 can be used to determine A*. 

dk - c k < Lk-1 < 
r k < L k -i < dk -c k < V k -1 
< T k < d k ~ Ck < Vk -1 

r fc < Lk-\ < < dje - e fc 

l*_i < r* < Uir-i <dk-c.k 

The temporal relations are illustrated in Figure 6, and can be summed “ ' ^ 

. , . rruistructing scheduling points according to the temporal relates s dtscussed . 
The correctness of the method, i.e„ the compleUne^d minimiaation of the scheduhng pomts , 

is verified later. 


( 10 ) 

( 11 ) 

( 12 ) 

(13) 

(14) 

(15) 


3.5.1 r k is Critical 

The task r„ must be tbe last task in any feasible schedule of W . Remember that otM can be 

r:;td; ^ * *. h ow„ d^ *. ^ *■ *• 

three cases. The readers may refer to the algorithm in seot.cn 3.7 for dew *■ .... 

Case ,*-«,< It-t: , - - feasible. Remember thehthere exists no feeble s^eome , 

w with finish time less than it-.. due to «»completeness ****** ?»»«. “ d ‘ ‘ ‘ " 

u the latest start time for r». Hence, w is not feasible, and thus the whole permutat.on, * 

feasible. 


73 


1 



i -£*-1 

£4-1 

(10) 

- case 1 

i Lk~ 1 


££*-i 

(ii) 

1 

Lk- 1 


£4-i 

(12) 

' — case 2 

| L k - 1 

£4-i I 


(13) 

1 

J 


£4-i j 


(14) 

1 

J 

jLjc-l £4-1 



(15) 

- case 3 


Figure 6: Temporal relations 

Case 2 (r* < Lk-i < d k - Ck) or (Xjt-i < r k < JJ k ~ i) : The scheduling points for pk is the 
set of j -r Ck , j = 1,..ut_i, subject to the constraints that r k must start after r k , and finish 
before d/ ; . Specifically, A* can be derived by Equations 16 and 17. 

Ajfc.i = maz(X k -i,i + c k ,r k + c k ) ( 16 ) 

Let Jmtn and J mo= denote the smallest and the largest integers of j satisfying A*,i < A*_ij+c* < <4. 
The rest of the scheduling points can be computed by 

Aj = A k — lj T Cj;, wheTC J min 5 j $ Jmas Cind i ~ j — Jmin 4 2 (17) 

J\ote that Vk = J mC r — Jmin 4 2. The example given in Figure 5 falls in this case. 

Case 3 Uk-x < 7“*: there is only one scheduling point. Since r* is the earliest start time for r*, 
the only scheduling point is r* + c*. 

3.5.2 Tk is Non-critical 

Remember that £7*(1) can be computed by Equation 2. The non-critical task r* is not necessarily 
included in the schedule for pk • Whether to include r* or not depends on how much weight may 
be gained by including r k . Let us consider the three cases. 


74 


I 









Case 1 djt - c* < Zjt-i' do nothing. The latest start time of rt is less than the lower bound, 
Lk-\ \ hence, t*. can not be included in any feasible schedule. The scheduling points and schedules 
for /!*_] remain the same as the scheduling points and schedules for pk- In our implementation, 
to save time and space, A*_) and A* use the same memory spaces; also, Ok-i and Ok use the same 
memory spaces. So now A* = A^_j and Ck — Ok-\. 

Case 2 (rk < Lk -1 < dk - Ck ) or < r k < Uk-\ ) ■ If T k is included, the new possible 

scheduling points for pk is the set of Xt-ij + c*, j = 1,..., v*-i, subject to the constraints that Tk 
must start after rt, and finish before d*.. Specifically, the new possible scheduling points , X ' k , can 
be derived by Equations 18 and 19. 

A^j = max(A fc _ lil + c k , r k + c*) (18) 

Let J m i n and J ma£ denote the smallest and the largest integers of j satisfying A^ : < A k-\, 3 -rCk < Q T. 
The rest of the scheduling points are 

A k,i ~ ^k— 1J "h Cki "wheTe Jmin ^ j < Jmax O.Tld i — j — J m in 2 (19) 

If Tk is not included, the scheduling points for pk are the old ones for pk-\\ i-e., 

)'k—lji j — 1, . • •, Vk-1 • (20) 

It is worth mentioning that some optimal schedules may include r*, and some may not. The 
scheduling points, A k, can be derived by the following two steps. 

1. Merge and sort the two arrays of scheduling points, A* and A*_ lf in Equations 18-20. 

2. The resultant array of scheduling points should follow the rule that the weights of the optimal 
schedules at the scheduling points should be strictly increasing. We remove any scheduling 
point that has a smaller weight thin that of its preceding scheduling point in the array. 

The example given in Figure 5 falls in this case. 

Case 3 Uk -1 < Tk' add one more scheduling point. The earliest start time of Tk is greater 
than the upper bound, Uk- hence, the new scheduling point is r* + c*. The weight of the 
optimal schedule computed at this scheduling point is lV(ai_)(Ajt_i iVi _ 1 )) + tu*, which is larger than 


75 









W(ok-i (At-i.v*., ))• So this scheduling point must be intluded to make the set of scheduling points 
for p*,. complete. Note again that the scheduling points and schedules for /ik-i remain unchanged 
as the scheduling points and schedules for /:*; i.e., A= Ak_ij and Ok{^kj) = Pk-i(^k-ij), for 
j = However, \k, Vk = T k + Ck and ak(Xk,v k ) = ojb_](A ( t_i iUjt _,)®r*, where Vk = v k -i + 1. 

3.6 Completeness and Minimization of Scheduling Points 

We would like to show that the sets of scheduling points derived in the three cases are complete 
and minimum. Note that cases 1 and 3 are special cases, and are not difficult to verify. Hence, we 
will only briefly discuss case 2. If r k is critical, we would like to show that If Ajt-j is complete and 
minimum, Ak derived by Equations 16 and 1? is also complete and minimum. 

Condition 1 of completeness: Due to the completeness of A*_], j(t) is empty when t < 
Ajt—l.i- Equivalently, E*_i(t - c*) is empty when t < Ajt_i,i + c*. According to Equation 1, 
c k (t) = o k -i{t - Ck ) 6 Tk. Hence, crjt(t) does not exist when t < Ak_i,i + c*. On the other hand, 
since r k is critical, u k {i) does not exist when t < r* + e*, which is the earliest finish time of 
r k . Therefore, E*(t) is empty when i < A*,}. This shows that condition 1 of the definition of 
completeness is satisfied. 

Condition 2 of completeness: Due to the completeness of A*—i, € £k-i(0> for any 

•Ajc-tj - t < Hy Equation 1, ct*_i(A*_ij) © r k is an optimal schedule at A k -\j + c k 

for p. k . Hence, o k -\ (A fc _ lo -) 6^6 £*(«), for Ak-ij + c k < I < A*_ lj+1 + c*. By Equation 17, 
A k,i = Ai_u -i- c k , for i - j - J m i n + 2, which indicates that Ck{h,i) = © n- Besides, 

A *.,-+1 = A k-ij +1 + Ck, for i + 1 = j + 1 - J vnin + 2, by Equation 17. Therefore, a k { A*,,) € S*(0> 
for Ai t ,'< 1 < A*,,’ 4 i. This shows that condition 2 of the definition of completeness is satisfied. 

Condition 3 of completeness: We know that = J mas — J m i n 4- 2. By Equation 17, Ak, v * = 
+ c fc , which indicates that ot(At, V4 ) = ot_i(Ai_i,j mM ) © t*. Due to the completeness 
of A*_i, Ok_i(Ak_i.j m „) € for At-i,^, < t < Afc-i.j m . x+ i, or just At_i,j m „ < t if 

4a.- = ujr-i- By Equation 1, ot-i(Ak-i,j m «) © t* is an optimal schedule at Ak_i,j m<>J + c* 
for /i*. Hence, (At_i,j„ OI ) © t* € £*(*), for At_i,j ra „ + c* < t. Note that the range of 


I I 


t < Xk-i,j mai +i + c* is removed. Because J max is the largest integer of j satisfying A*_i j + c<f < a k , 
the schedule a*_i(A*_ liJm<>I+1 ) © r k would not be feasible. Sincr 0k(X k<Vk ) = © r k , 

a k{X k ,v k ) € Ejt(t) for X k<Vk < t. This shows that condition 3 <A the definition of completeness is 
satisfied. 

Minimization: By Equation 1, W[o k {t)) = W(a k -i(t - c k ) © r k ) = W(o k -i{t - c^)), since a 
critical task has no weight. Because A*_i is minimum, W(a k -i(X^.ij)) < W(<7*_](Afc.-f ,J+ i))> 
for any 1 < j < v*_i - 1. That is, W(ojt_,(Ajt_, i: ,-) © r k ) < M / (o*-i(Aa_i, j +i) © n), for any 
1 < j < - 1. By Equations 16 and 37, W(o} t(A*_ij + c*)) < H / (o*(A|f_ij + i + c k )), and thus 

H / (a^(A;. i ,-)) < H / (a| f (A* t ,- + j)), for any 1 < i < v k — 1. This shows that \ k is minimum. 

If r k is non-critical, r k may be included or not included in the optimal schedules for /i k . Assuming 
that T k is not included in any of the optimal schedules, X k = A*., is complete, since X k ~i is 
complete. However, including rk may gain some more weight, bo we also need to consider the 
schedules including r*. If T k is included in the optimal schedules, A* derived by Equations 18 and 
19 is the complete set of scheduling points for the optimal schedules including T k , by the same 
reason described for the critical task. Hence, it is sufficient to construct the complete set of X k 
by selecting from A^ and A*_,. Since whether to include r k or not does not affect the feasibility 
of the schedules, we only need to consider the weights of the optima] schedules. A complete set 
of scheduling points indicates that the weights of the optimal schedules at these scheduling points 
should be non-decreasing. Furthermore, a complete and minimum sei of scheduling points indicates 
that the weights of the optimal schedules at these scbeiuling points should be strictly increasing. 
Hence, we can merge and sort the two arrays of A^ and A*.,, and remove any scheduling point 
that has a smaller weight than that of its preceding scheduling point in the array. The resultant 
scheduling points is thus complete and minimum. 

3.7 The Permutation Scheduling Algorithm (PSA) 

Algorithm PSA : 


77 



Input: a permutation sequence n = {ti,t 2 , ..., r n ) 

Output: an optimal schedule <7 n (A„ iUn ) 

Initialization: u 0 = 1; A 0tl = 0; oo(Ao.r) = (}; W(ao(A 0 ,i)) = 0 
for k - 1 
when 

case 1 ( d k - c k < Lk- 1 ) : (a is not feasible) 
exit 

case. 2 (r k < Lk -1 < 4 ~ c;-) or (L*_i < r k < £/*_i) : 

Computation for the first scheduling point: 

Ajt.i = mai (At_i,i + c*,r* + cjt) 

j = 1 if A*..!,! > Tk\ otherwise, j is the greatest integer such that A k-\j < Tk 

^{Ajt.i) = (A*_ij) © r* 

W / (a ik (A w )) = W(a*_ 1 (A fc _ a j)) 

Loop: j = J mtn to J mcx , where J miri and J maz denote the smallest and the largest 

integers of j satisfying A itl < A k -u + Ck < dk . 

J ' = j Lmin "f 2 

A k,i — A*_ij -f c* 
ojt(A*,i) = Oi-i(A*_u) © Tk 

W'(ff*(A* fi ))«W'(^-i(Ai-ij)) 

— Lma: ^ mm 4" 2 

case 3 (£4_! < r fc ) : (only one scheduling point ) 

Ajt.i = r* + Ck 

a <:(Ai,l) = Ok-l(Ai_i )Vi _,) © T k 

W(a k (Xk, l )) = W{^ 1 {X k _ 1 ^_ i )) 
v k = 1 


to n 

Tk is critical 






T k is non-critical 


when 

case 1 (d k - c k < Lk~\) : (scheduling points and schedules remain the same) 
/* Do nothing; r k cannot be included in any feasible schedule */ 

I* Hence, X k - X k -i and a k = a k -\ */ 


case 2 (r k < Lk-i < d k - c k ) or (L k - 1 < r k < U k -\) ■ 

Computation for the first new possible scheduling point: 

A' u = max(\ k - i.i + Ci, r k + c*) 

j = 1 if \ k -i'i > T k ; otherwise, j is the greatest integer such that \ k -ij < T k 

Wu) = <7Jt-i(Ajb-u)er t 

W / K-(^. 1 ))=W^_ 1 (A MJ ))+tn ic 

Loop: j = J min to J max , where J TO1 - n and J max denote the smallest and the largest 

integers e£ j satisfying A' fc<1 < A*_i j + c k < d k . 

i — j- Jmin *b 2 

K,i ~ ^k-lj + C k 

e'k(K,i) = 0k-\(X k -ij)&T k 
W(° k (KJ)=W(o k ^(\ k - lA j)) + rv k 
construct a k from a k -\ and c‘ k by 

1) merging and sorting A*_j and A* into one array 

2) making the weights of the schedules in the resultant array strictly 
increasing; removing any schedule off the array if necessary. 

case 3 {U k ~\ < r*) : (adding one more scheduling point) 
v k = v k -i + 1 
A*.v t = Tk -r c k 
^k(Ai.vi) = &k —3 (X k — 


79 




W'(a A (Ajfe^)) = H'(t7*_,(A*_ 1 . W4 . 1 )) + to* 

I* Note that Aij = A t _jj and c k (X k>j ) = cr t _i(Ajt_i j) for j = 1 to v k ~\ */ 

endfor 

4 Scheduling a Task Set 

To find an optimal schedule for the task set, we may have to consider all possible (n!) permutations. 
It is possible to reduce the search space by eliminating some infeasible permutations. For example, 
if < t j , there is no feasible schedule in which r t - is placed after rj. Even after the reduction, the 
search space might still be too large. We propose to use simulated annealing technique, recognizing 
that while this technique reduces the search, it may yield sub-optimal results. 

4.1 Simulated Annealing 

Simulated annealing is a stochastic approach for solving large optimization problems. It was de¬ 
veloped using statistical mechanics ideas to find a global minimum point in the energy space. 
Kirkpatrick et al [5] had demonstrated the power and applications of simulated annealing to the 
field of combinatorial optimization. 

To find the optimal solution of the optimization problem is similar to finding the lowest energy 
state of metal. The metal is melted first. Then it is cooled down slowly until the freezing point 
is reached. At each temperature, a number of trials are carried out to reach the equilibrium. The 
temperature has to be controlled not to drop too quicki otherwise, it is possible to be trapped 
in a local minimum energy configuration. Lower energy generally indicates a better solution. 
The annealing process starts from a randomly chosen configuration, proceeding to seek potentially 
promising neighbor configurations. The neighbor configuration is derived by perturbing the current 
configuration. If the neighbor configuration has a lower energy, the change is always accepted. The 
distinct feature is that the neighbor configuration with a higher energy can also be accepted with 
the probability of l/ 3 ", where T is the temperature, and E— E' represents the difference in the 
energy of current and neighbor configurations. Notice that when the temperature is high, an energy' 


80 





up jump is more likely than it is when the temperature is low, as it may reach the configuration, 
although with higher energy, which may lead to a better solution. An up jump means a jump from 
low energy to high energy, and a down jump means a jump from high energy to low energy. 

4.2 The Set Scheduling Algorithm (SSA) 

A permutation is used to represent the configuration. If a permutation is ordered in an Earliest 
Deadline First (EDF) fashion, we call it an EDF permutation. An EDF permutation may be a 
good starting permutation for the prote&s of simulated annealing for this problem. If the window 
of a task is contained in the window of another task, we say that the latter task contains the former 
task. If there are no containing relations among tasks, the EDF permutation is a permutation of 
which an optimal schedule of the task set is a subsequence [4], Thus, an optimal schedule for the 
task set can be generated by PSA by scheduling the EOF permutation. The energy function can 
be expressed by a loss function: 

loss = ^2 weight of rejected noncritical tasks 

A schedule is not acceptable if critical tasks are rejected. We may say that the loss of a rejected 
critical task is infinity. However, this kind of assignment makes it difficult to distinguish between 
a very bad schedule (e.g., a critical task is rejected) and even a worse schedule (more critical tasks 
are rejected). In general, the former schedule can be considered as an improvement over the latter 
one. If the loss incurred by a rejected critical task is assigned infinity, there i*no way to tell which 
is better between the schedule in which ©necntical task'\srejected and that in which three critical 
tasks are rejected. Hence, we assign a finite amount of loss to rejected critical tasks. The loss 
of a critical task must be large enough such that the scheduler will not reject a critical task to 
accommodate a number of non-critical tasks. 

The naghbor function may be obtained using one of the following t Wo methods. In the first, 
simple method, we randomly select one task from those rejected. This task is inserted in a randomly 
chosen location within a specified distance from its original location, where the distance is the 


81 








1 


number of tasks between two tasks in a permutation. The distance is used in this approach to 
control the degree of perturbation. 

The reason of rejecting a task is due to the acceptance of other tasks. Given a schedule for 
a permutation, it is sometimes difficult to identify which task results in the rejection of other 
tasks, especially when tasks are congested together. However, the task immediately before or after 
those rejected is likely to play a role. In the second method, we try to identify the task which 
causes the largest loss of weight. As a simple approach, we attribute the rejection of a task to 
the task accepted prior to it. Then we choose the task which causes the largest loss of weight and 
insert it within a specified distance. Due to the robustness of simulated annealing technique, the 
impact of not necessarily selecting the task which caused the largest loss is minimal. Note that in 
simulated annealing many parameters are randomized, and the energy function, together with the 
temperature, control the progress of the annealing process. Tindell et al [9] commented that the 
great beauty of the simulated annealing lies in that you only need to describe what constitutes a 
good solution without worrying about how to reach it. According to our experiments, we find that 
the first method performs better than the second method. However, the process in the first method 
sometimes falls into a local minimum. The combination of the two methods does perform better 
than any of the individual one. The Set Scheduling Algorithm (SSA) is presented in Figure 7. 

The initial temperature has to be large enough such that virtually all up jumps are allowed in 
the beginning of the annealing process. According to [9], the way to compute new temperature is 
that new temperature = tx. » current temperature, where 0 < o < 1. A step denotes an iteration 
in the inner loop in Figure 7, which is the process of scheduling a permutation and determining 
whether the permutation would become the current permutation. The thermal equilibrium can be 
reached if a certain number of down jumps or a certain number of total steps has been observed; 
and the freezing point, or the stopping condition, can be reached if no further down jump has been 
observed in a certain number of steps {5, 9]. 


82 


I 




■ 


Algorithm SSA : 

Begin 

choose initial temperature T 

choose edf permutation as the starting permutaion, y 
schedule y by PSA and compute its energy, E 
loop 

loop 

compute neighbor permutation y! 

schedule y! by PSA and compute its energy, E' 

if E' < E then 

making y' the current permutation: y «— y! and E — E' 
else 

E-E 1 

if e - 7 — > random(O.l) then 

making y' the current permutation: y — y! and E — E' 
else 

y remains as the current permutation 
until thermal equilibrium is reached 
compute new temperature: T *— o *T 
until stopping condition is reached 

End 


Figure 7: Set Scheduling Algorithm 


83 


I 


5 Experiment Result 


Experiments are conducted to stady the performance of SSA based on: 




„v j t _ number of times that the algorithm generates a feasible schedule 

eauiing ill } number of times that there does exist a feasible schedule for the task set 


• loss ratio = 


lo» of the schedule generated bv SSA — loss of an optimal schedule 
total weight of accepted noncritical tasks of an optimal schedule 


• iterations = number of permutations that the simulated annealing algorithm goes through to 
obtain the sub-optimal schedule 

We start with an EDF permutation. To study how good the result would be by using PSA to 
schedule the EDF permutation, the scheduling ability and loss ratio for the EDF permutation are 
computed as well. In our experiments, a task set consists of 100 tasks. The number of permutations 
in such a task set is 100! ~ 9.33 * 10 157 . To study how good the output of SSA is compared to an 
optimal schedule, it is rather impractical to go through such a great number of permutations for a 
task set to derive the optimal schedule and its minimum loss for comparison. Instead, we choose 
to make up a task set such that the task set is feasible and the loss of its optimal schedule is 0. 
Although the SSA algorithm is primarily designed for an overloaded system, we apply SSA to such 
task sets for measuring the performance. The parameters are shown in Figure 8. 


parameters 

value 

type 

window length 

mean.Wl = 20.0 

truncated normal distribution 

computation time 


truncated normal distribution 

load 

20%, 40%, 60%, 80% 

constants 

criticality ratio 

25%, 50%, 75% 

constants 

weight 

low.W=*l, higfc W=50 

discrete uniform distribution 


Figure 8: Parameters of the experiments 


The mean of window length, mean_Wl, Is set to be 20 time units. The load is the ratio of total 
computation time to the largest deadline, D, in the task set. Hence, the load indicates the difficulty 


I 


1 


I 


84 


I 























I 



of scheduling the task set. The mean of computation time, mean.C, is one third of the mean of 
window length, which allows the windows among tasks to overlap to some extent. How much the 
windows overlap partially depends on the load. If the load is high, the windows are congested 
together, and thus the overlapping is high. We expect some containing relations between tasks 
to occur and thus increase the difficulty for scheduling. Note that, without containing relations, 
scheduling the task set would be straightforward. The standard deviations of window length and 
computation time are set to be their means, respectively. Criticality ratio indicates the percentage 
of the critical tasks in the task set. It is set to be 25%, 50%, and 75%. The higher the criticality 
ratio, the more difficult it is to generate a feasible schedule for the task set. On the other hand, 
although it is easier to come up with a feasible schedule when the criticality ratio is low, the loss 
ratio may still be high. It may be necessary to go through many permutations before an acceptable 
loss ratio is reached. In our experiments, the acceptable loss -ratio is set to be 0%, which means 
that SSA will keep trying different permutations until either the loss ratio is 0 or the stopping 
condition is reached, in which SSA fails to find an optimal schedule. Note that a big energy (loss), 
1000, is incurred for a rejected critical task. Hence, for ar. infeasible schedule, the loss ratio may 
well be more than 100%. The weight of a non-critical task is an integer ranging from low_W=l to 
high_W=50, determined by a discrete uniform distribution function. For each individual experiment 
with different parameters, 200 task sets, each with 100 tasks, are generated for scheduling. The 
way of creating a feasible task set without loss is described in appendix A. 

From Figure 9a, The scheduling ability of SSA is 98.5% when criticality ratio is 75% and load 
is 80%, and is 100% for other lower criticality ratios and loads. This is because the simulated 
annealing algorithm focuses on searching suitable neighbor permutations in such a way that the 
rejected critical tasks, if any, may be accepted. Note that scheduling only the EDF permutation 
can not always generate a feasible schedule. The scheduling ability of scheduling EDF permutation 
degrades when load increases, which means tasks congest more together. The scheduling ability 
of scheduling EDF permutation also degrades when the criticality ratio increases, which make? 
meeting the deadlines of all critical tasks become more difficult. 


85 





1 


As far as non-critical tasks are concerned, SSA can not guarantee the minimum loss. However, 
even in the worst case given in Figure 9b, the loss ratio is less than 10%. The loss ratio becomes 
less when criticality ratio or load is less. In many cases, the loss ratios are less than 5%. As for 
scheduling the EDF permutation, the loss ratios are significantly larger. 

The number of permutations to be searched in simulated annealing depends on the situations 
of energy jumps, the way of reducing temperature, and how we define thermal equilibrium and 
stopping conditions. In the experiments, we find that reducing temperature faster does not impose 

a negative impact on the scheduling ability and loss. How to set the parameters in simulated 

/ 

annealing differs a great deal from one application to another. We do want to generate the result 
as good as possible, but are not willing to spend more computation time than necessary. This 
usually requires fine tuning the parameters to get the trade-off between the two goals. We find that 
the following parameters are beneficial: initial temperature = 3000, o = 0.8 (instead of 0.95 or even 
0.99 suggested in other applications), the number of down jumps to obtain thermal equilibrium = 
25, the number of total steps to obtain thermal equilibrium = 300, the number of steps with no 
further down jump to obtain the freezing point = 2000, which is also the stopping condition. The 
average number of permutations searched in simulates annealing is given in Figure 9c. If SSA can 
successfully generate a feasible schedule, the average number of permutations checked is no more 
than 4000 times. The number increases a little if SSA fail.- to find a feasible schedule, because in 
this case SSA does not stop until the freezing point is reached. Note that the average numbers of 
permurations are less than n 5 , which can roughly give us the idea about the complexity of searching 
over the permutation space. Additional studies have shown that if we modify the above parameters 
to increase the average number of permutations by about 10 times, the loss ratios can be further 
reduced by about 25% of the loss ratios obtained here. 

If time can be expressed in integers, the dynamic programming technique used in PSA rati be 
applied by computing cr*(t) at t = 1,.. D. Let us call this approach the integral PSA, compared to 
the original PSA with scheduling points, denoted by PSA SP in Figures 9d. Obviously, the integral 
PSA tends to compute more schedules than the original PSA. We would like to see how more 
efficient the original PSA algorithm is than the integral PSA. Specifically, we compare the average 


86 


I 


















number of schedules required to derive the optimal schedule for a permutation. For the integral 
PSA, the number of schedules computed is fixed, or n*D, as can be seen in Figure 1. For the original 
PSA, Vk is the number of schedules needed to schedule a permutation. The average number 
of schedules needed to schedule a permutation by PSA is computed over the permutations of a task 
set, and is presented in Figure 9d. The number for the original PSA decreases with the criticality 
ratio. This is because a critical task never increases the number of scheduling points; instead, the 
number of scheduling points might be decreased due to the timing constraint of the critical task. 
For the criticality ratios of 0.25,0.50, and 0.75, the average number of schedules required for a task 
set of 100 tasks are approximately 480,250, and 150, respectively. The complexity of the original 
PSA seems linear in this sense. On the other hand, the complexity of the integral PSA is quite 
high. The number decreases with load. This happens to be related to the way of generating the 
task set, in which D = totaLc / load. The number is equal to n * D, where D might fluctuate a 
little. 

6 Conclusion 

In this paper, we study the scheduling problem for a real-time system which is overloaded. A 
significant performance degradation may be observed in the system if the overload problem is not 
addressed properly [2]. As not all the tasks can be processed, the set of tasks selected for processing 
is crucial for the proper operation of an overloaded system. We assign to the tasks criticalities and 
weights on the basis of which the tasks are selected. The objective is to generate an optimal 
schedule for the task set such that all of the critical tasks are accepted, and then the loss of weights 
of non-critical tasks is minimum. 

We present a two step process for generating a schedule. First, we develop a schedule for 
a permutation of tasks using a pseudo-polynomial algorithm. The concept of scheduling points 
is proposed for the algorithm. In order to find the optima] schedule for the task set, we have to 
consider all permutations. The simulated annealing technique is used to limit the search space while 
obtaining optimal or near optimal results. Our experimental results indicate that the approach is 


88 






very efficient. 

The work presented in this paper can be easily extended to address the overload issue for 
periodic tasks. To schedule a set of periodic tasks with criticalities and weights, we can convert 
the periodic tasks in the time frame of the least common multiple of the task periods to aperiodic 
tasks. The schedule generated for the frame can be applied repeatedly for the subsequent time 
frames. 

Our algorithm can also be applied to solving the problem of scheduling imprecise computations 
[7], in which a task is decomposed logically into a mandatory subtask, which must finish before 
the deadline, and an optional subtask, which may not finish. The goal is to find a schedule such 
that the mandatory subtasks can all be finished by their deadlines and the sum of the computation 
times of the unfinished optional subtasks is minimum. A schedule satisfies the 0/1 constraint if 
every optional subtask is either completed or discarded (7). We can solve this problem by using 
our algorithm by setting the mandatory subtasks to be critical, and the optional subtasks to be 
non-critical with weights equal to their computation times. 

Appendix A. Generating a task set 

Generate computation times for tasks according to mean.C and the standard deviation 

D = (total computation time) / load 

Assigning starting instants, s k , to tasks such that 

the intervals between the computation times are truncated normally distributed 
For each task r k 

Determine the criticality by criticality .ratio and/or weight by low_W and highJW 

Compute the window length of r k according to mean_Wl and the standard deviation 
(note that window length > c*) 

align the window with the computation time in their middle points: 
r k = max(0,s k ~ f ) 

d k = min(D, r k -j- window Jength) 


89 





I 


The load determines how the tasks would be congested.' Once the largest deadline, D, has been 
computed, we separate the computation times of the tasks in such a way that the positions of the 
computation times on the time axis stretches over the range from 0 to D. Note that the starting 
instants of the computation times consist in an optimal schedule for the task set. In this way, all of 
the tasks in the task set can be accepted. At last, the windows are aligned with the computation 
times. 

References 

[1] M. R. Garey and D. S. Johnson. Computers and Intractability, a Guide to the Theory of 
NP-Completeness. W. H. Freeman Company, San Francisco, 1979. 

[2] Jayant R. Haritsa, Miron Livny, and Michael J. Carey. Earliest deadline scheduling for real-time 
database systems. In IEEE Real-Time Systems Symposium , Dec. 1991. 

{3] Shvh-ln Hwang, Sheng-Tzong Cheng, and Ashok K. Agrawala. An optimal solution for schedul¬ 
ing real-time tasks w’ith rejection. In International Computer Symposium, Dec. 1994. 

[4] Shyh-ln Hwang, Sheng-Tzong Cheng, and Ashok K. Agrawala. Optimization in non-preemptive 
scheduling for aperiodic tasks. Technical Report CS-TR-3216, TJMIAC5-TR-94-14, Department 
of Computer Science, University of Maryland at College Park, Jan. 1994. 

[5] S. Kirkpatrick, C.D. Gelatt, and M.P. Vecchi. Optimization by simulated annealing. Sci- 
ence(220), pages 671-680,1983. 

J6] C. L. Liu and J. Layland. Scheduling algorithm for multiprogramming in a hard real-time 
environment. Journal of the ACM, 20(1):46-61, Jan. 1973. 

[7] W.K. Shih, J. Liu, and J.Y. Chung. Fast algorithms for scheduling imprecise computations. In 
IEEE Real-Time Systems Symposium, pages 12-19, Dec. 1989. 


90 


1 





[8] Philip Thambidurai and Kishor S. Trivedi. Transient overloads in fault-tolerant real-time sys¬ 
tems. In IEEE Real-Time Systems Symposium, Dec. 1989. 

[9] K.W. Tindell, A. Burns, and A.J. Wellings. Allocating hard real-time tasks: An np-hard 
problem made easy. The Journal of Real-Time Systems, 4(2): 145—165, June 1992. 


91 







REPORT DOCUMENTATION PAGE 


f-orm Approv'd 
OMB No 070*-018$ 





% to «.»< »pr * *g«K »r« imcwam^ »#»* i<«y «©* ritl^ •*!» VOMtn. 

v***: >» i^fOio* r* s»n) cv *at #voro ©• <*•» 

-M- >; *^rt p*»Cf* l*. \f*Kr Orfffi'Viif <©* «*s© kro»n\. Ijl> leMr**©* 

« f v— C"*" o’ v*-'**o-'^**»i *»b ftrAwOK)* fforn (Of( A< Otll). DC J0>0) 


-. AGENCY USE ONLY (Ua»e OUnn) 2. REPORT DATE 

November 


3.REPORT TYPE AND DATES COVERED 


i TITLE AND SUBTITLE 

Scheduling an Overloaded Real-Time System 

S. FUNDING NUMBERS 

N00014-91-C-0195 

DASG-60-92-C-0055 

t. AUTHOR(S) 

Shyh-In Hwang, Chia-Mei Chen and Ashok K. Agrawala 


7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 

University of Maryland 

Department of Computer Science 

A. V. Villliams Building 

College Park, MD 20742 

8. PERFORMING ORGANIZATION 
REPORT NUMBER 

CS-TR-3377 
UMIACS-TR-94-128 

9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESSES! 

Honeywell, Inc. Phillips Laboratory 

3600 Technology Drive Directorate of Contracting 

Minneapolis, MN 55418 3651 Lowry Avenue SE 

Kirtland AFB NM 87117-5777 

TO. SPONSORING/MONITORING 

AGENCY REPORT NUMBER 

| 11. SUPPLEMENTARY NOTES 

____'_ 

12a. DISTRIBUTION/AVAILABILITY STATEMENT 

Y2b. DISTRIBUTION CODE 


AElTkACT (Mixtrwrr,, 3C v- zrzs) 

The real-time systems differ from the conventional systems in that every task in 
the real-time system has a timng constraint. Failure to execute the tasks under the 
timing constraints may result in fatal errors. Sometimes, it may be impossible to 
execute all the tasks in the task set under their timing constraints. Considering a 
system with limited resources, one solution to handle the overload problem is to 
reject some of the tasks in order to generate a feasible schedule for the rest. In 
this paper, ve consider the problem of scheduling a set of tasks without preemption in 
-aich each task is assigned criticality and weight. The goal is to generate an optima 
■chedule such that all of the critical tasks are scheduled and then the non—critical 
.asks are included so that the weight of rejected non-critical tasks is minimized, 
we consider the problem of finding the optimal schedule in two steps. First, we selec 
permutation sequence of the task set. Secondly, a pseudo-polynomial algorithm is I 
oposed to generate an optimal schedule for the permutation sequence. If the global 
optimal is desired, all permutation sequences have to be considered. Instead, we 
opose to incorporate the simulated annealing technique to deal with the large search 

OUT eyT>P''*'iTngTir aT reculrc eVriT.. rVvar ciut- Sc aV>T p Tn oe>r iprstp np?T 


«. SUEJEC7 TERMS 

Process Management; Nonnumerical Algorithms and Problems 


IS. NUMBER OP PAGES 

29 


YE. PRICE CODE 


Y7. SECURITY CLASSIFICATION 
OF REPORT 

■Unclassified 


YE. SECURITY CLASSIFICATION 
OF THIS PAGE 

Unclassified 


YS. SECURITY CLASSIFICATION 
OF ABSTRACT 

Unclassified 


20. LIMITATION OF ABSTRACT 

Unlimited 


JrSN 7SCPOT.2SO.SSOO 


SLawSatd toro 296 !Rev 2-89) 


ptimal schedules for the task sets In most cases while considering 
nly a limited number of permutations. 























Notes on Symbol Dynamics** 


Ashok K. AgrawaJa 

Department, of Computer Science, University of Maryland 
College Paris, Maryland 20742 

E-mail: agrawala@cs.umd.edu 
Christopher Landauer 

System Planning and Development Division, The Aerospace Corporation 
The Hallmark Building, Suite 187, 13873 Park Center Road, Kerndon, Virginia 22071 
Phone: (703) 318-1666, FAX: (703) 318-5409 

E-mail: cal@aero.org 


13 February 1995 


Abstract 

This paper introduces a new formulation of dynamic systems that subsumes both the classical discrete and differential 
equation models as well as current trends in hybrid models. The key idea is to express the system dynamics using 
symbols to which the notion of time is explicitly attached. The state of the system is described using symbols which 
are active for a defined period of time. The system dynamics is then represented as relations between the symbolic 
representations. 

We describe the notation and give several examples of its use. 


'This work is supported in part by ONR and DARPA under contract N00014-93-C-D295 to Honeywell and Computer Science Depart¬ 
ment at the University of Maryland. The views, opinions, and/or findings contained in this report are those of the author(s) and should 
not be interpreted as representing the official policies, either e xp r esse d or implied, of the Defense Advanced Research Projects Agency, 
ONR, the U.S. Government o: Honeywell. 

Computer facilities were provided in part by NSF grant CCR-8811954. 

T This work is supported in part by ARPA and Philips Labs under contract DASG60-92-0055 to Department of Computer Science, 
University of Maryland. The views, opinions, and/or findings contained in this report are those of the author(s) anc should not be 
interpreted as representing the official policies, either expressed or implied, of the Advanced Research Projects Agency, PL, or the U.S. 
Government. 


93 







Contents 


1 Introduction 3 

2 Descriptions of System Behavior 3 

3 Concepts and Notations 3 

3.1 State Variable. 3 

3.2 Symbol . 3 

3.3 Attribute Identifier. 3 

3.4 Expression. 4 

3.5 Interval. 4 

3.6 Characterizer. 4 

3.7 Event. 4 

4 System Description 4 

4.1 Dynamics. 4 

4.2 Normalization and Continuation. 5 

4.3 Continuation and Continuity . 5 

4.4 Characterizer Semantics and Inference. 6 

4.4.1 Inference. 

4.4.2 Prediction. 

4.4.3 Tbuth Maintenance 

4.5 Analysis. 7 

5 Examples 7 

5.1 ODE. 7 

5.1.1 First-Order. 7 

5.1.2 Second-Order Example. 8 

5.1.3 Higher-Order Example. 9 

5.2 Measurement.10 


94 


<O h 
























1 Introduction 


Traditionally, systems have been modelled using state variables defined in a metric space and the system dynamics 
defined using differential equations. This approach uses continuous descriptions of space and time. When we use 
computers for expressing and manipulating such models we have to use symbols to represent it. Symbols are discrete 
by their very nature, and require use of mapping from the continuous spaces to discrete spaces. These mappings 
cause problems unless carried out rather carefully. Further, when we consider the problems in which some aspects 
of the system are genuinely discrete, hybrid models have been used. As different techniques have to be used for 
continuous and discrete aspects of the system, significant complexity gets added to such models. 

Recognizing that the computer systems only use symbols for any representations, in this paper we present a for¬ 
mulation of system dynamics directly in terms of symbols. In order to handle the synamics, time interval over 
which a symbol is considered valid is explicitly attached. The symbols describing different aspects of the system 
may be from a set appropriate for that aspect. The dynamics is described in terms of rules connecting the symbolic 
representations. 

This paper contains the preliminary formulation of system dynamics in the framework of Symbol Dynamics. 

2 Descriptions of System Behavior 

For the purposes of this paper, behavior includes all the relationships among parts of a system at the same or different 
times. In particular, the combined relationships among parts of a system at the same time is usually called structure. 
Both of these aspects are subsumed in our use of the term behavior. 

We assume that our ability to generate or derive new information about the system behavior changes only at discrete 
points in time, since we expect to perform these processes on digital computers. The event times define the time 
scale. In this paper, we introduce Symbol Dynamics , a totally symbolic way to represent the important aspects of 
dynamical systems and processes, so that we can reason about them using computers. 

3 Concepts and Notations 

This section contains the basic notions of Symbol Dynamics. 

3.1 State Variable 

We assume that systems exist and change over time. We are looking for a method of describing those changes so we 
can compute how to control them. 

The systems we consider can be described with state variables. Each state variable is an observation on the system 
or a derivation from other state variables. 

We may or may not know a priori which state variables are important, or even which ones are determinable (i.e., the 
system comes first, and the state variables are chosen to be helpful in describing the behavior). We might call the 
state variables attributes of the state. 

3.2 Symbol 

We want to measure and compute with information about a system, so we need to map the system into formal spaces 
we understand better. 

A type is a symbol set, both representing a set of values and including some operations on those values; this is the 
notion of formal space used here. It includes collections of mutually dependent types and functions between different 
types. 

A symbol of a given type is an element of the set of values that type. Any notions of credibility, confidence, or 
uncertainty are part of the type system that is used. It is especially important to define the allowable operations on 
these kinds of types. For example, for measurements of a system, the symbol would include the measured value and 
the associated uncertainty value. 

3.3 Attribute Identifier 

We assume that we will want to know different things about the system behavior. We need names to keep track of 
the different things we measure or compute. 


95 






An attribute identifier is a name for a state variable (a state variable is like a probe into some aspect of the system 
behavior, and the attribute identifier is only the label). 

3.4 Expression 

An expression is a pair 

(attribute identifier: symbol), 

which is interpreted to mean the assertion that the state variable can be described by the symbol (when the expression 
is active). We will describe the precise semantics of these expressions later on. 

These are models of the state variable values. 

3.5 Interval 

An interval is a pair 

|start time, end time), 

assumed to describe a half-open interval (to save us from trouble with the topology). The end time may be omitted, 
in which case it is interpreted to mean infinity by default. 

3.6 Characterizer 

A characterizer is a pair 

(expression, interval), 
also written 

(attribute identifier: symbol; start time, end time), 

interpreted to mean that the expression is active during the specified interval. It becomes active at the start time, 
and becomes inactive at the end time. Each characterizer has a range (its interval of activity) and a scope (the set 
of attribute identifiers that occur in its expression). 

We may also consider a symbol set that includes arithmetic expressions that contain an explicit time variable t. For 
example, 

(p:j>o-ri*>*t;to,ii) 

represents a continuous change along the interval. 

We will also have occasion to reason about conditions at particular points in time, so the assertion language will also 
have characterizes of the form 
(expression, point). 

3.7 Event 

An event is the activation or deactivation of a characterizer. We make no limiting assumptions about simultaneous 
events. 

4 System Description 

A system description is a finite set of characterizers, so we assume explicitly that a system can be described by a 
finite set of characterizers. We insist that only a finite set of characterizers be active at any one time. Since each of 
those characterizers is active over a positive interval, there is therefore some small interval thereafter during which 
all of them are still active. 

Everything we know about a system’s behavior is described by characterizers and relationships among the charac¬ 
terizers. Domain models and context can be written as characterizers, generally with large intervals. 

4.1 Dynamics 

Relationships among characterizers are rules that define the dynamics. These rules take the form: 

if these characterizers (with a list) are active on these intervals, then this new one is also active on this 
other interval (not necessarily contained in the intersection of the original intervals). 

96 



I 


Rules can contain variable identifiers, with implicit universal quantification. 

Relationships hold on intervals and the combination may extend the range. We generate new characterizes according 
to the relationships, either predictive (range extension) or deductive (knowledge extension). 

The language in which the rules are written is important, since it has to accommodate notations from many different 
types, many of which will not be known when the language is defined. Some basic concepts that will be in any of 
these languages are continuity and derivatives. 

It is important to remember that the system comes first, and that the state variables are our choices for modeling 
and understanding the system. This means in particular that the coordinate systems we use are temporary, and that 
the constraints among the state variables are expressed explicitly as relationships. 


4.2 Normalization and Continuation 


Characterizes may have overlapping intervals. Normalization is the process of breaking each characterizer into two 
or more others, to fit the time scale. If t is an event time, and 
(a : r; s, e) 

is a characterizer with s < t < e, then we can replace it with two characterizes 
(a : v\s,i ) and (a : v;t,e). 

If two characterizes use the same attribute, 

(a : v\s,e) 
and 


(a : w;t,u), 

then we say that the second one continues the first one iff they are adjacent in time, so t = e. Continuity considerations 
in the transition from vtowat time t are treated in the next section. 

In any system with a finite density of event times, if we split every characterizer that spans an event time, then we 
end up with characterizes that start and stop at consecutive event times (though they may be continued by other 
characterizes). This has some computational conveniences. 

If we have two characterizes 
(c : v\t u t 2 ) 
and 


(a : u-;t 2 ,t 3 ), 

so that the second one continues the first, then we need some kind of explicit characterizer for the transition, active 
in an interval containing the transition time. If there is a description u in an appropriate, domain for which 
, _ J v, for t i <i< t s , 
hi, for ts < t < 1 3 , 


then we can conclude 


(a : u;ti,l 3 ). 

This is the opposite of normalization. 

If there is an overlap, that is, if the two characterizes 
(c : v:t:,ts) 
and 

(c : u.-;t 3 ,t 4 ) 

nave 

|*i,* 2 ) n 1 * 3 , *<) non-empty, 
and 

v(i) = w(t) for i € lmax(ti,t 3 ),min(t 2 ,i«)), 
then we can also conclude 

(o : u;min(t : ,t 2 ),max(t 3 ,t 4 )). 


4.3 Continuation and Continuity- 

One aspect of continuity is transitions from one symbol to another across interval boundaries. The transition 
relations are extra conditions that have to hold at the transition time (usually they are smoothness conditions for 
model transitions). 

A typical smoothness property is infinitesimal: for characterizes 
(a : v, to, *i) 


97 




and 


{a : w\t u t 2 ), 

we normally want, smoothness, written 
d v d w 

77 ,_. r “ 77 

and continuity, written 

u(t = t~) = w{t = tf). 

Both of these are point conditions on the attributes and their derivatives, and we can consider only conditions on 
attributes by using whatever derivatives are needed in the conditions: instead of 

(a : 



we use 

(c : (u,v');t 0 ,ti), 

and write our smoothness condition as 



If we aJso require continuity in each attribute, so that 
w(l = t+) = w(t = tj), 

then the upper limit in the previous expression can be omitted. 

It is therefore clear that we must deal with point events at transitions 

but not with point characterizes. If we make the transition continuity a property of the definition of continuation, 
then we can assert it or not in any given model. 

Of course, the expression t = i~ means that the interval [t 3 — t, t 3 ) is part of the limit computation for every e small 
enough, so we might be able to use these intervals for some small enough £ without having to take the limits. 

We will deal with these considerations in the simplest way possible. We have a characterizer that asserts continuity of 
the relevant attribute across a larger interval, such as [to, h) above. The only place that the continuity characterizer 
has new’ information is at the transition point t 3 , but we simply do not worry about the redundancy. 


4.4 Characterizer Semantics and Inference 

A characterizer is what we want to assume about what is true over its interval. It need not be consistent with 
the other characterizes' in a system description; we explicitly allow false assertions here, so we can reason using 
counterfactuais. 


4.4.1 Inference 

We can make inferences within intervals, according to some rules. If, say, there is a rule 

S]&.S 2 => S 3 , 

anc two characterizes 
(■-■ : 
and 

(t* - Sj, 12, ^ 3 ) 

with to < l 2 < t: < t 3 , then we can conclude 
(v : 53;t 2 ,tj). 


4.4.2 Prediction 

We can also make inferences that extend intervals in some cases. They take the form: If 
(v : s 3 ;t 0 ,t 3 ) 
and 

(is : S2;to, i :) 

are characterizes with to < t 3 , then there is a characterizer 
(= : 531*2,13) 

for some 1 2 ,t 3 , with to < t? < U < 13 - 


98 




4.4.3 Truth Maintenance 


Because we do not presume that the characterizers in a system axe truths, we need to be much more careful about 
when they can be used together, especially in the inference and prediction processes. Since the inference rules 
themselves are time dependent, we need to keep track of the dependencies of every characterizer, both how and when 
it was derived (how tells us about hypotheses and inference rules; when helps us in checking temporal consistency) 
and its interval of activity. 

We also need a way to indicate which characterizers we DO want to be true, so that different collections of charac¬ 
terizers can be compared and contrasted within the same context. We might want to consider computing various 
maximal consistent sets of irredundant assertions as an aid in this process. 

Various rules can be activated that lead to new conclusions in an interval, which can supersede old ones; we also 
assume partial deduction, not total. We therefore need to use some kind of non-monotonic logic. 

4.5 Analysis 

Simulation is a continuing surprise. 

We want tools with analytic power to help reduce our reliance on simulation, so we can make reliable predictions 
about the system behavior. 

All of our computations are performed from the symbols active at a given time. The advantage of dealing explicitly 
with time in this formulation is that we can sit outside the usual sequencing of events, taking a kind of ‘'side-long” 
look at the entire time line, and piece together parts of the models that we know more about regardless of whether 
or not they are the first ones in our time interval of interest. 

We can also perform the deductions in an order that is different from the order imposed by time, using any of a 
number of simple mechanisms, such as rule-based systems or rewrite logics; both are being investigated. 

5 Examples 

This section contains several examples that illustrate the utility of tifte notation. 

5.1 ODE 

A simple example that shows range extension is an ordinary differential equation fODE). For ODEs, the solution 
method is part of changing an ODE into a set of characterizers. 

So let us consider a simple second-order ODE for the sine function, 
v" — ~v> 

3 /( 0 ) = 1 , 

y(0) = o, 

and solve it with Euler's method (a particularly bad one for this kind of problem, by the way). 

First, we transform the equations into a first order system (in the usual UBy) Vy iiidng x=» y\ 

t 

y = =. 

-(o) = 1, 

3 /( 0 ) = 0 , 

and we also define z = z' = y". 

5.1.1 FirsP-Order 

Now the way Euler's method works is by linear extrapolation, so for a given time t = t 0 , if we have 
= (1 0 ) = x 0 , 

vUo) = Vo. 
then we have 

zq — z(i o) = — yo, 
and we take 

z{t) = Z C ~ 2 o * (i ~ to), 

V(0 = yo-r=o»(i-to), 


99 




for t in some small interval 
1*0, *2 = to 4 di). 

The characterizers that describe this situation are: 

(z : xo + zo * (i - to); to, to + dt), 

(y : yo 4 =0 * (* — *o); *o, to 4 dt), 

which we want to be true for all choices of xo.Vo.to, and di (which ones we actually use in our system description 
depend on how we choose the time intervals in the solution). 

The characterizers that describe the initial conditions are difficult, because they cannot be described with half-open 
intervals of the shape we have thus far described: 

(* : i;0), 

(y:0;0), 

which is always going to be a problem in systems that start at a certain time. 

In a more sophisticated system, the choice of next time interval would depend on the computed accuracy of the 
current solution. 

For this example, we simply make all the time intervals the same, and say that the characterizer pair 
(= : x\ 4 zj * (t - 1 1 ); tj, tj -r di), 

{y : Vj 4=j * (* - fj);ii,ij 4 dt) 
propagates the pair 

(2 : 20 4 *0 * (l — to); to, to 4 dt), 

(y '■ yo 4 20 * (t - to); to, to 4- dt) 
iff 

= 20 4 20 * di, 
y: = yo 4 -0 * dt, 

tj = to t dt, 

which are the conditions for the first pair to meet the second (the condition z\ — —yj is part of the definition of 
these characterizer pairs). 

Ex-tending the iteration, we have 
=(0) = 1, 
y(0) = 0, 

=(*4 1) = —(k) ~ y(*) * di, 
y(* 4 1) = y(fc)4 2 (*).dt, 

which can be wTitten as a vector eouation (we put the matrix on the right so we can use row vectors) 

(r,y)(0) = (1,0), 

(=.y)(*41) = (=,y)(*) ( _l f 

so if we write 7 for the identity matrix and J for the matrix 



then we have (with X = (x,v)) 

*( 0 ) = ( 1 , 0 ),' 

X(k 4 1) = X[k){J-T j.di), 
so 

^(*) = (1,0) (7 4 J-dt) k , 
which can be computed exactly. 

Since the eigenvalues J • di) are 1 = t ■ dt, which have magnitude 1 -f dt 2 , the successive powers of the matrix 

diverge for any dt > 0, and therefore so does the iteration. 


5.1.2 Second-Order Example 

In this section, we use the same differentia! equation problem, with a different solver, a second-order one that is 

almost able to converge properly. We therefore have 
/ 

= = -y. 


100 




1 


y' = 

=( 0 ) = 
y( 0) = o, 

as above. Our initial conditions are 

(i : 1; 0), 

{y : 0; 0), 

as before. 

The method we use is a simplified second-order Runge-Kutta method [?], [?), which basically amounts to averaging 
the usual Euler approximation in an interval with a linear reapproximation at the endpoint of the interval. At a 
given time 1 = to, if we have 
x(t 0 ) = 20 , 

y(io) - Vo, 

then we have 

x(t) = x 0 — yo * di - zo * dt 2 /2, 

2/(0 = yo + 2 0 * dt - y 0 * dt 2 /2, 

and it is the extra dt 2 terms that make the method second-order. 

As above, we assume equal time intervals and get an iteration 
2 ( 0 ) = 1 , 

y(0) = 0, 

x(k-f-1) = x(k) - y(k) * dt - x(k) * dt 2 /2, 

y(k~l) = y(k) + x(k) * dl - y(k) * dt 7 / 2, 
which can be written as a vector equation 
(2,y)(0) = (1,0), 

(*.*)(*+1) = (x,y )W( 1_ ^ 

and we have as above 

*(0) = (1,0), 

X{k+ 1) = X(k)[l « (1 — dt 2 /2) *f J « dt), 
so 

X(k) = (1,0) (1 * (1 - dt 2 /2) + J * dt) k , 
which can be computed exactly. 

Since the eigenvalues of (J * (1 - di 7 / 2) 4- J * dt) are 1 - dt 2 /2 ± i * dt, which have magnitude 1 4 dt A /A, this simple 
method still does not converge (but much more slowly). 


5.1.3 Higher-Order Example 

A similar analysis of the usual 4th-order Runge-Kutta method leads to an iteration 
x(t ) = 20 — yo * dt — xo * dt 2 /2 4 2/0 * dt 3 /6 -j- zo * dt 4 /24, 

y(t) = yo-i-2o * dt — yo * dt 2 /2 — xo * dt 3 /6-r yo * dt < /24, 

with matrix 

( 1 - dr 2 /2 4 di*f 24 dt - dt 3 /6 
^ -dt-rdt 3 /6 1 - dt 2 /2 4 dt</24 

and eigenvalue magnitude of 1 4 dt 6 /36 4- dt 8 /24 2 , which is still greater than one. In fact, since this equation (in 
(x,y) space) represents moving around a circle, any extrapolation method based on tangents at a single point will 
fail, since all of the tangent vectors point outward from the circle. We note that the iteration equations do have the 
first terms of the usual Maclaurin series for sin(dt) and cos(dt), so we try out a different iteration: 
x(t) = xo * cos(dt) - yo * sin(di), 

y (0 = yo * cos(dt) 4 2 0 * sin(dt), 

which can be written as a vector equation 
( z , y)(0) = (1,0), 



101 






cos(di) sin(dl) 
—sin(dt) cos(dl) 


(=,y)(* + i) = (*>y)M ^ 

and we have as above 

A'(0) = (1,0), 

A'(k + 1) = X(k)(I * cos(dl) + J » sin(di)), 
so 

X (k) = (1,0) (J * cos(dl) -f J* sin(dt))^, 

= (1,0) (J * cos(k * dl) 4- J * sin(k * dl)), 

and 

x(k*dt) = cos(k*dt), 
y(f: * dl) = stn(k * dl), 

from which we can hazard a guess as to the correct solution. 

5.2 Measurement 

Let us take a simple system in which the velocity and position are occasionally known through inexact measurement. 
Our state variables are p for the position, v for the velocity, and a for the unknown acceleration. 

We assume that the acceleration a is bounded by some constant A, so that for any times tc < li 
|v(ti) - u(t 0 )| < |li-to]* A. 

We assume that we have characterizes 
(a(0; l> ti) 

that describe the acceleration, and model characterizes 

(r = p';0-,-), 

(c= r';CT\-). 

Therefore, we can compute the velocity and position by 

v(t) = v(l 0 ) -f / a(u) cu, 

J i B <v<: 

p(t) — p(to) -r / v(u) du. 

The problem is to choose measurement tiroes and variables that maintain a certain accuracy in the estimates of 
position. 

We assume that we can measure position within a bound 
jpmeas(l) — p(t)| < P, 

and that we can measure velocity within a bound 

|vmeas(i) - v(0| < V, 

but that w>e want to keep our estimate of position either more accurately than the position measurement error 
(this might or might not be posable) or using as few measurements as possible. 

We assume first that xo,t>o are known, and consider an interval ]lo,ii). We compute 
jv(li)-uo| < |t 3 — to] * A, 
and therefore 

li(*i)-2o] < ^*|tj -lo! ! »A, 
so we would have to choose 
A t * tj -1 0 
so that 

A l < |V/A] 

to keep the velocity within bounds, and 
(A t) a < 12-P/A] 
to keep the position within bounds. 

But of course, we don’t know x(l) or v(t) after the first time interval, so we need to change the previous derivation 
a bit. 

We assume that we know z 0 and v 0 , and that 
]x(lo) — xq] < A xo 


102 


describes the accuracy of our knowledge of x(t) at time £ = t 0 , and 
|v(to) - wo! < A vo 

describes the accuracy of our knowledge of v(t) at time £ = to- Then the above inequalities become 
|v(£i) — vo] £ A vo + j£j — tol * A, 
and therefore 

l=(*i) - =o! < Ai 0 + |£ : - £ 0 | * A v 0 + i * |£j - t 0 | 2 * X, 
so we have to have 

A £ < |(V - A v 0 )M! 
to keep the velocity within bounds, and 

(A i) 2 + l:.^ v ° »(A £) < |2.(P-Ai 0 )M| 
to keep the position within bounds. 

At this point, we are stuck unless we can say something more helpful about the acceleration. Suppose we know that 
the acceleration jumps around, and that it has a distribution of values with mean 0 and variance R. In this case, we 
might be able to reduce the estimates for position and velocity and improve the time intervals. 

References 

[1] P. Henrici, Elements of Numerical Analysis, Wiley (1964) 

[2] J. Stoer, R. Bulirsch, Enfurhrung in die Numerische Mathematik, II Springer (1973) 


103 


REPORT DOCUMENTATION PAGE 


torrr* i.ppro^te 
0MS ho C704-0168 



•*t *t *•••»•>' • *»wxr*' •*>««•<«( i»r ««v 'p* •**t*»*»<j *••%!•«*$ **»» %o***«»^ 

>.■»•■•• •»» .»’ • “• — «■»# l<•' V>mo ••onpiog l»i\ ©» *»>» *>'*VO*^> O' 

#»«•• r w.<»r» l>*rn9»*i» <c* •^ic*** 1 * *»•«>* 0o~*»»o»* m*ooov. WIV /e*«er%©* . 

*•«,.» 5 . t *~a *»or*-6>* »fc«n*e* |D>0«>0UI1 «*******9 I©a. DC ?5W) | 


1. AGfNCY USE only Jinvr 2 . REPORT DaU 3 . REPORT TYPE AND DATES COVERED 

_February 13, 1995 Technical Report_ . 


A. Tnil AND SUBTITLE ] s. FUNDING NUMBERS I 


Notes on Symbol Dynamics 


6. AUTHOBiS) 


N00014-91-C-0195 and - 
DSAG-60-92-C-0055 


Ashok K. Agravala and Christopher Landauer 


7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 

University of Maryland 
A.V. Williams Building 
College Park, Maryland 20742 


8. PERFORMING ORGANIZATION 
REPORT NUMBER 

CS-TR - 3411 
UMIACS-TR - 95-15 


S. SPONSORING / mONITORING AGENCY NAME(S) AND ADDRESS(ES) 


Honeywell 

3660 Technology Drive 
Minneapolis, MN 55418 

Tn supplementary notes 


Phillips Labs 

3550 Aberdeen Ave. SE 

Kirtland AFB, NM 

87117-5776 


10. SPONSORING/MONITORING 
AGENCY REPORT NUMBER 


124. DISTRIBUTION / AVAILABILITY STATEMENT 


T2. ABSTRACT (Mai/nyn 200 wore*/ 



This paper introduces a nev formulation of dynamic systems that 
subsumes both the classical discrete and differential equation 
models as well as current trends in hybrid models. The key idea 
is to express the system dynamics using symbols to which the notion 
of time is explicitly attached. The state of the system is 
described using symbols which are active Iot a defined period 
of time. The system dynamics is then represented as relations 
between the symbolic representations. We describe the notation 
and give several examples of its use. 


•«4. SUBJECT TERMS 


C.m, Miscellaneous 


15. NUMBER OF PAGES 
11 nates 


16. PRICE CODE 



17. SECURITY CLASSIFICATION ) IE. SECURITY CLASSIFICATION 1$. SECURITY CLASSIFICATION | 20. LIMITATION OF ABS7RJ 
OF REPORT Or THIS PAGE OF ABSTRACT 


Unclassified 


Unclassified 


Unclassified 


S' 


Unlimited | 





















Allocation and Scheduling of Real-Time Periodic Tasks with 

Relative Timing Constraints* 


Sheng-Tzong Cheng and Ashok K. Agrawala 
Institute for Advanced Computer Studies 
Systems Design and Analysis Group 
Department of Computer Science 
University of Maryland 
College Park, MD 20742 
{stcheng,agrawala} @ cs.umd.edu 


Abstract 

Allocation problem has always been one of the fundamental issues of building the applica¬ 
tions in distributed computing systems (DCS). For real-time applications on DCS, the allocation 
problem should directly address the issues of task and communication scheduling. In this con¬ 
text, the allocation of tasks has to fully utilize the available processors and the scheduling 
of tasks has to meet the specified timing constraints. Clearly, the execution of tasks under 
the allocation and schedule has to satisfy the precedence, resources, and other synchronization 
constraints among them. 

Recently, the timing requirements of the real-time systems emerge that the relative timing 
constraints are imposed on the consecutive executions of each task and the inter-task temporal 
relationships are specified across task periods. In this paper we consider the allocation and 
scheduling problem of the periodic tasks with such timing requirements. Given a set of periodic 
tasks, we consider the least common multiple (LCM) of the task periods. Each task is extended 
to several instances within the LCM. The scheduling window for each task instance is derived to 
satisfy the timing constraints. We develop a simulated annealing algorithm as the overall control 
algorithm. An example problem of the sanitized version of the Boeing 777 Aircraft Information 
Management System is solved by the algorithm. Experimental results show that the algorithm 
solves the problem in a reasonable time complexity. 


‘This work is supported in part by Eonevwel] under N000I4-91-C-0195 and Army /P hilli ps under DASG-60-92- 
C-0055. The views, opinions, and/or findings contained in this report are those of the author(s) and should not be 
interpreted as representing the official policies, either expressed or implied, of Honeywell or Army/Phillips. 


105 






1 Introduction 


The task allocation and scheduling problem is one of the basic issues of building real-time ap¬ 
plications on a distributed computing system (DCS). DCS is typically modeled as a collection of 
processors interconnected by a communication network. Tor hard real-time applications, the allo¬ 
cation of tasks over DCS is to fully utilize the available processors and the scheduling is to meet 
their timing constraints. Failure to meet the specified timing constraints or inability to respond 
correctly can result in disastrous consequence. 

For the hard real-time applications, such as avionics systems and nuclear power systems, the 
approach to guarantee the critical timing constraints is to allocate and schedule tasks o priori. 
The essential solution is to find an static allocation in which there exists a feasible schedule for the 
given task sets. Ramamritbam [Ram90] proposes a global view where the purpose of allocation 
should directly address the schedulability of processors and communication network. A heuristic 
approach is taken to determine an allocation and find a feasible schedule under the allocation. 
Tindell et al. [TBW92] take the same global view and exploit a simulated annealing technique 
to allocate periodic tasks. A distributed rate-monotonic scheduling algorithm is implemented. In 
each period a task must execute once before the specified deadline. The transmission times for 
the communications are taken into account by subtracting the total communication time from the 
deadline and making the execution of the task more stringent. 

Simply assuring that one instance of each task starts after the ready time and completes before 
the specified deadline is nor enough. Some real-time applications have more complicated timing 
constraints for the tasks. For example, the relative timing constraints may be imposed upon 
the consecutive executions of a task in which the scheduling of two consecutive executions of a 
periodic task must be separated by a minimum execution interval. Co mmuni cation latency can be 
specified to make sure that the time difference between the completion of the sending task and the 
start of the receiving task does not exceed the specified value. The Boeing 777 Aircraft Information 
Management System is such an example [CDHC94]. For such applications, the algorithms proposed 
in literature do not work because the timing constraints are imposed across the periods of tasks. In 
this paper, we consider the relative timing constraints for real examples of real-time applications 
in Section 2. Based on the task characteristics, we propose the approach to allocate and schedule 
these applications in Section 3. A simulated annealing algorithm is developed to solve the problem 
in which the reduction on the search space is given in Section 4. In Section 5, we evaluate the 
practicality and show the significance of the algorithm. Instead of randomly generating the ad hoc 
test cases, we apply the algorithm to a real example. The example is the Boeing 777 AIMS with 
various numbers of processors. The experimental results are shown in Section 5. 


106 




2 Problem Description 


Various kinds of periodic task models have been proposed to represent the real-time system char¬ 
acteristics. One of them is to model an application as an independent set of tasks, in which each 
task is executed once every period under the ready time and deaoane constraints. Synchronization 
(e.g. precedence and mutual exclusion) and communications are simply ignored. Another model 
to take the precedence relationship and communications into account is to model the application 
as a task graph. In a task graph, tasks are represented as nodes while communications and prece¬ 
dence relationship between tasks are represented as edges. The absolute timing constraints can 
be imposed on the tasks. Tasks have to be allocated and scheduled to meet their ready time and 
deadline constraints upon the presence of synchronization and communications. The deficiency 
of task graph modeling is inability of specifying the relative constraints across task periods. For 
example, one can not specify the minimum separation interval between two consecutive executions 
of the same task. 

In the work [CA93], we modified the real-time system characteristics Vy taking into account 
the relative constraints on the instances of a task. We considered th« Scheduling problem of the 
periodic tasks with the relative timing constraints. We analyzed the timing constraints and derive 
the scheduling window for each task instance. Based on the scheduling window, we presented 
the time-based approach of scheduling a task instance. The task instances are scheduled one by 
one based on their priorities assigned by the proposed algorithms. In this paper we augment the 
real-time system characteristics by considering the inter-task co mm u ni cation on DCS. 

2.1 Task Characteristics 

The problem considered in this chapter has the following characteristics. 

• The Fundamentals: A task is denoted by the 4-tuple < p,-, e,-, A,-, p,- > denoting the period, 
computation time, low jitter and high jitter respectively. One instance of a task is executed 
each period. The execution of a task instance is non-preemptable. The start times of two 

consecutive instances of task t,- are at least p,- - A,- and at most p,- + p, apart. Let and 

ff be the start time and finish time of task instance t- respectively. The timing constraints 
specified in Equations 1 through 4 must be satisfied. 

n = *?+« 

= i? + LCM 

4 > 4~ z + Pi - ^ 


107 


( 1 ) 

( 2 ) 

(3) 


(4) 


•5- < +p> + ^ 

Vj = 2,...,n,+ 1. 

• Asynchronous Communication: Tasks communicate with each others by sending and 
receiving data or messages. The frequencies of sending and receiving tasks of a communication 
can be different. In consequence, communications between tasks may cross the task periods. 
When such asynchronous communications occur, the semantics of undersampling is assumed. 
When two tasks of different frequencies are communicating, schedule the message only at 
the lower rate. For example, if task A (of 10HZ) sends a message to task B (of 5HZ), then 
in every 200ms, one of two instances of task A has to send a message to one instance of 
task B. If the sending and receiving tasks are assigned to the same processor, then a local 
communication occurs. We assume the time taken by a local communication is negligible. 
When an interprocessor communication (IPC) occurs, the communication must be scheduled 
on the communications network between the end of the sending task execution and the start 
of the receiving task execution. The transmission time required to communicate the message 
i over the network is denoted by /x,-. 

• Communication Latency: Each communication is associated with a communication la¬ 
tency* which specifies the maximum separation between the start time of the sending task and 
the completion time of the receiving task. 

• Cyclic Dependency: Research on the allocation problem has usually focused on acyclic 
task graphs JBam90, ES92], Given an acyclic task graph G = {V,£},if the edge from task 
A to task E is in E then the edge from B to A can not be in E. The use of acyclic task 
graphs excludes the possibility of specifying the cyclic dependency among tasks. For example, 
consider the following situation in which one instance of task A can not start its execution 
until it receives data from the last instance of task B. After the instance of task A finished 
its execution, it sends data to the next instance of task B. Since tasks A and B axe periodic, 
the communication pattern goes on throughout the lifetime of the application. To be able to 
accommodate this situation, we take cyclic dependency into consideration. 

The timing constraints described above are shown in Figure 1. For periodic tasks A and B, the 
start times of each and every instance of task execution and communication are pre-scheduled such 
that (1) the execution intervals fall into the range between p— X and p+ -q and (2) the time window 
between the start time of sending task and the completion time of receiving task is less than the 
latency of the communication. In Figure 2, we illustrate examples of all possible communication 
patterns considered in this paper. The description of the communications in the task system is in 
the form of '"From sender-task-id (of frequency) To receiver-task-id (of frequency)''. If the sender 


108 


Time 



A to B 


B to A 


A to B 


Network: 


Figure 1: Relative Timing Constraints 


frequency is n times of the receiver frequency and no cyclic dependency is involved, then one 
of every n instances of the sending task has to communicate with one instance of the receiving 
task. (Examples of this situation axe shown in Figures 2.a.l and 2.a.2. Likewise, for the case in 
which the receiver frequency is n time that of the sender frequency and no cyclic dependency is 
present, the patterns axe shown in Figures 2.b.l and 2.b.2. For an asynchronous communication, the 
sending (receiving) task in low frequency sends (receives) the message to (from) the nearest receiving 
(sending) task as shown in Figure 2.a (2.b). The cases where cyclic dependency is considered are 
shown in Figures 2.c and 2.d. 


2.2 System Model 

A real-time DCS consists of a number of processors connected together by a communications 
network. The execution of an instance on a processor is nonpreemptable. To provide predictable 
communication and to avoid contention for the communication channel at the run time, we make the 
following assumptions. (1) Each IPC occurs at the pre-scheduled time as the schedule is generated. 
(2) At most one communication can occur at any given time on the network. 


109 





' 200 ms ‘ 

(a.2) 

From A (of 10HZ) to B (of 5HZ) 


1 B 1 


1 ^ 9 

1 A 

M 

1 

A 

1 * * 

1 



J 


200 ms 


200 ms * 

(b-2) 

From A (of 5HZ) to B (of 10HZ) 



200 ms 


(c) 

From A (of 10EZ) to B (of 5HZ) 
From B (of 5HZ) to A (of 1GHZ) 


(d) 

From A (of 10HZ) to B (of 10HZ) 
From B (of 10HZ) to A (of 10HZ) 


Figure 2: Possible Communication Patterns 


110 







2.3 Problem Formulation 


We consider the static assignment and scheduling in which a task is the finest granularity object 
of assignment and an instance is the unit of scheduling. We applied the simulated annealing 
algorithm [KGV83] to solve the problem of real-time periodic task assignment and scheduling with 
hybrid, timing constraints. In order to make the execution of instances satisfy the specifications 
and meet the timing constraints, we consider a scheduling frame whose length is the least common 
multiple (LCM) of all periods of tasks. Given a task set T and its communications C, we construct 
a set of task instances, /, and a set of multiple communications, M. We extend each task r; € T 
to n,- instances, r/, rf,..., and t"'. These n,- instances are added to J. Each communication 77 
7j 6 C is extended to min(n,-,n J ) 1 undersampled communications where n; = LCM/p, and nj = 
LCM /pj. These multiple communications are added to M. The extension can be stated as follows. 

• If ft; < ftj, then r; •-» Tj is extended to t* <-* tJ, t? *— rj, ..., and rj 1 '' tJ. 

• If n; > n_,-, then 7 ; •-* Tj is extended to 7 / *-> rj> 7 / *— rj, ..., and 7 / •-* rJ lj . 

• If n; = nj, then 7; >-* Tj is extended to r} <-+ rj, t} ^ rj, ...., and r t n ’ •-» tJ 1 . 

A task ID with a superscript of question mark indicates some instance of the task. For example, 

r } •-+ rj means that 7 / communicates with some instance of Tj. We describe how we assign the 
nearest instance for each communication in Section 4.1.2. 

The problem can be formulated as follows. Given a set of task instance, J, its communications 
M. we find an assignment d>, a total ordering c m of all instances, and a total ordering a c of all 
communications to minimize 

£(<?, Oc) = ~ ~ *i +1 + 4) + 21 &(4 + ' ~4~ Pi ~ Vi) 

'J ij 

+ E tv! - 0 + E - «*.»«)- 4) 

ij ij.kj 

+ 2Z 6(fl - 4 - Latency (t,- to 7 *)) (5) 

subject to sj > rj and 5(fj •— tj.,t7 c ) > f{. V tj *— tj., 

where 

’Due to undersampling, when an asynchronous communication is extended to multiple communications, the 
number of multiple communications is the smaller number of sender and receiver instances. 


Ill 



• 5; is the start time of rj under a,,,. 

• // is the completion time of r- under a m . 

• rj = p, x (j - 1) + r l; and d? = p,- x (j - 1) + d,. 

• 6(z) = 0, if i < 0; and = x, if x > 0. 

• <£( 77 ) is the ID of processor which r,- is assigned to. 

• rf >— t[ is the communication from rf to Tj[. If d>(r,-) = d>(r*), then r- >-* t[ is a local 
communication. 

• S{c,c z ) is the start time of communication c on the network under u c . 

• F(c , o c ) is the completion time of communication c on the network under o c . 

The minimum value of £(©. cr^Oc) is zero. It occurs when the executions of all instances 
meet the jitter constraints and all communications meet their latency constraints. A feasible 
multiprocessor schedule can be obtained by collecting the values of s? and //, V i and j. Likewise, 
a feasible network schedule can be obtained from 5(c. o c )s and F{c. c c )s. 

Since the task system is asynchronous and the communication pattern could be in the form of 
cyclic dependency, we solve the problem of finding a feasible solution (o. c m .c c ) by exploiting the 
cyclic scheduling technique and embedding the technique into the simulated annealing algorithm. 


3 The Approach 

3.1 Bounds of a Scheduling Window 

Define the scheduling window for a task instance as the time interval during which the task can 
start. Traditionally, the lower and upper bounds of the scheduling window for a task instance are 
called earliest start time ( est ) and latest start time (1st) respectively. These values are given and 
independent of the start times of the preceding instances. 

We consider the scheduling of periodic tasks -with relative timing constraints described in Equa¬ 
tions 3 and 4. The scheduling window for a task instance is derived from the start times of its 
preceding instances. A feasible scheduling window for a task instance r■ is a scheduling window 
in which any start time in the window makes the timing relation between s?~ : and s] satisfy 


112 


Equations 3 and 4. Formally, given sj, sf, ..and .., the problem is to derive the feasible 

scheduling window for rf such that a feasible schedule can be obtained if rf is scheduled within 
the window. 

Proposition 1 [CA93]: Let the est and 1st of rf be 

esl(rf ) = maiKsf 1 + p { - A,), (s- + (j - 1) x p { - (n,- - j + 1) x rj { )}, (6) 

and isi(rf) = + p, + tj,), (sj -f (j - 1) X p { + (n,- - j + 1) x A,)}. (7) 

If sf is in between the est(rf) and lst(rf), then the estimated est and ist of s"', based on s } { and 
specify a feasible window. 


3.2 Cyclic Scheduling Technique 

The basic approach of scheduling a set of synchronous periodic tasks is to consider the execution 
of all instances within the scheduling frame whose length is the LCM of all periods. The release 
times of the first periods of all tasks are zero. As long as one instance is scheduled in each period 
within the frame and these executions meet the timing constraints, a feasible schedule is obtained. 
In a feasible schedule, all instances complete the executions before the LCM. 

On the other hand, in asynchronous task systems, as depicted in Figure 2 in which the LCM 
is 200ms, the periods of the two tasks are out of phase. It is possible that the completion time 
of some instance in a feasible schedule exceeds the LCM. To find a feasible schedule for such an 
asynchronous system, a technique of handling the time value which exceeds the LCM is proposed. 

The technique is based on the linked list structure described in the work [CA93]. Without loss 
of generality, we assume the minimum release time among the first periods of all tasks is zero. We 
keep a linked list for each processor and a separated list for the communication network. Each 
element in the list represents a time slot assigned to some instance or communication. The fields of 
a time slot of some processor p: (1) task id i and instance id j indicate the identifier of the time slot. 

(2) start lime st and finish time ft indicate the start time and completion time of rf respectively. 

(3) prev ptr and next ptr are the pointers to the preceding and succeeding time slots respectively. 
The list is arranged in an increasing order of stariAime. Any two time slots are nonoverlapping. 
Since the execution of an instance is nonpreemptable, the time difference between stariAime and 
finishAime equals the execution time of the task. 


113 





Before: 


After: 



Figure 3: Insertion of a new time slot 


3.2.1 Recurrence 

Given any solution point (©, c m . c e ), we construct the schedule by inserting time slots to the linked 
lists. Let c m : tasked x instance-id — integer. The insertion of a time slot forr? precedes that for 

'l if Ms) < MsD- 

Recall that Equations 6 and 7 specify the bounds of the scheduling window for a task instance. 
Due to the communications, est(r^) in Equation 6 may not be the earliest time fox We define 

the effective start time as the time when (1) the hybrid constraints are satisfied and (2) ~f receives 
all necessary data or messages from all the senders. 

Given the effective start time r and the assignment of r, (i.e. p — d>(T,)), a time slot of processor 
p is assigned to rf where start.time > r and finish-lime - start.time = e;. that we have 
to make sure the new time slot does not overlap existent time slots. Since (ij the executions of 
all instances within one scheduling frame recur in the next scheduling frame and (2) it is possible 
that the time slot for some instance is over LCM. we subtract one LCM from the start-time or 
/ inish-time if it is greater than LCM. It means the time slot for this task instance will be modulated 


114 










Figure 4: The introduction of a pseudo instance 

and wrapped to the beginning of the schedule. As shown in Figure 3 The start-time of the new 
slot is t while the completion time is r + e— LCM. 

3.3 Pseudo Instances 

As stated in Section 2, we consider the communication pattern in which cyclic dependency exists 
among tasks. Given a set of tasks, T, a set of task instances, I, a set of communications, C, and 
any solution point, (©, a TO ,cr e ), we introduce pseudo instances to solve this problem. For any task 
t_, if there exists a task r y , in which (1) c m (rl) < o m (r y ), V :, (2) n- = n y , and (3) r- — r y € 
C and r y •— t. £ C, then a pseudo instance t •*is added to I. A pseudo instance is always a 
receiving instance. No insertion of time slots for pseudo instances is needed. For a pseudo instance, 
only the effective start time is concerned. The effective start time of a pseudo instance t”* 41 in 
the constructed schedule based on (©, a TO , © e ) is checked to see whether it is less than LCM -f si or 
not. If yes, then the execution of r2 for the next scheduling frame may start at LCM- + si which 
is exactly one LCM away from the execution of rl for the current scheduling frame. A graphical 
illustration of the introduction of pseudo instance to solve the synchronous communications of 
cyclic dependency is given in Figure 4 in which n = = 2. 


As for the asynchronous communications of cyclic dependency, no pseudo instances are needed. 
For example, if both r_ *— r y and r y >— r_ exist and n- = n y x n, then for each r-J, where j — 1, 
2, ..., n v , find a sending instance ~i € I and a receiving instance rl £ I such that (1) jl < s : y . 
(2) P y < st , and (3) r' x -J and ri r* are the communications. The relationship between :, j, 



115 


I 





( 2 ) 


(3) 



Figure 5: Asynchronous communications in mutuality 
and k can be stated as 

(j - 1) X n < i < k < j x n. (8) 

A graphical illustration can be found in Figure 5. In the example, the values of i, j, k , and n are 
6, 2, 8, 4 respectively. The communications r| <-+ r* and r* »->■ r® are scheduled before and after 
the scheduling of r* respectively. 

4 The Simulated Annealing Algorithm 

Kirkpatrick et al. [KGV83] proposed a simulated annealing algorithm for combinatorial optimiza¬ 
tion problems. Simulated annealing is a global optimization technique. It is derived from the 
observation that an optimization problem can be identified with a fluid. There exists an analogy 
between finding an optimal solution of a combinatorial problem with many variables and the slow- 
cooling of a molten metal until it reaches its low energy ground state. Hence, the terms about 
energy function, temperature, and thermal equilibrium are mostly used. During tbe search of an 
optimal solution, the algorithm always accepts the downward moves from the current solution point 
to the points of lower energy values, while there is still a small chance of accepting upward moves 
to the points of higher energy values. The probability of accepting an upbill move is a function of 
current temperature. The purpose of hill climbing is to escape from a local optimal configuration. 
If there are no upward or downward moves over a number of iterations, the thermal equilibrium 
is reached. The temperature then is reduced to a smaller value and the searching continues from 
the current solution point. The whole process terminates when either (1) the lowest energy point 
is found or (2) no upward or downward jumps have been taken for a number of successive thermal 
equilibrium. 

The structure of simulated annealing (SA) algorithm is shown in Figure 7. The first step of 


116 








the algorithm is to randomly choose an assignment <f>, a total ordering of instances within one 
scheduling frame, Cm, and a total ordering of communications for the instances, c c . A solution 
point in the search space of SA is a 3-tuple (<f>,cr m ,cr e ). The energy of a solution point is computed by 
equation (5). For each solution point P which is infeasible, (i.e. E v is nonzero), a neighbor finding 
strategy is invoked to generate a neighbor of P. As stated before, if the energy of the neighbor is 
lower than the current value, we accept the neighbor as the current solution; otherwise, a probability 

function (i.e. ezp(- £ y -)) is evaluated to determine whether to accept the neighbor or not. The 
parameter of the probability function is the current temperature. As the temperature is decreasing, 
the chance of accepting an uphill jump (i.e. a solution point with a higher energy level) is smaller. 
The inner and outer loops are for thermal equilibrium and termination respectively. The number of 
iterations for the inner loop is also a function of current temperature. The lower the temperature 
is, the bigger the number is. Methods about how to model the numbers of iterations and how 
to assign the number for each temperature have been proposed [LH91]. In this dissertation, we 
consider a simple incremental function. Namely, N = N + A where N is the number of iterations 
and A is a constant. The termination condition for the outer loop is E p = 0. Whenever thermal 
equilibrium is reached at a temperature, the temperature is decreased. Linear or nonlinear approach 
of temperature decrease function can be simple or complex. Here we consider a simple multiplication 
function (i.e. T = T x a, where a < 1). 


4.1 Evaluation of Energy Value for a Solution Point ( 6 , <7 m , o c ) 

The computation of the energy value stated in Equation 5 , is done by constructing multi-processor 
schedules and a network schedule, and collecting the the start and completion times of each task 
instance and communication from these schedules. 

The construction of the schedules is characterized by the priority assignment of the task in¬ 
stances in the set. The priority assignment algorithm determines the scheduling order among all 
the task instances. Each time when a task instance is chosen to be scheduled, the incoming com¬ 
munications of the instance are scheduled first and then the task instance itself. After all the 
task instances have been scheduled, the scheduling of the outgoing communications is performed. 
.An algorithmic description about how to compute the energy value for a solution point is given 
in Figure 6. Note that a communication is an incoming communication to a task instance if the 
frequency of the receiving task instance is equal to or less than that of the sending task instance. 

For example, ^ rf and <->■ rf are incoming communications to rf. On the other hand, if 
the sender frequency is less than the receiver frequency, then the communication is an outgoing 
communication, (e.g. •— r] is the outgoing communication of r£). 


117 




4.1.1 Priority Assignment of Task Instances: a m 


In the work [CA93], we presented the SLsF algorithm and the performance evaluation. The re¬ 
sults showed that SLsF outperforms SPF and SJF. In this paper we use the SLsF as the priority 
assignment algorithm for the task instances in I. 

Formally, if lst(rf) < bt(r£), then c m {rl) < a m (r^). And the insertion of a time slot for 
T- precedes that for t£ if c m (T f) < amC?*)- The time-based scheduling algorithm for a task 
instance is used to find a time slot for a task instance once the effective start time is given. We 
define the effective start time of a task instance as the earliest start time when the incoming 
communications are taken into account. Let t be the maximum completion time among all the 
incoming communications of a task instance, then the effective start time of the task instance is set 
to the bigger value among t and est (as stated in Equation 6). 


4.1.2 Scheduling the Incoming Communications:^ 

There are two kinds of incoming communications. The first kind is called the synchronous com¬ 
munication in which the frequencies of the sender and receiver are identical. The other kind is 
called the asynchronous communication in which the sending task instance is associated with a 
question mark. For such an asynchronous communication, we have to decide which instance of the 
sending task should communicate with the receiving task instance. The approach we take is to find 
the nearest instance of the sending task. The reason is that, by finding the nearest instance, the 
time difference between start time of the receiving instance and the completion time of the sending 
instance is the smallest. The chance of violating the latency constraint of a communication will be 
the smallest then. 

The nearest instance of a sending task can be found using the following method. Given an 
incoming communication rj •— rf, and the effective start time of r-, eft we search through the 
linked list of processor ©(t*) up to time eft. If there is some instance of t*, say r£, whose completion 
time is the latest among all scheduled instances of t*, then the nearest instance is found. Otherwise, 
we continue to search through the linked list until an instance of r* is found. We set the effective 
start time of the communication to be the completion time of the found instance. We also erase 
the question mark such that rj- is changed to •— rj’. For the synchronous communication, 
the effective start time of the communication is simply assigned as the finish time of the sending 
task instance. 

The scheduling of the communication is done by inserting a time slot to the linked list for the 
communications network. The start time of the time slot can not be earlier than the effective start 


118 





time of the communication. Once the time slot is inserted, we check the effective start time of rf 
to make sure that it is not less than the finish time of the time slot. If it is, the effective start time 
of rf is updated to be the finish time of the time slot. 

If a task instance has more than one incoming communication, the scheduling order among these 
communications is based on their latency constraints. The bigger the latency value is, the earlier 
the communication is scheduled. The incoming communication with the tightest latency constraint 
is scheduled last. It is because the effective start time of the receiving task instance is constantly- 
updated by the scheduling of the incoming communications. It is possible that the scheduling of 
the later incoming communications increases the effective start time of the receiving task instance 
and make the early scheduled communication violate its latency constraint if the constraint is tight. 


4.1.3 Scheduling the Outgoing Communications: o c 

The scheduling of the outgoing communications for the whole task set is performed after all the 
task instances have been scheduled. The scheduling order among these communications is based 
on the finish times of the sending task instances. The task instance with the smallest finish time is 
considered first. When a task instance is taken into account, all its outgoing communications are 
scheduled one by one according to their latency constraints. The communication with the tightest 
latency constraint is scheduled first. 

Given an outgoing communication rf •— and the finish time of rf, ff, the effective start 

time of the communication is set to be ff . Based on the effective start time, a time slot in inserted 
for this communication. Then the nearest instance of receiving task can be found based on the 
finish time of the time slot. 

For the example shown in Figure 5, The incoming communication marked with “(l) r is scheduled 
before the scheduling of r*. The sixth instance of r_ is chosen as the nearest instance. As for the 
outgoing communication marked with “(3) r , it is scheduled after the scheduling of ri, rf, rl, and 
rj. In this example, r* is the nearest instance of the outgoing co mm unication. 


4.2 Neighbor Finding Strategy: © 

The neighbor finding strategy is used to find the next solution point once the current solution point 
is evaluated as infeasible (i.e. energy- value is nonnegative). The neighbor space of a solution point 
is the set of points which can be reached by changing the assignment of one or two tasks. There 
are several modes of neighbor finding strategy. 


119 


• Balance Mode: We randomly move a task from the heavily-loaded processor to the lightest- 
loaded processor. This move tries to balance the workload of processors. By balancing the 
workload, the chance to find a neighbor with a lower energy value is bigger. 

• Swap Mode: We randomly choose two tasks r,- and t ; - on processors p and q respectively. 
Then we change <t> by setting 4>( T i) = 9 and 9 , ( T j) = P- 

• Merge Mode: We pick two tasks and move them to one processor. By merging two tasks to 
a processor, we increase the workload of the processor. There is an opportunity of increasing 
the energy level of the new point by increasing the workload of the processor. The purpose of 
the move is to perturb the system and allow the next move to escape from the local optimum. 

• Direct Mode: When the system is in a low-energy state, only few tasks violate the jitter 
or latency constraints. Under such a circumstance, it will be more beneficial to change the 
assignment of these tasks instead of randomly moving other tasks. From the conducted ex¬ 
periments, we find that this mode can accelerate the searching of a feasible solution especially 
when the system is about to reach the equilibrium. 

The selection of the appropriate mode to find a neighbor is based on the current system state. 
Given a randomly generated initial state (i.e. solution point), the workload discrepancy between 
the processors may be huge. Hence, in the early stage of the simulated annealing, the balance 
mode is useful to balance the workload. After the processor workload is balanced out, the swap 
mode and the merge mode are frequently used to find a lower energy state until the system reaches 
near-termination state. In the final stage of the annealing, the direct mode tries to find a feasible 
solution. The whole process terminates when a feasible solution is found in ■which the energy value 
is zero. 

5 Experimental Results 

We implemented the algorithm as the framework of the allocator on MAUI77’J[GMK + 91, MSA92, 
SdSA94], a real-time operating system developed at the University of Maryland, and conducted 
extensive experiments under various task characteristics. The tests involve the allocation of real¬ 
time tasks on a homogeneous distributed system connected by a communication channel. 

To test the practicality of the approach and show the significance of the algorithm, we consider a 
simplified and sanitized version of a real problem. This was derived from actual development work, 
and is therefore representative of the scheduling requirements of an actual avionics system. The 
Boeing 777 Aircraft Information Management System (AIMS) is to be running on a multiprocessor 


120 



10-Proc 

9-Proc 

8JProc 

7-Proc 

6-Proc 

Exec.Time (Sec) 

2369 

5572 

19774 

36218 

78647 

| — Hr : Min : Sec 0:39:29 

1:32:52 

5:29:34 

10:03:38 

21:50-47 


Table 1: The execution times of the AIMS with different number of processors 

system connected by a SafeBus (TM) ultra-reliable bus. The problem is to find the minimum 
number of processors needed to assign the tasks to these processors. The objective is to develop 
an off-line non-preemptable schedule for each processor and one schedule for the SafeBus (TM) 
ultra-reliable bus. 

The AIMS consists of 155 tasks and 951 communications between these tasks. The frequencies 
of the tasks vary from 5HZ to 40HZ. The execution times of the tasks vary from Oms to 16.650ms. 
The NEI and XEI of a task 1,- are p,- — 500p:s and p,- -f 500pzs respectively. Since 6 = 1000/rs = 1ms 
< 25ms 5 the smallest-period-first scheduling algorithm can be used in this case. Tasks communicate 
with others asynchronously and in mutuality. The transmission times for communications are in the 
range from 0/is to 447.733pis. The latency constraints of the communications vary from 68.993ms 
to 200ms. The LCM of these 155 tasks is 200ms. When the whole system is extended, the total 
number of task instances within one scheduling frame is 624 and the number of communications is 
1580. 

For such a real and tremendous problem size, pre-analysis is necessary. We calculate the resource 
utilization index to estimate the minimum number of processors needed to run AIMS. The index 
is defined as 

X 8.) 

LCM 

where e,- is the execution of task 1, and g,- = The obtained index for AIMS is 5.14. It means 

there exist no feasible solutions for the AIMS if the number of processors in the multiprocessor 
system is less than 6. 

The number of processors which the AIMS is allowed to run on is a parameter to the scheduling 
problem. We start the AIMS scheduling problem with 10 processors. After a feasible solution is 
found, we decrease the number of processors by one and solve the whole problem again. We run 
the algorithm on a DECstation 5000. The execution time for the AIMS scheduling problem with 
different numbers of processors is summarized in Table 1. The algorithm is able to find a feasible 
solution of the AIMS with six processors which is the minimum number of processors according 
to the resource utilization index. The time to find such a feasible solution is less than one day 
(approximately 22 hours). 


121 



















5.1 Discussions 


For feasible solutions of the AIMS with various numbers of processors, we calculate the processor 

utilization ratio (PU?>.) of each processor. The processor utilization ratio for a processor p is defined 
as 

Z^o,-)=p( e '' x $■) 

LCM 

The results are shown in Figure 8. The ratios are sorted into a non-decreasing order given a fixed 
number of processors. The algorithm generates the feasible solutions for the AIMS with 6, 7, 8, 9 
and 10 processors respectively. For example, for the 6-processor case, the PURs for the heaviest- 
loaded and lightest-loaded processors sue 0.91 and 0.76 respectively. For the 10-processor cases, the 
PURs are 0.63 and 0.28 respectively. We find that the ratio difference between the heaviest-loaded 
processor and the lightest-loaded processor in the 6-processor case is smaller than those in other 
cases. It means the chance for a more load-balanced allocation to find a feasible solution is bigger 
when the number of processors is smaller. 

The detailed schedules for the 6-processor case axe shown in Figure 9. The results are shown 
on an interactive graphical interface which is developed for the design of MARUT1. The time scale 
shown in Figure 9 is 100/zs. So the LCM is shown as 2000 in the figure, (i.e. 2000 x 100/US = 
200ms.) This solution consists of seven off-line non-preemptive schedules: one for each processor 
and one for the SafeBus (TM). Each of these schedules will be one LCM long where an infinite 
schedule can be produced by repeating these schedules indefinitely. Note that the pseudo instances 
are introduced to make sure the wrapping around at the end of the LCM-long schedules should 
satisfy the latency and next-execution-interval requirements across the point of wTap-around. The 
pseudo instances are no* shown in Figure 9. 

The inclusion of resource and memory constraints into the problem can be done by modifying 
neighbor-finding strategy. Once a neighbor of the current point is generated, it is checked to 
ascertain that the constraints on memory etc. are met. If not, the neighbor is discarded and 
another neighbor is evaluated. 


References 

[CA93] Sheng-Tzong Cheng and Ashok K. Agrawala. Scheduling of periodic tasks with relative 
timing constraints. Technical Report CS-TR-3392, UM1ACS-TR-94-135, Department of 
Computer Science, University of Maryland. College Park, December. 1993. Submitted 
to the JOth Annual IEEE Conference on Computer Assurance, COMPASS ’95 . 


122 



[CDHC94] 

[GMK+91] 

[HS92] 

[KGV83] 

[LH91] 

[MSA92] 

[Ram90] 

[SdSA94] 

[TBW92] 


T. Carpenter, K. Driscoll, K. Hoyme, and J. Carciofini. Arinc 659 scheduling: Problem 
definition. In Proceedings of IEEE Real-Time Systems Symposium, San Juan, PR, Dec. 
1994. 

0. Gudmundsson, D. Mosse, K.T. Ko, A.K. Agrawala, and S.K. Tripathi. Maruti: A 
platform for hard real-time applications. In K. Gordon, A.K. Agrawala, and P. Hwang 
(eds.), editors, Mission Critical Operating Systems. IOS Press, 1991. 

Chao-Ju Hou and Kang G. Shin. Allocation of periodic task modules with precedence 
and deadline constraints in distributed real-time systems. In Proceedings of the 1992 
IEEE 13th Real-Time Systems Symposium , pages 146-155, Phoenix, AZ, 1992. 

S. Kirkpatrick, C. D. Gelatt. and M. P. Vecchi. Optimization by simulated annealing. 
Science , 220(4598):671-6S0, May 1983. 

Feng-Tse Lin and Ching-Chi Hsu. Task assignment problems in distributed comput¬ 
ing systems by simulated annealing. Journal of the Chinese Institute of Engineers, 
14(5):537-550, Sept. 1991. 

Daniel Mosse, M.C. Saksena, and Ashok K. Agrawala. Maruti: An approach to real¬ 
time system design. Technical Report CS-TR-2845, UMLA.CS-TR-92-21, Department 
of Computer Science, University of Maryland, College Park, 1992. 

Krithi Ramamritham. Allocation and scheduling of complex periodic tasks. In Pro¬ 
ceedings of the 10th International Conference on Distributed Computing Systems , pages 
108-115, Paris, France, 1990. 

M. Saksena, J. da Silva, and A. K. Agrawala. Design and implementation of mamti- 
ii. Technical Report CS-TR-2845, Department of Computer Science, University of 
Maryland, College Park, 1994. 

K. W. Tindeli, A. Burns, and A. J. 'Wellings. Allocating hard real-time tasks: an 
NP-hard problem made easy. Real-Time Systems, 4(2):145-165, June 1992. 


123 







Given a solution point P = (<t>,c m ,c e ) 

While there is some unscheduled task instance do 

Find the next unscheduled instance. /* By the SLsF algorithm */ 
Let the instance be t\. 

Sort all the incoming communications of r\ based on 
the latency values into a descending order. 

Schedule each incoming communication starting from 

the biggest-latency one to the tightest-latency one. 

Schedule the instance rf. 

End While. 

Mark each instance as un-examined. 

While there is some un-examined task instance do 

Find the next un-examined task instance. /* By the finish times */ 
Sort all the outgoing communications of the task instance based 
on the latency values into an increasing order. 

Schedule each outgoing communication starting from 

the tightest-latency one to the biggest-latency one. 

Mark the task instance ex ami ned. 

End While. 



Collect the start time and finish time informations for each task instance and communication. 


Compute the energy value using Equation 5. 


I 


Figure 6: The pseudo code for computing the energy value 


124 


I 




Choose an initial temperature T 

Choose randomly a starting point P = (<j>,a m ,c c ) 

E v := Energy of solution point P 
if E v = 0 then 

output E v and exit /* E p = 0 means a feasible solution */ 

end if 
repeat 

repeat 

Choose N , a neighbor of P 
E n := Energy of solution point N 
if E n = 0 then 

output E n and exit /* E n = 0 means a feasible solution */ 

end if 

if E n < Ej, then 
P := N 
E p := E n 

else 

_ Ev-En 
X — 

if e = > random(0..1) then 
P := N 
E P := E n 

end if 

end if 

until thermal equilibrium at T 
T := g x T (where a < 1) 
until stopping criterion 


Figure 7: The structure of simulated ann ealing algorithm. 


125 






Utilisation JUtie 



Figure 9: The Allocation Results and Schedules for -AIMS with 6 processors 


126 


1 
























































REPORT DOCUMENTATION PAGE 

Form approved 

OMB No 074-0188 

1. AGENCY USE ONLY (leave blank) 

2. REPORT DATE 
January 1995 

3. REPORT TYPE END DATES COVERED 
Technical Report 


4. TITLE AND SUBTITLE 

Allocation and Scheduling of Real-Time Periodic Tasks with Relative 
Timing Constraints 


6. AUTHOR(S) 

Sheng-Tzong Cheng and Ashok K. Agrawala 


5. FUNDING NUMNBERS 

N00014091 -C-0195 
DSAG -60-C-0055 


PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 

University of Maryland 

Department of Computer Science 

A.V. Williams Building 

College Park, MD 20742 


8. PERFORMING ORGANIZATION 
REPORT NUMBER 

CS-TR-3402 

UMIACS-TR-95-6 


9. SPONSORING/ MONITORING AGENCY NAME(S) AND ADDRESS(ES) 10. SPONSORING/ MONITORING 
Honeywell Inc. Philips Laboratory AGENCY REPORT NUMBER 

3600 Technology Drive Directorate of Contracting 

Minneapolis, MN 55148 3651 Lowry Avenue, SE 

KWand AFB, NM 87117-5777 


11. SUPPLEMENTARY NOTES 


12.a. DISTRIBUTION/ AVAILABILITY STATEMENT 


12.b. DISTRIBUTION CODE 


13. ABSTRACT (Maximum 200 words) 

Allocation problem has always been one of the fundamental issues of building the applications in distributed computing 
systems (DCS). For real-time applications on DCS, the allocation problem should directly address the issues of task and 
communication scheduling. In this context, the allocation of tasks has to fully utilize the available processors and the 
scheduling of tasks has to meet the specified timing constraints. Clearly, the execution of tasks under the allocation and 
schedule has to satisfy the precedence, resources, and other synchronization constraints among them. 

Recently, the timing requirements of the real-time systems emerge that the relative timng constraints are imposed on the 
consecutive executions of each task and the inter-task temporal relationships are specified across task periods. In this 
paper we consider the allocation and scheduling problem of the periodic tasks with such timing requirements. Given a set of 
periodic tasks, we consider the least common multiple (LCM) of the task periods. Each task is extended to several 
instances within the LCM. The scheduling window for each task instance is derived to satisfy the timing constraints. We 
develop a simulated annealing algorithm as the overall control algorithm. An example problem of the sanitized version of the 
Boeing 777 Aircraft Information Management Systems is solved by the algorithm. Experimental results show that the 
algorithm solves the problem in a reasonable time complexity. 


14. SUBJECT TERMS 

Process Management; Special Purpose and Application-Based Systems 


15. NUMBER OF PAGES 

22 


16. PRICE CODE 


17. SECURITY CLASSIFICATION 
OF REPORT 

Unclassified 


18. SECURITY CLASSIIFICATION 

19. SECURITY CLASSIFICATION 

OF THIS PAGE 

OF ABSTRACT 

Unclassified 

Unclassified 


20. LIMITATION OF 
ABSTRACT 

Unlisted 


MSN 7540-01 280-5500 


127 


Standard Form 298 (Rev 2-89) 






























Scheduling of Periodic Tasks with Relative Timing Constraints * 


Sheng-Tzong Cheng and Ashok K. Agrawala 
Institute for Advanced Computer Studies 
Systems Design and Analysis Group 
Department of Computer Science 
University of Maryland 
College Park, MD 20742 
{stch eng,agrawala} @cs.umd.edu 


Abstract 

The problem of non-preemptive scheduling of a set of periodic tasks on a single processor 
has been traditionally considering the ready time and deadline on each task. As a consequence, 
a feasible schedule finds that in each period ODe instance of each task starts the execution after 
the ready time and completes the execution before the deadline . 

Recently, the timing requirements of the real-time systems emerge that the relative timing 
constraints are imposed on the consecutive executions of each task. In this paper, we consider 
the scheduling problem of the periodic tasks with the relative timing constraints imposed on two 
consecutive executions of a task. We analyze the timing constraints and derive the scheduling 
window for each task instance. Based od the scheduling window, we present the time-based 
approach of scheduling a task instance. The task instances are scheduled one by one based on 
their priorities assigned by the proposed algorithms in this paper. We conduct the experiments 
to compare the schedulability of the algorithms. 


"This work is supported in part by Eonevweh under N00014-91-C-0195 and Army/Phillips under DASG-60-92- 
C-0055. The views, opinions, and/or findings contained in this report are those of the author(s) and should not be 
interpreted as representing the official policies, either expressed or implied, of Honeywell or Army /Phillips. 


129 






1 Introduction 


The task scheduling problem is one of the basic issues of building real-time applications in which the 
tasks of applications are associated with timing constraints. For the hard real-time applications, 
such as avionics systems and nuclear power systems, the approach to guarantee the critical timing 
constraints is to schedule periodic tasks a priori. A non-preemptive schedule for a set of periodic 
tasks is generated by assigning a start time to each execution of a task to meet their timing 
constraints. Failure to meet the specified timing constraints can result in disastrous consequence. 

Various kinds of periodic task models have been proposed to represent the real-time system 
characteristics. One of them is to model an application as a set of tasks, in which each task is 
executed once every period under the ready time and deadline constraints. These constraints impose 
constant intervals in which a task can be executed. In literature, many techniques [2, 3, 4, 5, 6, 7, 8] 
have been proposed to solve the scheduling problem in this context. The deficiency of this modeling 
is the inability of specifying the relative constraints across task periods. For example, one can not 
specify the timing relationship between two consecutive executions of the same task. 

Simply assuring that one instance of each task starts the execution after the ready time and 

/ 

completes the execution before the specified deadline is not enough. Some real-time applications 
have more complicated timing constraints for the tasks. For example, the relative timing constraints 
may be imposed upon the consecutive executions of a task in which the scheduling of two consecutive 
executions of a periodic task must be separated by a minimum execution interval. The Boeing 777 
Aircraft Information Management System is such an example [1]. One possible solution to the 
scheduling problem of such applications is to consider the instances of tasks rather than the tasks. 
A task instance is defined as one execution of a task within a period. With the notion of task 
instances, one is able to specify the various timing constraints and dependencies among instances 
of tasks. 

In this paper, we consider the relative timing constraints imposed on two consecutive instances 
of a task. The task model and the analysis of the timing constraints are introduced in Sections 2 
and 3 respectively. Based on the analysis, we are able to derive the scheduling window for each 
task instance. Given the scheduling window of a task instance, we present the time-based approach 
of scheduling a task instance in Section 4. We propose three priority assignment algorithms for the 
task instances in Section 5. The task instances are scheduled one by one based on their priorities. 
In Section 6, we evaluate the three algorithms and show the experimental results. 

130 




2 Problem Statement 


Consider a set of periodic tasks T = { r t - | i = 1, ... n }, where r, is a 4-tuple < p t -, e,-, A,-, rj,- > 
denoting the period, computation time, low jitter and high jitter respectively. One instance of a 
task is executed each period. The execution of a task instance is non-preemptable. The start times 
of two consecutive instances of task r,- axe at least p,- - A,- and at most p, -f 77, • apart. 

In order to schedule periodic tasks, we consider the least common multiple (LCM) of all periods 
of tasks. Let n, be the number of instances for task r,- within a schedule of length LCM. Hence, ti,- 
= -rj-. A schedule for a set of tasks is the mapping of each task r,- to n,- task instances and the 


assigning of a start time s : - to the j-th instance of task r,-, rf, V i = 1, ... n and j = 1, ..., n ; 
feasible schedule is a schedule in which the following conditions are satisfied for each task r,-: 

. A 

fi = 

4 + ti 

(1) 

»i + l _ 

— 

5; LCM 

(2) 

4 > 

s \ 1 + Ti — A; 

(3) 

VI 

+ Pi + ni 

(4) 


Vj = 2, . . ., TLi -f 1. 



The non-preemption scheduling discipline leads to Equation 1 where // is the finish time of rj. 
Another condition fox non-preemption scheduling is that given any :, j, k and. £, if s’ < s f k then fj 
< s k . It means the schedule for any two instances is non-overlapping. The constructed schedule of 
length LCM is invoked repeatedly by wrapping-around the end point of the first schedule to the 
start point of the next one. Hence, as shown in Equation 2, the start time of the first instance in 
the next schedule is exactly one LCM away from that of the first schedule. Finally, Equations 3 
and 4 specify the relative timing constraints between two consecutive instances of a task. 


3 Analysis of Relative Timing Constraints 

Define the scheduling window for a task instance as the time interval during which the task can 
start. Traditionally, the lower and upper bounds of the scheduling window for a task instance are 
called earliest start time (est) and latest start time (1st) respectively. These values are given and 
independent of the start times of the preceding instances. 


131 





1 Instance ID 

est = sf~ i + p t - - A, 

1st = s-" 1 + Pi + 77 , 

actual start time (s^) 

i T? 

0 

40 

4 

1 rf 

39 

49 

40 

1 

75 

85 

77 

1 r? 

112 

122 

113 

! rf 

148 

158 

* 


Table 1: An example to show the wrong setting of scheduling windows 


We consider the scheduling of periodic tasks with relative timing constraints described in Equa¬ 
tions 3 and 4. The scheduling window for a task instance is derived from the start times of its 

preceding instances. A feasible scheduling window for a task instance rf is a scheduling window 
in which any start time in the window makes the timing relation between s^ _1 and sf satisfy 
Equations 3 and 4. Formally, given s], s}, ..., and ..sp 1 , the problem is to derive the feasible 

scheduling window for rf such that a feasible schedule can be obtained if rf is scheduled within 
the window. 

For the sake of simplicity, we assume that r,- = 0 and d.; = p,\ V i. in this section. Then, simply 
assigning est and hi of rf as sf~ } -i- p,- — A,- and s ^ -1 -f p,- -j- 77 , respectively where i — 1 , 2, .... n 
and j = i, 2, .... n,, is not tight enough to guarantee a feasible solution. For example, consider 
the case shown in Table 1 in which a periodic task r, is to be scheduled. Let LCM, p,, A,-, and r n 
be 200, 40, 5, and 5 respectively. Hence, there are 5 instances within one LCM (i.e. n,- = 5). The 
first column in Table 1 indicates the instance IDs. The second and third col umns give the est and 
1st of the scheduling windows for the task instances specified in the first column. The last column 
shows the actual start limes scheduled for the particular task instances. The actual start time is 
a value in between est and 1st of each task instance. For instance, the est and 1st of rf are 39 and 
49 respectively. It means 39 < sj < 49. The scheduled value for sf, in the example, is 40. Since 
sf = s] *r LCM = 204, we find that any value in the interval [148,158] can not satisfy the relative 
timing constraints between rf and rf. As a consequence, the constructed schedule is infeasible. 

We draw a picture to depict the relations among the start times of task instances in Figure 1. 
W hen rf is taken into account, the scheduling window for sf is obtained by considering its relation 
with sf 1 as well as that with sf' and . We make sure that once sf is determined, the estimated 
est and 1st of if ', based on sf and specify a feasible scheduling window for sf '. Namely, the 

interval-which is specified by the estimated est and 1st of s"’ , based on sf. overlaps the interval 


132 

















1 s’ 1 ' 43 


Figure 1: The relations between the task instances 

W' +1 - (w + w),*?*’- Cp. - >()]• 

Proposition 1: Let the est and 1st of r- be 

«*(T?) = rnoiKsf 1 + p, - A t ), (s- + (j - 1) x p,- - (n; - j -f 1) x p,)}, (5) 

and = min{(sp’ -fp, + p,), (s } + (j - 1) x p v + (n., - j + 1) x A,-)}. (6) 

If s? is in between the est(r^) and lst(rj), then the estimated est and Is! of s’ 1 ’, based on sf and 
s”' + , specify a feasible window. 

Proof: Let l and p be the estimated est and 1st of s’ 1 ', based on s^, respectively. 

Hence, 

t - + fo “ j) * (Pi ~ x <) (7) 

P = s] T («.- - i) X (p, + 7};) (8) 

To guarantee the existence of feasible start time of t*', the interval [£,p] has to overlap the 
interval [s’ 1 ' ' (p, -f p,). s’" ' J - (p : - - A,)]. Hence the following conditions have to be satisfied: 


-1 > p. - a,- 


133 


(10) 


— fj. < + 7?i • 

By replacing £ in Equation 9 with s^ 4 (n, - j) x (p,- - A,), we obtain 

< s’ 1 * 41 - (n; - j 4 l) X (p; - A;) 

= 5; 4 LCM - (n, - j 4 1) x (p, - A,) 

= 5- 4 nj x pi - (n, - j + 1) x (p,- - A,) 

= 5 • 4 (j - 1) X Pi + (n,- - j + 1) x A; (11) 

Likewise, by replacing p in Equation 10 with s\ 4 (n,- — j) x (p,- 4 p t ), we have 

sj > - (n* - i 4 1) X (p,- 4 7?,) 

= 5,- 4- LCM - (n; - j 4 1) X (pi 4 Vi) 

= s] 4 (j - 1) x pi - (ni - j 4 1) x Vi ( l2 ) 

So. According to Equations 12 and 3, we choose the bigger value between (s? 1 4 Pi — A,-) and 
($J 4 ( j - 1) x p.; - (r„, — j 4 1) x Vi) the est of rf. Similarly, according to Equations 11 and 4, 

we assign the smaller value of {s-~ l 4 p; 4 p,) and (s- 4 (j — 1) x p, 4 (n,- — j 4 1) x A,) as the 
ist. 

□ 

Example 3.1: To show how Proposition 3 gives a tighter bound to find feasible scheduling windows, 
we consider the case shown in Table 1 again. We apply Equations 5 and 6 to compute the esi and 
1st of each instance. The results are shown in Table 2. Note that the scheduling windows for r* 
and r t s are tighter than those in Table 1. As a consequence, any start time in the interval [159,160] 
for r* satisfys the relative timing constraints between rf and rf. 

3.1 Property of Scheduling Windows 

Define P,-(x,y, r) as the predicate in which the estimated est and 1st of rf, based on sf and sf, 
specify a feasible scheduling window for In Proposition 3 , we prove that for any s J - in between 
esl(rf) and lst(rf) as specified in Equations 5 and 6, P,-(f, 4 1) is true. 


134 



| Instance ID 

est from Equation 5 

1st from Equation 6 

actual start time (s 3 ) 

r} 

0 

40 

4 

* 1 

39 

49 

40 

'«• 

75 

85 

77 


114 

122 

115 

IHSHH 

159 

160 

159 ~ 160 


Table 2: The correct setting of scheduling windows based on Proposition 3.1. 


Lemma 1 Given sj, sf, ..and s 3 , if,Vk = 2, j. est(V*j < s\ < 1st (r-j as specified in 
Equations 5 and 6, then Pi(j,y , n,- 4 1) is true, V y = j 4 1, j 4 2, ..n,-. 

Proof: We prove that the estimated est and Lst of rf, based on s 3 and if' 4 ', Stf«Cify a feasible 
scheduling window, by showing that (1) the estimated scheduling window of 5?, based on sj, is 
specified by the interval 


Wi + (y - j) * (pi - A,-), sj 4 (y - j) x (pi 4 j?,)], (13) 

(2) the estimated scheduling window of sf, based on sf’ +1 , is specified by the interval 

[*r S - ( n i - V T 1) X (pi 4 7?,), if ,+1 - (n, - y 4 1) X (Pi - A.)], (14) 

and (3) the intervals in Equations 13 and 14 overlap. 

In Figure 2, we see that the necessary and sum dent conditions for the overlapping of the 
intervals spedfied in Equations 13 and 14 are 

s] + (y - j) X (Pi - A,) < sf ,+1 - (n,- - y 4 1) X (Pi - A,) (15) 

and sf 1 '" 5 - («i - y + 1) x (p s - 4 77 ,) < sj 4 (y - j ) x (p,- 4 77 ,). (16) 

By solving the Equations 15 and 16, we obtain 

s i < sj 4 (j - l) x p, 4 (ti, - j 4 1) x A,- 
and 5- > s] + {j-l)xpi-(ni-j+l)xr r: . 

The above two equations describe the same conditions as Equations 11 and 12 do. Hence, P,-(j, y. n, 4 1) 
is true, V y = j 4 1- j 4 2, ..., n z . 


135 
























I 


4 + (y ~ j) x {pi - a,) 4 + (2/ - j) x (p { + 7?,-) 


«r +l - (n; - y + 1) x (p,- + J?i) s *’ +1 - (n ; - y + 1 ) x (->; - A;) J 


Figure 2: The overlapping of two intervals 


□ 

Lemma 2 Given s], sj, ..., s\, and an integer no, where 1 < no < j, if, V k = 2, ..., j, estfrf) 
< s* < 1st( 7 f) are specified as in Equations 5 and 6, then P,[j, y, n,- -f n 0 ) is true, V y = j + 1, 
j + 2, • •n,-. 

Proof: We use the same method in Lemma 1 to prove it. We show that (1) the estimated scheduling 


window of sf, based on sj, is specified by the interval 

14 + {y~ j) * {Pi - A,), s? + {y - j ) x (p.- + t?,)], (17) 

(2) the estimated scheduling window of s*. based on s?'”"", is specified by the interval 

l 5 n.+nc _ ( n . j. no _ x _ ( n . + no _ x _ A{)], (IS) 

and (3) these two intervals overlap. 

The following conditions have to be satisfied to make sure the overlapping of the two intervals. 

4 < + (j - 1) x p, + (m - j + 1) x A,-- (p, — A) x no- 1 ( 19 ) 

and sj > s? -f (j ~ 1) * pv - (n ; - j + 1) x 77, - (p, + 73,) x n 0 - 1. (20) 


Since s- < s' 10 - (p,-A) x (n 0 -l) and s- > s* 0 - (pv-t-tj.) x (7i 0 - 1), we rewrite Equations 19 
and 20 

4 < s ?° + (j ~ 1) X pv + (n,- - j + 1) x A,—(py - A) x n 0 - 1 


136 


I 








< £i.+ (j ~ 1) x p, + (n,- - j + 1) x A,- 
a.nd s\ > + O' - 1) x p t - - (n,- - j + 1) x 7?, —(p, + 7?,) x n 0 - 1 . 

> fl + 0 ~ 1) x P. - (n,- - j + 1) x th 
Hence y , n,- ■+ n 0 ) holds for any 1 < no < j. 

□ 

Theorem 1 Given sj , 5 ?, .... and s], if, V k = 2, ..j, estftfy < sf < 1st (r, k ) as specified in 
Equations 5 and 6, then Pi{j,y, z) is true, V y = j + 1, j + 2, ..n,-, and z = m + 1, n, + 2, .. 
n,- -r j. 

By combining the proofs in Lemmas 1 and 2, it is easy to see that Theorem 1 holds. Based on 
Theorem 1 , we can assign the scheduling window for t- by using Equations 5 and 6 once sj, sf, 

c ? -1 

Before we present the scheduling technique for a task instance, let us consider the following 
objective. The objective can be formulated as follows. Given a set of tasks with the characteristics 
described in Section 2. we schedule the task instances for each task within one LCM to minimize 

" = E (21) 

Subject to the constraints specified in Equations 1 through 4, 
where a(z) = z, if x > 0; = -z, otherwise. 

Basically, we try to schedule every instance of a task one period apart from its preceding 
instance. An optimal schedule is a feasible schedule with the minimum total deviation value from 
one period apart for instances. 

4 The Time-Based Scheduling of a Task Instance 

We consider the time-based solution to the scheduling problem by using a linked list. Each element 
in the list represents a time slot assigned to a task instance. A time slot w has the following fields: 
(1) task id 1 and instance id j indicate the identifier of the time slot. (2) start time st and finish time 

ft indicate the start time ana completion time of respectively. (3) prev ptr and next ptr are the 


137 



Figure 3: Insertion of a new time slot 


pointers to the preceding and succeeding time slots respectively. We arrange the time slots in the 
list in increasing order by using the start timt as the key. Any two time slots are non-overlapping. 
Since the execution of an instance is non-preemptable, the time difference between start time and 
finish time, equals the execution time of the task. 

4.1 Creating a Time Slot for the Task Instance 

Consider a set of n tasks. Given a linked list and a task instance rf , we schedule the instance by 
inserting a time slot to the list. According to equations 5 and 6, we compute the est(r-) and lst(r■?) 
first. Let 5 be the set of unoccupied time intervals that overlap the interval jest(r^), lst[r -)] in the 
linked list. The unoccupied time intervals in 5 are collected by going through the list. Each time 
when a pair of time slots (u',m+ 1) is examined, we compute £ = max{est(-jf), }t(w)} and p = 
min{lst(r^). st(w 1)}, where ft(w) is the finish time of the time slot id, and st{w 4-1) is the start 
time of the slot next to tc. If £ < p, then we add the interval [£, p] to 5. 

The free intervals in S are the potential time slots which rf can be assigned to. Since we try 
to schedule rj as close to one period away from the preceding instance rf' 1 as possible, we sort 5, 
based on the function of the lower bound of each interval, a(s; -1 + p, - £), in ascending order. 
Without loss of generality, we assume that 5 after the sorting is denoted by {int 3 . ini- 2 , - 


138 





The idea is that if -■ is scheduled to ini*, then the value in equation 21 will be smaller than that 
of the case in which rf is scheduled to intfc+i. 

The scheduling of rj can be described as follows. Starting from inlj, we check whether the 

length of the interval is greater or equal to the execution time of rf or not. If yes, then we schedule 

the instance to the interval. One new time slot is created in which the start time is the lower bound 
of the interval and the finish time equals the start time plus the execution time. The created time 
slot is added to the linked list and the scheduling is done. If the length is smaller than the execution 
time, then we check the length of the next interval until all intervals are examined. An example is 
shown in Figure 3 in which the slot with dark area represents r-. In this example we assume that 
es£(rf) < ft and £7 - ft > e. It means the free slot between the first and second occupied slots 
can be assigned to r-. 


4.2 Sliding of the Time Slots 


In case none of the intervals in S can accommodate a iask instance, the sliding technique is used 
to create a big enough interval by sliding the existence time slots in the list. 

To make the sliding technique work, we maintain two values for each time slot: left, laxity and 
right laxity. The value of left laxity indicates the amount of time units by which a time slot can be 
left-shifted to a earlier start time. Similarly^ the right laxity indicates the amount of time units by 
which a time slot can be right-shifted to a later start time. 

Given the time slots Wk. and Wk~ i, where a and b are the task and instance identifiers of 

u>k respectively, the laxity values of the time slot Wk can be computed by: 


leftJaxity(wk) 

rightJaxiiy(u>k) 

where 

and 


- «*', 4 ~ /i(w*_i)+ leftJaxity(w k -i)} 
min{lsi' - s*, st(u>* +: ) - /* + rip htJaxit y(u;* + i)} 
est' = max{est(~ b ), s^ 1 - {p a + t? 0 )} 

1st' = min{lst{r b c ), s^ 1 - (p B - A c )}. 


( 22 ) 

(23; 


Note that the interval [est', 1st') defines the sliding range during which r b can start without 
shifting r B ~ l or r b ~'-. A schematic illustration of equations 22 and 23 is given in Figure 4. 

From equations 22 and 23, we see that the computing of leftJaxity(wk) depends on that of iXk-\ 
and the computing of right Jaxity(wk) depends on that of ivk~\- It implies a two-pass computation 


139 







Figure 4: An illustration of leftJaxiiy(iv k ) and rightJaxity(w k ) 

is needed to compute the laxity values for all time slots. The complexity is 0{2N) where N is the 
number of time slots in the linked list. 

The basic idea of the sliding technique is described as follows. Given a task instance r? and a 
set of unoccupied intervals, 5 = {inti, :nl 2 , ..., ini, we check one interval at a time to see if 
the interval can be enlarged by shifting the existent time slots. Two possible wavs of enlargement 
are (3) by either shifting the time slots, that precede the interval, to the left or (2) shifting the 
slots, that lollow the interval, to the right. The shifting depends on which direction minimizes the 
objective function in Equation 21. 

4.3 The Algorithm 

An algorithmic description about how to schedule a task instance, as described in Sections 4.1 
and 4.2, is given in Table 3. 

The procedures Left_Shift(u>^,time_units) and Eight_Shift(u-'i,time.units) in Table 3 may involve 
the shifting of more than one time slot recursively. For example, consider the case in Figure 4. if 
Right_Shift(uj^, 1st' — s£) is invoked (i.e. w k is to be shifted right by 1st' — time units), then 
tyfc+i has to be shifted too. It is because the gap between w k and is st(w k +i) — which is 








smaller than 1st' - s h 0 . In this case, Right.Shift(^ +) ,/st / - s£ - st(wk+i) + ft) is invoked. 

We do not enlarge an interval at both ends. Enlarging an interval at both ends needs to shift 
certain amount of preceding time slots to the left and shift some succeeding slots to the right. It is 
possible that some task instance is shifted left, while t*' + 1 is shifted right. As a consequence, the 
timing constraints between si and could be violated. For example, Let and s£ +1 before the 
shifting be 10 and 20 respectively. The execution time for t x is 5 time units. Assume the left laxity 
of rf is 5 and the right laxity of rj' +1 is 5. It implies s*! +1 — si < 15. Consider the scheduling of a 
task instance rj with execution time 15. If we enlarge the interval between r* and r| +1 by shifting 
7? left 5 time units and r* +1 right 5 time units, then we get a new interval with 15 time units for 
r\. However, it turns out that s*! +1 = 25, si = 5, and the relative timing constraints between rjf 
and rL +J is violated. 


5 The Priority-Based Scheduling of a Task Set 

We consider the priority-based algorithms for scheduling a set of periodic tasks with hybrid timing 
constraints. Given a set of periodic tasks T = { 7, | : = 1, ..., n } with the task characteristics 
described in Section 2, we compute the LCM of all periods. Each task r, is extended to n,- task 
instances: rj , r?, .. rf'. A scheduling algorithm c for F is to totally order the instances of all 
tasks within the LCM. Kamely, o : task-id x instance-id — integer. 

Three algorithms are considered. They are smallest latest-start-lime //rst'SLsF), smallest period 
first (SPF), and smallest jitter first (SJF) algorithms. 

5.1 SLsF 

The scheduling window for a task instance rj depends on the scheduling of its preceding instance. 
Once s]~ : is determined, the scheduling window of the instance can be computed by equations 5 
and 6. The scheduling window for the first instance of a task r,- is defined as [r,-,d,' — e,]. 

The idea of the SLsF algorithm is to pick one candidate instance with the minimum 1st among 
all tasks at a time. One counter for each task is maintained to indicate the candidate instance. All 
counters are initialized to 1. Each time when a task instance with the smallest 1st is chosen, the 
algorithm in Table 3 is invoked to schedule the instance. After the scheduling of the instance is 
done, the counter is increased by one. The counter for r,- overflows when it reaches n, -f 1. It means 


141 








that all the instances of t, are scheduled. The algorithm terminates when all counters overflow. 

We can compute the relative deadline for a task instance by adding the execution time to the 
1st If the execution times for all tasks are identical, the SLsF algorithm is equivalent to the earliest 
deadline first (EDF) algorithm. 

5.2 SPF 

The task periods determine the LCM of T and the numbers of instances for tasks within the LCM. 
In the most cases, the task with the smaller period has the tighter timing constraints. Namely, 
(A,- + 77 ,) < (A j -f t/j) if pi < pj. To make the tasks with the smaller periods meet their timing 
constraints, the SPF algorithm favors the tasks with smaller periods. 

The SPF algorithm uses the period as the key to arrange all tasks in non-decreasing order. The 
task with the smallest period is selected to schedule first. The instances of a particular task are 
scheduled one by one by invoking the algorithm in Table 3. After all the instances of a task are 
scheduled, the next task in the sequence is scheduled. 

5.3 SJF 

We define the jitter of a task r, as (A,- -f t?;). It is proportional to the range of the scheduling 
window. Hence, The schedulability of a task also depends on the jitter. 

Instead of using the period as the measurement, the SJF algorithm assigns the higher priority 
to the tasks with the smaller jitters. The task with the smallest jitter is scheduled first. 

5.4 The Solution 

The composition of the time-based scheduling of a task instance and the priority assignment of 
task instances is shown in Figure 5. The priority assignment can be done by using SLsF, SPF, or 
SJF. The function Scheduk-AnJnstance() is invoked to schedule a single task instance. 

6 Experimental Evaluation 

We conduct two experiments to study and compare the performance of the three algorithms. The 
purpose of the first experiment is to study the effect of the number of tasks and utilization on 

142 






A set of tasks is given 


Find the next unscheduled task instance 
By some priority-based assignment, 
Such as SLsF, SPF, and SJF. 



Schedule.Andnsi.ance 

() as shown in Table 3 


Some instance is unscheduled 


All instances are scheduled 


Figure 5: A schematic flowchart for the solution 


143 




the schedulabilitv of each algorithm. The objective of the second experiment is to compare the 
performance of the three algorithms. 


6.1 The First Experiment 

The task generation scheme for the first experiment is characterized by the following parameters. 

• Periods of the tasks: We consider a homogeneous system in which the period of one task 
could be either the same as or multiple of the period of another. We consider a system with 
40, 80, 160, 320, and 640 as the candidate periods. There may be more than one task with 
the same period. 

• The execution time of a task, e, : It has the uniform distribution over the range [0,-^], where 
Pi is the period of the task r,-. The execution time could be a real value. 

• The jitters of a task: A; = p,- = 0.1 x p,-. 


We define the utilization of a task system as 


A’ 


rr~' £i 


(24) 


In the first experiment, the utilization value and the number of tasks in a set are the controlled 
variables. Given an utilization value U and the number of tasks N the scheme first generates a 
run of raw data by randomly generating a set of N tasks based on the the selected periods, jitter 
values, and the execution time distribution. The utilization of the raw data, u, is then computed by 
Equation 24. Finally, the utilization value of the raw data is scaled up or down to U by multiplying 
“■ to the execution time of each generated task. As a consequence, we obtain a set of tasks with 
the specified {U ,/v) value. 

For each combination of {U,N) in which U = 5%, 10%, 15%, ... 100% and A 7 = 10, 20, and 
30, we apply the scheme to generate 5000 cases of input data and use the three algorithms to 
solve them. The schedulabilitv degree of each (U Js T ) combination for an algorithm is obtained by 
dividing the number of solved cases by 5000. Since the jitter values is 1/10 of periods, it is observed 
that the SPF and SJF algorithms yield the same results. The results are shown in Figure 6. 

As can be seen in Figures 6(a) and (b) the number of tasks has the different effects on the 
three algorithms. For SLsF, given a fixed utilization value, the schedulabilitv degree increases 


144 





+) <t>) 

g ow dml ability Seh»«nil ability 



Figure 6: The effect of the numbers of tasks on the schedulability 


as the number of tasks in a system becomes bigger. It is beacuse the execution time of a task 
becomes smaller as the number of tasks increases. For a task system with smaller execution time 
distribution, the chance for SLsF to find a feasible solution is Trigger. The same phenomenon is 
also found in Figure 6(b) for SPF and SJF in the low-utilization cases (i.e. U < 20%). However, 
for the high-utilization cases in Figure 6(b), the complexity of the number of tasks dominates the 
algorithms and the schedulability decreases. 


6.2 The Second Experiment 

The task generation scheme for the second experiment is characterized by the following parameters. 
. LCM = 300 

• The number of tasks is 20. 

• Periods of the tasks: We consider the factors of the LCM as the periods. They are 20, 30, 
50, 60, 100,150, and 300. There may be more than one task w’ith the same period. 


145 






• The execution time of a task, e,- : It has the uniform distribution over the range [0.^], where 
Pi is the period of the task r,. The execution time could be a real value. 

• The-jitters of a task: A,• = 77 ; = 0.1 x p; + 2 x e,-. 


The generation scheme for the second experiment is similar to the first one. Given an utilization 
value U, a set of 20 tasks is randomly generated according to the parameters listed above and then 
the execution time of each task is normalized in order to make the utilization value equal to U 
exactly. 


We generate 5000 cases of different task sets for each utilization value ranging from 0.05 to 1.00. 
The schedulability degree of each algorithm on a particular utilization value is obtained by dividing 
the number of solved cases by 5000. "We compare the schedulability degrees of the algorithms on 
different utilization values. The results are shown in Figure 7(a). 


As can be see in Figure 7(a) the SLsF algorithm outperforms the other two algorithms. For 
example, when the utilization = 50%, the schedulability- degree of SLsF is 0.575 while those of SPF 
and SJF are less than 0.2. It is because the way of assigning the priorities to the task instances in 
the SLsF algorithm reflects the urgency of task instances by considering the latest start times. 


We also compare the objective function value ~ in Equation 21 among the three algorithms. 
We define the normalized objective function for an algorithm as 

5000 



(25) 


{ 1 if the algorithm can not find a feasible solution to case i. 

0 if mci(:j = min{i). 

e,-—mtnfO 

mS(,-)-m.A(,-) otherwise. 

Given case i, the values of min(i) and max(i) are calculated am ong the objective values obtained 
from the algorithms which solve the case. For the algorithms which can not find a feasible solution 
to case :, the objective values are not taken into account when min(i ) and mcr(i) are calculated. 
The results of the normalized objective functions for each algorithm on different utilization values 
are shown in Figure 7(b). 

It is observed that in the low-utilization cases SJF finds feasible solutions with smaller objective 
values. It is because that SJJr schedules the tasks with the smallest jitters first. By scheduling 
the tasks with smaller jitter value first it is more easier to make the instances of a task one period 
apart, we can find a feasible solution with smaller objective value. However, in the middle- or 


146 




*c**«ulability 


4 ) 


N*nMli»d fwv:tifco 



Figure 7: The comparison of three algorithms 


high-utilization cases, the schedulabilitv dominates the normalized objective function, and SLsF 
outperforms the other two algorithms in these regions. 


7 Summary 

In this paper we have considered the static non-preemptive scheduling algorithm on a single proces¬ 
sor for a set of periodic tasks with hybrid timing constraints. The time-based scheduling algorit hm 
is used to schedule a task instance once the scheduling window of the instance is given. We also have 
presented three priority’ assignment algorithms for the task instances and conducted experiments 
to compare the performance. From the experimental results, we see that the SLsF outperforms the 
other two algorithms. 

The techniques presented in this chapter can be applied to multi-processor real-time systems. 
Communication and synchronization constraints can be also incorporated. In our future work, the 
extension to a distributed computing systems will be investigated. 


147 









References 


[1] T. Carpenter, K. Driscoll, K. Hoyme, and J. Carciofmi. Arinc 659 scheduling: Problem defini¬ 
tion. -In Proceedings of IEEE Real-Time Systems Symposium, San Juan, PR, Dec. 1994. 

[2] M. L. Dertouzos and A.K. Mok. Multiprocessor on-line scheduling of hard real-time tasks. IEEE 
Transactions on Software Engineering , 15(12):149T—1506, Dec. 1989. 

[3] M.G. Harbour, M.H. Klein, and J.P. Lehoczky. Fixed priority scheduling of periodic tasks 
with varying execution priority. In Proceedings of IEEE Real-Time Systems Symposium , pages 
116-128, Dec. 1991. 

[4] Krithi Ramamritham. Allocation and scheduling of complex periodic tasks. In Proceedings of 
the 10th International Conference on Distributed Computing Systems , pages 108-115, Paris, 
France, 1990. 

[5] T. Shepard and J.A.M. Gagne. A pre-run-time scheduling algorithm for hard real-time systems. 
IEEE Transactions on Software Engineering, 17(7):669—677, July 1991. 

[6] K. Tinaell, A. Burns, and A. Weldings. An extendible approach for analyzing fixed priority hard 
real-time tasks. Real-Time Systems, 6(2), March 1994. 

[7] J.P.C. Verboosel. E.J. Luit, D.K. Hammer, and E. Jansen. A static scheduling algorithm for 
distributed hard real-time systems. Real-Time Systems, pages 227-246, 1991. 

[8] J. Xu and D.L. Parnas. Scheduling processes with release times, deadlines, precedence, and 
exclusion relations. IEEE Transactions on Software Engineering, 16(3):360-369, March 1990. 





Schedule_An_Instance (”/): 

Input: A linked list, a task instance rf and a sequence of sorted free intervals, 2 — { inti, ini 2 , . • 
in which each interval overlaps [e$£(tr?),/s£(if )]. 


Let the execution time of 7 / be e. 

For n = 1 to |5| do 

Let inl n be [C,p]- 
If p - £ > e then 

Return a new time slot with start time = i and finish time = t + e. 

End if. 

End for. 

Compute left lazily and right laxity for each time slot in the linked list by equations 22 and 23. 
For *1 = 1 to |5| do 

Let intr, be [£,p\. 

If £ > s{~ ' J -f pi then /* Thy left shift first then right shift */ 

Let the time slot that immediately precedes int„ be tn*. 

If leftJczity(wk) *f p - t > e then /’ Left shift */ 

Left_Shift(u;^,e - p + £). 

Return a new time slot w-ith starl lime — p - e and finish time = 

Else 

Let the time slot that immediately follows :nt„ be w K . 

If riohl.lczity(wk ) — p — £ > e then /* Right shift “/ 

PJght_Shift(in^.e — p *f ^). 

Return a new time siot with start time = .£ and finish lime = £ •he. 
Enc If. 

End If. 

Else /' Try right shift first then left shift */ 

Let the time slot that immediately follow^ inl n be in*. 

If rightJczily(wk) ■¥ p - £ > e then /* Right shift “/ 

Right_Shift(ujj c ,e — p -f £). 

Return a new time slot with start time = l and finish lime = L -f e. 

Else 


Let the time slot that immediately precedes int n be w K . 
If leftJazilxfiwk) *f p — £ > e then /* Left shift */ 
Left_Shift(u:i,e - p £). 


Return a new time slot with starl lime = p - e and finish time = 
End If. 

End If. 

End If. 

End for. 

vSchedule rj at the end of linked list. 


P- 


Table 3: Tic Scheduling.*:; a Task Instance 
149 


•1 ini |S| ) 


y 




REPORT DOCUMENTATION PAGE 

Form approved 

OMB No 074-0188 

1. AGENCY USE ONLY (leave blank) 2. REPORT DATE 3. REPORT TYPE END DATES COVERED 

1/3/1995 Technical Reports 

4. TITLE AND SUBTITLE 

Scheduling of Periodic Tasks with Relative Timing Constraints 

5. FUNDING NUMNBERS 

N00014-91-C-0195 

6. AUTHOR(S) 

S.-T. Cheng and A. K. Agrawala 

7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 
University of Maryland 

Department of Computer Science 

A.V. Williams Building 

College Park, MD 20742 

8. PERFORMING ORGANIZATION 
REPORT NUMBER 

CSTR 3392 

9. SPONSORING/ MONITORING AGENCY NAME(S) AND ADDRESS(ES) 
PhillipsLaboratory 

Director of Contracting 

3651 Lowry Avenue SE 

Kirtland AFB, NM 87117-5777 

10. SPONSORING/ MONITORING 
AGENCY REPORT NUMBER 

11. SUPPLEMENTARY NOTES 

12.a. DISTRIBUTION/ AVAILABILITY STATEMENT 

12.b. DISTRIBUTION CODE 

13. ABSTRACT (Maximum 200 words) 

The problem of non-preemptive scheduling of a set of periodic tasks on a single processor has been 
traditionally considering the ready time and deadline on each task. As a consequence, a feasible schedule 
finds that in each period one instance of each task starts the execution after the ready time and completes 
the execution before the deadline. Recently, the timing requirements of the real-time systems emerge that 
the relative timing constraints are imposed on the consecutive executions of each task. In this paper, we 
consider the scheduling problem of the periodic tasks with the relative timing constraints imposed on two 
consecutive executions of a task. We analyze the timing constraints and derive the scheduling window 
for each task instance. Based on the scheduling window, we present the time-based approach of 
scheduling a task instance. The task instances are scheduled one by one based on their priorities 
assigned by the proposed algorithms in this paper. We conduct the experiments to compare the 
schedulability of the algorithms. 

14. SUBJECT TERMS 

Time constraints, timing requirements 

15. NUMBER OF PAGES 

21 

16. PRICE CODE 

17. SECURITY CLASSIFICATION 18. SECURITY CLASSIIF1CATI0N 19. SECURITY CLASSIFICATION 20. LIMITATION OF 

OF REPORT OF THIS PAGE OF ABSTRACT ABSTRACT 

Unclassified Unclassified Unclassified Umlimited 


MSN 7540-01 280-5500 


150 


Standard Form 298 (Rev 2-89) 

























A Scalable Virtual Circuit Routing Scheme for ATM Networks* 

Cengi2 Alaettinoglu Ibrahim Matta A. Udaya Shankar 

Information Sciences Institute Institute for Advanced Computer Studies 

University of Southern California Department of Computer Science 

' Marina del Rey, CA 90292 University of Maryland 

College Park, MD 20742 


October 1994 


Abstract 

High-speed networks, such as ATM networks, are expected to support diverse quality-of- 
service (QoS) requirements, including real-time QoS. Real-time QoS is required by many appli¬ 
cations such as voice and video. To support such service, routing protocols based on the Virtual 
Circuit (VC) model have been proposed. However, these protocols do not scale well to large 
networks in terms of storage and communication overhead. 

In this paper, we present a scalable VC routing protocol. It is based on the recently proposed 
viewserver hierarchy, where each viewserver maintains a partial view of the network. By querying 
these viewservers, a source can obtain a merged view that contains a path to the destination. 
The source then sends a request packet over this path to setup a real-time VC through resource 
reservations. The request is blocked if the setup fails. We compare our protocol to a simple 
approach using simulation. Under this simple approach, a source maintains a full view of the 
network. In addition to the savings in storage, our results indicate that our protocol performs 
close to or better than the simple approach in terms of VC carried load and blocking probability 
over a wide range of real-time workload. 


Categories and Subject Descriptors: C.2.1 [Computer-Communication Networks]: Network Archi¬ 
tecture and Design —packet networks; store and forward networks ; C.2.2 [Computer-Communication Net¬ 
works]: Network Protocols —protocol architecture ; C.2.m [Routing Protocols]; F.2.m [Computer Network 
Routing Protocols]. 


’ This work is supported in part by ARPA and Philips Labs under contract DASG6D-92-0055 to Department of 
Computer Science, University of Maryland, and by National Science Foundation Grant No. NCR 89-04590. The work 
of C. Alaettinoglu is also supported by National Science Foundation Grant No. NCR 93-23043. The views, opinions, 
and/or findings contained in this report are those of the author(s) and should not be interpreted as representing the 
official policies, either expressed or implied, of the Advanced Research Projects Agency, PL, the National Science 
Foundation, or the U.S. Government. 


151 






Contents 

1 Introduction 1 

2 Related Work 4 

3 Viewserver Hierarchy Query Protocol 5 

4 Update. Protocol for Dynamic Network Conditions 10 

5 Evaluation 13 

6 Numerical Results 16 

6.1 Results for Network 1.. 16 

6.2 Results for Network 2 . 18 

7 Conclusions 19 


152 





I 


1 Introduction 

Integrated services packet-switched networks, such as Asynchronous Transfer Mode (ATM) net¬ 
works [21], are expected to carry a wide variety of applications with heterogeneous quality of ser¬ 
vice (QoS) requirements. For this purpose, new resource allocation algorithms and protocols have 
been proposed, including link scheduling, admission control, and routing. Link scheduling defines 
how the link bandwidth is allocated among the different services. Admission control defines the 
criteria the network uses to decide whether to accept or reject a new incoming application. Routing 
concerns the selection of routes to be taken by application packets (or cells) to reach their desti¬ 
nation. In this paper, we are mainly concerned with routing for real-time applications (e.g., voice, 
video) requiring QoS guarantees (e.g., bandwidth and delay guarantees). 

To provide real-time QoS support, a number of virtual-circuit (VC) routing approaches have 
been proposed. A simple (or straightforward) approach to VC routing is the link-state full-view 
approach. Here, each end-system maintains a view of the whole network, i.e. a graph with a vertex 
for every node 1 and an edge between two neighbor nodes. QoS information such as delay, band¬ 
width, and loss rate are attached to the vertices and the edges of the view. This QoS information 
is flooded regularly to all end-systems to update their views. When a new application requests ser¬ 
vice from the network, the source end-system uses its current view to select a source route to the 
destination end-system that is likely to support the application’s requested QoS, i.e., a sequence of 
node ids starting from the source end-system and ending with the destination end-system. A VC- 
setup message is then sent over the selected source route to try to reserve the necessary resources 
(bandwidth, buffer space, service priority) and establish a VC. 

Typically, at every node the VC-setup message visits, a set of admission control tests are 
performed to decide whether the new VC, if established, can be guaranteed its requested QoS 
■without violating the QoS guaranteed to already established VCs. At any node, if these admission 
tests are passed, then resources are reserved and the VC-setup message is forwarded to the next 
node. On the other hand, if the admission tests fail, a VC-rejected message is sent back towards 
the source node releasing resource reservations made by the VC-setup message, and the application 
request is either blocked or another source route is selected and tried. If the final admission tests 
at the destination node are passed, then a VC-established message is sent back towards the source 
node confirming resource reservations made during the forward trip of the VC-setup message. Upon 
receiving the VC-established message, the application can start transmitting its packets over its 

3 We refer to switches and end-systems collectively as nodes. 


153 



reserved VC. This VC is torn down and resources are released at the end of the transmission. 

Clearly, the above simple routing scheme does not scale up to large networks. The storage at 
each end-system and the communication cost are proportional to N x d, where N is the number of 
nodes and d is the average number of neighbors to a node. 

A traditional solution to this scaling problem is the area hierarchy used in routing protocols 
such as the Open Shortest Path First (OSPF) protocol [18]. The basic idea is to aggregate nodes 
hierarchically into areas: “close” nodes axe aggregated into level 1 areas, “close” level 1 areas are 
aggregated into level 2 areas, and so on. An end-system maintains a view that contains the nodes 
in the same level 1 area, the level 1 areas in the same level 2 area, and so on. Thus an end-system 
maintains a smaller view than it would in the absence of hierarchy. Each area has its own QoS 
information derived from that of the subareas. A major problem of an area-based scheme is that 
aggregation results in loosing detailed link-level QoS information. This decreases the chance of the 
routing algorithm to choose “good” routes, i.e. routes that result in high successful VC setup rate 
(or equivalently high carried VC load). 

Our scheme 

In this paper, we present a scalable VC routing scheme that does not suffer from the problems of 
areas. Our scheme is based on the viewserver hierarchy we recently proposed in [3, 2] for large 
internetworks and evaluated for administrative policy constraints. Here, we are concerned with the 
support of performance/QoS requirements in large wide-area ATM-like networks, and we adapt our 
viewserver protocols accordingly. 

In our scheme, views are not maintained by every end-system but by special switches called 
viewservers. For each viewserver, there is a subset of nodes around it, referred to as the viewservers 
precinct. The viewserver only maintains the view of its precinct. This solves the scaling problem 
for storage requirement. 

A viewserver can provide source routes for VCs between source and destination end-systems 
in its precinct. Obtaining a route between a source and a destination that are not in any single 
view involves accumulating the views of a sequence of viewservers. To make this process efficient, 
viewservers are organized hierarchically in levels, and an associated addressing structure is used. 
Each end-system has a set of addresses. Each address is a sequence of viewserver ids of decreasing 
levels, starting at the top level and going towards the end-system. The idea is that when the views 
of the viewservers in an address are merged, the merged view contains routes to the end-system 


154 



from the top level viewservers. 

We handle dynamic topology changes such as node/link failures and repairs, and link cost 
changes. Nodes detect topology changes affecting itself and neighbor nodes. Each node commu¬ 
nicates these changes by flooding to the viewservers in a specified subset of nodes; this subset is 
referred to as its flood area. Hence, the number of packets used during flooding is proportional to 
the size of the flood area. This solves the scaling problem for the communication requirement. 

Thus our VC Touting protocol consists of two subprotocols: a view-query protocol between end- 
systems and viewservers for obtaining merged views; and a mew-update protocol between nodes and 
viewservers for updating views. 

Evaluation 

In this paper, we compare our viewserver-based VC routing scheme to the simple scheme using 
VC-level simulation. In our simulation model, we define network topologies, QoS requirements, 
viewserver hierarchies, and evaluation measures. To the best of our knowledge, this is the firs; 
evaluation of a dynamic hierarchical-based VC routing scheme under real-time workload. 

Our evaluation measures are the amount of memory required at the end-systems, the amount 
of time needed to construct a path 2 , the carried VC load, and the VC blocking probability. We 
use network topologies each of size 2764 nodes. Our results indicate that our viewserver-based VC 
routing scheme performs close to or better than the simple scheme in terms of VC carried load 
and blocking probability over a wide range of workload. It also reduces the amount of memory 
requirement by up to two order of magnitude. 

Organization of the paper 

In Section 2, we survey recent approaches to VC routing. In Section 3, we present the view-query 
protocol for static network conditions, that is, assuming all links and nodes of the network remain 
operational. In Section 4, we present the view-update protocol to handle topology changes. In 
Section 5, we present our evaluation model. Our results are presented in Section 6. Section 7 
concludes the paper. 

2 We use the terms route and path interchangeably. 


155 


2 Related Work 


In this section, we discuss routing protocols recently proposed for packet-switched QoS networks. 
These routing protocols can be classified depending on whether they help the network support 
qualitative QoS or quantitative (real-time) QoS. For a qualitative QoS, the network tries to provide 
the service requested by the application with no performance guarantees. Such a service is often 
identified as “best-effort”. A quantitative QoS provides performance guarantees (typically required 
by real-time applications); for example, an upper bound on the end-to-end delay for any packet 
received at the destination. 

Routing protocols that make routing decisions on a per VC basis can be used to provide either 
qualitative or quantitative QoS. For a quantitative QoS, some admission control tests should be 
performed during the VC-setup message’s trip to the destination to try to reserve resources along 
the VC’s path as described in Section 1. 

On the other hand, the use of routing protocols that make routing decisions on a per packet 
basis is problematic in providing resource guarantees [5], and qualitative QoS is the best service 
the network can offer. 

Since we are concerned in this paper with real-time QoS, we limit our following discussion to 
VC routing schemes proposed or evaluated in this context. We refer the reader to [19, 6] for a good 
survey on many other routing schemes. 

Most of the VC routing schemes proposed for real-time QoS networks are based on the link- 
state full-view approach described in Section 1 [6, 1, 10, 24]. Recall that in this approach, each 
end-system maintains a view of the whole network, i.e. a graph with a vertex for every node and 
an edge between two neighbor nodes. QoS information is attached to the vertices and the edges of 
the view. This QoS information is distributed regularly to all end-systems to update their views 
and thus enable the selection of appropriate source routes for VCs, i.e. routes that are likely to 
meet the requested QoS. The proposed schemes mainly differ in how this QoS information is used. 
Generally, a cost function is defined in terms of the QoS information, and used to estimate the 
cost of a path to the VC’s destination. The route selection algorithm then favors short paths with 
minimum cost. See [17, 22] for an evaluation of several schemes. 

A number of VC routing schemes have also been designed for networks using the Virtual Path 
(VP) concept [15, 14]. This VP concept has been proposed to simplify network management and 
control by having separate (logically) fully-connected subnetworks, typically one for each service 
class. In each VP subnetwork, simple routing schemes that only consider one-hop and two-hop 


156 






paths are used. However, the advantage of using VPs can be offset by a decrease in statistical 
multiplexing gains of the subnetworks [15]. In this work, we are interested in general network 
topologies, where the shortest paths cam be of arbitrary hop length and the overhead of routing 
protocols is of much concern. 

All the above VC routing schemes are based on the link-state approach. VC routing schemes 
based on the path-vector approach have also been proposed [13]. In this approach, for each desti¬ 
nation a node maintains a set of paths, one through each of its neighbor nodes. QoS information 
is attached to these paths. For each destination, a node exchanges its best feasible path 3 with its 
neighbor nodes. The scheme in [13] provides two kinds of routes: pre-computed and on-demand. 
Pre-computed routes match some well-known QoS requirements, and are maintained using the 
path-vector approach. On-demand routes are calculated for specific QoS requirements upon re¬ 
quest. In this calculation, the source broadcasts a special packet over all candidate paths. The 
destination then selects a feasible path from them and informs the source [13, 23]. One drawback 
of this scheme is that obtaining on-demand routes is very expensive since there are potentially 
exponential number of candidate paths between the source, and the destination. 

The link-state approach is often proposed and favored over the path-vector approach in QoS 
architectures for several reasons [16]. An obvious reason is simplicity and complete control of the 
source over QoS route selection. 

The above VC routing schemes do not scale well to large QoS networks in terms of storage 
and communication requirements. Several techniques to achieve scaling exist. The most common 
technique is the area hierarchy described in Section 1. 

The landmark hierarchy [26, 25] is another approach for solving the scaling problem. The link- 
state approach can not be used with the landmark hierarchy. A thorough study of enforcing QoS 
and policy constraints with this hierarchy has not been done. 

Finally, we should point out that extensive effort is currently underway to fully specify and 
standardize VC routing schemes for the future integrated services Internet and ATM networks [9]. 

3 Viewserver Hierarchy Query Protocol 

In this section, we present our scheme for static network conditions, that is, all links and nodes 
remain operational. The dynamic case is presented in Section 4. 

A feasible path is a path that satisfies the QoS constraints of the nodes in the path. 


157 






Conventions: Each node has a unique id. Nodelds denotes the set of node-ids. For a node u, we 
use nodeid(u) to denote the id of u. NodeNeighbors(u ) denotes the set of ids of the neighbors of u. 

In our protocol, a node u uses two kinds of sends. The first kind has the form “Send(m) to v”, 
where m is the message being sent and v is the destination-id. Here, nodes u and v are neighbors, 
and the message is sent over the physical link (u, v). If the link is down, we assume that the packet 
is dropped. 

The second kind of send has the form “Send(m) to v using sr”, where m and v are as above 
and sr is a source route between u and v. We assume that as long as there is a sequence of up 
links connecting the nodes in sr, the message is delivered to v. This requires a transport protocol 
support such as TCP [20], 

To implement both kind of sends, we assume there is a reserved VC on each link for sending 
routing, signaling and control messages [4]. This also ensures that routing messages do not degrade 
the QoS seen by applications. 

Views and Viewservers 

View’s are maintained by special nodes called viewservers. Each viewserver has a precinct, which is 
a set of nodes around the viewserver. A viewserver maintains a view, consisting of the nodes in its 
precinct, links between these nodes and links outgoing from the precinct 4 . Formally, a view’server 
x maintains the following: 

Precinct : C Nodelds. Nodes whose view- is maintained. 

View : - View of z. 

= {(ti, timestamp, expiryiime, {(u, cost) : v € Node Neighbors(u)}) : 
u € Precinct} 

The intention of View, is to obtain source routes between nodes in Precincts. Hence, the 
choice of nodes to include in Precincts and the choice of links to include in View x axe not arbitrary. 
Precincts and View z must be connected; that is, between any two nodes in Precincts , there should 
be a path in View x . Note that View x can contain links to nodes outside Precincts. We say that a 
node v. is in the view of a viewserver x, if either v is in the precinct of z, or View x has a link from 
a node in the precinct of x to node -u. Note that the precincts and views of different viewservers 
can be overlapping, identical or disjoint. 

* No: all the links need 10 be included. 


158 



For a link (ti,v) in the view of a viewserver x, View x stores a cost. The cost of the link (u,v) 
equals a vector of values if the link is known to be up; each cost value estimates how expensive it 
is to cross the link according to some QoS criteria such as delay, throughput, loss rate, etc. The 
cost equals oo if the link is known to be down. Cost of a link changes with time (see Section 4). 
The view also includes timestamp and expirytime fields which are described in Section 4. 

Viewserver Hierarchy 

For scaling reasons, we cannot have one large view. Thus, obtaining a source route between 2 source 
and a destination which are far away, involves accumulating view-s of a sequence of viewservers. To 
keep this process efficient, we organize viewservers hierarchically. More precisely, each viewserver is 
assigned a hierarchy level from 0,1,..., with 0 being the top level in the hierarchy. A parent-child 
relationship between viewservers is defined as follows: 

1. Every level i viewserver, i > 0, has a parent viewserver whose level is less than i. 

2. If view'server x is a parent of viewserver y then x's precinct contains y and y's precinct 
contains x. 

3. The precinct of a top level viewserver contains all other top level viewservers. 

In the hierarchy, a parent can have many children and a child can have many parents. We extend 
the range of the parent-child relationship to ordinary nodes; that is, if Precinct * contains the node 
u, we say that u is a child of x, and x is a parent of u. We assume that there is at least one parent 
viewserver for each node. 

For a node u. an address is defined to be a sequence (zo,Xi, . . .,St) such that s,- for i < t is 
a view'server-id, xq is a top level view'server-id, x t is the id of u, and x,- is a parent of z,+i. A 
node may have many addresses since the parent-child relationship is many-to-many. If a source 
node wants to establish a VC to a destination node, it first queries the name servers to obtain a 
set of addresses for the destination 5 . Second, it queries viewservers to obtain an accumulated view- 
containing both itself and the destination node (it can reach its parent viewservers by using fixed 
source routes to them). Then, it chooses a feasible source route from this accumulated view and 
initiates the VC setup protocol on this path. 

View-Query Protocol: Obtaining Source Routes 

We now describe how a source route is obtained. 

i Querying the name servers can be done in the same way as is done currently in the Internet. 


159 





We want a sequence of viewservers whose merged views contains both the source and the 
destination nodes. Addresses provide a way to obtain such a sequence, by first going up in the 
view-server hierarchy starting from the source node and then going down in the viewserver hierarchy 
towards the destination node. More precisely, let (so,..-,$t) be an address of the source, and 
(do,...,di) be an address of the destination. Then, the sequence {s t -y, ..so, do ,..., d;_i) meets 
our requirements. In fact, going up all the way in the hierarchy to top level viewservers may not 
be necessary. We can stop going up at a viewserver s if there is a viewserver dj,j < /, in the view 
of s, (one special case is where s,- = dj). 

The view-query protocol uses two message types: 

• (RequestViev, s^address, d.address ) 

where s.address and djiddress are the addresses for the source and the destination respec¬ 
tively. A RequestViev message is sent by a source node to obtain an accumulated view con¬ 
taining both the source and the destination nodes. When a viewserver receives a RequestViev 
message, it either sends back its view or forwards this request to another viewserver. 

• (EeplyViev, s.adaress, d.address, accumview) 

where s.address and djiddress are as above and accumview is the accumulated view. A 
ReplyVieu message is sent by a view-server to the source or to another viewserver closer to 
the source. The accumview field in a ReplyVieu message equals the union of the view-s of 
the viewservers the message has visited. 

We now describe the view-query protocol in more detail (please refer to Figures 1 and 2). To 
establish a VC to a destination node, the source node sends a RequestViev packet containing the 
source and the destination addresses to its parent in the source address. 

Upon receiving a RequestViev packet, a view-server x checks if the destination node is in its 
precinct 6 . If it is, x sends back its view in a ReplyVieu packet. If it is not, x forwards the request 
packet to another viewserver as follow-s (details in Figure 2): x checks whether any viewserver in 
the destination address is in its view-. If there is such a viewserver, x sends the RequestViev packet 
to the last such one in the destination address. Otherwise a is a viewserver in the source address, 
and it sends the packet to its parent in the source address. 

V'.Ten a viewserver z receives a ReplyVieu packet, it merges its view to the accumulated view- 
in the packet. Then it sends the ReplyVieu packet towards the source node in the same way it 
would send a RequestViev packet tow-ards the destination node (i.e. the roles of the source address 

£ Even though the destination can be in the view of *, its QoS characteristics is not in the view if it is not in the 
precinct of z. 


160 




Constants 

FizedRoutes v (x), for every viewserver-id x such that x is a parent of u, 

= {(yi> • • • > Vn) '■]/>£ Nodelds}. Set of routes to i 

Events 

RequesiView u (s.address, djiddress ) {Executed when u wants a source route} 

Let s.address be {s 0 ,...,s t _ 1> i t ) ) and sr £ FixedRovtes u (s,- 1 ); 

Send(RequestViev, sjiddress, djiddress) to s ,_ 3 using Sr 

Rtceivt u (ReplyVies, sjaddress, djiddress, accumview) 

Choose a feasible source route using accumview, 

If a feasible route is not found 

Execute RequestView u again with another source address and/or destination address 


Figure 1: View-query protocol: Events and state of a source node u. 


Constants 

Precinct x . Precinct of x. 

Variables 

View x . View of x. 

Events 

Receive x ( RequestVies, s-address, d.address ) 

Let d.address be (d 0 ,..., d,); 
if d, £ Precinct x then 

forward x ( RequestVieu, sjiddress, d.address, {}); 

else / orward x (ReplyViec, djaddress , s.address, V iew x )\ {addresses are switched} 

endif 

Receive x ( ReplyViev, sjiddress, djaddress, view) 

jorward x (ReplyVieu, s.address, d.address, view U View x ) 

where procedure forward x (type, s.address, djiddress, view ) 

Let s.address be (sq, . . ,,s t ), d.address be {do, ....dj); 

if 3: : d, in View x then 

Let s' = max{j : d 3 in View x )\ 

target := d,-; 

else target := s; such that s, + i = nodeid(x)\ 
endif; 

sr := choose a route to target from nodeid(x) using View x ; 

• if type = ReauestViev theD 

Send(RequestViev, sjiddress, djiddress) to target using sr; 

else Send(ReplyVies, sjaddress, djiddress, view) to target using sr; 

endif 


Figure 2: View-query protocol: Events and state of a viewserver x. 
and the destination address are interchanged). 


161 










When the source receives a Reply View packet, it chooses a feasible path using the accumvie w 
in the packet. If it does not find a feasible path, it can try again using a different source and/or 
destination addresses. Note that the source does not have to throw away the previous accumulated 
views: it can merge them all into a richer accumulated view. In fact, it is easy to change the protocol 
so that the source can also obtain views of individual viewservers to make the accumulated view 
even richer. Once a feasible source route is found, the source node initiates the VC setup protocol. 

Above we have described one possible way of obtaining the accumulated views. There are 
various other possibilities, for example: (1) restricting the ReplyView packet to take the reverse 
of the path that the RequestViev packet took; (2) having ReplyView packets go all the way 
up in the viewserver-hierarchy for a richer accumulated view; (3) having the source poll the 
viewservers directly instead of the viewservers forwarding request/reply messages to each other; 
(4) not including non-transit nodes (e.g. end-systems) other than the source and the destination 
nodes in the accumview : (5) including some QoS requirements in the RequestView packet, and 
having the viewservers filter out some nodes and links. 

4 Update Protocol for Dynamic Network Conditions 

In this section, we first describe how topology changes such as link/node failures, repairs and cost 
changes, are detected and communicated to viewservers, i.e. the view-update protocol. Then, we 
modify the view-query protocol appropriately. 

View-Update Protocol: Updating Views 

Viewservers do not communicate with each other to maintain their views. Nodes detect and 
communicate topology' changes to viewservers. Updates are done periodically and also optionally 
after a change in the outgoing link costs. 

The communication between a Dode and viewservers is done by flooding over a set of nodes. 
This set is referred to as the flood area. The topology of a food area must be a connected graph. 
For efficiency, the flood area cam be implemented by a hop-count. 

Due to the nature of flooding, a viewserver can receive information out of order from a node. In 
order to avoid old information replacing new information, each node includes successively increasing 
time stamps in the messages it sends. The timestamp field in the view of a viewserver equals the 
largest timestamp received from each node. 


162 




Due to node and link failures, communication between a node and a viewserver can fail, resulting 
in the viewserver having out-of-date information. To eliminate such information, a viewserver 
deletes any information about a node if it is older than a time-to-die period. The expirytime field 
in the view of a viewserver equals the end of the time-to-die period for a node. We assume that 
nodes send messages more often than the time-bo-ciie veiue (to avoid false removal). 

The view-update protocol uses one type dt message a& follows: 

• (Update, nid, timestamp , floodarea, ncostset ) 
is sent by the node to inform the viewservers about current costs of its outgoing links. Here, 
nid and timestamp indicate the id and the time stamp of the node, ncostset contains a cost 
for each outgoing link of the node, and floodarea is the set of nodes that this message is to 
be sent over. 

Constants: 

FloodArea s . (C Nodelds). The hood area of the node. 

Variables: 

Clock s : Integer. Clock of g. 

Figure 3: State of a node g. 

The state maintained by a node g is listed in Figure 3. We assume that consecutive reads of 
Clock s returns increasing values. 

Constants: 

Precinct,. Precinct of i. 

TimtToDic, : Integer. Time-to-die value. 

Variables: 

View,. View of r. 

Clock,. : Integer. Clock of z. 

Figure 4: State of a viewserver x. 

The state maintained by a viewserver x is listed in Figure 4. 

The events of node g are specified in Figure 5. The events of a viewserver x are specified in 
Figure 6. When a viewserver x recovers, Vievi- is set to {). Its view becomes up-to-date as it 
receives new information from nodes (and remove false information with the time-to-die period). 


163 











Update s {Executed periodically and also optionally upon a change in outgoing link costs) 

ncosisei := compute costs for each outgoing link; 
flood s ((Update, nodeid(g), Clock s , Flood Area 9 , ncosisei))-, 

Receive s {packet) {an Update packet) 

floods [packet] 

where procedure flood s [packet] 

if nodeid{g ) € packet.floodarea then 

{remove g from the flood area to avoid infinite exchange of the same message.) 

packet.floodarea := packet.floodarea — {nodeid{g))\ 

for all h € NodcNcighbors(g) A h £ packet.floodarea do 

Send(pad:et) to h\ 

endif 

Node Failure Model: A node can undergo failures and recoveries at anytime. We assume failures are 
fail-stop (i.e. a failed node does not send erroneous messages). 


Figure 5: View-update protocol: Events of a node g. 


Receive z (Update, nid, is, FloodArea, ncset ) 
if nid £ Precinct, then 

if 3 {nid, timestamp, expirytime, ncostset) £ View. A Is > timestamp then 

{received is more recent; delete the old one) 

delete {nid, timestamp, expirytime, ncosisei) from View : ; 

endif 

if —3(nid, timestamp, expirytime, ncostset) £ Vieu^ then 
ncosisei subset of edge-cost pairs in ncset that are in View .; 
insert {nid, ts, Clock z + TimeToDie z , ncostset) to View.] 
endif 
endif 

Delete z {Executed periodically to delete entries older than the time-to-die period) 

for all {nid, istamp, expirytime, ncset) £ V'ieu; r A expirytime < Clock, do 
delete {nid, istamp, expirytime, ncset) from View z : 

Viewserver Failure Model: A viewserver can undergo failures and recoveries at anytime. We ass um e 
failures are fail-stop. When a viewserver x recovers, View z is set to {). 


Figure 6: View update events of a viewserver x. 


Changes to View-Query Protocol 

We now enumerate the changes needed to adapt the view-query protocol to the dy nami c case (the 
formal specification is omitted for space reasons). 

Due to link and node failures, RequestViev and ReplyViev packets can get lost. Hence, the 


164 





source may never receive a ReplyViev packet after it initiates a request. Thus, the source should 
try again after a time-out period. 

When a vjewserver receives a RequestView message, it should reply with its views only if the 
destination node is in its precinct and its view contains a path to the destination. Similarly during 
forwarding of RequestView and ReplyViev packets, a viewserver, when checking whether a node 
is in its view, should also check if its view contains a path to it. 

5 Evaluation 

In this section, we present the parameters of our simulation model. We use this model to com¬ 
pare our viewserver-based VC routing protocols to the simple approach. The results obtained are 
presented in Section 6. 

Network Parameters 

W 7 e model a campus network which consists of a campus backbone subnetwork and several depart¬ 
ment subnetworks. The backbone network consists of backbone switches and backbone links. 

Each department netw-ork consists of a hub switch and several non-hub switches. Each non-hub 
switch has a link to the department’s hub switch. And the department’s hub switch has a link to 
one of the backbone switches. A non-hub switch can have links to other non-hub switches in the 
same department, to non-hub switches in other departments, or to backbone switches. 

End-systems are connected to non-hub switches. An example network topology is shown in 
Figure 7. 

In our topology, there are 8 backbone switches and 32 backbone links. There are 16 departments. 
There is one hub-switch in each department. There is a total of 240 non-hub switches randomly 
assigned to different departments. There are 2500 end-systems which are randomly connected to 
non-hub switches. Thus, we have a total of 2764 nodes. 

In addition to the links connecting non-hub switches to the hub switches and hub switches to 
the backbone switches, there are 720 links from non-hub switches to non-hub switches in the same 
department, there are 128 links from non-hub switches to non-hub switches in different departments, 
and there are 64 links from non-hub switches to backbone switches. 

The end-points of each link are chosen randomly. However, we make sure that the backbone 
network is connected; and there is a link from node v to node v iff there is a link from node v to 


165 






0 Backbone switches 
^ Hub switches 
Q Non-hub switches 
|_| End-systems 


Figure 7: Ad example network topology. 


node u. 

Each link has a total of C units of bandwidth. 

QoS and Workload Parameters 

In our evaluation model, we assume that a VC requires the reservation of a certain amount of 
bandwidth that is enough to ensure an acceptable QoS for the application. This reservation amount 
can be thought of either as the peak transmission rate of the VC or its ‘'effective bandwidth” [12] 
varying between the peak and average transmission rate. 

VC setup requests arrive to the network according to a Poisson process of rate A, each requiring 
one unit of bandwidth. Each VC, once it is successfully setup, has a lifetime of exponential duration 
with mean 1 /fi. The source and the destination end-systems of a VC are chosen randomly. 

An arriving VC is admitted to the network if at least one feasible path between its source and 
destination end-systems is found by the routing protocol, where a feasible path is one that has links 
with non-zero available capacity. From the set of feasible paths, a minimum hop path is used to 
establish the VC; one unit of bandwidth is allocated on each of its links for the lifetime of the VC. 
On the other hand, if a feasible path is not found, then the arriving VC is blocked and lost. 

We assume that the available link capacities in the views of the viewservers are updated instan- 


166 








taneously whenever a VC is admitted to the network or terminates. 


Viewserver Hierarchy Schemes 

We have evaluated our viewserver protocol for several different viewserver hierarchies and query 
methods. We next describe the different viewserver schemes evaluated. Please refer to Figure 7 in 
the following discussion. 

The first viewserver scheme is referred to as base. Each switch is a viewserver. A viewserver’s 
precinct consist of itself and the neighboring nodes. The links in the viewserver’s view consist of 
the links between the nodes in the precinct, and links outgoing from nodes in the precinct to nodes 
not in the precinct. For example, the precinct of viewserver u-consists of nodes u,v, ur,s- 

As for the viewserver hierarchy, a backbone switch is a level 0 viewserver, a hub switch is a 
level 1 viewserver and a non-hub switch is a level 2 viewserver. Parent of a hub switch viewserver 
is the backbone switch viewserver it is connected to. Parent of a non-hub switch viewserver is the 
hub switch viewserver in its department. Parent of an end-system is the non-hub switch viewserver 
it is connected to. 

We use only one address for each end-system. The viewserver-address of an end-system is the 
concatenation of four ids. Thus, the address of s is z.v.u.s. Similarly, the address of d is z.v.x.d. 
To obtain a route between s and d, it suffices to obtain view-s of viewservers u,v,x. 

The second viewserver scheme is referred to as base-QT (w-here the QT stands for U query up 
to top"). It is identical to base except that during the query protocol all the viewservers in the 
source and the destination addresses are queried. That is, to obtain a route between s and d. the 
views of u.v.z.z are obtained. 

The third view’server scheme is referred to as vertex-extension. It is identical to base except 
that viewserver precincts are extended as follows: Let ? denote the precinct of a viewserver in the 
base scheme. For each node u in P, if there is a link from node u to node v and v is not in P, node 
v is added to the precinct; among v's links, only the ones to nodes in P are added to the view. In 
the example, nodes z,y,x,q are added to the precinct of u, but outgoing links of these nodes to 
other nodes are not included (e.g. (i,p) and ( z.q ) are not included). The advantage of this scheme 
is that even though it increases the precinct size by a factor of d (where d is iV>e average number of 
neighbors to a node), it increases the number of links stored in the view by a factor less than 2. 

The fourth viewserver scheme is referred to as veriex-extension-QT. It is identical to vertex- 
extension except that during the query protocol all the viewservers in the source and the destination 


167 






addresses are queried. 


6 Numerical Results 

6.1 Results for Network 1 

The parameters of the first network topology, referred to as Network 1, are given in Section 5. The 
link capacity C is taken to be 20 [6], i.e. a link is capable of carrying 20 VCs simultaneously. 

Our evaluation measures were computed for a (randomly chosen but fixed) set of 100,000 VC 
setup requests. Table 1 lists for each viewserver scheme (1) the minimum, average and maximum 
of the precinct sizes (in number of nodes), (2) the mini mum, average and maximum of the merged 
view sizes (in number of nodes), and (3) the minimum, average and maximum of the number of 
viewservers queried. 


Scheme 

Precinct Size 

Merged View Size 

No. of Viewservers Queried 

base 

5 / 16.32 / 28 

4 / 56.46 / 81 

1 / 5.49 / 6 

base-QT 

5 / 16.32 / 28 

27 / 59.96 / 81 

6 / 6.00 / 6 

vertex-extension 

22 / 88.11 / 288 

14 / 155.86 / 199 

1 / 5.49 / 6 

vertex-extension-QT 

22 / 88.11 / 288 

113 / 163.28 / 199 

6 / 6.00 / 6 


Table 1: Precinct sizes, merged view sizes, and number of viewservers queried for Network 1. 


The precinct size indicates the memory requirement at a view»server. More precisely, the memory 
requirement at a viewserver is 0 (precinct size x d). except for the vertex-extension and vertex- 
extension-QT schemes. In these schemes, the memory requirement is increased by a factor less 
than two. Hence these schemes have the same order of viewserver memory requirement as the base 
and base-QT schemes. 

The merged view size indicates the memory requirement at a source end-system during the 
query protocol; i.e. the memory requirement at a source end-system is 0(merged view size x d ) 
except for the vertex-extension and vertex-extension-QT schemes. Note that the source end-system 
does not need to store information about end-systems other than itself and the destination. The 
numbers in Table 1 take advantage of this. 

The number of viewservers queried indicates the communication time required to obtain the 
merged view at the source end-system. Hence, the “real-time” communication time required to 
obtain the merged view at a source is slightly more than one round-trip time between the source 


168 























and the destination. 

As is apparent from Table 1, using a QT scheme increases the merged view size by about 6%, 
and the number of viewservers queried by about 9%. Using the vertex-extension scheme increases 
the merged view size by about 3 times (note that the amount of actual memory needed increases 
only by a factor less than 2). 

The above measures show the memory and time requirements of our protocols. They clearly 
indicate the savings in storage over the simple approach as manifested by the smaller view sizes. To 
answer whether the viewserver hierarchy finds many feasible paths, other evaluation measures such 
as the carried VC load and the percent VC blocking are of interest. They are defined as follows: 

• Carried VC load is the average number of VCs carried by the network. 

• Percent VC blocking is the percentage of VC setup requests that are blocked due to the fact 
that a feasible path is not found. 7 

. In our experiments, we keep the average VC lifetime (l//r) fixed at 15000 and vary the arrival 
rate of VC setup requests (A). Figure 8 shows the carried VC load versus A for the simple approach 
and the viewserver schemes. Figure 9 shows the percent VC blocking versus A. At low values of A, 
all the viewserver schemes are very close to the simple approach. At moderate values of A. the base 
and base-QT schemes perform badly. The vertex-extension and vertex-extension-QT schemes are 
still very close to the simple approach (only 3.4% less carried VC load). Note that the performance 
of the viewserver schemes can be further improved by trying more viewserver addresses. 

Surprisingly, at high values of A, all the viewserver schemes perform better than the simple 
approach. At A = 0.5, the network with the base scheme carries about 30% higher load than the 
simple approach. This is an interesting result. Our explanation is as follows. Elsewhere [2], we 
have found that when the viewserver schemes can not find an existing feasible path, this path is 
usually very long (more than 11 hops). This causes our viewserver nierarchy protocols to reject 
VCs that are admitted by the simple approach over long paths. The use of long paths for VCs is 
undesirable since it ties up resources at more intermediate nodes, which can be used to a dmi t many 
shorter length VCs. 

In conclusion, we recommend the vertex-extension scheme as it performs close to or better 
than all other schemes in terms of VC carried load and blocking probability over a wide range of 
workload. Note that for all viewserver schemes, adding QT yields slightly further improvement. 

' Recall that we assume a blocked VC setup request is cleared (i.e. lost). 


169 





CARRIED VC LOAD vs Arrival rate 



Figure 8: Carried VC load versus arrival rate for Network 1. 


PERCENT VC BLOCKING vs Arrival rale 



Figure 9: Percent VC blocking versus arrival rate for Network 1. 


6.2 Results for Network 2 

The parameters of the second network, referred to as Network 2, are the same as the parameters 
of Network 1. However, a different seed is used for the random number generation, resulting in a 
different topology and distribution of source-destination end-system pairs for the VCs. 

We again take C = 20, and we fix 1 //i at 15000. Our evaluation measures were computed for 


170 







I 


a set of 100,000 VC setup requests. Table 2, and Figures 10 and 11 show the results. Similar 
conclusions to Network 1 hold for Network 2. An interesting exception is that at high values of A, 
we observe that the vertex-extension scheme performs slightly better than the vertex-extension-QT 
scheme (about 4.2% higher carried VC load). The reason is the following: Adding QT gives richer 
merged views, and hence increases the chance of finding a feasible path that is possibly long. As 
explained in Section 6.1, this results in performance degradation. 


Scheme 

Precinct Size 

Merged View Size 

No. of Viewservers Queried 

base 

4 / 16.32 / 33 

4 / 57.61 / 80 

1 / 5.52 / 6 

base-QT 

4 / 16.32 / 33 

30 / 60.64 / 80 

6 / 6.00 / 6 

vertex-extension 

17/ 90.36 / 282 

16 / 159.70 / 214 

1 / 5.52 / 6 

vertex-extension-QT 

17 /90.36 / 282 

113 / 166.97 / 214 

6 / 6.00 / 6 


Table 2: Precinct sizes, merged view sizes, and number of viewservers queried for Network 2. 


We have repeated the above evaluations for other networks and obtained similar conclusions. 

7 Conclusions 

We presented a hierarchical VC routing protocol for ATM-like networks. Our protocol satisfies QoS 
constraints, adapts to dynamic topology changes, and scales well to large number of nodes. 

Our protocol uses partial views maintained by viewservers. The viewservers are organized 
hierarchically. To setup a VC, the source end-system queries viewservers to obtain a merged view 
that contains itself and the destination end-system. This merged view is then used to compute a 
source route for the VC. 

We evaluated several viewserver hierarchy schemes and compared them to the simple approach. 
Our results on 2764-node networks indicate that the vertex-extension scheme performs close to or 
better than the simple approach in terms of VC carried load and blocking probability over a wide 
range of real-time workload. It also reduces the amount of memory requirement by up to two order 
of magnitude. We note that our protocol scales even better on larger size networks.[3]. 

In all the viewserver schemes we studied, each switch is a viewserver. In practice, not all 
switches need to be viewservers. We may associate one viewserver wdth a group of switches. This is 
particularly attractive in ATM networks where each signaling entity is responsible for establishing 
VCs across a group of nodes. In such an environment, viewservers and signaling entities can be 


171 



























CARRIED VC LOAD vs Arrival rate 



Figure 10: Carried VC load versus arrival rate for Network 2. 


PERCENT VC BLOCKING vs Arrival me 



combined. 

However, there is an advantage of each switch being a viewserver; that is, source nodes do not 
require fixed source routes to their parent viewservers (in the view-query protocol). This reduces 
the amount of hand configuration required. In fact, the base and base-QT viewserver schemes do 
not require any hand configuration. 

Our evaluation model assumed that views are instantaneously updated, i.e. no delayed feedback 


172 









between link cost changes and view/route changes. We plan to investigate the effect of delayed feed¬ 
back on the performance of the different schemes. We expect our viewserver schemes to outperform 
the simple approach in this realistic setting as the update of views of the vjewservers requires less 
time and communication overhead. Thus, views in our viewserver schemes will be more up-to-date. 

As we pointed out in [3], the only drawback of our protocol is that to obtain a source route 
for a VC, views are merged at (or prior to) the VC setup, thereby increasing the setup time. This 
drawback is not unique to our scheme [8, 16, 7, 11). Reference [3] describes several ways, including 
cacheing and replication, to reduce the setup overhead and improve performance. 


References 

[1] E. Ahmadi, J. Chen, and R. Guerin. Dynamic Routing and Call Control in High-Speed Integrated 
Networks. In Proc. Workshop on Systems Engineering and Traffic Engineering, ITC'JS, pages 19—26, 
Copenhagen, Denmark, June 1991. 

[2] C. Alaettinoglu and A. U. Shankar. Viewserver Hierarchy: A New Inter-Domain Routing Protocol and 
its Evaluation. Technical Report UMIACS-TR-93-98, CS-TR-3151, Department of Computer Science, 
University of Maryland, College Park, October 1993. Earlier version CS-TR-3033, February 1993. 

[3] C. Alaettinoglu and A. U. Shankar. Viewserver Hierarchy: A New Inter-Domain Routing Protocol. In 
Proc. IEEE INFOCOM ’94, Toronto, Canada, June 1994. 

[4] A. Alles. ATM in Private Networking: A Tutorial. Hughes LAN Systems, 1993. 

[5] P. Almouist. Type of Service in the Internet Protocol Suite. Technical Report RFC-1349, Network 
Working Group, July 1992. 

[6] L. Breslau, D. Estrin, and L. Zhang. A Simulation Study of Adaptive Source Routing in Integrated 
Services Networks. Available by anonymous ftp at catarina.usc.edurpub/breslau, September 1993. 

[7] J. N. Chiappa. A New IP Routing and Addressing Architecture. Big-Internet mailing list., 1992. 
Available by anonymous ftp from munnari.oz.au:big-internet/list-axchive. 

[8] D.D. Clark. Policy routing in Internet protocols. Request for Comment RFC-1102, Network Information 
Center. May 1989. 

[9] R. Coltun and M. Sosa. VC Routing Criteria. Internet Draft, March 1993- 

[10] D. Comer and R. Yavatkar. FLOWS: Performance Guarantees in Best Effort Delivery Systems. In Proc. 
IEEE INFOCOM, Ottawa, Canada, pages 100-109, April 1989. 

[11] D. Estrin. Y. Rekhter, and S. Hotz. Scalable Inter-Domain Routing Architecture. In Proc. A CM 
SIGCOMM ’92, pages 40-52, Baltimore, Maryland, August 1992. 

[12] R. Guerin, H. Ahmadi, and M. Naghshineh. Equivalent Capacity and its Application to Bandwidth 
Allocation in High-Speed Networks. IEEE J. Select. Areas Commvn., SAC-9(7):968-981, September 
1991. 

[13] A. Guillen, R. Kia, and B. Sales. An Architecture for Virtual Circuit/QoS Routing. In Proc. IEEE 
International Conference on Network Protocols ’9S, pages 80-87, San Francisco, California, October 
1993. 

[14] S. Gupta, K. Ross, and M. ElZarki. Routing in Virtual Path Based ATM Networks. In Proc. GLOBE- 
COM ’92, pages 571-575, 1992. 

[15] R-E. Hwang, J. Kurose, and D. Towsley. MDP Routing in ATM Networks Using Virtual Path Concept. 
In Proc. IEEE INFOCOM, pages 1509-1517, Toronto, Ontario, Canada, June 1994. 

[16] M. Lepp and M. Steenstrup. An Architecture for Inter-Domain Policy Routing. Internet Draft. Available 
from the authors., June 1992. 

[17] I. Matta and A.U. Shankar. An Iterative Approach to Comprehensive Performance Evaluation of Inte¬ 
grated Services Networks. In Proc. IEEE International Conference on Network Protocols ‘94, Boston, 
Massachusetts, October 1994. To appear. 

[18] J. Mov. OSPF Version 2. RFC 1247, Network Information Center, SRI International, July 1991. 


173 



[19] C. Parris and D. Ferrari. A Dynamic Connection Management Scheme for Guaranteed Performance 
Services in Packet-Switching Integrated Services Networks. Technical Report TR-93-005, International 
Computer Science Institute, Berkeley, California, January 1993. 

[20] J. Postel. TVansmission Control Protocol: DARPA Internet Program Protocol Specification. Request 
for Comment RFC-793, Network Information Center, SRI International, 1981. 

[21] M. Prycker. Asynchronous Transfer Mode - Solution for Broadband ISDN. Ellis Horwood, 1991. 

[22] S. Ram pal, D. Reeves, and D. Agrawal. An Evaluation of Routing and Admission Control Algorithms 
for Multimedia Traffic in Packet-Switched Networks. Available from the authors, 1994. 

[23] H. Suzuki andF. Tobagi. Fast Bandwidth Reservation Scheme with Multi-Link and Multi-Path Routing 
in ATM Networks. In Proc. IEEE INFOCOM ’9£, pages 2233-2240, Florence, Italy, May 1992. 

[24] E. Sykas, K. Vlakos, I. Venieris, and E. Protonotarios. Simulative Analysis of Optimal Resource Allo¬ 
cation and Routing in IBCN’s. IEEE J. Select. Areas Commun., 9(3):486—492, April 1991. 

[25] P. F. Tsuchiya. The Landmark Hierarchy: Description and Analysis, The Landmark Routing: Ar¬ 
chitecture Algorithms and Issues. Technical Report MTR-87W00152, MTR-87W00174, The MITRE 
Corporation, McLean, Virginia, 1987. 

[26] P. F. Tsuchiva. The Landmark Hierarchv:A New Hierarchy For Routing In Very Large Networks. In 
Proc. ACM SIGCOMM ’ 88 , August 1988*. 



REPORT DOCUMENTATION PAGE 


QMS No C7&C-018S 


•wdw •eoo'v-t Os.'Sr*' »o» t*».* £*•*<!»©* :* t or* et.*!**^ o«i« uH/'trv 

3*" '■"'“O ***C - 4,4 **C '* “?*f*'*: ’*»•**•■ •** ■'WfniO 4 '** t*».\ pgrefn O* OtKff O’ IMj 

•>•*•» •••?"■-»** **’K< •".i «••!' fcfOwn'P'' **ro*rn (C?C<-D ift8) DC JCSQ3 

1. AGENCY USE Only (Ltavt bianx', 2. REPORT DATE 3. REPORT TYPE AND DATES COVERED 

October 1994 Technical 

4. TITLE AND SUBTITLE 

A Scalable Virtual Circuit Routing Scheme for ATM Networks 

S. FUNDING NUMBERS 

C DASG60-92-0055 

G NCR 89-04590 

G NCR 93-21043 

6. AUTHOR(S) 

Cengis Alaettinoglu. Ibrahim Matta and A. Udaya Shankar 

7. PERFORMING ORGANIZATION NAM£(S) AND ADDRESSES! 

Department of Computer Science 

A. V. Willliams Building 

University of Maryland 

College Park, MD 20742 

E. PERFORMING ORGANIZATION 

REPORT NUMBER 

CSTR-3360 

UMIACS-TR 94-115 

9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESSEES) 

Phillips Laboratory- 
Directorate of Contracting 

3651 Lowry Avenue SE 

Kirtland AFB NM 87117-5777 

10. SPONSORING /MONITORING 

AGENCY REPORT NUMBER 

11. SUPPLEMENTARY NOTES 

12a. DISTRIBUTION/AVAILABILITY STATEMENT 

12b. DISTRIBUTION CODE 


13. ABSTRACT (Maximum 200 */crci) 


High-speed networks, such as ATM networks, are expected to support diverse 
ouality-of-service (QoS) requirements, including real-time QoS. Real-time QoS is 
required by many applications such as voice and video. To support such service, 
routing protocols based on the Virtual Circuit (VC) model have been proposed. However 
these protocols do not scale well to large networks in terms of storage and 
communication overhead. 

In this paper, we present a scalable VC routing protocol. It is based on the 
recently proposed viewserver hierarchy, where each viewserver maintains a partial 
view of the network. By querying these viewservers, a source can obtain a merged vie*’ 
that contains a path to the destination. The source then sends a request packet over 
this path to setup a real-time VC through resource reservations. The request is 
blocked if the setup fails. We compare our protocol to a simple approach using 
simulation. Under this simple approach , a source maintains a full view of the 
network. In addition to the savings in storage, our results indicate that our 


• protocol performs close or better than the simple approach in terms of VC carried 
i load and Slocking probability over a wide range of real-time workload._ 


14. SUBJECT TERMS 

Computer-Communication Networks: Network Architecture and 
Design, Network Protocols;Routing Protocols: Computer Network 
Routine Protocols 

15. NUMBER OF PAGES 

22 pages 

16. PRICE CODE 

17. SECURITY CLASSIFICATION 

18 SECURITY CLASSIFICATION 

15. SECURITY CLASSIFICATION 

20. LIMITATION OF ABSTRACT 

OF REPORT 

OF THIS PAGE 

OF ABSTRACT 


i unclassified 

unclassified 

Unclassified 

Unlimited 

- — -- 


S*.2**oi r c 29S 2-89) 


*$N -2SO-5SOO 


175 






















1 


I 


176 


I 



Hierarchical Inter-Domain Routing Protocol 
with On-Demand ToS and Policy Resolution* 

Cengiz Alaettinoglu. A. Udaya Sbankar 


Institute for Advanced Computer Studies 
Department of Computer Science 
University of Maryland 
College Park, Maryland 20742 


June 20, 1994 


Abstract 

Traditional inter-domain routing protocols based on superdomains maintain either “strong” 
or “weak” ToS and policy constraints for each visible superdomain. With strong constraints, 
a valid path may not be found even though one exists. With weak constraints, an invalid 
domain-level path may be treated as a valid path. 

We present an inter-domain routing protocol based on superdomains, which always finds 
a valid path if one exists. Both strong and weak constraints are maintained for each visible 
superdomain. If the strong constraints of the superdomains on a path are satisfied, then the 
path is valid. If only the weak constraints are satisfied for some superdomains on the path, the 
source uses a query protocol to obtain a more detailed ‘‘'internal” view of these superdomains, 
and searches again for a valid path. Our protocol handles topology changes, including node/link 
failures that partition superdomains. Evaluation results indicate our protocol scales well to large 
internetworks. 


Categories and Subject Descriptors: C.2.1 [Computer-Communication Networks]: Network Archi¬ 
tecture and Design —packet networks; store and forward networks: C.2.2 [Computer-Communication Net¬ 
works]: Network Protocols —protocol architecture: C.2.m [Routing Protocols]; F.2.m [Computer Network 
Routing Protocols]. 


" This work is supported in part by AP.PA and Philips Labs under contract DASG50-S2-0055 to Department 
of Computer Science, University of Maryland, and by National Science Foundation Grant No. NCP.. 89-04590. The 
views, opinions, and/or findings contained in this report are those of the author(s) and should not be interpreted as 
representing the cmdai poliaes, either expressed o: implied, of the Advanced pLesearch Projects Agency, PL, NSF, 
or the U.S. Government. Computer facilities were provided iu part by NSF grant CCPl-8512954. 








1 Introduction 


A computer internetwork, such as the Internet, is an interconnection of backbone networks, regional 
networks, metropolitan area networks, and stub networks (campus networks, office networks and 
other small networks) 5 . Stub networks are the producers and consumers of the internetwork traffic, 
while backbones, regionals and MANs are transit networks. Most of the networks in an internetwork 
are stub networks. Each network consists of nodes (hosts, routers) and links. A node that has a 
link to a node in another network is called a gateway. Two networks are neighbors when there is 
one or more links between gateways in the two networks (see Figure 1). 



Figure 1: A portion of an internetwork. (Circles represent stub networks.) 

An internetwork is organized into domains 2 . A domain is a set of networks (possibly consisting 
of oniy one network) administered by the same agency. Domains are typically subject to policy 
constraints, which are administrative restrictions on inter-domain traffic {7, 11, 8, 5j. The policy 
constraints c:’ a domain U are of two types: transit policies , w’hich specify how other domains 
can use the resources of U (e.g. SO.01 per packet, no traffic from domain V); and source policies. 
which specify constraints on traffic originating from U (e.g. domains to avoid/prefer, acceptable 
connection cost). Transit policies of a domain are public (i.e. available to other domains), whereas 
source policies are usually private. 

Within each domain, an intra-domain routing protocol is executed that provides routes between 
source and destination nodes in the domain. This protocol can be any of the typical ones, i.e., 
next-hop or source routes computed using distance-vector or link-state algorithms. To satisfy 

1 For exa^cpie. ESFNET, MILNET are backbones, and Suranet, CeruNel axe regionals. 

: Also referred to as routing domcms or administrative damans. 


178 





type-of-service (ToS) constraints of applications (e.g. low delay, high throughput, high reliability, 
minimum monetary cost), each node maintains a cost for each outgoing link and ToS. The intra- 
domain routing protocol should choose optimal paths based on these costs. 

Across all domains, an inter-domain routing protocol is executed that provides routes between 
source and destination nodes in different domains, using the.services of the intra-domain routing 
protocols within domains. This protocol should have the following properties: 

(1) It should satisfy the policy constraints of domains. To do this, it must keep trad: of the 
policy constraints of domains [5j. 

(2) An inter-domain routing protocol should also satisfy ToS constraints of applications. To do 
this, it must keep track of the ToS services offered by domains [5]. 

(3) An inter-domain routing protocol should scale up to very large internetworks, i.e. with a very 
large number of domains. Practically this means that processing, memory and communication 
requirements should be much less than linear in the number of domains. It should also 
handle non-hierarchical domain interconnections at any level [8] (e.g. we do not want to 
hand-configure special routes as ‘‘'back-doors”). 

(4) An inter-domain routing protocol should automatically adapt to link cost changes and node/iink 
failures and repairs, including failures that partition domains [13]. 

A Straight-Forward Approach 

A straight-forward approach to inter-domain routing is domain-level source routing with link-state 
approach [7, 5l. in this approach, each router 0 maintains a domain-level view of the internetwork, 
i.e., a graph with a vertex for every domain and an edge between every two neighbor domains. 
Policy and ToS information is attached to the vertices and the edges of the view. 

When a source node needs to reach a destination node, it (or a router* in the source's domain) 
first examines this view and determines a domain-level source route satisfying ToS and policy 
constraints, i.e., a sequence of domain ids starting from the source’s domain and ending with the 
destination’s domain. Then packets are routed to the destination using this domain-level source 
route and the intra-domain routing protocols of the domains crossed. 

For example, consider the internetwork of Figure 2 (each circle is a domain, and each thin line 

No; aU nodes maintain routing tables. A router is a. node that maintains a. routing table, 
referred to as the policy server ir. [T] 


i 








is a domain-level interconnection). Suppose a node in dl desires a connection to a node in dl. 
Suppose the policy constraints of a’3 and dl9 do not allow transit traffic originating from dl. Every 
node maintains this information in its view. Thus the source node can choose a valid path from 
source domain dl to destination domain dl avoiding d3 and dl9 (e.g. thick line in the figure). 



Figure 2: An example interdomain topology. 

The disadvantage of this straightforward scheme is that it does not scale up for large internet¬ 
works. The storage at each router is proportional to Np x Ed, where N'd Is the number of domains 
and Ed is the average number of neighbor domains to a domain. The communication cost for 
updating views is proportional to Nr x Er, where Nr is the number of routers in the internetwork 
and Er is the average router neighbors of a router (topology changes are flooded to ah routers in 
the internetwork). 

The Superdomain Approach 

To achieve scaling, several approaches based on hierarchically aggregating domains into superdc- 
mains have been proposed [16, 14, 6]. Here, each domain is a level 1 superdomain, ‘"close” level 1 
superdomains are grouped into level 2 superdomains, “close” level 2 super domains are grouped into 
level 3 superdomains, and so on (see Figure 3). Each router x maintains a view that contains the 
level 1 superdomains in x's level 2 superdomain, the level 2 superdomains in x : s level 3 superdomain 
(excluding the n : s level 2 superdomain), and so on. Thus a router maintains a smaller view than 
it would in the absence of hierarchy. For the sunercomain hierarchy of Figure 3, the views of two 


180 











Figure 3: An example of superdomain hierarchy. 



Figure 4: View of a router in <21. Figure 5: View of a Rxrterin <216. 

The superdomain approach has several problems. One problem is that the aggregation results 

\ 

in loss of domain-level ToS and policy information. A superdomain is usually characterized by a 
single set of ToS and policy constraints derived from the ToS and policy constraints of the domains 
in it. Routers outside the superdomain assume that this set of constraints applies uniformly to 
each of its children (and by recursion to each domain in the superdomain). If there axe domains 
with different (possibly contradictory) constraints in a superdomain, then there is no good way of 
deriving the ToS and policy constraints of the superdomain. 

The usual technique [16] of obtaining ToS and policy constraints of a superdomain is to obtain 
either a strong set of constraints or a weak set of constraints 5 from the ToS and policy constraints of 
1 "strong” and “weak” are referred to respectively as “union” and “intersection” in [36] 


181 








the children superdomains in it. If strong (weak) constraints are used for policies, the superdomain 
enforces a policy constraint if that policy constraint is enforced by some (all) of its children. If 
strong (weak) constraints are used for ToS constraints, the superdomain is assumed to support a 
ToS if that ToS is supported by all (some) of its children. The intention is that if strong (weak) 
constraints of a superdomain are (are not) satisfied then any (no) path through that superdomain 
is valid. 

Each approach has problems. Strong constraints can eliminate valid paths, and weak constraints 
can allow invalid paths. For example in Figure 3, d 16 allows transit traffic from dl while dl9 does 
not; with strong constraints G would not allow transit traffic from dl, and with weak constraints 
G would allow transit traffic from dl to be routed via dl9. 

Other problems of the superdomain approach are that the varying visibilities of routers compli¬ 
cates superdomain-level source routing and handling of node/link failures (especially those that par¬ 
tition superdomains). The usual technique for solving these problems is to augment superdomain- 
level views with gateways [16] (see Section 3). 

Our Contribution 

In this paper, we present an inter-domain routing protocol based on superdomains, which finds 
a valid path if and only if one exists. Both strong and weak constraints are maintained for each 
visible superdomain. If the strong constraints of the superdomains on a path are satisfied, then 
the path is valid. If only the weak constraints are satisfied for some superdomains on the path, the 
source uses a query protocol to obtain a more detailed “internal" view of these superdomains, and 
searches again for a valid path. 

We use superdomain-level views with gateways and a link-state view update protocol to handle 
topology changes including failures that partition superdomains. The storage cost is O(logTv'x) x 
log h'D ) without the query protocol. We demonstrate the scaling properties of the query protocol 
by giving evaluation results based on simulations. Our evaluation results indicate that the query 
protocol can be performed using '15% extra space. 

Our protocol consists of two subprotocols: a view-query protocol for obtaining views of 
greater resolution when needed; and a view-update protocol for disseminating topology changes 
to the views. 





I 


Several approaches to scalable inter-domain routing have been proposed, based on the super¬ 
domain hierarchy [1, 14, 16, 9, 6], and the landmark hierarchy [18, 17]. Some of these approaches 
suffer from loss of ToS and policy information (and hence may not find a valid path which exists). 
Others are still in a preliminary stage. (Details in Section 8.) 

One important difference between these approaches and ours is that ours uses a query mechanism 
to obtain ToS and policy details whenever needed. In our opinion, such a mechanism is needed 
to obtain a scalable solution. Query protocols are also being developed to enhance the protocols 
in [9, 6]. Reference [2] presents protocols based on a new kind of hierarchy, referred to as the 
viewserver hierarchy (more details in Section 8). 

A preliminary version of the view-query protocol was proposed in reference [1]. That version 
differs greatly from the one in this paper. Here, we augment superdomain-level views with gate¬ 
ways. In [1], we augmented superdomain-level views with superdomain-to-domain edges (details in 
Section 8). Both versions have the same time and space complexity, but the protocols in this paper 
are much simpler conceptually. Also the view-update protocol is not in reference [1). 

Organization of the paper 

In Section 2, we present some definitions used in this paper. In Section 3, we define the view data 
structures. In Section 4, we describe how views are affected by topology changes. In Section 5, we 
present the view-query protocol. In Section 6, we present the view-update protocol. In Section 7, 
we present our evaluation model and the results of its application to the superdomain hierarchy. 
In Section 8, we survey recent approaches to inter-domain routing. In Section 9, we conclude and 
describe cacheing and heuristic schemes to improve performance. 

2 Preliminaries 

Each domain has a unique id. Let Domainlds denote the set of domain-ids. Each node has a 
unique id. Let Nodelds denote the set of node-ids. For a node z, we use domainid(z) to denote 
the domain-id of z’s domain. 

The superdomain hierarchy defines the following parent-child relationship: a level t, i > 1, 
superdomain is the parent cf each level i — 1 superdomain it contains. Top-level superdomains 


183 






have no parents. Level 1 superdomains, which are just domains, have no children. For any two 
superdomains X and Y, X is a sibling of Y iff X and Y have the same parent. X is an ancestor 
(descendant) of Y iff A’ = Y or X is an ancestor (descendant) of Y’s parent (child). 

Each router maintains information about a subset of superdomains, referred to as its visible 
superdomains. The visible superdomains of a router x axe (1) x’s domain itself, (2) siblings of x’s 
domain, and (3) siblings of ancestors of x's domain. In Figure 3, the visible superdomains of a 
router in dl are dl,d2,d2,B,C, G, J (these are shown in Figure 4). Note that if a superdomain U 
is visible to a router, then no ancestor or descendant of V is visible to the router.' 

Each superdomain has a unique id, i.e. unique among all superdomains regardless of level. Let 
SuperDomainlds denote the set of superdomain-ids. Domainlds is a subset of SuperDomainlds. 
For a superdomain U , let level(Cf) denote the level of U in the hierarchy, let Ancestors([/) denote 
the set of ids of ancestor superdomains of U in the hierarchy, and let Children(17) denote the set 
of ids of child superdomains of U in the hierarchy. 

For a router x, let VisibleSuperDomains(x) denote the set of ids of superdomains visible from 
x. 

We extend the above definitions by allowing their arguments to be nodes, in which case the node 
stands for its domain. For example, if x is a node in domain d. Ancesxors(x) denotes Ancestors(d). 

3 Superdomain-Level Views with Gateways 

For routing purposes, each domain (and node) has an address, defined as the concatenation of the 
superdomain ids starting from the top level and going down to the domain (node). For example in 
Figure 3, the address of domain dlb is G.E.dlb, and the address of a node h in dl5 is G.E.dlb.h. 

When a source node needs to reach a destination node, it first determines the visible superdo¬ 
main in the destination address and then by examining its view determines a superdomain-level 
source route (satisfying ToS and policy constraints) to this superdomain. However, since routers 
in different superdomains maintain views of different sets of superdomains, this superdomain-level 
source route can be meaningless at some intermediate superdomain’s router x because the next 
superdomain in this source route is not visible to z. For example in Figure 4, superdomain-level 
source route (d2,B,G,C) created at a router in d2 becomes meaningless once the packet is in G , 
where C is not visible. 


184 




The usual technique of solving this problem is to augment superdomain-level views with gate¬ 
ways and edges between these gateways. 

Define the pair U:g to be an sd-gateway iff U is a superdomain and g is a node that is in U and 
has a link to a node outside V. Equivalently, we say that g is a gateway 0 / V. 

Define (U:g,h) to be an actual-edge iff U:g is an sd-gateway, h is a gateway not in U, and there 
is a link from g to h. 

Define { U:g,h) to be a virtual-edge iff U:g and U:h are sd-gateways and g ^ h (note that there 
may not be a link between g and h ). 

( U:g,h) is an edge iff it is an actual-edge or a virtual-edge. An edge ( U:g,h) is also said to be 
an outgoing edge of U:g. Define edges of U :g to be the set of edges outgoing from U:g. Define edges 
of U to be the set of edges outgoing from any gateway of U. 

Let Gaxe-Erays(£/) denote the set of node-ids of gateways of U. Let Edges(Z7:<?) denote the edges 
of U:g. Note that we never use “edge* as a synonym for link. 

A gateway g of a domain can generate many sd-gateways, specifically, U:g for every ancestor U 
of g'' s domain such that g has a link to anode outside U. A link ( g,h ) where g and h are gateways 
in different domains, can generate many actual-edges; specifically, actual-edge ( U:g,h ) for every 
ancestor V of g : s domain such that V is not an ancestor of h’s domain. 

For the internetwork topology' of Figure 2, the corresponding gateway-level connections are 
shown in Figure 6 where black rectangles are gateways. For the hierarchy of Figure 3, gateway 
g in Figure 6 generates sd-gateways dl6:p, E:g, and G:g. The link {g.h) in Figure 6 generates 
actual-edges (dl6:g,h), ( E:g,h ), (G:g,h). 

To a router, at most one of the sd-gateways generated by a gateway g is visible, namely U:g 
where V is an ancestor of g's domain and U is visible to the router. At most one of the actual-edges 
generated by a link {g.h) between two gateways in different domains is visible to the router, namely 
edge ( U:g,h) where U:g is visible to the router. None of the actual-edges are visible to the router 
if g and h are inside a visible superdomain. For example in Figure 3, of the actual-edges generated 
by link ( g,h ), only ( G:g , h ) is visible to a router in dl, and only {dl6:g,h) is visible to a router in 

die. 

A router maintains a view consisting of the visible sd-gateways and their outgoing actual- and 
virtual-edges. An edge ( U:g,h ) in the view of a router connects the sd-gateway U:g to the sd- 


185 


Figure 6: Gateway-level connections of internetwork of Figure 2. 

gateway V:h such that V:h is visible to the router. For the superdomain-level views of Figures 4 
and 5. the new views are shown in Figures 7 and 8, respectively. 



Figure 7: View of a router in dl. Figure 8: View of a router in dl6. 



The view of a router x contains, for each superdomain U that is visible to x or is an ancestor 
of x. the strong and weak constraints of U and a set referred to as Gateways&Edges z (U). This 
set contains, for each gateway y of U, the edges of U:y and their costs. The reason for storing 
information about ancestor superdomains is given in Section 5. The cost field is used to satisfy ToS 
constraints and is described in Section 4. The timestamp field is described in Section 6. Formally, 
the view of x is defined as follows: 


186 






V iew x . View of x. 

= {(£/, strong_constraints([7), weak_constrainns(I7), Gateway s&Edges x (U)) : 

U £ VisibleSuperDomains(z) U Ancestors^) } 

where 

Gaieways&Edges x (U). Sd-gateways and edges of U. 

= {(jf, timestamp , {( 2 , cost) : {U:y,z) £ Edges(Z7:y)}) : y £ Gatevays(£7) }. 

ToS and policy constraints can also be specified for each sd-gateway and edge. Our protocols 
can be extended to handle such constraints, but we have not done so here in order to keep their 
descriptions simple. 

A superdomain-level source route is now a sequence of sd-gateway ids. With this definition, it 
is easy to verify that whenever the next superdomain in a superdomain-level source route is not 
visible to a router, there is an actual-edge (hence a link) between the router and the next gateway 
in this route. 

4 Edge-Costs and Topology Changes 

A cost is associated with each edge. The cost of an edge equals a vector of values if the edge is up; 
each cost value indicates how expensive it is to cross the edge according to some ToS constraint. 
The cost equals cc if the edge is an actual-edge and it is down, or the edge is a virtual-edge (U:g, h) 
and h can not be reached from g without leaving U. 

Since an actual-edge represents a physical link, its cost can be determined from measured link 
statistics. The cost of a virtual-edge ( U:g,h ) is an aggregation of the cost of physical links in 
V and is calculated as follows: If U is a domain, the cost of ( U:g,h ) is calculated as the maxi¬ 
mum/minimum/average cost of the routes within U from g to h [4]. For higher level superdomains 
U, the cost of ( U'-g,h } is derived from the costs of edges between the gateways of children super¬ 
domains of U. 

Link cost changes and link/node failures and repairs correspond to cost changes, failures and 
repairs of actual- and virtual-edges. Thus the attributes of edges in the views of routers must be 
regularly updated. For this, we employ a view-update protocol (see Section 6). 


187 








Link/node failures can also partition a superdomain into cells, where a cell of a superdomain 
is defined to be a maximal subset of nodes of the superdomain that can reach each other without 
leaving the superdomain. Superdomain partitions can occur at any level in the hierarchy. For 
example, suppose U is a domain and V is its parent superdomain. V can be partitioned into cells 
without V being partitioned (i.e. if the cells of U can reach each other without leaving V). The 
opposite can also happen: if all links between U and the other children of V fail, then V becomes 
partitioned but U does not. Or both U and V can be partitioned. In the same way, link/node 
repairs can merge cells into bigger cells. 

We handle superdomain partitioning as follows: A router detects that a superdomain U is 
partitioned when a virtual-edge of U in the router’s view has cost oo. "When a router forwards 
a packet to a destination for which the visible superdomain, say U , in the destination address is 
partitioned into cells, a copy of the packet is sent to each cell by sending a copy of the packet to 
each gateway of U ; the id V in the destination address is “marked” in the packet so that subsequent 
routers do not create new copies of the packet for U. 

5 View-Query Protocol 

"When a source node wants a superdomain-level source route to a destination, a router in its domain 
examines its view and searches for a valid path (i.e. superdomain-level source route) using the 
destination address 6 . We refer to this router as the source router. Even though the source router 
does not know the constraints of the individual domains that are to be crossed in each superdomain, 
it does know the strong and weak constraints of the superdomains. We refer to a superdomain 
whose strong constraints are satisfied as a valid superdomain. If a superdomain’s weak constraints 
are satisfied but strong constraints are not satisfied, then there may be a valid path through this 
superdomain. We refer to such a superdomain as a candidate superdomain. 

A path is valid if it involves only valid superdomains. A path cannot be valid if it involves 
a superdomain which is neither valid nor candidate. We refer to a path involving only valid and 
candidate superdomains as a candidate path. 

e We assume that the source has the destination’s address. II that is not the case, it would first query the name 
servers to obtain the address for the destination. Querying the name servers can be done the same way it is done 
currently in the Internet. It requires nodes to have a set of fixed addresses to name servers. This is also sufficient in 
our case. 


1 


I 


I 


1 


188 


I 



If the source router’s view contains a candidate path (I/o : Po 0 i ■■ ■■> Uo'9o no > U\ :£i 0 , • • •, fr'i :£i nj , • , 

Um-gmoT ■ ■,Um'9m nm ) to the destination (and does not contain a valid path), then for each candi¬ 
date superdomain £/,• on this path, the source router queries gateway 5 ,- 0 of I/,- for the internal view of 

This internal view consists of the constraints, sd-gatewavs and edges of the child superdomains 
of U{. 

When a router x receives a request for the internal view of an ancestor superdomain U, it 
returns the following data structure: 

lVieu; x (U). Internal view of U at router x. 

= {(V, strong_constraints(V), seak_consTraints(V), Gateways&Edges z (V)) £ View x : 

V £ Children([/)} 

It is to simplify the construction of IViev^iJJ) that we store information about ancestor su¬ 
perdomains in the view of router x. Instead of storing this information, router x could construct 
JView x (U ) from the constraints, sd-gateways and edges of the visible descendants of U. We did 
not choose this alternative because the extra information does not increase storage complexity. 

When the source router receives the internal view' of a superdomain U. it does the following: 
(1) it removes the sd-gateways and edges of U from its view; (2) it adds the sd-gatewavs and edges 
of children superdomains in the internal view of U ; and (3) searches for a valid path again. If there 
is still no valid path but there are candidate paths, the process is repeated. 

For example, consider Figure 3. For a router in superdomain dl (see Figure 7), G is visible and 
is a candidate domain. The internal view of G is shown in Figure 9, and the resulting merged view 
is shown in Figure 10. The valid path through G (visiting dl6 and avoiding dl9) can be discovered 
using this merged view (since the strong constraints of E are satisfied). 

Consider a candidate route to a destination: (Uo'.go,,..Uo'-go,^, Z7i : Pi 0 , • • Uyig \, ••• , 

Um : 9m 0 1 • • •> U m -9rr. nm )• If super domain [/,• is partitioned into cells, it may re-appear later in the 
candidate path (i.e. for some j = i, Uj = U{). In this case both gateways and g-j 0 are queried. 
Timestamps are used to resolve conflicts between the information reported by’ these gateways. 

The view-query protocol uses two types of.messages as follows: 

• (RequestIVi en. sdid, gid, sMddress, djxddress) 


189 






I 



Figure 9: Internal view of G. Figure 10: Merged view at dl. 

Sent by a source router to gateway gid to obtain the internal view of superdomain sdid. 
sjiddress is tbe address of the source router, djiddress is the address of the destination 
node (of the desired route). 

• (ReplylVieu, sdid, gid, iview, djiddress) 

where iview is the internal view of superdomain sdid, and other parameters are as in the 
RequestIViev message. It is sent by gateway gid to the source router. 

The state maintained by a source router x is listed in Figure 15. PendingReq x is used to 
avoid sending new request messages before receiving all outstanding reply messages. WView x and 
PendingReq x are allocated and deallocated on demand for each destination. 

The events of router x are specified in Figure 15. In the figure, * is a wild-card matching any 
value. TimeOutx event is executed after a time-out period from the execution of Request, event to 
indicate that the request has not been satisfied. The source host can then repeat the same request 
afterwards. 

The procedure search x uses an operation “ReliableSend(m) to v T , where m is the message being 
sent and t is either an address of an arbitrary router or an id of a gateway of a visible superdomain. 
ReliableSend is asynchronous. The message is delivered to v as long as there is a sequence of up 
links between u and v.~ (Note that an address is not needed to obtain an inter-domain route to a 
gateway of a visible superdomain.) 

Router Failure Model: A router can undergo failures and recoveries at anytime. We 
assume failures are fail-stop (i.e. a failed router does not send erroneous messages). When a router 
x recovers, the variables WView. and PendingReq x are lost for all destinations. The cost of each 
edge in View x is set to oc. It becomes up-to-date as the router receives new information from other 

' This involves time-outs, retransmissions, etc. It requires a transport protocol support such as TCP. 


1 


I 


1 


190 


I 





routers. 


6 View-Update Protocol 

A gateway g, for each ancestor superdomain U, informs other routers of topology changes (i.e. 
failures, repairs and cost changes) affecting U'.g’s edges. The communication is done by flooding 
messages. The flooding is restricted to the routers in the parent superdomain of U, since U is 
visible only to these routers. 

Due to the nature of flooding, a router can receive information out of order from a gateway. In 
order to avoid old information replacing new information, each gateway includes increasing time 
stamps in the messages it sends. Routers maintain for each gateway the highest received time 
stamp (in the timestamp field in Vteu; x ), and discard messages with smaller timestamps. Time 
stamps do not have to be real-time clock values. 

Due to superdomain partitioning, messages sent by a gateway may not reach all routers within 
the parent superdomain, resulting in some routers having out-of-date information. This out-of-date 
information can cause inconsistencies when the partition is repaired. To eliminate inconsistencies, 
when a link recovers, the two routers at the ends of the link exchange their views and flood any new 
information. As usual, information about a superdomain V is flooded over U's parent superdomain. 

The view-update protocol uses messages of the following form: 

♦ (Update, sdid , gid, timestamp, edge-set ) 

Sent by the gateway gid to inform other routers about current attributes of edges of sdidigid. 
timestamp indicates the time stamp of gid. edge-set contains a cost for each edge. 

The state maintained by a router x is listed in Figure 16. Note that AdjLocalRouters. or 
AdjForeignGatevays r can be empty. IntraDomainRT x contains a route (next-hop or source) 8 for 
every reachable node of the domain. We assume that consecutive reads of Clock = returns increasing 
values. 

Routers also receive and flood messages containing edges of sd-gateways of their ancestor su¬ 
perdomains. This information is used by the query protocol (see Section 5). Also the highest 
timestamp received from a gateway g of an ancestor superdomain is needed to avoid exchanging 

* ]ntraDomainRTs is a view in case of a link-state routing protocol or a distance table in case of a distance-vector 
routing protocol. 


191 










the messages of g infinitely during flooding. 

The events of router x are specified in Figure 16. We use Ancestor,-(£/) to denote the superdomain- 
id of the :th ancestor of 17, where Ancestoro(Z7) = U. In the view-update protocol, a node u uses 
send operations of the form u Send(m) to r”, where m is the message being sent and v is the 
destination-id. Here, nodes u and v are neighbors, and the message is sent over the physical link 
(u, v). If the link is down, we assume that the packet is dropped. 

7 Evaluation 

In the superdomain hierarchy (without the query protocol), the number of superdomains in a view 
is logarithmic in the number of superdomains in the internetwork [10]. 9 However, the storage 
required for a view is proportional not to the number of superdomains in it but to the number of 
sd-gateways in it. As we have seen, there can be more than one sd-gateway for a superdomain in 
a view'. 

In fact, the superdomain hierarchy does not scale-up for arbitrary internetworks; that is, the 
number of sd-gateways in a view can be proportional to the number of domains in the internetwork. 
For example, if each domain in a superdomain XJ has a distinct gateway with a link to outside U, 
the number of sd-gateways of V would be linear in the number of domains in U. 

The good news is that the superdomain hierarchy does scale-up for realistic internetwork topolo¬ 
gies. A sufficient condition for scaling is that each superdomain has at most log Np sd-gateways; 
this condition is satisfied by realistic internetworks since most domain interconnections are “hier¬ 
archical connections” i.e. between backbones and regionals, between regionals and MAKs, and so 
on. 

In this section, we present an evaluation of the scaling properties of the superdomain hierarchy 
ana the query protocol. To evaluate any inter-domain routing protocol, we need a model in which 
we can define internetwork topologies, policy/ToS constraints, inter-domain routing hierarchies, 
and evaluation measures (e.g. memory and time requirements). We have recently developed such 
a model {3]. We first describe our model, and then use it to evaluate our superdomain hierarchy. 
Our evaluation measures are the amount of memory required at the routers, and the amount of 

s Ever, though the results in [10] were lor intra-domain routing, it is easy to show that the analysis there holds 
for inter-domain routing as well. 


192 





time needed to construct a path. 


7.1 Evaluation Model 

We first describe our method of generating topologies and policy/ToS constraints. We then describe 
the evaluation measures. 

Generating Internetwork Topologies 

For our purposes, an internetwork topology is a directed graph where the nodes correspond to 
domains and the edges correspond to domain-level connections. However, an arbitrary graph will 
not do. The topology should have the characteristics of a real internetwork, like the Internet. 
That is, it should have backbones, regionals, MANS, LANS, etc.; there should*be hierarchical 
connections, but some “non-hierarchical” connections should also be present. 

For brevity, we refer to backbones as class 0 domains, regionals as class 1 domains, metropolitan- 
area domains and providers as class 2 domains, and campus and local-area domains as class 3 
domains. A (strictly) hierarchical interconnection of domains means that class 0 domains are 
connected to each other, and for : > 0, class i domains are connected to class : — 1 domains. 
As mentioned above, we also want some “non-hierarchicaT connections, i.e., domain-level edges 
between domains irrespective of their classes (e.g. from a campus domain to another campus 
domain or to a backbone domain). 

In reality, domains span geographical regions and domain-level edges are often between do¬ 
mains that are geographically close (e.g. University of Maryland campus domain is connected to 
SUBA.NET regional domain which are both in the east coast). We also want some edges that are 
between far domains. A class i domain usually spans a larger geographical region than a class i +1 
domain. To generate such interconnections, we associate a “region” attribute to each domain. The 
intention is that two domains with the same region are geographically close. 

The region of a class i domain has the form ro.rj.---.rj, where the r ; -’s are integers. For 
example, the region of a class 3 domain can be 1.2.3.4. For brevity, we refer to the region of a 
class i domain as a class i region. 

Note that regions have their own hierarchy which should not be confused "with the superdomain 
hierarchy. Class 0 regions are the top level regions. We say that a class i region ro-rj. • • • .rj_j.rj 


193 






is contained in the class i— 1 region ro-rj. • • - (where i > 0). Containment is transitive. Thus 
region 1.2.3.4 is contained in regions 1.2.3, 1.2 and 1. 


/ / 

, / i.i 


! ti (ayG 


\ \\K 

\ \\ 
\ V 
\ 


rTytTTL- 


cjj ((\D 


~Jl 






X \ 

^ \ \ 2 
J ' X 
J \ \ 

I \ 


\ \ 

\ V 

x \ 

\ \ 

;■>;>, 

\ \ ' 

1^2 \ \ \ 

\ \ \ 
1 I 1 
/ / I 

/ J 


Figure 11: Regions 


Given any pair of domains, we classify them as local, remote or fax, based on their regions. 
Let X be a class i domain and Y a class j domain, and without loss of generality let i < j. X 
and y are local if they axe in the same class i region. For example in Figure 11, A is local to 
B,C,J, K, M, N, O, P, and Q. X and Y are remote if they are not in the same class i region but 
they are in the same class i — 1 region, or if i ~ 0. For example in Figure 11, some of the domains 
.4 is remote to are D^E,F, and L. X and Y are /or if they are not local or remote. For example 
in Figure 11, A is far to J. 

We refer to a domain-level edge as local (remote . or far) if the two domains it connects are local 


3151 













(remote, or far). 

We use the following procedure to generate internetwork topologies: 

• We first specify the number of domain classes, and the number of domains in each class. 

• We next specify the regions. Note that the number of region classes equals the number of 
domain classes. We specify the number of class 0 regions. For each class i > 0, we specify a 
branching factor, which creates that many class i regions in each class i — 1 region. (That is, 
if there are two class 0 regions and the class 1 branching factor equals three, then there are 
six class 1 regions.) 

• For each class :, we-randomly map the class i domains into the class i regions. Note that 
several domains can be mapped to the same region, and some regions may have no domain 
mapped into them. 

• For every class i and every class j, j > i, we specify the number of local, remote and far 
edges to be introduced between class i domains and class j domains. The end points of the 
edges are chosen randomly (within the specified constraints). 

• We ensure that the internetwork topology is connected by ensuring that the subgraph of class 
0 domains is connected, and each class i domain, for i > 0, is connected to a local class i - 1 
domain. 

• Each domain has one gateway. So all neighbors of a domain are connected via this gateway. 
This is for simplicity. 

Choosing Policy/ToS Constraints 

We chose a simple scheme to model policy/ToS constraints. Each domain is assigned a color: green 
or red. For each domain class, we specify the percentage of green domains in that class, and then 
randomly choose a color for each domain in that class. 

A valid route from a source to a destination is one that does not visit any red intermediate 
domains; the source and destination domains are allowed to be red. 

This simple scheme can model many realistic policy/ToS constraints, such as security constraints 
and bandwidth requirements. It cannot model some important kinds of constraints, such as delay- 
bounds. 


195 


Computing Evaluation Measures 

The evaluation measures of most interest for an inter-domain routing protocol are its memory, time 
and communication requirements. We postpone the precise definitions of the evaluation measures 
to the next subsection. 

The only analysis method we have at present is to numerically compute the evaluation measures 
for a variety of source-destination pairs. Because we use internetwork topologies of large sizes, it 
is not feasible to compute for all possible source-destination pairs. We randomly choose a set 
of source-destination pairs that satisfy the following conditions: (1) the source and destination 
domains are different stub domains, and (2) there exists a valid path from the source domain to the 
destination domain in the internetwork topology. (Note that the straight-forward scheme would 
always find such a path.) 

7.2 Application to Superdomain Query Protocol 

We use the above model to evaluate our superdomain query protocol for several different super- 
domain hierarchies. For each hierarchy, we define a set of superdomain-ids and a parent-child 
relationship on them. 

The first superdomain hierarchy scheme is referred to as child-domains. Each domain d (re¬ 
gardless of its class) is a level-1 superdomain, also identified as d. In addition, for each backbone d, 
we create a distinct level-4 superdomain referred to as d-A. For each regional d, we create a distinct 
ievel-3 superdomain d-3 and make it a child of a randomly chosen level-4 superdomain e-A such 
that d and e are local and connected. For each MAN d, we create a distinct level-2 superdomain 
d-2 and make it a child of a randomly chosen level-3 superdomain e-3 such that d and e are local 
and connected. Please see Figure 12. 

We next describe how the level-1 superdomains (i.e. the domains) are placed in the hierarchy. 
A backbone d is placed in, i.e. as a child of, d-A. A regional d is placed in d-3. A MAN d is placed 
in d-2. A stub d is placed in e-2 such that d and e are local and connected. Please see Figure 12. 

The second superdomain hierarchy scheme is referred to as sibling-domains. It is identical 
to child-domains except for the placement of level-1 super domains corresponding to backbones, 
regionals and MANs. In sibling-domains, a backbone d is placed as a sibling of d-A. A regional d 
is placed as a sibling of d- 3. A MAN d is placed as a sibling of d-2. Please see Figure 13. 


196 









In leaf-domains , backbones and regionals are placed in some ievel-2 superdomain, as follows. A 
regional d, if superdomain d- 3 has a child superdomain e-2, is placed in e-2. Otherwise, a new level- 
2 superdomain d- 2 is created and placed in d-Z. d is placed in d- 2. A backbone d, if superdomain 
d-4 has a child superdomain /-3, is placed in the level-2 superdomain containing the regional /. 
Otherwise, a new level-3 superdomain d- 3 is created and placed in d-4, a new level-2 superdomain 
d- 2 is created and placed in d-Z. d is placed in d-2. Please see Figure 14. 

Note that in leaf-domains, all level-1 superdomains are placed under level-2 superdomains. 
Whereas other schemes allow some level-1 superdomains to be placed under higher level superdo¬ 
mains. 



Figure 14: leaf-domains 

The fourth superdomain hierarchy scheme is referred to as regions. In this scheme, the super¬ 
domain hierarchy corresponds exactly to the region hierarchy used to generate the internetwork 
topology. That is, for a class 1 region x there is a distinct level 5 (top level) superdomain i-5. For 
a class 2 region x.y there is a distinct level 4 superdomain x.y-4 placed under level 5 superdomain 
s-5, and so on. Each domain is placed under the superdomain of its region. Please see Figure 11. 


198 








Results for Internet-work 1 


The parameters of the first internetwork topology, referred to as Internetwork 1, are shown in 


Table 1. 


Ciass i 

No. of Domains 

No. of Regions 10 

% of Green Domains 

Edges b 

Class j 

etween C 

Local 

Lasses i aj 

Remote 

id j 

Far 

0 

10 

4 

0.80 

0 

8 

6 

0 

1 

100 

16 

0.75 

0 

190 

20 

i 

0 





1 

26 

5 

0 

2 

1000 

64 

0.70 

0 

100 

0 

0 





1 

1060 

40 

0 





2 

200 

40 

0 

3 

10000 

256 

0.20 

0 

100 

0 

0 





1 

1C. ' 0 

0 





2 

10100 

50 

0 





3 

50 

50 

50 


Table 1: Parameters of Internetwork 1. 


Our evaluation measures were computed for a (randomly chosen but fixed) set of 100.000 source- 
destination pairs. For a source-destination pair, we refer to the length of the shortest valid path in 
the internetwork topology as the shortest-path length, or spl in short. The minimum spl of these 
pairs was 2. the maximum spl was 15, and the average spl was 6.84. 

For each source-destination pair, the set of candidate paths is examined in shortest-first order 
until either a valid path was found or the set was exhausted and no valid paths were found. 
For each candidate path, RequestIView messages are sent to all candidate superdomains on this 
path in parallel. All Reply IV iev messages are received in time proportional to the round-trip 
time to the farthest of these superdomains. Hence, total time requirement is proportional to the 
number of candidate paths queried multiplied by the round-trip time to the farthest superdomain 
in these paths. Let msgsizt denote the sum of average RequestIVieu message size and average 

1D Branching factor is 4 for all region classes. 


199 




































































Scheme 

No query needed 

Candidate Paths 

Candidate Superdomains 

child-domains 

220 

3.31/13 

7.35/38 

sibling-domains 

220 

3/10 

6.17/22 

leaf-domains 

219 

6.31/24 

15.94/66 

regions 

544 

3.70/12 j 7.79/30 


Table 2: Queries for Internetwork 1. 

ReplyIViev message size. The number of candidate superdomains queried times msgsize indicates 
the communication capacity required to ship the RequestIVieu and ReplylViev messages. 

Table 2 lists for each superdomain scheme the average and maximum number of candidate paths 
and candidate superdomains queried. As apparent from the table, sibling-domains is superior to 
other schemes and leaf-domains is much worse than the rest. This is because in leaf-domains , even 
if only one domain d in a superdomain V is actually going to be crossed, all descendants of U 
containing d may need to be queried to obtain a valid path (e.g. to cross backbone A in Figure 14, 
it may be necessary to query for superdomain A- 4, then £-3, then C- 2). 



Initial 

view size 

Merged view size 

Scheme 

in sd-gat.ewavs 

in superdomains 

in sd-gateways 

in superdomains 

child-domains 

964/1006 

42/60 

1089/1282 

100/298 

sibling-domains 

1167/1269 

70/99 

1470/2190 

148/337 

leaf-domains 

963/1006 

40/60 

1108/1322 

130/411 

regions 

492/715 

85/163 

1042/2687 

158/369 


Table 3: View sizes for Internetwork 1. 

Table 3 lists for each superdomain scheme the average and maximum of the initial view size 
and of the merged view size. The initial view size indicates the memory requirement at a router 
without using the query protocol (i.e. assuming the initial view has a valid path). The merged view 
size indicates the memory requirement at a router during the query protocol (after finding a valid 


200 





path). The memory requirement at a router is 0(view size in number of sd-gateways x Eq) where 
Ec is the average number of edges of an sd-gatewav. Note that the source does not need to store 
information about red and non-transit domains in the merged views (other than the ones already 
in the initial view). The numbers for the merged view sizes in Table 3 take advantage of this. 

As apparent from the table, leaf-domains , child-domains and regions scale better than sibling- 
domains. There are two reasons for this. First, placing a backbone (regional or MAN) domain d as a 
sibling to d -4 (d -3 or d- 2) doubles the number of level 4 (3 or 2) superdomains in the views of routers. 
Second, since these domains have many edges to the domains in their associated superdomains, the 
end points of each of these edges become sd-gateways of the associated superdomains. Note that 
regions scales much superior to the other schemes in the initial view size. This is because most 
edges are local (i.e. contained within regions), thus contained completely in superdomains. Hence, 
their end points are not sd-gateways. 

Overall, the child-domains and regions schemes scale best in space, time and communication 
requirements. We have repeated the above evaluations for two other internetworks and obtained 
similar conclusions. The results are in Appendix A. 

8 Related Work 

In this section, we survey recently proposed inter-domain routing protocolsSupport ToS and 
policy routing for large internetworks. 

Nimrod [6] and IDPR [16] use the link-state approach with domain-level source routing to 
enforce policy and ToS constraints and superdomains to solve scaling problem. Nimrod is still in 
a design stage. Both protocols suffer from loss of policy and ToS information as mentioned in the 
introduction. A query protocol for Nimrod is being developed to obtain more detailed policy, ToS 
and topology information. 

BGP [12] and ID BP [14] are based on a path-vector approach [15]. Here, for each destination 
domain a router maintains a set of paths, one through each of its neighbor routers. ToS and policy- 
information is attached to these paths. Each router requires 0(Nd x Nd x Er) space, where Nr> 
is the average number of neighbor domains for t domain and Nr is the number of routers in the 
internetwork. For each destination, a router exchanges its best valid path with its neighbor routers. 
However, a path-vector algorithm may not find a valid path from a source to the destination even 


201 







if such a route exists [16] n (i.e. detailed ToS and policy information may be lost). By exchanging k 
paths to each destination, the probability of detecting a valid path for each source can be increased. 
But to guarantee detection, either all possible paths should be exchanged (exponential number of 
paths in the worst case) or source policies should be made public and routers should take this into 
account when exchanging routes. However, this fix increases space and communication requirements 
drastically. 

IDRP [14] uses superdomains to solve the scaling problem. It exchanges all paths between 
neighbor routers subject to the following constraint: a router does not inform a neighbor router 
of a route if usage of the route by the neighbor would violate some superdomain 5 s constraint on 
the route. IDRP also suffers from loss of ToS and policy information. To overcome this problem, 
it uses overlapping superdomains: that is, a domain and superdomain can be in more than one 
parent superdomain. If a valid path over a domain can not be discovered because the constraints 
of a parent superdomain are violated, the same path may be discovered through another parent 
superdomain whose constraints are not violated. However, handling ToS and policy constraints 
in general requires more and. more combinations of overlapping superdomains, resulting in more 
storage requirement. 

Reference [9] combines the benefits of path-vector approach and link-state approach by having 
two modes: An NR mode, which is an extension of IDRP and is used for the most common ToS 
and policy constraints: and a SDR mode, which is like IDPR and is used for less frequent ToS and 
policy requests. This study does not address the scalability of the SDR mode. Ongoing work by 
this group considers a new SDP*. mode which is not based on IDPR. 

Reference [19] suggests the use of multiple addresses for each node, one for each ToS and Policy. 
This scheme does not scale up. In fact, it increases the storage requirement, since a router maintains 
a route for each destination address, and there are more addresses with this scheme. 

The landmark hierarchy [18, 17] is another approach for solving scaling problem. Here, each 
router is a landmark with a radius, and routers which are at most radius away‘from the landmark 
maintain a route for it. Landmarks are organized hierarchically, such that radius of a landmark 
increases with its level, and the radii of top level landmarks include all routers. Addressing and 

:: For example, suppose a router u has two paths Pi and P2 to the destination. Let u have a router neighbor r, 
which is in another domain, u chooses and informs v of one of the paths, say Pi. But Pi may violate source policies 
of t's domain, and P2 may be a valid path for v. 


202 





packet forwarding schemes are introduced. Link-state algorithms can not be used with the landmark 
hierarchy, and a thorough study of enforcing ToS and policy constraints with this hierarchy has 
not been done. 

In [1], we provided an alternative solution to loss of policy and ToS information that is perhaps 
more faithful to the original superdomain hierarchy. To handle superdomain-level source routing 
and topology changes, we augmented each superdomain-level edge ( U,V ) with the address of an 
“exit" domain u in U and an “entry” domain v in V. To obtain internal views, we added for 
each visible superdomain V the edges from U to domains outside the parent of U. Surprisingly, 
this approach and the gateway-level view approach have the same memory and communication 
requirements. However, the first approach results in much more complicated protocols. 

Reference [2] presents interdomain routing protocols based on a new kind of hierarchy, referred 
to as the viewserver hierarchy. This approach also scales well to large internetworks and does 
not lose detail ToS and policy information. Here, special routers called viewservers maintain the 
view of domains in a surrounding precinct. Viewservers are organized hierarchically such that 
for each viewserver, there is a domain of a lower level viewserver in its view, and views of top 
level viewservers include domains of other top level viewservers. Appropriate addressing and route 
discovery schemes are introduced. 

9 Conclusion 

We presented a hierarchical inter-domain routing protocol which satisfies policy and ToS con¬ 
straints, adapts to dynamic topology changes including failures that partition domains, and scales 
well to large number of domains. 

Our protocol achieves scaling in space requirement by using superdomains. Our protocol main¬ 
tains superdomain-level views with sd-gateways and handles topology changes by using a link-state 
view update protocol. It achieves scaling in communication requirement by flooding topology 
changes affecting a superdomain V over U 's parent superdomain. 

Our protocol does not lose detail in ToS, policy and topology information. It stores both a 
strong set of constraints and a weak set of constraints for each visible superdomain. If the weak 
constraints but not the strong constraints of a superdomain V are satisfied (i.e. the aggregation has 
resulted in loss of detail in ToS and policy information), then some paths through U may be valid. 


203 






Our protocol uses a query protocol to obtain a more detailed “internal” view of such superdomains, 
and searches again for a valid path. Our evaluation results indicate that the query protocol can be 
performed using 15% extra space. 

One drawback of our protocols is that to obtain a source route, views are merged at or prior 
to the connection setup, thereby increasing the setup time. This drawback is not unique to our 
scheme [7, 16, 6, 9], There are several ways to reduce this setup overhead. First, source routes 
to frequently used destinations can be cached. Second, the internal views of frequently queried 
superdomains can be cached at routers dose to the source domain. Third, better heuristics to 
choose candidate paths and candidate superdomains to query can be developed. 

We also described an evaluation model for inter-domain routing protocols. This model can be 
applied to other inter-domain routing protocols. We have not done so because predse definitions of 
the hierarchies in these protocols are not available. For example, to do a fair evaluation of IDPR[16], 
we need precise guidelines for how to group domains into superdomains, and how to choose between 
the strong and weak methods when defining policy/ToS constraints of superdomains. In fact, these 
protocols have not been evaluated in a way that we can compare them to the superdomain hierarchy. 

References 

[1] C. Alaettinoglu and A. U. Shankar. Hierarchical Inter-DomaiD Routing Protocol with On-Demand 
ToS and Poicy Resolution. In Proc. IEEE International Conference on Networking Protocols ’98. San 
Fransisco. California, October 1993. 

[2] C. Alaettino|lu and A. U. Shankar. Viewserver Hierarchy: A New Inter-Domain Routing Protocol and 
its Evaluation. Technical Report UM1ACS-TR-93-98, CS-TR-3151. Department of Computer Science, 
University of Maryland, College Park, October 1993. Earlier version CS-TR-3033, February 1993. 

[3] C. Alaeuinoflu and A. U. Shankar. Viewserver Hierarchy: A New Inter-DomaiD Routing Protocol. In 
Proc. IEEE INFOCOM ‘94, Toronto, Canada, June 1994. To appear. 

[4] A. Bar-Noy and M. Gopal. Topology Distribution Cost vs. Efficient Routing in Large Networks. In 
Proc. ACM SICCOMM ‘90, pages 242-252, Philadelphia, Pennsylvania, September 1990. 

[5] L. Breslau and D. Estrin. Design of Inter-Administrative Domain Routing Protocols. In Proc. ACM 
SIGCOMM ‘90, pages 231-241, Philadelphia, Pennsylvania, September 1990. 

[6] I. Castinevra, J. N. Chiappa, C. Lynn, R. Ramanathan, and M. Steenstrup. The Nimrod Routing Archi¬ 
tecture. Internet Draft., March 1994. Available by anonymous ftp from research. Itp. com:pub/nimrod. 

[7] D.D. Clark. Policy routing in Internet protocols. Request for Comment RFC-1102, Network Information 
Center, May 1989. 

[8] D. Estrin. Policy requirements for inter Administrative Domain routing. Request for Comment RFC- 
1125, Network Information Center, November 1989. 


204 


[9] D. Estrin, Y. Rekhter, and S. Hotz. Scalable Inter-Domain Routing Architecture. In Proc. ACM 
S1GC0MM ’92, pages 40-52, Baltimore, Maryland, August 1992. 

[10] L. Kleinrock and F. Kamoun. Hierarchical Routing for Large Networks. Compuier Networks and ISDN 
Systems, (1):155-174, 1977. 

[11] B.M. Leiner. Policy issues in interconnecting networks. Request for Comment RFC-1124, Network 
Information Center, September 19S9. 

[12] K. Lougheed and Y. Rekhter. Border Gateway Protocol (BGP). Request for Comment RFC-1105, 
Network Information Center, June 1989. 

[13] R. Perlman. Hierarchical Networks and Subnetwork Partition Problem. Computer Networks and ISDN 
Systems, 9:297-303, 1985. 

[14] Y. Rekhter. Inter-Domain Routing Protocol (IDRP). Available from the author., 1992. T.J. Watson 
Research Center, IBM Corp. 

[15] K. G. Shin and M. Chen. Performance Analysis of Distributed Routing Strategies Free of Ping-Pong- 
Type Looping. IEEE Transactions on Computers, 1987. 

[16] M. Steenstrup. An Architecture for Inter-Domain Policy Routing. Request for Comment RFC-1478, 
Network Information Center, July 1993. 

[17] P. F. Tsuchiva. The Landmark Hierarchy: Description and Analysis, The Landmark Routing: Ar¬ 
chitecture Algorithms and Issues. Technical Report MTR-87W00152, MTR-87W00174, The MITRE 
Corporation, McLean, Virginia, 1987. 

[IS] P. F. Tsuchiva. The Landmark Hierarchv:A New Hierarchy For Routing In Very Large Networks. In 
Proc. ACM SIGCOMM ’ 88 , August 1988. 

[19] P. F. Tsuchiva. Efficient and Robust Policy Routing Using Multiple Hierarchical Addresses. In Proc. 
ACM SIGCOMM ‘91, pages 53-65, Zurich, Switzerland, September 1991. 


A Results for Other Internetworks 


Results for Internetwork 2 

The parameters of the second internetwork topology, referred to as Internetwork 2, are the same as 
the parameters of Internetwork 1 but a different seed is used for the random number generation. 

Our evaluation measures were computed for a set of 100,000 source-destination pairs. The 
minimum spl of these pairs was 1, the maximum spl was 14, and the average spl was 7.13. 

Table 5 and Table 4 shows the results. Similar conclusions as in the case of Internetwork 1 hold. 

* 

Results for Internetwork 3 
v 

The parameters of the third internetwork topology, referred to as Internetwork 3, are shown in 
Table 6. Internetwork 3 is more connected, more class 0, 1 and 2 domains are green, and more 
class 3 domains are red. Hence, we expect bigger view sizes in number of sd-gateways. 


205 





Scheme 

No query needed 

Candidate Paths 

Candidate Superdoir.ains 

child-domains 

205 

4.52/20 

10.22/47 

sibling-domains 

205 

3.01/8 

6.50/21 

leaf-domains 

205 

8.80/32 

21.34/82 

regions 

640 

3.52/10 

7.85/28 


Table 4: Queries for Internetwork 2. 



Initial 

. 

view size 

Merged 

view size 

Scheme 

in sd-gatewavs 

in superdomains 

in sd-gateways 

in superdomains 

child-domains 

958/1012 

43/60 

1079/1269 

118/306 

sibling-domains 

1153/1283 

72/101 

1480/2169 

160/324 

leaf-domains 

956/1009 

41/58 

1095/1281 

156/387 

regions 

624/1024 

110/231 

1356/3578 

206/435 


Table 5: View sizes for Internetwork 2. 

Our evaluation measures were computed for a set of 100,000 source-destination pairs. The 
minimum spl of these pairs was 1, the maximum spl was 11, and the average spl was 5.95. 

Table 8 and Table 7 shows the results. Similar conclusions as in the cases of Internetwork 1 
and 2 hold. 


^Branching factor is 4 fox all domain classes. 


206 
















Class i 

No. of Domains 

No. of Regions 12 

% of Green Domains 

Edges b 

Class j 

etween 

Local 

Classes i and j 

Remote ! Fa- 

1 

0 

10 

4 

0.85 

0 

8 

7 . 

0 

1 

100 

16 

0.80 

0 

190 

20 

0 





1 

50 

20 

0 

2 

1000 

64 

0.75 

0 

500 

50 

0 





1 

1200 

100 

0 





2 

200 

40 

0 

3 

10000 

256 

0.10 

0 

300 

50 

0 





1 

250 

100 

0 





2 

10250 

150 

50 





3 

200 

150 

100 


Table 6: Parameters of Internetwork 3. 


Scheme 

No query needed 

Candidate Paths 

Candidate Superdomains 

child-domains 

142 

3.99/29 

7.70/43 

sibling-domains 

142 

2.95/10 

5.39/22 

leaf-domains 

142 

9.65/70 

18.99/103 

regions 

676 

3.47/17 

6.25/21 


Table 7: Queries for Internetwork 3. 


207 



















































































Initial 

view size 

Merged view size 

Scheme 



in sd-gateways 


child-domains 

2160/2239 

43/60 

2354/2647 

107/348 

sibling-domains 

2365/2504 

72/101 

2606/3314 

148/356 

leaf-domains 

2159/2236 

41/58 

2386/2645 

160/648 

regions 

1107/1644 

110/231 

1850/3559 

194/436 


Table 8: View sizes for Internetwork 3. 


1 


* 




208 


1 



























Variables: 

View x . Dynamic view of x. 

WView x (djiddress). Temporary view of x. djaddress is the destination address. 

"Used for merging internal views of superdomains to the view of x. 

P ending Req x (d.address). Integer, djsddress is the destination address. 

Number of outstanding request messages. 

Events: 

Requesl~{djiddress) {Executed when x wants a valid domain-level source route} 
allocate 1Wieu; r (d_adciress) := View x ; allocate Pending Req x (djaddress) := 0; 
sear ch x (djiddr ess); 

where 

search x (d.address) 

if there is a valid path to djaddress in WView x {dja.ddress) then 
result := shortest valid path; 

deallocate WVieu; x (dMddress), PendingReq x (djaddress); 
return result ; 

else if there is a candidate path to djaddress in WView x {djaddress) then 

Let cpaih = (D'o:$o 0 , • • -,Uo-9o, t , Ui:gi 0 ,.. DVsi,, i •" , U m -.g mo ,..., ) 

be the shortest candidate path; 
for U x in cpath such that U, is candidate do 

ReliableSend(RequestIVies, Ui, gi t . address(x), djaddress) to p* 0 
PendingReq x (d.address) := P ending Req x (d.addr ess) -f 1; 

else 

deallocate WVieu. r (cLaddress), PendingReq x (dMddress); 
return failure; 
endif 
endif 

TimeOut x (djaddress ) {Executed after a time-out period and PendingRcq x (djiddress) gi 0.} 
deallocate WVieu. I (<f.address), PendingReq.(djaddress); 
return failure; 


Figure 15: view-query protocol: State and events of a router x. (Figure continued on next page.) 


v 


209 




Jlece:ve r (RequestIVies, sdid,x,SMddress, djiddress ) 

ReliableSend(ReplyIVies, sdid, 2 ,/Fjein^t/^d-flcidress) to s_address; 

Receive : (ReplylVies, sdid, gid , iview, d-nddress) 

if PendingReq T (d.address) ^ 0 then {No time-out happened} 

PendingReq x (d.address) := PendingReq z (d.address) - 1; 

{merge internal view} 
delete ( sdid,*,*,») from WView z \ 
for (child, scons, wcons, gateivay-sei) in iview do 
if ->3 (child,*,*,”) € WView z then 

insert (child, scons, wcons, gaieway-sei) in WView~\ 

else 

for (gid, is, edge-sei) in gaieway-sei do 

if 3 (gid, iimesiamp, *) € Gateways&Edges s (child) A is > limesiamp then 
delete (gid, *, *) from Gaieways&Edgcs x (child)-, 
endif; 

if -6 (gid, », *) € Gaieways&Edges.(child ) then 

insert (gid, is, edge-sei) to Gcleways&Edges.(child)-, 
endif 

endif 

if PendingReq z (djiddress ) = 0 then {All pending replies are received} 

search z ( d.address ); 
endif 
endif 


Figure 15: view-query protocol: State and events of a router x. (cont.) 


I 




j 
" 1 


210 






Constants: 

AdjLocalRouters r . (C Nodelds). Set of neighbor routers in x’s domain. 

AdjForeignGateways x . (C Kodelds). Set of neighbor routers in other domains. 

Ancestor,(x). (C SuperDomainlds). ith ancestor of x. 

Variables: 

View x .. Dynamic view of x. 

IntraDomainRTs. Intra-domain routing table of x. Initially contains no entries. 

Clock x : Integer. Clock of x. 

Events: 

Receive z (Update, sdid, gid, is, edge-sei) from sender 

if 3 (gid, timestamp, *) € Gateways&Edges x (sdid) A ts > timestamp then 
delete (gid, *, *) from Gateway s&Edges x (sdid)', 
endif; 

if -> 3(gid , *, «} € Gateways&Edges x (sdid ) then 
flood : ((Update, sdid, gid, ts, edge-set))-, 
insert (gid, ts, edge-sei) to Galeways&Edges x (sdid); 
update.pareni.domainSx{level(sdid) -f 1); 
endif 

where 

updaie.parent.domains x (startinglevel) 

for level := siartinglevel to number of levels in the hierarchy do 
sdid := Ancesror/ e i/ej(i); 
if x € Gateways (sdid) then 

edge-set := aggregate edges of sdid:x using View x , JniraDomainRTs and links of x; 
timestamp = Clocks', 

flood x ( (Update, sdid, x, timestamp, edge-sei))-, 
delete (x. », «) from Gaieways&Edges x (sdid ); 
insert (x, timestamp, edge-sei) to Gaieways&Edges x (sdid)\ 
endif 

Do.Update- {Executed periodically and upon a change in lniraDomainRT x or links of x) 

update^aTentjdomainSs (I) 

Link ^Recovery. (y) {(x, y) is a link. Executed when (x,y) recovers.} 

for all (sdid, *, *, *) in View- do 

if 3s : Ancestor.-(y) = Ancestor y(sdid) then 

for all (gid, timestamp, edge-set) in Gateways&Edges x (sdid) do 
Send((Update, sdid, gid, timestamp, edge-set )) to y; 

endif 

floods(packei) 

for all y € AdjLocalRouters. do 
Send(packei) to y; 

for all y € AdjForeignGateways. A 3: : Ancestor,(y) = Ancestor] (packet.sdid) do 
Send (packet) to y; 


Figure 16: view-update protocol: State and events of a router x. 


211 









REPORT DOCUMENTATION PAGE 



* ’•wv' or' if*r *O f ««M»i 

m-c --*■ -Ntrno* r’ »“**>»*^*:*r' V-**o r^a*»©.nq t*.\ t>w 

r t*. ■»r*OOu.'Mf'\ Nrr»Kr\ D* r fnv»if lo' 

**; ) r V " C'*'" y »r3 HwC*>r* •fOufl'O'* ^'Oiffl(0J0*-0'8l 


t-orm Appro^eo 
OMB Ho 0704-01BB 


rr»*r«*>rq in||rwniO«n. ififin**; 0»l*MHKCr>. 

Q*f©»nq tn*t qwrorA m*wnr ©» #«y *wrci o* i**n 

lo' •fltO'nji'OA OpffO'Ont fcroon* l/'i JfMwyy' 

’Oi^rt (07D*-0 '88) w*\K^»qt©r. DC ^0S03 


2. REPORT DATE 

3. REPORT TYPE AND DATES COVERED 

June 20, 1994 

Technical 


V AGENCY USE ONLY (Lfjvf bunk) 


4. title and subtitle 

Hierarchical Inter-Domain Routing Protocol with 
On-Demand ToS and Policy Resolution 


6. AUTHOR(S) 

Cengiz Alaettinoglu and A. Udaya Shankar 


7. PERFORMING ORGANIZATION NAME(S) AND ADDR£SS(£S) 

University of Maryland 
A. V. Williams Building 
Department of Computer Science 
College Park, MD 20742 


9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES) 

Phillips Labs' 

3550 Aberdeen Ave. SE 
Kirtland AFB, NM 87117-5776 


DASG-60-92-C-0055 


8. PERFORMING ORGANIZATION 
REPORT NUMBER 

CS-TR 3299 
UM1ACS-TR-94-73 


10. SPONSORING/MONITORING 
AGENCY REPORT NUMBER 



12a. DISTRIBUTION/AVAILABILITY STATEMENT 


13. ABSTRACT (Maximum 200 word) 

Traditional inter-domain routing protocols based on superdomains maintain 
either "strong" or "weak" ToS and policy constraints for each visible super¬ 
domain. With strong constraints, a valid path may not be found even though 
one exists. With weak constraints, an invalid domain-level path may be 
treated as a valid path. 

We present an inter-domain routing protocol based on superdomains, which 
always finds a valid path if one exists. Both strong and weak constraints are 
maintained for each visible superdomain. If the strong constraints of the 
superdomains on a path are satisfied, then the path is valid. If only the weak 
constraints are satisfied for some superdomains on the path, the source uses 
a query protocol to obtain a more detailed "internal" view of these super¬ 
domains, and searches again for a valid path. Our protocol handles topology 
changes, including node/link failures that partition superdomains. Evaluation 
results indicate our protocol scales well to large internetworks. 



sueject terms (Routing Protocols); (Computer Network Routing Protocols 

(Computer-Communication Networks): Network Architecture and --- 

Design- packet networks; store and forward networks; (Computer 6 ' 

Communication Networks :Nerwnr'- c--p T ^r-sr^T—axnhi rrnirl - ——- ———rr—r r 

SECURITY CLASSIFICATION j 18. SECURITY CLASSIFICATION IS. SECURITY CLASSIFICATION 20. LIMITATION OF A-STRAC. 
OF REPORT OF THIS PAGE OF ABSTRACT 


Unclassified 


NS tv 7S40-Oi'2SO-SSOO 


Unclassified 


Unclassified 


Unlimited 


Sust'oa'd F^tfri 298 'Rev 2-89) 









DEPARTMENT OF THE AIR FORCE 

PHILLIPS LABORATORY (AFMC) 



30 Jul 97 


MEMORANDUM FOR DTIC/OCP 

FROM: Phillips Laboratory/C A 
3550 Aberdeen Ave SE 
Kirtland AFB, NM 87117-5776 

SUBJECT: Public Releasable Abstracts 

1. The following technical report abstracts have been cleared by Public Affairs for 
unlimited distribution: 

PL-TR-96-1126, Pt 1 ADB222369 PL 97-0685 (clearance number) 

PL-TR-96-1126, Pt 2 ADB222192 PL 97-0685 

2. Any questions should be referred to Jan Mosher at DSN 246-1328. 

JANET E. MOSHER 
Writer/Editor 


cc: 

PL/TL/DTIC (M Putnam) 




