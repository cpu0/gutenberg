M 7J-1 lb52 


(N4$A-CK-l/37tflH) CONTINUATION Dr OFStA'-'CH 
[NTH LANOUA3- CONCEPTS f V> TH“ -- J I S ? I 

SJPPOkT r NV I RON Mr NT Final R 'port ( SoutiivHSt 
Pyso.jrch Inst.) 306 n C6CL 0 30 

0 3/61 

CONTINUATION OF RESEARCH 
INTO LANGUAGE CONCEPTS FOR 
THE MISSION SUPPORT ENVIRONMENT 


line I d s 
0033010 


FINAL REPORT 


NASA Grant No. NAG 9-435 
SwRI Project No. 05-3531 


Prepared for: 

NASA 

Johnson Space Center 
Houston, TX 77058 


Septembers, 1991 



SOUTHWEST 

SAN ANTONIO 
DETROIT 


R ESEARCH INSTITUTE 

HOUSTON 

WASHINGTON.DC 




SOUTHWEST RESEARCH INSTITUTE 


6220 CULEBRAROAD • POST OFFICE DRAWER 28510 • SAN 


ANTONIO. TEXAS. USA 76228-0510 • (512) 684.51 1 1 - TELEX 244846 


September 10, 1991 

Ms. Maryland Edwards 
NASA-Johnson Space Center 
Building 12, DJ23 
Houston, Texas 77058 

Subject: Delivery of Final Report for the Continuation of Research Into 

nguage Concepts: NASA Grant No. NAC9-435; SwRI Project 05-3531 

Dear Ms . Edwards , 

Languag^^cn^ep^s^re^a^ch ^rant Research Into 

contains a summary of the ef fort’s lilf T l 5 ‘ ^ final re P ort 

report contains the MWng section" ° n ^ ^ ^ “ nal 

conS i^r ^st °sLt„ "/the fr„ r al 0r "; d „rr tis^V’ 

T^lLuT^Tont^n 6 T* r * ted “ 8— - included in 

Prototype doc^ts andthe Ari„vrcr,»r i ™% Gr * PhlC '“ 1 Ct> "’ P 

iu cne Aaa investigation documents are included. 

LnSL^Pro^ot^e^ls'^nc^eS 6 iTtheT^t" ^ T Graphical Com P 

report. included in the last section of the final 

Bartoi^r<5?r522 5 :3So St ir n Dr 0r st 0 ™ en i S ’n P Jr Se ^ P ° <=*“ «- 

, or Dr. Steven W. Dellenback at (512) 522-3914. 
Sincerely, 

y&y Melvin A. Schrader 
0 Director 

Data Systems Department 

TJB : vc 


Enclosures 


cc : 


Susan B. Crumrin e 
Timothy J. Barton 
Steven W. Dellenback 

NASA Scientific and Information Facility (2 copies) 



SAN ANTONIO, TEXAS 

HOUSTON. TEXAS • DETROIT, MICHIGAN • 


WASHINGTON. DC 




SOUTHWEST RESEARCH INSTITUTE 
Post Office Drawer 28510, 6220 Culebra Road 
San Antonio, Texas 78228-0510 


CONTINUATION OF RESEARCH 
INTO LANGUAGE CONCEPTS FOR 
THE MISSION SUPPORT ENVIRONMENT 


FINAL REPORT 


NASA Grant No. NAG 9-435 
SwRI Project No. 05-3531 


Prepared by: 

Timothy J. Barton 
Jeremiah M. Ratner 


Prepared for: 
NASA 

Johnson Space Center 
Houston, TX 77058 


September 5, 1991 


Approved: 



Melvin A. Schrader, Director 
Data Systems Department 



Table of Contents 


1.0 Introduction 

2.0 Graphical Comp Environment Concepts 2 

2.1 Graphical Comp Builder Prototype Specifications 2 

2 .1.1 Graphically Represented Comps 2 

2.1.2 Graphical User Interface 3 

2.1.3 MO AL Language 

3.0 Graphical Comp Builder Prototype Development 4 

3.1 Graphical Comp Builder Prototype Documentation 4 

4.0 Investigation of Ada for Control Center Software 6 

4.1 Ada Investigation 6 

4.2 Investigation and Comparison of Ada and C 5 

5.0 Appendix A - Graphical Comp Environment Design Specifications 

6.0 Appendix B - Graphical Comp Builder Prototype Documentation 

7.0 Appendix C - Ada Investigation 

8.0 Appendix D - Comparison of C and Ada Programming Languages 

9.0 Appendix E - Hartstone Benchmark Results 

10.0 Appendix F - Graphical Comp Builder Prototype Source Code 


Page i 


Final Report 



1.0 Introduction 

Southwest Research Institute (SwRI) was awarded a grant by NASA- Johnson Space Center (JSC) 
to perform research in the area of Specification Driven Languages (NASA Grant NAG 9-339) The 
purpose of the research was to investigate alternative programming techniques/concepts which 
could be utilized in control center software development environments. At the conclusion of the 
Specification Driven Language Grant, a follow on grant (NASA Grant NAG 9-435) was awarded 

to further pursue Specification Driven Languages and to prototype the concepts investigated during 
the previous grant. 6 


This final report is a summary of the work completed under the follow on grant. In 
grant has focused on the following areas of research: 


summary, the 


A concept for a more intuitive and graphically based Computation (Comp) Builder was 
developed. This concept is the result of knowledge gained during the previous grant and 
research performed on the current grant. This concept is described in a document 
enuded Graphical Comp Environment Concepts and Prototype Design 
Specifications and is contained in Appendix A. b 

The Graphical Comp Builder Prototype was developed to demonstrate the concepts 
which were researched during the early phases of this grant. The Graphical Comp 
Builder Prototype is an X Windows based graphical tool which allows the user to build 
Comps using graphical symbols. The prototype allowed NASA users to become 
amiliar with the new concepts and allowed the research team to gain feedback on the 
viability of the new concepts. 

Investigation has been conducted to determine the availability and suitability of the Ada 
programming language for the development of future control center type software The 
Space Station Freedom Project (SSFP) has identified Ada as the desired programming 
anguage for the development of Space Station Control Center (SSCC) software 
systems. The Department of Defense (DoD) has mandated Ada as the programming 

language for all new DoD software. Due to these mandates and related directions within 
private industry, an investigation of Ada was necessary. 


The results of the research areas described above 
appendices of this final report. 


are contained in the following sections and 


Page 1 


Final Report 


Graphical Comp Concepts 


2.0 Graphical Comp Environment Concepts 

One of the main goals of the research grant was the development of concepts for a more graphical 
means to represent comps. Most comps are constructed from engineering diagrams and flow charts 
which describe the system to be monitored. These engineering diagrams and flow charts are very 
graphical in nature. Using existing control center software, these engineering diagrams and flow 
charts must be manually converted into textual algorithms. These textual algorithms are then 
manually entered into the comp builder software. 

A concept of a software system was developed as part of this research grant which would allow 
comps to be entered into the comp builder software in a manner which more closely matches the 
engineering diagrams and flow charts used to describe the systems. This allows comps to be 
constructed in a more natural and direct fashion, and more accurately due to the removal of the 
manual conversion from a graphical representation to a textual representation. The Graphical 
Comp Environment Concepts and Prototype Design Specifications are included as Appendix A of 
this final report. The Graphical Comp Environment Concepts and Prototype Design Specifications 
contain a concept for a Comp development, maintenance, and operations environment which is 
more graphically based than existing textually based environments. 

A prototype demonstration of portions of the Graphical Comp Environment Concepts has been 
completed. The Graphical Comp Builder portion of the Graphical Comp Environment has been 
prototyped and demonstrated to NASA. The Graphical Comp Builder portion of the concept 
determines how the formally textual comps will be graphical represented. The Graphical Comp 
Builder portion of the environment is also the least dependent on the facilities provided by the 
underlying hardware and operating system software. The Graphical Comp Execution Environment 
is very dependent on the underlying hardware and operating system software, so this portion of the 
concept was not prototyped. 

2.1 Graphical Comp Builder Prototype Specifications 

The Graphical Comp Builder Prototype Specifications were developed to guide the development 
of the demonstration prototype. The knowledge gained on the prior grant during the review of the 
Computation Development Environment (CODE) influenced the development of the Graphical 
Comp Builder Prototype Specifications. This knowledge was used to ensure that the specifications 
identify a software system that is relevant and applicable to a control center environment. 

The concepts demonstrated by the Graphical Comp Builder Prototype are a departure from the 
textually represented comps. The initial phase of the research grant included an investigation into 
the various methods available to graphically represent information similar in nature to the data 
contained in the engineering diagrams and flow charts used at NASA. 

2.1.1 Graphically Represented Comps 

A portion of the research performed on the grant has been in the area of graphically representing 
data. Numerous software packages were investigated to determine the currently available 
strategies for representing data similar to the engineering diagrams and flow charts used by control 
center personnel. Each software package was installed at SwRI and exercised for several days so 
a thorough understanding of the mechanisms used to graphically represent data could be assessed. 
Once the package had been exercised and evaluated, a review of the graphical representation 
mechanisms was developed. 


Page 2 


Final Report 



software U pack^ag^raneed 8 fr WCre ° btamed and exercised during the investigation period. The 
inexpensive IBM PC prograi^s m TreTe C sori PleX 3nd expensive UNIX work station software, to 

function, but all utilized fsn-anhi™? software Packages were often very different in nature and 
included: mea " S t0 repreSent data ' Some of packages investigated 

flow chart generation packages 
microwave circuitry design/simulation packages 
schematic design/drawing packages 
PC board layout packages 
graphics drawing packages 

a review of each package was developed. Packages 

or because of their gross ineffectiveness were°id C fif- e * n representing graphical data 

NASA during a visiuo S^I » A ”g 0 » 3 " ^ dem °" st ™ d » 

2.1.2 Graphical User Interface 

Bdi ' d “ ^ was the 

previous gran, had determine ,ha,t?n fhouuh CODF? ? GUI wi ' hin the *°«»‘ype. The 
always intuitive or easy to use. The X wind™ USed j mouse 30(1 graphics, it was not 
improved the GUI of CODE so it was h ■ prot ° types developed on the previous grant 
Graphical Comp Butider Ze T* ^ ^ l ° USe ‘ ^ dev elo P ment of the 

efficient user interface was Specified. SpCClflCatl0nS atterapted » « that an intuitive and 

strategies, als^prov^ f to ^ dentif y ^phical representation 

GUI which would benefit the Graphical Como BuilderP^ 3 Gl !L aild the mech anisms of each 
of each package were recorded sotite most desirable feat °T' ^ strengths and weaknesses 
for use in the Graphical Comp Builder Prototype if appropriate ? ^ COUld * Spedfied 

-ftware packages were also demonstrated 

2.1.3 MOAL Language 

- rSSSS' AS * -“>• of ^ research 
Application Language (MOAL) was developed Th^nTu^ 6 " 12 ' 1 '? 1 7 ,he Misslon Operations 


Page 3 


Final Report 



Prototype Development 


3 0 Graphical Comp Builder Prototype Development 

SSSSrssS ssskss;-- s= 

implementation of the Graphical Comp Builder Prototype was begun. 

BBSS®! 

iL Graphical Comp Builder Prototype was developed in the C language on UNIX-based Sun 

mmn ^ n? to become the industry standard. The research team was able to assess the strengths and 
weaknesses of both GUI’s during the development of the Graphical Comp Builder Prototype. 

The MOTIF version of the Graphical Comp Builder Prototype has been completed^ 

demonstrated to NAS A- JSC. A complete listing of the C language source fo j; 

version of the Graphical Comp Builder Prototype is included in Appendix F of this final report. 

3 1 Graphical Comp Builder Prototype Documentation 

A discussion of the implementation of the MOTIF version of the Graphical Comp Builder 
Prototype is contained in the Graphical Comp Builder Prototype Documentation. The Graphical 
Comp^uilder Prototype Documentation was developed to provide information about the 
following aspects of the Graphical Comp Builder Prototype: 

. The major concepts of the Graphical Comp Builder Prototype are identified ^and l their 
implementation within the Prototype are discussed in the first section of the Grap 
Comp Builder Prototype Documentation. This section discusses the graphical nature of 
the Prototype and also discusses the Comp hierarchy, report generation, and automatic 
code generation features of the Graphical Comp Builder Prototype. 

. A more complete list of the various features contained within the Graphical Comp 
Builder Prototype are contained in the second section of the Graphical Comp Bu 
Prototype Documentation. 

. The third section of the Graphical Comp Builder Prototype Documentation contains a 
brief discussion of the implementation of the Prototype. Thts section i ldenti tes e 
module hierarchy, data files, and data structures of the Graphical Comp Builde 

Prototype. 



^Graphical Comp Builder Prototype Documentation i 


Prototype Development 


is contained in Appendix B of this final 



Final Report 



Investigation of Ada 


4 0 Investigation of Ada for Control Center Software 

DoD software. Therefore, a preliminary mi/estigauon in performance 

Builder was conducted. Initial investigation into Ada s acceptance at 
of a program written in Ada are the two areas of investigation to date. 

^^‘“rinvesugauon imo Ada ^ to 

at the NASA Ada User ’ s Symposium is contained in Appendix U 

The second step in the investigation of Ada focused on the rc ^ ve ^ rf “ Q “ ^SkTas 
contained in Appendix C. 

4.2 Investigation and Comparison of Ada and C 

NASA is about to embark on the development of millions of lines of software for the SSCC and 
Thfspa« Son Training Facility (SSTF). Most of the P— f or^S( : have been 

written in the C or FORTRAN programming languages dmn| tejat “ in 

htfsil: alptanc e of the C progranunrng 

Tand 8 Ada programing lT~op ’ Jilts of £ 

investigation were presented to NASA-JSC on Marcn 8, vrti. « ^ n 

investigation are contained in Appendix D of this final report. 



SOUTHWEST RESEARCH INSTITUTE 
Post Office Drawer 28510, 6220 Culebra Road 
San Antonio, Texas 78228-0510 


GRAPHICAL COMP ENVIRONMENT 
CONCEPTS AND PROTOTYPE 
DESIGN SPECIFICATIONS 


NASA Grant No. NAG 9-435 
SwRI Project No. 05-3531 


Prepared by: 
Timothy J. Barton 
Jeremiah M. Ratner 


Prepared for: 
NASA 

Johnson Space Center 
Houston TX 77058 


January 28, 1991 


Approved: 



Melvin A. Schrader, Director 
Data Systems Department 




Table of Contents 


1.0 


2.0 


Purpose 


Graphical Comp Builder Prototype Specifications ... 

2.1 GCB Feature Specifications 

2.1.1 Graphical Interface 

2.1.2 MOAL Support 

2.1.3 Report Generation 

2. 1 .4 Graphical Representation of Logical Expressions .... 

2.1.5 Comp Executer/Debugger 

2.1.6 Library 

2.1.7 Macro 

2.1.8 MS ID Selection 

2.1.9 Operating System Shell 

2 . 1.10 Command Line Comp Specification 

2.2 GCB User Interface Specifications 

2.2.1 Graphical Symbols 

2.2.2 Expression Builder 

2-2.3 Graphical Symbol Placement Model 

2.2.3. 1 Grid-based vs. Cell-based Placement 

2.2.4 Graphical Placement Model Design Specification 

2.2.5 Popups and Text Helds 

2.2.6 Symbol/Work Area Manipulation Functions 

2.2.6. 1 Select Symbol 

2.2. 6.2 Connect Symbols 

22 . 6.3 Move Block 

2.2.6.4 Delete Block 

2 . 2 . 6. 5 Delete Symbol 

2.2.6.6 Delete Line 

22 . 6.1 Undo 

2.2.6.8 Print 

22 . 6.9 Select Font and Symbol Size 

22.7 Mouse Function S ummar y 


IM I X 

..-2 

3 

3 

3 

.....3 
3 

4 

.....4 

.....4 

....4 

....4 

....6 

....6 

....7 

....8 

...8 

...9 

...9 

...9 

...9 

.10 

.10 

.11 

.11 

.11 

11 

11 

12 



2.3 GCB Environment Specifications 

* 13 

2.3.1 Software Environment 



2.3.2 Hardware Environment .... 

i3 

2.4 GCB Prototype Design Specifications 

2.4.1 GCB Data Structures .. 

* 

2.4. 1.1 Comp Status Structure 

2.4.1.2 Work Area Cell Structure ••••14 

2.4.1.3 Symbol Structure 

2.4. 1.4 Line List Structure ^ 

2.4. 1.5 Line Map Structure ••••—..17 

2.4. 1.6 Line Cell Map Structure ^ 

2.4.1.7 UNDO Stack Struc tur e —17 

2.4.2 GCB Data Files 17 

2-4.2 . 1 Graphical Comp Hie 18 

2.4.2.2 A SCII Comp File ^ 

2.4.2.3 Comp Library 

2-4- 2.4 Workstation Global Table 

2.4.2.5 MSID Table 19 

2.4.2.6 User Macro Files 

2.4.2Z7 User Configuration Hie * 9 

2.4.3 GCB Module Hierarchy 


19 


20 


Graphical Comp Environment Specs 



Purpose 


1.0 Purpose 

ss" !Ss£S^“ *■ FF 

*' completed Graphical Comp Environment concept and proto^es wffl ^v™ 5 * 

The prototype Design Specifications will be broken into the following major sections: 

Graphical Comp Builder Prototype (GCB) 

Graphical Comp Compiler Prototype (GCC) 

Graphical Comp Execution Environment Prototype (GCEE) 

The Graphical Comp Environment will require all three of the ahnv* j 

complete and functional system. Each pan will be a separate anH ; ? Cd parlS 10 ** a 

will be designed to operate with the othe^o. * independent P"*™®, but each 

^tion^to^^^)^^S U r W U T “ ■f aphically build “ d fault 

Graphical 0 " P Comp,ler wiU in P“< information from the 

.He "Graphical £££* * 

Env_, Prototype will contio. the execution of the fa^,, detecnonXmhn^^u“e 

be used during flTgl^pSi™^ Prototype wiU 

be used off-line during development mnHe ^? P udder Protot ype and Compiler wiU 

Compiler each can be® 

Environment witi requne executable Comps produced by tire ComS'myp ' EX ' CUti °" 


Page 1 


Graphical Comp Environment Specs 




2.1 GCB Feature Specifications 

The Graphical Comp Builder Prototype will provide a number of features to allow users, such as 
flight controllers and engineers, to very easily design and document fault detection algorithms. 

he number one goal of the Graphical Comp Builder Prototype is to be a tool which is easy to use 
yet contains the elements which are necessary to build fault detection Comps. Many of the features 
specified address the ease of use goal. 

The Graphical Comp Builder Prototype will also contain several features designed to aid the Comp 
implementor in the development of Comps and their supporting documentation. Some of these 

eatures include: a Comp Executer, path generator, and a graphical means to view logical 
expressions. 6 

2.1.1 Graphical Interface 

The Graphical Comp Builder Prototype will use a set of graphical symbols to represent the 
algorithms which are needed to perform fault detection and notification. The graphical nature of 
the Graphical Comp Builder Prototype will make the tool easier to use than existing Comp 
builders. The graphical interface specifications are discussed in their own section due to their 
importance to the success of the entire Graphical Comp Environment. The graphical interface 
specifications are contained in Section 2.2 on page 6. 

2.1.2 MOAL Support 

^ P A f^ COmp B “ ilder Protot yP e wiU aUow the user to construct Comps which are based on 
r -u ^ (Mission Operations Application Language) constructs as identified in the Comp 
Builder / Comp Manager Level B Requirements (JSC-23459). The MOAL language has been 
speci led by JSC flight controllers. The MOAL contains the language elements required by flight 
controllers to perform fault detection algorithms. 4 Y gm 

2.13 Report Generation 

The Graphical Comp Builder Prototype will provide several repons to document the developed 
graphical Comps. The Graphical Comp Builder Prototype will generate a listing of 
inputs, outputs, and possible test cases. The Graphical Comp Builder Prototype will also generate 

Di3?d hv?h^ 8 h al80rl ‘ hms co " tai,,ed in the Comps. The algoriihm descriptions will be 
provided by the user dunng the specification of DECISION symbols. 

The Graphical Comp Builder Prototype will generate a repon identifying all possible execution 
paths through each Comp. This repon may grow to be very large depending on the size of the 

h Se i| W1 n °, Ufied dunn S the P ath generation process as to the number of paths. 
The user will be allowed to abon the path generation process. 

2.1.4 Graphical Representation of Logical Expressions 

The Graphical Comp Builder Prototype will allow the user to select a DECISION symbol to be 

DFrrsTnN reP T, n K f “ nc,i ° n w, “ allow ,he user 10 s “ th = express™ of the 

DECISION symbol to be graphically represented. The logical operators will be represented as 

grap teal symbols This function will allow the logical expressions of DECISION symbols to be 
vtewed in terms of AND gates and OR gates in a graphical manner. The graphical representation 
of logical expressions may be viewed or printed only. The logical expression cannot be modified 
or maintained by the graphical representation. 



PRECEDING PAGE BLANK NOT FILMED 


Graphical Comp Environment Specs 



2.1.10 Command Line Comp Specification 

The Graphical Comp Builder Prototype may be initially executed with a Graphical Com D name 
specified as an argument to the Graphical Comp Builder Prototype program.^ the event that a 

W ^ the Graphical COmp BuUdK P “»we wiU load Comp i„,o the 


Page 5 


Graphical Comp Environment Specs 

PRECEDING PAGE BLANK NOT FILMED 



2.2.2 Expression Builder 

Mde^otTe XT^utrle^ Wlthin lhe Graphical Comp 

either a DECISION or SET symbTthe u S £ vSl W T •° r a f T SymboL U P°" selecting 
a popup using the keyboard and having the expression narJS'T 5 ' !) . typmg 1116 ex P re ssion into 
mouse-driven menu and having the choices for onemr P a ^ U 1S Completed ’ or 2) using a 
the input process. The second^ethod wiU be aWHri!!? ° I J er ^ constrained at each step in 
udder in the various versions of the Comp Builder The aranhicai t0 6 raouse ' driven expression 
by the Expression Builder. The fust action perforae^w^ l “^.“Pnaaon buUder will be called 
bow the expression must be completed. If the u”r setoS B '"“ U,g “ expression "iH determine 
usmg the mouse, then the expression must be conroieted ken &om die Expression BuUder 
BuUder. If the user begins typing in an ^ “ SUlg the mouse “<* die Expression 

the keyboard. The user will be given the option o^ahorri* Pre h SK> n m “ SI ** cora P ie ted using 
expression. After the expression budding is aborted the nil ?, | UlJding of “ incomplete 
the expression with the other mechanism or of starting a newexnress ^ 'll' ° P ' i0n of 1 build ing 

nte benefit of this approach is that the user who does „o. need A 7 “ mechanisni - 

expressions quickly, but without immediate emS^ guidance of the editor may input 
build bod, Comps and the expresst^lTcom^f • Whl1 ' novi “ wi “ be abfeto 

of expression buUding wUl ensure that only logicSv sounded" 101 "* <Wv '" racnus - BoIh racMS 
are entered. The Expression BuUder wiU step 8 the user thromd.T^'l'^’' COtTeCI ex P res sions 
operands and operators in a way that is svntacucallv ^T? ,? ! “‘““on of the expression 
more details.) The keyboard method will au ensTl ,hT “ ' M0TIF Com P BuUd «- for 
parsing the expression after the user has completed tvni7Tr COrrec * Comps are built by 

The user will also hav, ,h. , P typing the expression into the popup. 

expression. The logical form, if it° app^nme ' l XpreSsion as wel1 as the Comp 
f h logical foim is not entered bv the user then the r- h “botnauc in place of the Comp 

•he DECISION symbol. The logical fotm win not t l 75 P eXprcssion will be displayed in 
Expression Builder. The logical form is provide^so the mefcnn h^ " '* const ™ c ‘ ed using the 
easier to understand and are independent of the i-, 6 USC buiId ^ a P hlcal comps which are 

“ * Comps to be cSSmS? *e execute Com" 

ZttSSK ,he 

at this Pp^o^this may alS ° bC emered 

a much larger text field than either the logical or comn ev ^^Documentation field will be 
be available so the Comp builder can document the aleoriS^"* ^ Documentation field will 
Documentation field will be included in the Hoc, g hms ln a completely textual form. The 
Builder Prototype. ln the docum ^tauon produced by the Graphical Comp 

2.2.3 Graphical Symbol Placement Model 

menu a ^Phical symbol from a 

emplate, and drag or place them in the desired location in the ^ COmponems from a menu 
placement model, the way in which ?J£~« 


Page 7 


„„„„ Graphical Comp Environment Soers 

PRECEDING PAGE BLANK NOT FILMED ^ 




2.2.5 Popups and Text Fields 

infbrmadM ,o User MdT” n ' CCSSary '° in P“' or display 

editing fu„ CIi011s to provide a user-friendly ttd conristeroT, rf' ’"“S’" 1 0p " lLook «*« field 
funcnons will be available in all text edit fields: C ° nSIStent lnterface - The following text editing 

* Home and End keys 

* Insen and Delete keys 

All other traditional OpenLook text *,1;, f 

positioning of the text cursor unctions, including mouse controlled 

2_2.6 Symbol/Work Area Manipulation Functions 

te & Zr Cread “ ° f 0p ' ration d »ng the course 

fissr. - * - -“-^srsss rjsrjrsz 

^rn,^ra^^trr^ u — • «»». b u„o„ 

•yptcal sequences which illusuate the user “f - - 

Edit Mode : 2 ft! “ MOdC > MOV ' S ^‘ •> Mode 
Mode > Add S y mbo1 -> CANCEL -> Edit Mode 

In both cases, the user is returned to Edit Mode. 

functions aUow ““ser ro add fymT™conn la's ymtol Perf ° med °" the f^phical symbols. The 
the acuve Comp. a. connect symbols, and in general maintain the Symbols in 

2. 2.6.1 Select Symbol 

The Select Symbol function will nllnur rh» 

current Comp and will allow the user to ^aceThVsefeaed s Symboi “ ** added ® *0 

seta a symbol from the avatlable symMs by pLtTfhf “ ^ Work ^ ^ user w, 11 
clicking with the left mouse button. The selected Z!, ,,T“ P 01 "® over ,hc symbol and 

r°-'n.o,he worl: area. an outline of the symbol will tw, hlghll 8 hted - As the pointer 

the symbol. The symbol will be placed whpn »L • ? highlighted, allowing the user to place 
user can abort the symbo, m ° S ' ” 0 ““ 

h tung the ESC key. The user can also abon toe S s tL r U "° n 0U,Side Ihe work ““ or by 
buuon on die CANCEL button in ,he sutms a^a ^f Uncd0 " by Poking, the left mouse 
formation from the user, a popup will be disDlavni • placcd s ynbol requires additional 
been placed by die user. P P * dlSplayed ln Ihe “ork area after the new symbol hal 

2.2.6.2 Connect Symbols 

The Connect Symbol function will aiinui ,u 

“ nct,on w,u b= by 

Page 9 


Preceding page bi/imk *ir-r C ° Mp s P ew 



2.2.6.5 Delete Symbol 

aid exiling the” ; lymtaLT^ Del'emS^m tolfScdon ' ^U^^* y £ b ° l and 111 lines cnM ™8 
After selecnng Delete Symbol torn die Edit MoSe mel tt from ,hc “ Mode menu 

by clicking the left mouse button on any cell allocated , o' fs^r” 3 Symbo1 for deledo " 

status area or b^h ESC^y ‘ f “” Cli ° n “ a " y SMp by clickin « "» CANCEL button in the 

2.2.6.6 Delete Line 

Delete Line tocdM^bTlv^abTe fr^Te eidSting logical con "ecting line He 

Edt. Mode by choking the ^ “““ -? also be avaitabfedmSg 

If the user selects a line ,h,,„ " S,uft kcy ls depressed. 8 

an unambiguous segment S“ “d" ° ne - — * * be asked to select 

itanjs tucaor" by^hdng' £Sc^. taedon 31 Itoe by clicking die CANCEL button in d,e 

2. 2. 6.7 Undo 

s sssss ns SKresys r 
xzixssr ■ ■ - "■ “ • ~ 

2.2.6 .8 Print 

Graphical Comp Builder 

ou V u. may appear on a ptanrtr*^^^^^^ - page P sL, s oZ £ 

^ fo“ a^S^n mf N ™ ^ ^ See ls What You 
8 1«" X T,~T CM f er ' If ,he defauJt P a P CT size ^,."^ ^ W ‘ a °P' rat<! similar to the sheet 

e^'dbe^ slae^ill notaffeef the 6 a^pearatme of tl^ “T 

xtenci beyond the work area window, Ind the user mavT* ^ the virtual work area will 

different sections of the schematic in the wo^aJea^dow "°" the work ™ <o Z “ 

2.2.6.9 Select Font and Symbol Size 

that changes' fon a “L wduS 'dte : op,S„t m chan° f 'T 60 '* ** ‘ he f ° ms ° f 'ext. The funcuon 
Sizes, or only the font size of the cuirendy selected svmhof I sym , bolfont siz “. all new symbol font 

SI. ■be'svmbol^ose ^ Z°,t ToT '"^^ ““mhi font sTrn 

be changed, and a popup window will accept "he new font sTzf “ ^ ° " ,he « 


Page 11 


Graphical Comp Environment Specs 

PRECEDING PAGE BLANK NOT FiLMED 



2.3 GCB Environment Specifications 

GrapWcai eomp Euiider Prototype must be available to as many potential users as possible 
These potential users have a varied assortment of computer hardware available on which to run the 

Graphical Comp Btulder Prototype, so the Graphical Comp Builder Prototype will be written m as 
portable a way as is reasonably possible. 

2.3.1 Software Environment 

The Graphical Comp Builder Prototype will be written initially in the C programming language 

P^Iot^J t ° I SUpply f d controI the interface. The GnpSSp b2t 

Prototype will be implemented eventually in the Ada programming language when support for X 

Widows .^available for Ada. OpenLook will bathe iarge^Zdows bu,T d«ta 

r M* c a * ^ 0mp Prototype will not preclude a conversion to the MOTIF widget set 

to meet NASA’s current and future usage requirements. Wldget set 

2*3.2 Hardware Environment 

TTie Graphical Comp Builder Prototype will be implemented initially on UNIX-based Sun SPARC 
Stations. As with any X Windows based application, the client ponton of the appTcauonwd *e 
X server may reside on very different hardware platfonns as long as a network connects the^Zr 
and client. Any hardware platform that supports an X Windows server will be sufficient for the 

^^“forTZ 0 ' T ^““P Builder Prototype. Any UNK-based corner 
ill be sufficient for the client pomon of the Graphical COmp BuUder Prototype The client and 

semr pornons of the application may res.de witWn the same host. orTey may reside on v^ 
ddiferent hardware platforms as long as both are connected via an X Windows compatible netwotk 

“et empire a pc — — • - 


Graphical Comp Environment Specs 

PRECEDING PAGE BLANK NOT FILMED 




comp_create_dateO » 
c °mp_create_time[] , 
comp_update_date Q , 
comp_update_time[] , 
comp_purpose[]; 

) 

2.4.1.2 Work Area Cell Structure 

wtocli wUtoot temiWerathe w °* ““ ‘" IO a numbCT of small ceUs 

The Graphical Comp Builder Prototvoe will b \“ S ' d ln “ n,a11 !' “ mi “ a 8e the work area, 

bitmap will identify which type of construct i, m ?“ a blt ™P of I 1 ' cells m the work area. This 
empty, contain a toe, contra porton“ a L °S CaCh «"■ EaCh «" ca " 116 

wU, not be dynamically allocated, so the strucrure sire 

TTm fotowtng ts the ceU map sducture which wiU be used to identify each cell in the work area: 

/* if -1, free cell, otherwise type indicator */ 


mt 

union 


cell_type; 

{ 

Symbol * symbol; 
LincList *lines; 

} cell_entry; 


/ if -1, free cell, else index into symbol map*/ 

/* linked list of lines - cell may be pan of >1 line*/ 


The following stacdcally sired and allocated array of cell map strucutres will be maintained- 
struct Cell cell_map[MAX_ROWS*MAX_COLS}; d ‘ 

2.4.1.3 Symbol Structure 

ldendf^di the^ s^ctoM^omain^^^thc work^^e^ “S* Symb01 structures whi ^ will 
type, its location in the work area, any connectivity 1 ^ s1 ^ ua Wl11 ldentif y the symbol 
information. The symbol structures Jill be dynaiJicallv^!^^^ ^ 0ther su PP ortin & 
Graphical Comp Builder Prototype. y located dunng the execution of the 

to the 5 " different symtoU^^e DECISION wmW '° 'J? en,ify the mforn,a,lon ^at Is specific 
TRUE and FALSE parts, whereas the ,he ‘“Sical express.ons and 

structure will be usei m idendfy each ^ «• Allowing 

struct Symbol { 


int symbol_type; 

int height, width; 

int ulcx, uicy; 

LineList *from_lines; 


/*identifies the type of symbol*/ 

/*size of symbol in cells*/ 

/ upper left comer x and y coordinates*/ 
/*list of lines entering symbol*/ 


Page IS 


Graphical Comp Environment Specs 

PRECEDING PAGE BLANK NOT FILMED 




GCB Design Specifications 


2.4.1.4 Line List Structure 

The Line List Structure will identify a list of lines. The Line List will tv> • * 

Line List Structure will be used to idenrifv rh^ Uct r . . Wli ^ used 111 two ^stances. One 

Line Us, Structure wiT te u£l t T a work area celL A second 

dynamically allocated linked list structure of die line Us*t wiU be used in nl^ *?* SJmb0i ' 11 * 
anay. This wiU reduce the size of die Cell Map Structure and SBlt,<:iUly 

struct LineList { 


LineMap *line; 

LineList *next; 


/* index into line map */ 

/ next line for same cell or symbol */ 


2.4.1.5 Line Map Structure 


The Line Map Structure will identify each logical line The Line 
symbols connected by the line, and will point To a Lfae CeU Ma 
work area cells used by the line. P 


Map Structure will contain 
Structure which will list all 


the 

the 


struct LineMap ( 
LincCellMap “Mine; 
int from, to; 

) 


/♦list of line cells*/ 

/* indices to symbol map */ 


struct linestruct linemapfMAXLINES } ; 
2.4.1.6 Line Cell Map Structure 


The Line Cell Map Structure will identify all the work area crti« u 

ceu Map - - * ^ by * ** 


j 


int cell_row, cell_col; 
LineCellMap *next; 


/* cell map indicies */ 

/* pointer to next cell map entry */ 


2.4.1.7 UNDO Stack Structure 

The UNDO Stack Structure will main tain a Her nf tv,® i 

stack will allow the user to “undo” certain operations ° peratlons P erforme d by the user. This 


Page 17 — — 

preceding Page », a Grap Comp Environment Specs 

PAGE eu »NK NOT FILMED 




Th . — — — — — — _ Design Sp ecifications 

inidal CompZib 

- ‘" 4 - 2 - 4 Workstation Global Table ™ 

contain die names t^^rwWc^ 0 ^^ 0 " G1 ° bal TabIe ' This file will 

applications by the Graphical Comps. ^ ^ h WlU ^ out P ut to other workstation 

2*4.2 «5 MSID Table 

execution of ^ ** f“ retrieval of data values and the 

Prototype will inrdally stul nZ GrapUcal Com P Builder 

Mhto 

“ SmS ' TO ' “® - «*— - available 

^ h, 4r“a^eM°n: MS^Zabt To ^ ° raphicaJ Co ”P Builder 
frequendy by the user. SID “ ble 10 ,dra “ f >' "* MSID’s that are used most 

2A.2.6 User Macro Files 

W,U <T * Graphical Comp 

for macro files initially will be the GCB directory huheustt^shn° d ^f ct0 G r ‘ default directory 

path may be modified and the new pad, may Z recorded ; „ 1 tU ? C “ >,y ' The macro directory 

flies wdl have the following extension: * MAC ^ user s configuntdon file. Macro 

2A.2.7 User Configuration File 

The user* will ha^Te optoZoS^'hTu^sted coS?" ° t lNtm:s that “* “ s « configurable 
nrne the Graphical Comp Builder Profo Z e ^^T" 00 ‘° * which is accessed every 
U. the GCB directory in the user’s homeXectory and^h'avf^M ' W "' be srarcd 

nc m ° Wing ° pd0ns *^1 be stored in the User Configuradon Fde: ' U “ r CFG - 

be aSTa ^pS&^RIehTO^uSfcd aCCKSCd by *= us 'c *«! 

■hen the Graphical Comp Builder * e “"““d line at execution, 

accessed by the user. If the user is executing , def “ lt » last directory that was 
Ae first time, then the GDB directory of the user’Thn 1 ^^ 1 ” 13 BuiIder Prototype for 

default The default directory will be displav^d m th, WiU be used as *e 

selection. ^ 06 msplayed t0 thc u ^er dunng Graphical Comp file 

The Comp Library directory path will be one nf th~ 

configuration file. This will allow the user to place the lih° PU °? S St ° red in the user s 
* The path to the user’s m*™ n u ^ dmetor y wherc needed, 

will allow the user to plSe^ Configuration File. This 


Page 19 


Graphical Comp Environment Specs 

PKECtUiiiiu Fmu c d u.nfv ixui riu vito 




SOUTHWEST RESEARCH INSTITUTE 
Post Office Drawer 28510, 6220 Culebra Road 
San Antonio, Texas 78228-0510 


GRAPHICAL COMP BUILDER 
PROTOTYPE DOCUMENTATION 


NASA Grant No. NAG 9-435 
SwRI Project No. 05-3531 


Prepared by: 
Timothy J. Barton 
Jeremiah M. Ratner 


Prepared for: 
NASA 

Johnson Space Center 
Houston TX 77058 


August 28, 1991 


Approved: 



Melvin A. Schrader, Director 
Data Systems Department 




Table of Contents 


1.0 Purpose 

2.0 Graphical Comp Builder Prototype Concepts 

2.1 Graphical Representation of Comp Algorithms 

2 . 1.1 Graphical Symbols 

2.1.2 Logical Connecting Lines 

2.1.3 Expression Builder 

2.1.4 Work Area 

2. 1.4.1 Graphical Symbol Placement Model 
2-2 Graphical Comp Hiearchv 

2 . 2.1 Multiple Position Support 

2.2.2 Comp Structure 

2.3 Report Generation 

2.4 Automadc Code Generation 

2.5 User Interface 

3.0 Graphical Comp Builder Prototype Features 

3.1 Graphical Representation of Comp Algorithms 

3.1.1 Work Area 

3.1.2 Add Symbol 

3.1.3 Move Symbol 

3.1.4 Edit Symbol 

3.1.5 Symbol Implode 

3.1.6 Delete Symbol 

3.1.7 Connect Symbols 

3.1.8 Delete Connecting Line 

3.1.9 Move Block 

3.1.10 Copy Block 

3.1.11 Delete Block ” 

3.1.12 UNDO and CANCEL 

3.2 Position Management 

3.2.1 Select Position 

3.2.2 Create Position 

3.3 Comp Management 

3.3.1 Select Comp 

3.3.2 Create Comp 

3.3.3 Select Comp Root Element 

3.3.4 Edit Comp Purpose 


1 

2 


3 

3 

4 

4 

5 

5 

5 

7 

7 

8 

....10 

10 

10 

10 

10 

11 

11 

11 

11 

11 

....12 

....12 

....12 

....12 

....13 

,...13 

...13 

...13 

...13 

...13 

...14 

...14 


tO to 




3.3.5 Display Comp CallFlow 

3.3.5. 1 Displayer 

3.3.6 Install Comp 

3.3.7 Validate Comp 

3.3.8 Comp Report Generation 

3.4 Element Management 

3.4.1 Select Element 

3.4.2 Create Element 

3.4.3 Delete Element 

3.4.4 Save Element 

3.4.5 Copy Element 

3.4.6 Edit Element Purpose 

3.4.7 Print Element 

3.4.8 Audit Element 

3.4.9 Install Element 

3.5 Options Management 

3.5.1 Display Options 

3.5.2 Symbol Display 

3.5.3 Symbol Snap 

3.5.4 Audit Toggle 

3.5.5 Set Colors 

3.5.6 Set Target Language 

3.6 Help System 

4.0 GCB Implementation Notes 

4.1 Data Files 


....14 

....14 

....14 

....15 

....15 

...15 

...15 

...15 

...15 

...15 

...16 

...16 

...16 

..16 

..17 

..17 

..17 

..17 

..18 

.18 

.18 

.18 

.19 

20 


4.1.1 Position Directory 

4.1.2 Comp Directory 

4.1.3 Comp File 


4.1.4 Graphical Element File .. 


4.1.5 Library Graphical Element Directory 

T") 

4.1.0 Lomp Installation Files “ 

4. 1 . 6.1 Comp Header File 


4. 1.6. 2 skeleton element.o 


4.1.7 Element Installation Files 


4.1.7.1 Element C Language Source File . 



4 1 8 PnctS !n‘ LangUage 0bject File 03 

4.1.8 PostScript Files 

4.1.8 . 1 PostScript Template File 


PostScript File 

*.i.y neip 1 ext File . 



Page ii 


GCB Documentation 




4.1.10 Error Log File 

4.1.11 User Configuration File 

4.1.12 Displayer Output File 

4.1.13 User Defined Functions Directory and Files 

4.1.14 Object Access Table 

4.1.15 Work Station Global Table 

4.2 Data Structures 

4.2.1 Symbol Array 

4.2.2 Cell Map 

4.2.3 Line Structures 

4.2.4 Symbol Table 

4.3 GCB Program Flow 

4.3.1 Section 1 - Initialization 

4.3.2 Section 3 - Callback Routines 

5.0 Appendix A 


.23 

.24 

.25 

.25 

.25 

.25 

.26 

.26 

.26 

.26 

.27 

.29 

30 

30 


6.0 Appendix B 


Page iii 


GCB Documentation 




1.0 Purpose 

Pmtnf° CUI TT, nt ^ eSC u beS lhe functionalit y and implementation of the Graphical Como Builder 

and imp “ as ,he «* ° f 

• existing NASA Comp Builders 

• existing NASA high-level languages, such as UIL, GOAL, etc. 

• existing applications which manipulate graphical symbols 

^°^^^uem^mple^nta^on oHheGrapMcy^m^uil^^ototype^ 5 f ° r ^ s P ecif ’ caI ' on 

fea,u?/s d a d ,he Graphic f h Comp - Buildcr Pro,o,yi,c “ d also 

Comp Builder ^cont^eV^t^foIliw^g ^cdo^Secdon'^'o'^Hs^ l* 1 ^^* 1 * 03 * 


Page 1 


GCB Documentation 



GCB Concepts 


2.0 Graphical Comp Builder Prototype Concepts 

The Graphical Comp Builder Prototype was designed around several basic concepts to make the 
process of developing and maintaining Comp algorithms an easier and more intuitive task. This 
section describes the key concepts of the Graphical Comp Builder Prototype. 

2.1 Graphical Representation of Comp Algorithms 

One of the most important aspects of the Graphical Comp Builder Prototype is evident in the 
Prototype’s name. The Graphical Comp Builder Prototype allows the user to graphically represent 
Comp algorithms instead of using traditional text based methods. Comp algorithms are often 
designed and documented using graphical representations. Comp algorithm documentation often 
looks much like a flowchart. The Graphical Comp Builder Prototype was designed to support the 
development and maintenance of Comp algorithms using flowchart type constructs. This feature 
makes it very easy to implement Comp algorithms from design documentation and allows the 
Graphical Comp Builder Prototype user to maintain Comp algorithms using a representation that 
is familiar and comfortable. 

The graphical Comp algorithm representation supported by the Graphical Comp Builder Prototype 
is based on a set of graphical symbols and logic flow lines. The user builds the graphical Comp 
algorithm from the graphical symbols. The order of execution, or algorithm flow, is determined by 
the way in which the symbols are connected by the user. 

2.1.1 Graphical Symbols 

The Graphical Comp Builder Prototype uses a predefined set of graphical symbols to represent the 
various actions that are performed by Comp algorithms. These symbols form the basic building 
blocks of each Comp algorithm and represent the basic operations which are performed in every 
Comp. The set of graphical symbols is available in a palette menu in the lower left-hand comer of 
the Prototype’s screen. The user selects the desired symbol and then places it in the Comp Work 
Area (see the Work Area Section on page 4 for more information about the Work Area) using the 
mouse. The user may then connect the symbols in the Work Area to define the Comp algorithm 
flow during Comp execution. The Graphical Comp Builder Prototype allows the user to construct 
Comps from the following graphical symbols: 

BEGIN oval in shape, no entry point, single exit path. This symbol represents the 
beginning of the Comp. 

END circle in shape, multiple entry points, no exit path. This symbol indicates the 

end of the Comp. 

IF modified diamond shape, multiple entry points, two exit paths. This symbol is 

used to enter logical expressions into the Comp. 

SET rectangle shaped, multiple entry points, single exit path. This symbol 

represents the “setting” of a variable or signal, similar to a programming 
language assignment statement. 

PRINT hollerith card (punched card) shaped, multiple entry points, single exit path. 

This symbol represents the output of a formatted string during the execution 
of the Comp. 

CALL rounded rectangle shape, multiple entry points, single exit path. This symbol 

indicates that the current Comp is to be suspended, and the Comp named 


Page 2 


GCB Documentation 



GCB Concepts 


within the symbol is to be started. When the named Comp completes its 
execution (reaches its END symbol), execution resumes in the current Comp 
at the next symbol. This symbol functions much like a subroutine “call” in a 
C or FORTRAN language program. 


ACTIVATE modified rectangle shape, multiple entry points, single exit path. This symbol 
represents the start of execution of an asynchronous Comp in parallel with the 
current Comp. This symbol functions much like a forkQ call in a C language 
program. 


STOP 

PAUSE 


octagon (stop sign) shaped, multiple entry points, single exit path. This 
symbol indicates the termination of a parallel Comp. This symbol is used to 
“stop” a Comp which was spawned by an ACTIVATE symbol. 

alarm clock shaped, multiple entry points, single exit path. This symbol 
causes the Comp to pause for a specified time period. 


It is from this collection of graphical symbols that the user constructs a Comp algorithm. 

The shape of the IF, PRINT, and SET symbols were chosen for their expandability. These symbols 
often may have to expand to allow the Comp designer to enter long expressions or text strings. The 
squared sides of these symbols may expand or shrink depending on the size of the expression 
entered by the Comp designer. 


2.1.2 Logical Connecting Lines 

Once two or more graphical symbols have been selected and entered in the Work Area, then the 
user may logically connect the symbols to define the control flow between the symbols during 

execution. The user may very easily introduce looping or recursion simply by connecting one 
symbol to another. 


2.1.3 Expression Builder 

The IF and SET graphical symbols may contain textual logical expressions. It is through these two 
symbols that much of the work of a Comp algorithm is performed. The IF symbol is used to 
represent a logical expression which returns a true or false value. The result of the logical 
expression determines which connecting line is traversed out of the symbol. The SET symbol is 
used to assign values to local variables, global variables, and to Work Station Globais. The SET 

symbol may be used to put values into Object Access (data acquisition) for retrieval bv other 
control center applications. 

The logical expressions in the IF and SET symbols are called Comp Expressions. Comp 
Expressions may be entered via the keyboard or the expressions may be constructed using the 
Expression Builder. The Expression Builder is a collection of logical expression building blocks 
contained in a menu. The Expression Builder steps the user through the building of Comp 
Expressions by activating only the expression building blocks that are valid for the current state of 
the logical expression. The Graphical Comp Builder Prototype provides the Expression Builder for 

novice users and also allows the more proficient user to enter expressions directly via the keyboard 
if desired. 

Each IF and SET graphical symbol also allows the user to enter two levels of supporting 
documentation for each expression. The user may enter a short description of the expression and a 
much longer textual description if desired. The short description may be used to aid the user in the 


Page 3 


GCB Documentation 


GCB Concepts 


building of the Comp algorithm, whereas the larger description field is designed to provide 
supporting documentation in the printed repons generated by the Graphical Comp Builder 
Prototype. These two documentation fields allow the user to logically design and document Comp 
algorithms. The logical design of the Comp algorithm may be constructed and documented by one 
user, and the Comp Expressions may be entered at a later date, possibly by another user. The 
documentation support provided by the Graphical Comp Builder Prototype aids the Comp design 
and development process by maintaining the Comp documentation with the Comp itself. 

2.1.4 Work Area 

The Graphical Comp Builder Prototype allows the user to construct Comp algorithms using 
graphical symbols and logical connecting lines. The building of the Comp algorithm takes place 
within the Work Area. The Work Area is a large, scrolled area in which the graphical symbols are 
placed and connected. A majority of the time spent building a Comp with the Graphical Comp 
Builder Prototype is spent in manipulating the graphical symbols and the connecting lines in the 
Work Area. The Graphical Comp Builder Prototype has been designed to provide the user with 
powerful, yet easy to use functions to manipulate the graphical symbols and connecting lines in the 
Work Area. 

2.1.4.1 Graphical Symbol Placement Model 

The Graphical Comp Builder Prototype allows the user to select a graphical symbol from a palette 
menu and then place the symbol in the Work Area. The user may then position the graphical 
symbol in any unoccupied place in the Work Area by “dragging” the symbol using the mouse. The 
graphical placement model, i.e., the way in which components are placed and connected on the 
screen, is a hybrid of the two styles used in most software packages that involve the manipulation 
of graphical symbols. These two methods are: 

• A grid-based approach 

• A cell-based approach 

In the grid-based approach, the drawing area is defined by a point grid. A symbol is “snapped” to 
the defining set of grid points closest to the desired location; a drawn line is snapped to the grid 
points that conform most closely to its path. The benefit of grid-based approach is the precision 
with which components can be placed is configured by the granularity of the grid. The grid-based 
approach suffers due to the fact that it is harder to place and connect symbols than in other methods. 

In the cell-based model, the drawing area is defined by a grid of cells. Each component occupies 
exactly one cell. The advantage of this approach is that symbol placement is easy; the user doesn’t 
have to be concerned with precise placement or uniform spacing. The disadvantage is the 
flexibility of arbitrary placement is lost. In addition, connectivity becomes problematic: a line is a 
component, and so no more than one line may occupy a cell. Thus, all lines must be a cell width 
apart. This severely limits the line drawing capabilities of cell-based applications and negates their 
ease of use. 

The Graphical Comp Builder Prototype uses a combination of these two approaches. The Work 
Area drawing region is composed of a grid of small, unseen cells, and symbols may occupy more 
than one cell. Connecting lines may also occupy more than one cell if the line is longer than one 
cell in length. Connecting lines are one cell in width but may be many cells in length. Each logical 
cell may contain only one of the following: 

• a portion of a graphical symbol 


Page 4 


GCB Documentation 


GCB Concepts 


• a portion of a connecting line 

Symbol shapes may expand in one-cell gradations to contain long expressions. 

The advantages of this hybrid approach are: 

• Ease of symbol placement that is comparable to the basic cell-based approach but more 
flexible and efficient in its use of Work Area real estate - there is less “external 
fragmentation.” 

• Flexibility of connecting line placement that approximates that of the grid-based approach, 
but because of the restriction that only one line may appear in a cell, gives the user more 
structured line placement. 

• Arbitrarily large symbols may be constructed which contain long expressions. This is due 
to the fact that a single graphical symbol may occupy many logical cells. 

• As with the grid-based approach, it is easier to place arbitrary label text. 

The Graphical Comp Builder Prototype provides a number of functions to assist the user in the 
development of graphical Comp Elements. These functions allow the user to manipulate the 
graphical symbols and connecting lines in the Work Area. 

2.2 Graphical Comp Hiearchy 

The Graphical Comp Builder Prototype allows the user to construct and maintain Comp algorithms 
in a very logical and powerful fashion. The Graphical Comp Builder Prototype contains features 
which allow the user to group Comps according to function to aid the Comp maintenance process. 
The Graphical Comp Builder Prototype also contains features which allow the Comp algorithm 
designer to decompose algorithms into a number of smaller, more manageable components. The 
Graphical Comp Builder Prototype implements a hiearchy of three main components to allow the 
user to decompose algorithms into smaller, more manageable pieces: 

• Position 

• Comp 

• Element 

Each of these components of the Graphical Comp Builder Prototype are described in following 
sections. 

2.2.1 Multiple Position Support 

The Graphical Comp Builder Prototype was designed to allow the user to group Comp algorithms 
according to their function. In a control center environment, Comp algorithms are usually grouped 
together based on the flight control position for which they were designed. The Graphical Comp 
Builder Prototype contains and supports the concept of grouping and maintenance of Comp 
algorithms based on a flight control position. In the Graphical Comp Builder Prototype, the flight 
control position is the highest level in the Comp hiearchy. 

2.2.2 Comp Structure 

A number of logical Comp algorithms may be necessary for each flight control position and the 
Graphical Comp Builder Prototype allows the user to maintain a number of Comps for each 
position. The second level in the Graphical Comp Builder Prototype hiearchy is the Comp. Each 
Comp may become a stand-alone executable and may be managed by the Comp Manager 


Page 5 


GCB Documentation 


GCB Concepts 


application during control center operations. Each Comp is primarily a logical entity and does not 
perform the actual work of the Comp algorithm. The Comp component of the hiearchv does not 
contain the graphical symbols or connecting lines. 

Each Comp is composed of one or more Comp Elements. The Comp Elements contain the 
graphical symbols and connecting lines which contain the logic and control flow of the Comp. 
Comp Elements form the lowest level of the Graphical Comp Builder Prototype hiearchy. 

Comp Elements are analogous to subroutines of a main program. Each Comp contains one or more 
Comp Elements and the Comp serves as a container of its Comp Elements. The Comp is the only 
entity which may be managed outside the Graphical Comp Builder Prototype. Comp Elements may 
only be maintained using the Graphical Comp Builder Prototype and serve only as the building 
blocks from which Comps are composed. 

Each Comp contains a root Comp Element. The root Comp Element is the start point of the Comp’s 
Element hiearchy. The root Comp Element may contain the entire Comp algorithm or the root 
Element may call other Comp Elements. As in traditional programming language subroutines, 
Comp Elements may transfer program control flow to another Comp Element. When a Comp 
Element reaches its END symbol, control is returned to the parent Comp Element. In the event the 
root Element reaches its END symbol, the Comp executable is terminated. Using this concept, the 
user may build a Comp of practically unlimited depth and breadth by adding calls to other Comp 
Elements. The user may decompose complex Comp algorithms into logical subunits and then 
decompose individual logical subunits into even more subunits. The following diagram displays 
an example Comp which is composed of eight Comp Elements. This example Comp hiearchy 
displays the flexibility available for decomposing complex Comp algorithms into smaller, 
modular, more manageable components. 



Page 6 


GCB Documentation 








GIB Concepts 


2.3 Report Generation 

automatically geSS '!“ C ° mp algorithm developer by 

time producing and maintaining suDDortina ° P algorithm developers often spend more 

tsszzssz ihe « com^r P ^rs£:; 

■ sretTafrr ,s ? -- - * . 

Comps at three different ^ n "W *“«* the user to docutn „ 

■he. high level design of each Element w^“ta a Como / ^ m deSig " ° f ,he C °" p . 
logical expression within a Comp Element Th^ r ?• ^ USCr Can docu ment each 
Z a.so document each Comp Element hy 

contains much o°Z infomation°Sd‘ Tnamp^ ge " era,es a printed report which 
The report generated by the Graphical Comp BuZr P Supponi "S documentation, 
to generate the Comp executables (lists of vrtabts^ H h Pe T"' 3 '" 5 informa '™ used 
contains the supporting documentation entered by me user ‘ 5 ' PeS ’ " C ° also 

The combination of these two features: mn I, u ^ * 

easier for the Comp algorithm designer. ' ' devcl ° pmem of supporting documentation much 
2.4 Automate Code Generation 
The Graphical Comp Builder Prototvne’e 

detection algorithm which can be DeiformpriH 13111 purpose * s to allow the user to specify a fault 

Builder Prototype captures Graphical Com 

whtch can be run during operations. The execmab es " d . the " *f nera “ executable program 
Prototype are built automaticallv within the r„ k p ™ duced hy the Graphical Comp Builder 

Comp Builder Prototype performs the following proc« s toTrod”' 11 " Prolo,ypc ' Graphical 
performed dunng operations: g process t0 produce an executable which can be 

has properly connected *^£7 h^lT l ° the USer 

audits each graphical symbol to ensure the logical £ phlCal Comp Builder Prototype then 

* If eirors are not detected dunna rh h T eXpreSS1 ° ns are P^perly completed. 

file is generated for the Comp EkmenTT^Com^r ^ " C IangUa S e sour « 

compiled using the resident C compiler An object fi eTr' h source is then 

C language source file. ob j i ectfile is produced for each Comp Element 

successfully 'cor^iled.^c^^C^Mguage 'souroeT f ElemCm haVe bee " generaIed a " d 

Comp s C language source file contains irfbHl C ‘ s P roduccd for the Comp. The 

root Element. The Comp’s C language source is Then l Th a '” C ° nIa ‘ nS Ihe cali 10 ,hc 

b =e source is then compiled to produce an object file. 



GCB Documentation 



GCB Concepts 


After the object files are produced for the Comp and for each of the Comp's Element files, 
then all of the object files are linked together to produce a Comp executable. 

The executable produced from this process can be run during control center operations. The 
executables produced by ‘.he Graphical Comp Builder Prototype are dependent on several 
other applications in the control center. 

The executables produced by the Graphical Comp Builder Prototype are usually 
controlled by a master program called the Comp Manager. The Comp Manager 
application is used to start and stop the Comp executables. The Comp executables are 
not designed to be run directly from the command line. The Comp Manager is used to 
control and monitor the execution of the executables produced by the Graphical Comp 

Builder Prototype. 

The executables produced by the Graphical Comp Builder Prototype display messages 
on the flight controller's screen to report the status of the system being monitored by 
the Comp and to report the status of the Comp itself. The Comp designer specifies what 
types of messages to display and when to display the messages during execution by 
placing PRINT symbols in the Comp’s Elements. The Comp executables do not display 
these messages on the flight controller’s screen directly. The messages are sent to 
another application program which controls the flight controller s screen. 

The executables produced by the Graphical Comp Builder Prototype retrieve data from 
the control center’s data acquisition system. The Comp executables automatically are 
built with the proper interfaces to the control center’s data acquisition system. 


2.5 User Interface 

The Graphical Comp Builder Prototype is an X Windows and MOTIF based tool. The Graphical 
Comp Builder Prototype screen is composed of four main areas: 

• MOTIF menu bar 

• Comp Element Work Area 

• Comp status area 

• Graphical symbol palette menu 

The MOTIF menu bar contains most of the Graphical Comp Builder Prototype menus. The Comp 
Element Work Area is a large scrolled window area in which the graphical Comp is construct^ . 
The Comp status area contains various information to identify the current Comp Element w ic is 
active in the Work Area and also contains information about the Comp. The graphical symbo 
palette menu contains bitmapped icons which represent the available Comp Element building 
blocks. The graphical symbol palette menu is overlaid with the Expression Builder during the 
completion of IF and SET symbols. 

The Graphical Comp Builder Prototype uses popups wherever necessary t0 in P u ‘ %^f play 
information to the user. User input text fields are implemented using the standard MOTIF text 
fields to provide a user-friendly and consistent interface. Each popup uses a consistent button 
layout to provide a consistent interface: 

• each popup contains a CANCEL button which is located at the bottom left of the popup 
form. 

. each popup contains a HELP button which is located at the bottom right of the popup form. 


Page 8 


GCB Documentation 


GCB Concepts 


most popups contain a DONE button which is located at the bottom of the popup form iust 
to the right of the CANCEL button. 


Page 9 


GCB Documentation 


GCB Features 


3.0 Graphical Comp Builder Prototype Features 

The Graphical Comp Builder Prototype provides a number of features to allow users, such as flight 
controllers and engineers, to very easily design and document fault detection algorithms. This 
section details the various features and capabilities of the Graphical Comp Builder Prototype. 
Section 4.0 of this document discusses the implementation of these features. 

3.1 Graphical Representation of Comp Algorithms 

The Graphical Comp Builder Prototype allows the user to build and maintain Comp algorithms 
using graphical symbols much like a flow chart The flow chan type representation of the Comp 
algorithm is easier to understand than existing textually based methods. The flow chan type 
representation of the Comp algorithm is constructed in the Work Area portion of the Graphical 
Comp Builder Prototype s screen. The Graphical Comp Builder Prototype provides a number of 
features which allow the user to very easily build and maintain the Comp algorithms in the Work 
Area. 

3.1.1 Work Area 

The Work Area has several features to make the building and maintenance of graphical Comps 
easier. The Work Area is a large, scrolled window. The user may construct graphical Comps which 
are larger than the size of the Work Area. The Work Area scroll bars allow the user to move within 
the graphical Comp. The user may also "zoom out" to view the Work Area in a reduced scale view. 
The reduced scale view allows the user to view the entire Comp algorithm in the Work Area. The 
user may edit the Comp algorithm in the Work Area while working in the reduced scale view. All 
functions which are available in the full scale view are also available in the reduced scale, or 
zoomed view. 

The Work Area has two speed menus which provide both Work Area specific funtions and 
general file functions. The Work Area specific functions are only available via the speed menus. 
The general file functions are available via other menus within the Graphical Comp Builder 
Prototype. 

3.1.2 Add Symbol 

The user may add a new graphical symbol to the Comp algorithm in the Work Area. To add a new 
symbol, the user clicks the left mouse button in one of the symbols in the symbol palette menu. If 
the symbol to be added is a BEGIN or END symbol, the symbol will appear in the Work Area and 
the user may place the symbol using the mouse. Otherwise, a popup will be displayed which allows 
the user to complete the information required for the symbol. Once the information has been 
entered in the popup, the new symbol will appear in the Work Area and the user may place the 
symbol using the mouse. 

3.1.3 Move Symbol 

The user may move a single graphical symbol within the Work Area by placing the mouse pointer 
in the symbol and then dragging it within the Work Area while holding down the left mouse button. 
If a symbol contains connecting lines, its connecting lines will be deleted after the symbol is 
moved. The Graphical Comp Builder Prototype currently does not attempt to maintain line 
connectivity after a symbol has been moved. This limitation is mitigated by the ease with which 
the user can connect symbols and by the Move Block function which allows the user to move a 
collection of symbols while maintaining their line connectivity. 


Page 10 


GCB Documentation 


UND0 ^ UNDO function win 

symbol's original location. ° re any connectin S “»« if any exisced at the 

3.1.4 Edit Symbol 

«Stn •cSSKS Z rk sa Area by - mouse Poimer 

originally define the symbol will then allow the mC P ° PUP whlch allowed the user to 

attributes. The UNDO function will ^recover changeTmad^bythe ^tSy^^oKuMtion! 8 

3.1.5 Symbol Implode 

The user may "implode" into CALL and ACTIVATE symbols Thr r mn i^ f • 
user to edit the Comp Element specified in the cvmu ' . e Implode functIon allow s the 

Comp Element to edit. The Implode function could he mp l° de 1S a faster method of selecting a 
choosing the proper Comp Element toplodeanows thp * 6 P Cd by SdeCI Elemcnt a " d *=■> 
into that symbol. The user may Implode P into a svmhol' h i ‘° ‘’“I* ‘° a Symbo1 and thcn lm P lo d= 

3.1.6 Delete Symbol 

Wo* Area by placing the mouse pointer 
graphical symbol and its connect.ng Imes are dele.ed“e Wo* Ama^ * ““ d ° W "' Th = 
The Delete Symbol fuention can be "undone” by the Ul^mo f 

restore the symbol to its original location and win re^^ 0 funCtlon ’ The UNDO function will 
symbol’s original location. re any connect ing lines if any existed at the 

3.1.7 Connect Symbols 

The user may logically connect two symbols within th- wr i a 

user places the mouse pointerwithin the first symbol dictate mTdd| T ° tW ° Symbols ’ the 

moves the mouse out of the symbol in the direction 7 l u 116 mouse butt °n, then the user 

Orthogonal anchor points may be placed at anv noinrd ‘° draW the conn ecting line. 

the middle mouse button. To conclude the line the the C0nstructl0n of the line by clicking 

symbol and clicks the mtddle mouse button. ^ PlaCeS the mouse P ointer within the end 

Connecting lines may not go through symbols other than the start h k , „ 

have an associated direction and the connecting line, , d SymboL Conn ecting lines 

direction. connecting lines are drawn with arrow heads to indicate the 

The Connect Symbols function can be "undone" by the I JNTno f • ^ 

remove the connecting line which was just added lo the Wm* AreT' 0 "' ^ UND ° fUnCti ° n WiU 

3.1.8 Delete Connecting Line 

delete a connecting line" bypllcing A C ° nnecting Iine ‘ The user may 

button while the shift key is depressed. P hC mC and cllckin S the middle mouse 

The Delete Line fuention can be ’ undone" bv the T riynn t ^ 

the connecting line which was deleted. function. The UNDO function will restore 


Page 11 


GCB Documentation 



GCB Features 


3.1.9 Move Block 

The Move Block function allows the user to mark a set of symbols and their connecting lines using 
a rubber-banded box and to move them via the mouse to another location within the Work Area. 
The Move Block function is available via the right mouse button speed menu in the Work Area. 
The user selects the rectangle anchor point by clicking the left mouse button, then the user can 
expand the rectangle by moving the mouse. The user can anchor the size of the bounding box by 
clicking the left mouse button a second time. The user will see a rectangular box which indicates 
the area to be moved and can place this area by moving the mouse. The selected area can then either 
be anchored in the new location by clicking the left mouse button, or the Move Block function can 
be aborted by clicking the CANCEL button in the Status area. 

The Move Block fucntion can be "undone" by the UNDO function. The UNDO function will move 
the symbols and their connecting lines to their original position in the Work Area. 

3.1.10 Copy Block 

The Copy Block function allows the user to mark a block of symbols and their connecting lines 
using a rubber-banded box and to copy them to a new location in the Work Area. The Copy Block 
function is available via the right mouse button speed menu in the Work Area. The user selects the 
Copy Block rectangle anchor point by clicking the left mouse button, then the user can expand the 
rectangle by moving the mouse. The user can anchor the size of the bounding box by clicking the 
left mouse button a second time. The user will see a rectangular box which indicates the size of the 
area to be copied and can place this area by moving the mouse. The selected area can then either 
be anchored in a new location by clicking the left mouse button, or the Copy Block function can 
be aborted by clicking the CANCEL button in the Status area. 

The Copy Block function can be "undone" by the UNDO function. The UNDO function will 
remove the new symbols and their connecting lines from the Work Area. 

3.1.11 Delete Block 

The Delete Block function allows the user to mark a block of symbols and their connecting lines 
using a rubber-banded box and to delete them. The Delete Block function is available via the right 
button speed menu in the Work Area. The user selects the rectangle anchor point by clicking the 
left mouse button, then the user can expand the rectangle by moving the mouse. The user can 
anchor the size of the bounding box by clicking the left mouse button a second time. The user will 
see a rectangular box which indicates the area to be deleted. The Delete Block function can be 
aborted by clicking the CANCEL button in the Status area. 

The Delete Block function can be "undone" by the UNDO function. The UNDO function will 
restore the symbols and their connecting lines. 

3.1.12 UNDO and CANCEL 

The Comp Status Area contains a dual function push button which may be used to cancel or "undo 1 
functions which are performed within the Graphical Comp Builder Prototype. The push button is 
a CANCEL button if the user is in the midst of performing any of the above mentioned functions, 
otherwise, the push button will be an UNDO button. The push button label changes during 
execution of the Graphical Comp Builder Prototype to indicate which function is active. 


Page 12 


GCB Documentation 



GCB Features 


function can be canceled I The S fSLw^V^ anCei CU ^ ent °P eration - Almost every multi-step 
within the Graphic “cotp B„toXo“ Pl ' S ° f h ° W CANCEL b ““°" "ay «- 

' bnlr^e ay „:er 0n m av e trfd *' * ' ? ymb °‘ 31 “ y ■**» * electing the CANCEL 

p '~ mi whi,e edw ^ “ 

’ button Cr may ab0It the c0nnecll0n of two symbols a< any point by selecting the CANCEL 

user performed the last function. The effects of an UNDO de^H ^ ^ “ W&S in before the 

by the user. An UNDO may perform somethin e d Pend ° n the functl0n Iast Performed 

perform a more complex operation such as coo4n™ ^ mo ™f 3 SmgIe Symbo1 ’ or ir may 
The UNDO function is also available from the'LtmoSul* me'nu." C ° nneCdng HneS - 

3.2 Position Management 

The Graphical Comp Builder PrototVDe allnu/s th- 

directories for different flight control positions Thu n ° rgan,x Com P s lr >to different 
multiple flight control positions on a sincle Si,? °” S the user to maintain Comps for 
Graphical Comp Builder Prototype 01 ^ Fife SySKm (NFS) disk - The 

, , , „ , yP mainS several fancttons to support multiple Positions. 

3.2.1 Select Position 

The Select Position function allows the nw m • . 

Position function allows the user to traverse the fife ™ * X1S * ns P ° sition d^ctory. Die Select 
directories are not located in a single SyStem fa ,hc evem the Posi “™ 

3.2.2 Create Position 

The Create Position function allows the user m . . 

function prompts the user for the new Position nam/nnTth ' “ 10n | directOT y- T 1 ® Create Position 
directory which will be created. 6 3 d then dls P la y s die name and path of the 


3.3 Comp Management 


The Graphical Comp Builder Prototype allows th» . . . 

specified flight control position. The Graphical ComnR r ° h 121 ™ 3111 multiple Comps within a 
functions to assist the user in the’mataien"^^* 8 ^ Pr0t ° tyPe C ° mainS a number of 

3.3.1 Select Comp 

The Select Comp function allows the nwr tr, c »i . /• 

specified Position. 1 from a llst of existing Comps within the 

3.3*2 Create Comp 

The Create Comp function allows the user to creme » n 

Create Comp function creates a new directory within rhT lhC Specified p °sidon. The 

single Comp are maintained in the Comp directory lie Crca7atnTf° ry ' ^ ° f ‘ he fiIeS f ° r a 
for the Comp s purpose and the name of the Cnmn Cl.. 1 , P funcuon Prompts the user 
Comp. e me Com P dement which will be the root Element of the 


Page 13 


GCB Documentation 



GCB Features 


3.3.3 Select Comp Root Element 

The Select Comp Root Element function allows the user to select the root Comp Element of a 
Comp’s hiearchy. The Select Comp Root Element function allows the user to select the root 
Element from a list of Comp Elements which comprise the Comp. 

3.3.4 Edit Comp Purpose 

The Edit Comp Purpose function allows the user to edit and save the Comp Purpose text which is 
displayed in the Status area of the Graphical Comp Builder Prototype. The Edit Comp Purpose 
function displays the Comp’s current Purpose text, and then allows the user to modify the text. 

3.3.5 Display Comp CallFIow 

The Display Comp CallFIow function displays the hiearchy of the Comp Element calls within a 
Comp. The Display Comp CallFIow starts at the root Element of the Comp and recursively 
traverses the list of Element calls. The hiearchy of Element calls are presented to the user in the 
Displayer. 

3.3.5.1 Displayer 

The Displayer is a large, output only window that allows the user to monitor the progress of several 
operations within the Graphical Comp Builder Prototype. The Displayer allows the user to monitor 
the progress of operations which may take more than a couple of seconds to complete. The 
Displayer is used during the following operations: 

• The Displayer is used during the Installation of an Element. The Displayer allows the user 
to view the different stages of Element Installation and also displays status information. 

• The Displayer is used during the Installation of a Comp. The Displayer allows the user to 
view the different stages of Comp Installation and also displays status information. 

• The Displayer is used during the Comp Validation process. 

The Displayer popup window is not modal. The user may leave the Displayer popup window on 
the screen even after the operation which caused the Displayer to be displayed has completed. This 
allows the user to refer to information within the Displayer during the editing of Comp Elements. 
The output of the Displayer is recorded into a disk file. 

3.3.6 Install Comp 

The Graphical Comp Builder Prototype’s ultimate mission is the generation of a Comp executable 
which can be managed by the Comp Manager. There are two main steps in the generation of a 
Comp executable from the Comp entered by the user: 

• The graphical Comp is converted into C language source files. 

• The C language source files generated by the Graphical Comp Builder Prototype are 
compiled and linked to produce a Comp executable. 

These two steps are implemented via the “Install Element” menu button and the “Install Comp” 
menu button. C language source files are generated via the “Install Element” menu button and an 
executable Comp is produced via the “Install Comp” menu button. See the Install Element section 
on page 16 for more details about the Install Element function. 

The Install Comp function first ensures that an object file has been produced for each graphical 
Comp Element in the Comp. The Install Comp function then generates several C language source 


Page 14 


GCB Documentation 



ElemtmobjS ““ resui ‘ in « ob J ect 11 le and the Comp 
comp process are Th * «>*» of «he InstaS 

3.3.7 Validate Comp 

‘ he da “ ^ Md SiZ “ ° f "» »— retrieved 

Global tables. The Valida e Comn t “ C ° mained in ,hc 0b j CCI A «ess and Work Station 
aaaate Lomp function presents its results to the user in the Displayer. 

3.3.8 Comp Report Generation 

SpaS^“™^d prinlrt repom 10 documem the 

Comp and Print Element menu buttons vL Z r™ T ^ "* available ™ *0 Mm 

report which contains the information for the current ComT Th 8e " era,e a m “ltipage printed 

following information: om P’ ^ nnt C° m P report contains the 

• Comp name 

• Comp purpose 

• List of Comp Elements which comprise the Comp 

• List of global variables used in the Comp 

• An Element level report for each Comp Element in the Comp 

An examp,e report generated by the Print Comp function is contented in Appendtx A 

printed repons. ^° mP CUITCm ‘ y ^ " Ms, Scrip, primers during the generation of 

3.4 Element Management 

^in;%tmed°S ,0 ma,Main mUi ‘ iple Comp «*■»»» 

to assist the user in the maintenance of Comp Elements ^ COntains a number of functions 

3.4.1 Select Element 

specifiedCom^ 111 fUnC&0n alIows the user t0 ^lect from a list of existing Comp Elements for the 

3.4.2 Create Element 

3.4.3 Delete Element 

The user may select EIement from ^ specified Comp. 

3.4.4 Save Element 

The Save Element function will cav? nil 

Save Element fnnetton w,„ £,£ SSSSSr * ** * 


Page 15 


GCB Documentation 



GCB Features 


3.4.5 Copy Element 

The Copy Element function allows the user to copy the Comp Element in the Work Area to a new 
Comp Element with a different name. 

3.4.6 Edit Element Purpose 

The Edit Element Purpose function allows the user to edit and save the Comp Element s Purpose 
text which is displayed in the Status area of the Graphical Comp Builder Prototype. The Edit 
Element Purpose function displays the Comp Element’s current Purpose text, and then allows the 
user to modify the text. 

3.4.7 Print Element 

The Print Element function allows the user to print the Comp Element active in the Work Area. 
The user may print the Comp Element in one of two modes: 

• The user may print a Comp Element in the “normal” mode. The normal mode report prints 
the Comp Element in the Work Area using the same size symbols and fonts as is used to 
display the Comp Element in the Work Area. The normal mode report requires as many as 
4 pages to print the entire Element due to the fact that the Work Area is larger than a single 
sheet of 8 1/2" by 11" paper. 

• The user may also print a Comp Element in “reduced mode. The reduced mode report 
prints the entire Comp Element on a single 8 1/2" by 11" page. The reduced mode report 
uses a smaller symbol size and font to fit the entire Work Area on a single page. 

An example report generated by the Print Element function is contained in Appendix B. 

3.4.8 Audit Element 

The Audit Element function allows the user to verify the Comp Element has been properly 
constructed and is ready for Installation. The Audit Element function operates on the graphical 
Comp Element active in the Work Area. The Audit Element function is composed of two functions 
which perform the following checks: 

• The Audit Lines function will check the logical connectivity of each of the graphical 
symbols in the Work Area. The Audit Lines function will ensure that each symbol has at 
least one line entering the symbol and at least one line leaving the symbol. In the case of an 
IF symbol, the Audit Lines function will ensure the IF symbol has both a TRUE and 
FALSE logical connecting line leaving the symbol. 

• The Audit Expressions function will check the Comp Expression of each of the graphical 
symbols in the Work Area. The Audit Expressions function will ensure the Comp 
Expression exists and that it is syntactically correct. The Audit Expressions function will 
parse and type check the Comp Expression to verify it is syntactically and semantically 
correct. 

The Audit Lines and Audit Expressions functions can be performed separately or they may be 
performed together. 

The Audit Element function highlights the symbols which have failed the specified Audit tests. The 
symbol highlighting may be turned off via the Clear Audit function. 


Page 16 


GCB Documentation 


GCB Features 


3.4.9 Install Element 

The Install Element function generates a MOAL or C language source file for the graphical Comp 
Element in the Work Area. If a C language source file is generated for the Element, then the C 
language source file is compiled to produce an object file. If an object file is successfully produced, 
the Install Element function marks the Comp Element as up-to-date. If the user makes and saves 
any changes to the graphical Comp Element, the Comp Element is marked as being out-of-date. 
This feature will ensure the user’s object files are consistent with their corresponding graphical 
Comp Element. The Install Element process is presented to the user in the Displayer. 

3.5 Options Management 

The Graphical Comp Builder Prototype has several user configurable options. Some of these 
options may be configured during the execution of the Prototype. The following sections describe 
the options which are user configurable during the execution of the Graphical Comp Builder 
Prototype. 

3.5.1 Display Options 

The Display Options function displays a popup which identifies the different user configurable 
options and each option’s current value. The Display Options popup contains the following 
information: 

• The name of the flight control Position in which the user is working is displayed. 

• The name of the current Comp is displayed. 

• The name of the Comp Element which is active in the Work Area is displayed. 

• The path and filename of the Displayer output file is displayed. 

• The path and filename of the Error Log file is displayed. 

• The state of the Symbol Snap toggle is displayed. 

• The state of the Comp Element Audit toggle is displayed. 

• The target language for Installation operations is displayed. 

• The path and filename of the Object Access Table is displayed. 

• The path and filename of the Work Station Global Table is displayed. 

• The path to the User Defined Functions is displayed. 

• The user’s name, as determined from the /etc/password file, is displayed. 

• The current time and date, as determined from the computer’s system clock is displayed. 
The time and date displays are not updated while the Display Options popup is displayed. 

3.5.2 Symbol Display 

The Graphical Comp Builder Prototype allows the user to control the display of the expressions in 
the graphical symbols. The Symbol Display function allows the user to specify whether the Comp 
Expression or Logic Description text should be displayed in the symbols in the Work Area. The 
Symbol Display function is available in both the Options menu and the right mouse button speed 
menu. 


Page 17 


GCB Documentation 



GCB Features 


3.5.3 Symbol Snap 

The Graphical Comp Builder Prototype allows the user to place and move the graphical symbols 
m the Work Area using either a snap grid or free hand. If the symbols are placed or moved while 
snap is turned on, the symbol will be "snapped" so that the center of the symbol will be on a snap 
me. The symbols are snapped so that the center of the symbol is on the snap grid. This allows the 
user to line up the connecting lines which exit symbols. 

The user may also place symbols free hand. The Work Area is bordered by a ruler bar which may 
be used to place symbols or connecting lines. The ruler bar contains a moving pointer which 
displays the location of the mouse pointer. The ruler bar pointer indicates the center of the symbol 

during symbol movement functions and indicates the end of the current line segment during 
connecting line functions. ° 

3.5.4 Audit Toggle 

? e ;f^ 0ggle C ? ntr0lS thC °P eration of the Au dit Element function. The user may elect to turn 
t e Audit Element function continuously on or the user may wish to explicitly select the Audit 
Element function as desired. If the Audit Element function is continuously turned on, the Comp 
Element in the Work Area will be Audited every time an operation is perfomed in the Work Area 

3.5.5 Set Colors 

The Set Colors function allows the user to set the foreground and background colors of the 
^aphicd symbois in the Work Area. The Set Colors function affects only the current Comp 
ement. The specified colors are saved with the Comp Element and are restored every time the 
Comp Element is read into the Work Area. The Set Colors function allows the user to set the color 
o individual symbol types, or the user can set all symbol types to the same color. For example, the 

back^ntT ^ BEGIN symboIs t0 a blue background and all END symbols to a yellow 

3.5.6 Set Target Language 

The Graphical Comp Builder Prototype was designed to automatically produce source code for 
several different languages. The Set Target Language function of the Graphical Comp Builder 

so'Sles US6r 10 SdeCt WhiCh kngUage t0 USC dUling the automatic generation of the 

• The Graphical Comp Builder Prototype can automatically generate C source files. 

♦ The Graphical Comp Builder Prototype can also automatically generate MOAL source 
files. A compiler currently does not exist for MOAL language files, so a Comp executable 
can not be produced if MOAL is chosen as the target source language. 

* T be Graphical Comp Builder Prototype was also initially designed to support UIL source 

fi m nd ? t m TargCt Language P°P U P con tains a UIL option. Due to the unavailability 
of UIL the UIL source code generation functions were not completed in the Graphical 
Comp Builder Prototype. The Set Target Language popup will inform the user that UIL 

source code generation has not been implemented if the user selects UIL in the Set Target 
Language popup. 


GCB Documentation 


GCB Features 


3.6 Help System 

The Graphical Comp Builder Prototype contains two levels of online help text to assist the user 
during execution of the Prototype. The Graphical Comp Builder Prototype allows the user to select 
Help from the main menu bar. Within the main menu bar help, there are three categories of help 
text: 

• The user can view help text which describes the conventions of the Work Area. This set of 
help text identifies the different mouse button conventions and their function. 

• The user can view help text which describes the graphical symbol palette menu. This set of 
help text describes the function of the different graphical symbols. The user may use the 
mouse to select the graphical symbol for which to display help text. 

• The user may also browse through the entire collection of help text. All of the help text for 
the Graphical Comp Builder is maintained in a single disk file. The user may browse 
through the entire file if desired. 

Each of the Graphical Comp Builder Prototype popup windows contains a HELP button in the 
lower right hand comer of the popup. This HELP button allows the user to view the help text for 
the current popup window. 


Page 19 


GCB Documentation 



GCB Implementation Notes 


4.0 GCB Implementation Notes 

This section provides the details concerning the implementation of the Graphical Comp Builder 
Prototype. The Implementation Notes are contained in three sub-sections: 

Data Files - this sub-section details the various disk files maintained or accessed by the 
Graphical Comp Builder Prototype. 

Data Structures - this sub-section details the most important data structures which are 
maintained by the Graphical Comp Builder Prototype. 

• Module Hiearchy - this sub-section describes the general layout and program flow of the 
major modules within the Graphical Comp Builder Prototype. 

These sub-sections provide the user with information specific to the implementation of the 
Graphical Comp Builder Prototype. To gain a thorough understanding of the Graphical Comp 
Builder’s Module Hiearchy and its implementation, it is important to first understand the nature of 
X Windows and Motif event driven applications. Refer to X Windows documentation for 
information about event driven applications. 

4.1 Data Files 

The Graphical Comp Builder uses a number of data files in several different directories during 
execution. The following subsections describe the purpose of the various data files and also 

identifies the directories where the Graphical Comp Builder Prototype expects to locate these data 
files. 

4.1.1 Position Directory 

The Graphical Comp Builder Prototype allows the user to maintain different flight control 
positions. Each logical flight control position is maintained in a separate directory The Position 
Directories can be identified by their “.POS” extension. The “.POS” extension is searched for by 
the Select Position functions within the Graphical Comp Builder Prototype. The Create Position 
functions in the Graphical Comp Builder Prototype will automatically create a Position Directory 
with the correct extension. The Position Directories may reside at any place within the Unix file 
system. The Position Directory basename will correspond to the Position name. For example, the 
Position Directory for the INCO Position would be: INCO.POS. 

4.1.2 Comp Directory 

The Graphical Comp Builder Prototype creates a subdirectory for each Comp which is created 
during execution. The Comp Directories are created as subdirectories of the Position Directory. 
Each Comp Directory must end with a “.DIR” extension. The Select Comp functions within the 
Graphical Comp Builder Prototype will search for the “.DIR” extension. The Create Comp 
functions will automatically create Comp Directories with the proper extension. The Comp 
Directory basename will correspond to the Comp name. For example, the Comp Directory for the 
PumpSwitch Comp would be: PumpSwitch.DIR. 

4.1.3 Comp File 

Each Comp Directory will contain a Comp File. The Comp File serves several purposes: 

• The Comp File contains the Comp Purpose text. 


Page 20 


GCB Documentation 


GCB Implementation Notes 


The Comp File contains a list of the Elements which are maintained in the correspondinc 
Comp Directory. 

* The Comp File contains the Comp’s symbol table. 

The Comp File can be identified by its “.CMP” file extension. Only one Comp File exists for each 
Comp and only one Comp File should exists within a Comp Directory. The Comp File basename 
will correspond to the Comp name. For example, the Comp File name for the PumpS witch ComD 
would be: PumpSwitch.CMP. F 

The Comp File is automatically maintained by the Graphical Comp Builder Prototype and each 
Comp File is composed of three logical pans in the following order: 


Comp Purpose Length and Text 
List of Elements 

Comp Symbol Table 


4.1.4 Graphical Element File 

Each Comp is composed of one or more Comp Elements. Each Element is maintained in a 
raphical Element File. The Graphical Element files serve several purposes: 

• The Graphical Element File contains the Element purpose text and several status indicators 
including: Element Create Date, Element Update Date, and Element Author. 

• The Gra P hlcal Element File contains the data which identifies the location and tvpe of each 
of the graphical symbols within the Element. 

• The Graphical Element File contains the expressions and supporting text for each of the 
graphical symbols within the Element. 

• The Graphical Element File contains the data which identifies the connectina lines which 
logically connect the graphical symbols. 

k ICS C ° mp ^ maintained in Comp Directory. Graphical Element 

co^nnH^ ^ ^ ' • GEF ” eXtension ‘ The Graphical Element File basename will 

orrespond to the Element name. For example, the Graphical Element File name for the 
MainPumpl Element would be: MainPumpl.GEF. 

Prorm GraPhl H Cal Flle ’ S automati cally maintained by the Graphical Comp Builder 

Prototype and each file is composed of six logical pans in the following order: 


Page 21 


GCB Documentation 




GCB Implementation Notes 


Element Status Values 
Element Purpose Length and Text 
Element Symbols and Text 
Element Line Segments 
Element Logical Lines 
Element Line Lists 


4.1.5 Library Graphical Element Directory 

The Graphical Comp Builder Prototype allows the user to maintain a Library of Graphical Element 
Files. The Library of Graphical Element Files is maintained in a directory specified by the user via 
the User Configuration File (see the User Configuration File section on page 24 for information on 
the User Configuration File). 

4.1.6 Comp Installation Files 

The Graphical Comp Builder Prototype uses a number of files during the generation and linking of 
the Comp executable. These files have different functions and reside in several different locations. 

4.1.6.1 Comp Header File 

During the Comp Installation, a header file (“*.h”) is created in the Comp Directory containing an 
“extern” for each of the Comp’s global variables. The Comp Header File basename will correspond 
to the Comp name. For example, the Comp Header File name for the PumpSwitch Comp would 
be: PumpSwitch.h. The Comp Header File is used during the compilation of the Element C 
Language Source Files. 

4.1.6.2 ske!eton_element.o 

The skeleton_element.o file is linked into the Comp executable during the Comp Installation 
process. This file resides in the Graphical Comp Builder executable directory. The 
skeleton_element.o file contains the object routines which are linked into every executable Comp. 
The skeleton_element.o file contains the following routines: 

• process table initialization and maintenance routines 

• data acquisition interface routines 

• matrix manipulation routines 

4.1.7 Element Installation Files 

The Graphical Comp Builder generates a number of files during the Installation of an Element. 
These files have different functions but all files are created in the Comp Directory. 

4.1.7.1 Element C Language Source File 

During an Element’s installation, a C language or MOAL language source file is generated from 
the Graphical Element File. The C Language Source File basename will correspond to the Element 


Page 22 


GCB Documentation 




GCB Implementation Notes 


name. For example, the C Language Source File name for the MainPumpl Comp Element would 
be: MainPumpl. c 

4.1.7.2 Element C Language Object File 

During an Elements ’ s installation, a C language object file is generated from the C language source 
file. This file is generated automatically by the Graphical Comp Builder Prototype during the 
Installation process. This file is produced by executing the workstation’s resident C compiler on 
the Element’s C language source file. The C Language Object File is linked into the Comp 
Executable which is produced during the Comp Installation process. 

4.1.8 PostScript Files 

The Graphical Comp Builder Prototype currently supports only PostScript compatible printers. 
The PostScript print functions access and create several PostScript files during Element printing. 

4.1.8.1 PostScript Template File 

The Graphical Comp Builder Prototype uses a template file which contains the functions needed 
to generate a PostScript file during the printing of Elements. This PostScript Template File is 
named: ps_template and is located in the Graphical Comp Builder Prototype executable’s 
directory. The PostScript Template File is not printed by the Graphical Comp Builder Prototype. 
It is only used to build the PostScript File which is printed. 

4.1.8.2 PostScript File 

During the printing of an Element, the PostScript Template File is copied to the Comp Directory. 
The Comp Directory copy of the PostScript Template file is then modified to include the Element 
specific information. The modified PostScript file is renamed ps_file when it is copied to the Comp 
Directory. The PostScript File in the Comp Directory is the file which is printed during report 
generation. 

4.1.9 Help Text File 

The Graphical Comp Builder Prototype help system extracts help text from a disk file called 
GCBDoc during execution. This disk file is located in the same directory as the Graphical Comp 
Builder Prototype executable. This disk file is a standard ASCII file and may be modified with an 
editor. The GCBDoc help text file contains keywords which are used by the Graphical Comp 
Builder Prototype to locate the desired section of help text. The keywords in the GCBDoc help text 
file correspond to the keywords in the source file: tokens.h. Any change to the GCBDoc help text 
keywords or to the list of keywords in the file tokens.h, must be updated in both locations or the 
help text may not be selected properly during execution. The keywords in the GCBDoc help text 
file are identified by the asterisk in column 1. The GCBDoc help text file should not contain tab 
characters. 

4.1.10 Error Log File 

The Graphical Comp Builder Prototype will generate an Error Log File if errors are detected which 
should not occur during normal operation of the Graphical Comp Builder Prototype. The Error Log 
File is an ASCII file which contains the date and time the error occurred and a short description of 
the error condition. The Graphical Comp Builder Prototype will append new error messages to the 
end of the Error Log File as the errors are detected. The user may specify the location of the Error 


Page 23 


GCB Documentation 



GCB Implementation Notes 


Log File via the User Configuration File (see the User Configuration File section on page 24 for 
more information about the User Configuration File). 


4.1.11 User Configuration File 

The Graphical Comp Builder Prototype contains a number of features that are user configurable 
during execution. The state or value of the various options will be automatically saved to a user 
specific configuration file when the user exits the Graphical Comp Builder Prototype. The next 
time the user executes the Graphical Comp Builder Prototype, the user’s defaults will be restored 
to the state or value which the user last selected. 

The User Configuration File is saved as an ASCII text file. Each option is saved on a separate line 
in the configuration file. Each line contains an option name followed by a corresponding value. The 
Graphical Comp Builder Prototype will search several directories at the start of execution to locate 

the User Configuration File. The following directories will be searched in the following order to 
locate the User Configuration File: 

» the current directory 


• the user’s home directory 

The name of the User Configuration File is always: .Defaults.GCB The following options and 
corresponding values are stored in the User Configuration File: 

• The directory containing the Library Element GEF files. 

• Th , e type of Element which was last edited by the user. This option may have one of two 
values: ELEMENT or LIB RAR Y_ELEMENT. 

• The path and name of the disk file in which to write the Displayer’s output. 

• The name of the Comp last edited by the user. 

• The name of the Element last edited by the user. 

• The path and name of the Error Log file. 

The level of error log reporting. This option may be one of the following: “1”, “2”, or “3” 
Error log level “3” is used to specify the most verbose error reporting. Error log level “1” 
is the default setting and should be used during normal operations. 

• The path and name of the Object Access table. 


• The path and name of the last Position in which the user was working. 

The name of the last Position in which the user was working. 

• The target language for code generation. This option may be one of two values: MOAL or 


• The path and name of the directory containing the User Defined Functions object files. 

• The path and name of the Work Station Global table. 

• The state of the Display Symbol toggle. This option may be one of two values: “1”, or “0”. 

value of “1” indicates the Logic Description text should be displayed in the graphical 
symbols. A value of “0” indicates the Comp Expression text should be displayed in the 
graphical symbols. 

rerrnin^t^ ^ Jf ' $aVed t0 the User Configuration File should not end in a 
terminating backslash (“/”). 


Page 


GCB Documentation 


GCB Implementation Notes 


4.1.12 Displayer Output File 

The Graphical Comp Builder Prototype uses a standard “Displayer” to allow the user to view 
several operations during execution. See the Displayer section on page 14 for more information on 
the function of the Displayer. Each time the Displayer is presented to the user, a copy of the text 

h * pIayed “ tbC Lf reen 15 aIso written t0 a disk fil e- This file may be printed, copied, or 
edhted by the user This file is created each time the Displayer is presented to the user, and the 

p vious copy of the file is deleted. The user may specify the location and name of the Displayer 
Output File via the User Configuration File. p ye 

4*1*13 User Defined Functions Directory and Files 

The Graphical Comp Builder Prototype allows the user to make calls to C language object files 
which were created outside of the Graphical Comp Builder Prototype. These User Defined 
Funcuons are located in a directory specified by the user via the User Configuration File The User 
Defined Function names must begin with “FN_”. The Graphical Comp Builder Prototype will 
display to the user alist of the C language object files which begin with the proper formatduring 

— s rr 0fIFandSET Symbo1 ex P ressions - The Comp Installation process will locate the 
User Defined Function object files during the linking of the Comp executable. 

4.1.14 Object Access Table 

The Graphical Comp Builder Prototype will access an Object Access Tihle Hm-i™ rh n 

rass?’ °*' “ •“ ~ ss. - - 

4.1.15 Work Station Global Table 


Page 25 


GCB Documentation 


GCB Implementation Notes 


4.2 Data Structures 

The Graphical Comp Builder Prototype maintains a number of different data structures during 
execution. The following subsections will describe the more important data structures maintained 
by the Graphical Comp Builder Prototype. 

4.2.1 Symbol Array 

Each graphical symbol of an Element is maintained in the Symbol Array while an Element is active 
in the Work Area. The Symbol Array is a fixed length array of Symbol structures. The Symbol 
structure and Symbol Array are defined in gcb.h. All the information for a graphical symbol is 
available via fields or pointers contained in the Symbol structure, including the following: 

• The expressions contained in each graphical symbol are available via pointers in the 
Symbol structure. The data space for the expressions is malloc()’ed as needed. The Symbol 
structure does not contain any data space for the expressions within the Symbol structure. 

• Pointers to the connecting lines which enter and exit the Symbol are contained in the 
Symbol structure. The line information is not contained within the Symbol structure. The 
Symbol structure contains only pointers to Line Lists and Line structures which are 
maintained separate from the Symbol structure. 

• The coordinates relative to the Work Area and dimensions of the Symbol are contained in 
the Symbol structure. 

Almost all of the functions which manipulate the graphical symbols in the Work Area maintain the 
Symbol Array of structures due to the fact that almost every aspect of each graphical symbol is 
specified in the Symbol structure. 

4.2.2 Cell Map 

The Graphical Comp Builder Prototype utilizes a logical grid of cells as an efficient and powerful 
method of maintaining the Work Area. See the Graphical Symbol Placement Model section on 
page 4 for more information about the Cell Map concept. 

The Work Area Cell Map is implemented as a two dimension array of Cell Structures. Each Cell 
Structure contains a type flag and a pointer. The type flag indicates if the Cell is occupied and may 
have one of three values: Symbol Cell, Line Cell, or vacant. If the Cell is not vacant, the pointer 
will point to the graphical symbol structure or line structure which occupies the cell. The Cell 
Structure definition and the double dimensioned array of Cell Structures is contained in gcb.h. 

4.2.3 Line Structures 

The Graphical Comp Builder Prototype allows the user to logically connect the graphical symbols 
in the Work Area. The Element builder determines the program flow of the Element by the manner 
in which the graphical symbols are connected. A collection of structures are maintained by the 
Graphical Comp Builder Prototype to record the logical lines which connect symbols. There are 
three main Line Structures which are maintained by the Graphical Comp Builder Prototype 
software: 

• The LineSeg structure is the most basic element of the connecting lines between symbols. 
A LineSeg structure maintains the information for a single line segment from one point to 
another point. A logical connecting line between two graphical symbols may be composed 
of multiple line segments. Each orthogonal change in direction starts another line segment. 


Page 26 


GCB Documentation 



GCB Implementation Notes 


Each LineSeg structure contains a pointer to the next segment in the logical line if one 
exists. Each LineSeg structure contains the information needed to draw the line, including 
the information to draw the line segment’s arrow head if one is at the end of the line 
segment. 

• The Line structure represents a logical connecting line between two graphical symbols. 
Each Line structure contains a pointer to the first line segment of the logical line. The 
remaining segments of the logical line are available via a pointer in the LineSeg structure 
which points to the next line segment in the logical line. Each Line structure also contains 
a pointer to the two graphical symbol entries in the Symbol Array which the line connects. 

• The LineList structure represents a list of separate logical lines. The LineList structure is 
the highest level line structure. Each LineList structure contains a linked list of pointers to 
logical Line structures. LineList structures are used to record the list of lines which enter a 
graphical symbol. Each symbol may have only one or two lines which exit the symbol but 

many logical lines may enter a symbol, and the LineList structure is used to record each of 
these lines. 


Each of the three Lme Structures also includes a key field. The key field is used to record the line 
information of an Element File to disk and to restore an Element’s lines during the reading of an 
ement File from disk. The key field of each structure is set to a unique number before an Element 
File is written to disk. The unique numbers in the key fields are then used to reconstruct the 
interwoven network of pointers during the reading of an Element File from disk. 

^e various Line Structures are dynamically allocated as needed to maintain the Element in the 
Work Area. The Line Structures are defined in gcb.h. 

4.2.4 Symbol Table 


The Graphical Comp Builder Prototype maintains a Symbol Table of the identifiers and variables 
which comprise the expressions within the graphical symbols of a Comp. The following entities 

are maintained in the Symbol Table for each Comp- 


• The name of each Element which comprises the Comp is maintained in the Symbol Table. 

• The name of each local variable within an Element is maintained in the Symbol Table. 

• The name of each global variable within a Comp is maintained in the Symbol Table. 

• The name of each Object and each Work Station Parameter is maintained in the Symbol 


• The name of each User Defined Function and the name of each intrinsic function (cos, tan 
sqn, etc.) is maintained in the Symbol Table. The Symbol Table contains an entry for eve™ 
mtnnsic function, even if it is not referenced in the Comp. Only the names of the User 
Defined Functions which are referenced within a Comp are maintained in the Symbol 

The Symbol Table contains the following information about each entry: 

• The name of each symbol is maintained in the Symbol Table. 

• The use count of each symbol is maintained within the Symbol Table. The use count is a 

count of the number of times each variable or Element name is referenced within all of the 
Elements of the Comp. 


Page 27 


GCB Documentation 


GCB Implementation Notes 


• The attributes of each symbol are maintained within the Symbol Table. The attributes field 
is implemented as a collection of bit masks. The bits in the attributes field of a Symbol 
Table entry indicate various information including: variable data type and variable scope. 
The Installation status of Elements is also maintained in the attributes field of the Symbol 
Table entry. 

• The number of rows and columns of non-scalar variables is also maintained in the Symbol 
Table. 

A list of local variables is maintained for each Element name. The local variables of an Element 
are maintained as a list of children of the Element. In this way, the local variables of an Element 
are tied to the Element. Different Elements within a Comp may have local variables of the same 
name. Each time a local variable is accessed in the Symbol Table, the name of the Element in which 
the local variable is defined is supplied to ensure the correct local variable is accessed. 

Global variables are maintained in the root of the Symbol Table and have no parent due to the fact 
that global variables can be accessed from any Element within a Comp. 

The Comp Symbol Table is implemented as a linked list of structures. The Symbol Table Structure 
definition is contained in symbol. h. 


Page 28 


GCB Documentation 



GCB Program Flow 


4.3 GCB Program Flow 

A high level program flow diagram for the Graphical Comp Builder Prototype is contained in the 
figure below: 



Section 3 


A f hC pr ° gram .f ow a PPears to be very simple due to the program structure that is typical 

of X Windows and Motif based applications. There are only three main areas of program flow 
within most X Windows programs and the Graphical Comp Builder Prototype is no exception The 
three mam areas of program flow and their function are- 


• The first section of a typical X Windows program contains the establishment of the 
connection to the X Windows server and the definition of the X-based user interface. 

• The second section of a typical X Windows program is the main X Windows event loon. 
This code is usually linked into the application and is not written as part of the application. 

t-T v WS 6Vent l0 ° P Sends and receives events to and from the X Windows server 
The X Windows event loop is called at the start of the application and remains in control 
of the application until the program is terminated. The X Windows event loop will call 
various callback routines based on the events which occur in the X server. 


Page 29 


GCB Documentation 



GCB Program Flow 


• The third section of a typical X Windows program contains the callback routines. This 
section of code is where most application specific processing is performed. The majority of 
the Graphical Comp Builder specific software is contained within callback routines or is 
called by the callback routines. 

Each X Windows program usually contains these three sections of code. The relative size and 
complexity of these three sections varies between applications. In the case of the Graphical Comp 
Builder Prototype, the callback routines section of the application comprises approximately 90% 
of the software in the Prototype. The following two sections will describe in greater detail the first 
and third sections (initialization and callback routines). The second section is generic to all X 
Windows applications and is not specific to Graphical Comp Builder Prototype. The reader is 
referred to the X Windows documentation for more information about the second section. 

4.3.1 Section 1 - Initialization 

The Initialization Section of the Graphical Comp Builder Prototype comprises approximately 10% 
of the code in the Prototype. The initialization routines perform the following functions in the 
following order: 

• The Initialization routines contained in gcb.c setup a collection of signal handlers to trap 
desired Unix OS events. The Control-C signal is an example of the signals which are 
trapped. 

• The Initialization routines contained in gcb.c establish a connection to the X server and 
open the X Display. 

• The Initialization routines contained in init_X.c construct the X Windows interface. The 
Graphical Comp Builder Prototype builds all main windows and popup windows during 
initialization. 

• The Initialize routines contained in init_vars.c and utils.c initialize all global variables, 
including the graphical symbol array and the Work Area cell map. The Initialize routines 
also read the user’s Configuration File and set the variables identified in the User 
Configuration File to the specified values. 

4.3.2 Section 3 - Callback Routines 

The X Windows callback routines and the routines called by the callback routines, comprise about 
90% of the code in the Graphical Comp Builder Prototype. Due to the event driven nature of an X 
Windows based application, these callback routines are only called as the result of a user’s action 
within the X Windows interface. Almost every trace of a sequence of events within the Graphical 
Comp Builder Prototype begins in the source file: init_X.c. It is within this file that the majority of 
the interface is defined and the event handlers installed. 

The following is an example of the sequence of events and the typical program flow that occurs 
during most operations performed by the user within the Graphical Comp Builder Prototype. The 
following example shows the sequence of events and the program flow that occurs when the user 
selects and reads in an existing Element file. 


Page 30 


GCB Documentation 


GCB Program Flow 


Event 

Resulting Program Flow 

Source 

File 

User selects the 
Element menu. 

The Element pulldown menu is displayed. This menu 
was defined during the building of the user interface. 

init_X.c 

User selects the 
“Select Element” 
menu button. 

The callback routine cbr_elem_popup() was installed 
during the building of the user interface for this event 
and is called. 

init_X.c 


The callback routine cbr_elem_popup() makes a call to 
load_element_list() to load the Element selection list 
of the “Select Element” popup before the popup is 
displayed. 

element_file.c 


The load_element_list() routine makes a call to 
read_comp_list() to read the list of Element names 
from the Comp file. 

comp_file.c 


The callback routine cbr_elem_popup() makes a call to 
display the “Select Element” popup to the user. 

element_file.c 


The “Select Element” popup is displayed to the user. 
The “Select Element” popup was defined during the 
building of the user interface in init_X.c. A call was 
made from init_X.c to build_sel_elem_popup() in 
element_file.c to build the “Select Element” popup 
during the initialization of the user interface. 

popup built in 
element_file.c 


The callback routine for the Element selection list is 
called. The callback routine cbr_el_selected() was 
installed when the “Select Element” popup was built in 
build_sei_elem_popup(). 

element_file.c 

User selects an 
Element name 

from the list. 

The callback routine cbr_el_selected() determines the 
name of the Element the user wants to read and then 
makes a call to read_element_file() to read the 
specified Element file from disk into the Graphical 
Comp Builder Prototype. 

element_file. 


Once the Element file has been read from disk, control 
returns to the X Windows main event loop and the 
cycle begins again. 



Page 31 


GCB Documentation 



GCB Program Flow 


The preceding scenario is typical of each operation the user performs within the Graphical Comp 
Builder Prototype. For each operation the main program flow is basically the same. 


Page 32 


GCB Documentation 


Appendix A 





from the payload bar. This comp 
will monitor the status of the 
RMS pumps to make sure they remain 
within nominal and critical limits. 





Elements 


Installed 


CheckPumpl 

yes 



CheckPump2 

no 



Global Variables 

Type 

Dimensions 

Use Count 

V873457E 

int 


2 

GV cont 

int 

1 

2 



Page 1 



Purpose : 


Position : 
Comp : 

Element Name: 
Element Type : 
Author : 
Created : 

Last Update: 
Status : 


RMS 


Extract 

RootElement 

ELEMENT 

Timothy J. Barton 

08 / 25/1991 

08 / 27/1991 


This element sets up a loop which 
tests the two main pumps which 
drive the RMS. The loop continue 
flag is not altered within this 
Comp. The user can control the 
Comp from the Comp Manager. 


Complete 




Logical 

Description 


Comp 

E' session 


Comment 


continue until the 
extraction finishes 


continue until the 
extraction finishes 


GV cont : = 1 


Initialize the loop control variable to be TRUE. This loop 
should run forever. This comp is stopped by the user via 
the Comp Manager once the extraction has been completed. 


Page 3 








gical 
script ion 


check the continue flag. 


imp 

{passion 



omrcent 


Check to make sure we should ' go around' and perform 
the tests again. 


Page 4 







Position : 
Comp : 

Element Name : 
Element Type: 
Author : 
Created: 

Last Update: 
Status : 


Extract 

CheckPumpl 

ELEMENT 

Jerry Ratner 

08/27/1991 

08/27/1991 

Complete 


Purpose : 

This element checks the Pumpl 
pressures. This element checks 
the critical high and critical 
low limits. This element is 
set up to check for Rev. 2 type 
pumps ** 





Page 5 



limit . 



Comp 

F ression 



Comment 


'Sgh\imit ee TL t Woh U Sir? SSU ?h h ? S exceeded critical' 
Columbia and DiscSvIry Js J 2 f psl ' 2 PUmpS USed on 

The Rev. l pumps have critical high limit of 115 ps i. 


Page 6 









Page 7 



Appendix B 




Position : 
Comp: 

Element Name: 
Element Type : 
Author : 
Created : 

Last Update : 
Status : 


Extract 

CheckPumpl 

ELEMENT 

Jerry Ratner 

08 / 27/1991 

08 / 27/1991 

Complete 


Purpose : 

This element checks the Pumpl 
pressures. This element checks 
the critical high and critical 
low limits. This element is 
set up to check for Rev. 2 type 
pumps ^ 




SOUTHWEST RESEARCH INSTITUTE 
Post Office Drawer 28510, 6220 Culebra Road 
San Antonio, Texas 78228-0510 


ADA INVESTIGATION 


NASA Grant No. NAG 9-435 
SwRI Project No. 05-3531 


Prepared by: 
Timothy J. Barton 


Prepared for: 
NASA 

Johnson Space Center 
Houston TX 77058 


September 5, 1991 




Ada User’s Symposium 


1.0 Investigation of Ada for Control Center Software 

Investigation has been conducted to determine the availability and suitability of the Ada 
programming language for the development of future control center type software. The Space 
Station Freedom Project (SSFP) has identified Ada as the desired programming language for the 
development of Space Station Control Center (SSCC) software systems. The Department of 
Defense (DoD) has mandated Ada as the programming language for all new DoD software. Due 
to these mandates and related directions within private industry, an investigation of Ada was 
necessary. 

1.1 Ada User’s Symposium 

The first step in the investigation into Ada was to determine if the Ada programming language was 
receiving acceptance within NASA. The Ada programming language had a well publicized birth 
and was purported to be the High Order Language (HOL) of the 1980s and 1990s. During the last 
several years, Ada has received less publicity. It was important to determine if Ada was slipping 
into obscurity or quietly gaining acceptance, before significant effort was expended using Ada. The 
first step was to determine if it was still appropriate to develop an Ada version of the Graphical 
Comp Builder. 

The NASA Ada User s Symposium was the ideal event to determine NASA’s commitment to Ada. 
The presenters’ experiences with current Ada compilers also provided data on the ability of Ada 
compilers to produce a Graphical Comp Builder Prototype with acceptable performance. 

The Third Annual NASA Ada User’s Symposium was held at NASA-JSC’s Gilruth Center on 
November 6, 1990. The Ada Symposium directly answered the two main questions about Ada: 

• Is Ada gaining acceptance? 

• Will Ada executable’s performance be acceptable? 

The first question was answered immediately. The first hour and a half was a discussion about the 
Ada projects at the various NASA centers. Representatives from Goddard, JPL, Langley, JSC, and 
LeRC (Lewis Research Center) discussed the various projects using Ada and the Ada development 
labs at their respective center. A short summary of these projects is included. 

The second question was answered through the course of the entire day. The symposium was not 
just a group of Ada fanatics who are oblivious to the merits of C and FORTRAN and who think 
that Ada should be used in every piece of software that is written. Almost all of the presenters 
discussed the development and performance impacts caused by using Ada in their project instead 
of FORTRAN. In most cases, a performance comparison table to FORTRAN was presented which 
clearly indicated the performance of the Ada version. The audience and the presenters were very 
objective and very honest in their discussions about Ada. 

1.1.1 NASA Center Status Reports 

The first part of the symposium was a status report from the following NASA centers: 

• Johnson Space Center 

• Goddard Space Flight Center 

• Langley Research Center 

• Lewis Research Center 

• Jet Propulsion Laboratory 


Page 1 


Ada Investigation 


Ada User’s Symposium 


• JSC 

A short description of the projects at each center is included. 

1.1.1.1 JSC 

Most of the Ada work being done at JSC is in the SSCC and SSF Training Facility. The SSE which 
is being done by Lockeed is all in Ada and they are projecting that 1 million lines of Ada will be 
written before SSE is completed. OADP and OPAS are two projects within the SSCC that are using 
Ada. Some other projects at JSC are: 

• STA- Shuttle Training Aircraft 

• COMPASS - Computer Aided Scheduler 

• SMSS - F16 Stores Management System Simulator 

• JAEL - JSC Avionics Engineering Lab 

The JSC campus HVAC system is computer controlled using Ada. 

1.1.1.2 GSFC 

The Flight Dynamics Division at Goddard is using Ada very extensively. In 1984 less than 1% of 
all software developed at Goddard was in Ada. They estimate that more than 10% of all software 
developed in 1990 at Goddard will be in Ada. Goddard is probably the most committed of the 
NASA centers to Ada and they have extensive statistics to prove their move to Ada. The big 
projects at Goddard are: 

• FTS - Flight Telerobotic Servicer - all software in Ada 

• STGT - Second TDRS Ground Terminal - all software in Ada 

• HST - Hubble Space Telescope interface simulator 

• EUVE - Extreme Ultraviolet Explorer - spacecraft flight software 

1.1.1.3 LaRC 

Some of the projects at Langley are: 

• CSI- Control Structures Interaction - shuttle bay instrumentation platform 

• AFE- Aeroassist Right Experiment 

Langley is very big on Ada because they usually have very short turn-around times for their 
projects and they have found that Ada is faster to develop in than FORTRAN due to high reuse of 
software. It takes a software engineer longer to write an Ada module than a FORTRAN module, 
but the Ada module is often reused on other projects, whereas the FORTRAN modules are often 
rewritten due to the tighter coupling of the module to the particular program. 

1.1.1.4 LeRC 

The Electrical Systems Division of Lewis Research Center is building the Power Management and 
Distribution controller for SSFP. All the code in the Power Management system is in Ada and they 
are very pleased. As an example, the power on the SSF recently changed from AC to DC, and the 
Lewis software developers were very pleased with the maintainability of their Ada software. 


Page 2 


Ada Investigation 




1.1.1.5 JPL 

JP L is one NAS A center where very little Ada work is going on. JPL is not using Ada due to several 
actors. The staff at JPL feel there are not enough people with Ada experience so they see Ada as 
a risk item. JPL probes have had great success and they are afraid to abandon FORTRAN and 

assembler. The developers at JPL view Ada as big and slow, and their probes are small and have 
limited resources. 

1.1.2 Symposium Speakers 

The rest of the day, was devoted to speakers from the various NASA centers discussing their 
particular project in detail, A summary of some of the projects that were discussed is included. 

1.1.2.1 STGT - Second TDRS Ground Terminal 

™ s “ 'ff rc t time r je l° 2 VAX 63XX and 28 "Options) being done by General 
Electric (GE). They estimate that 490,000 lines of Ada will be written before STGT is completed 

GE is very .repr essed w ith Ada’s ability to aid in the management and development of a large 
software project. STGT is being completed ahead of schedule and it works. One of Ada’s strengths 

° Pmi0n ' ‘ S ' h ”' USability of Ada code - D “ri"g development of one portion of STGT 
,00 lines out of 90,000 total lines of Ada were reused from another portion of STGT For one 

of FORTRAN 15 ’ develo P ed “ *“• Ada squired 5,000 lines of code whereas 40,000 lines 

o FORTRAN were needed to write the same exact simulator. 

1. 1.2.2 STA - Shuttle Training Aircraft 

Mo S w1 J 5 S L h f!! whieh can be computer contrelled to fly like the shuttle 

35 ’T f t ‘ STA 1S used hy P lIots t0 practice shuttle landings and descent. STA uses Snerrv 
and Motorola processors in its Guidance Control Computer (GCC) to control the wing surfaces a^d 

oririnan Cnab e GuIfs . tream t0 exhibit shuttle-like flight characteristics. The STA was 
° f Hif ^ r° gram i 1 i ne f d u° mp ! ete y m assembl y language. Most of the software has been convened 

datt bCen C ° nVerted t0 ^ ^ Pr ° jeCt haS CXtensive timin S 

S F0RTRAN to Ada. Not surpnsmgly, FORTRAN is faster than Ada, but only about 

15% faster. The group which is responsible for STA feel that their Ada programi are deLitelv 

much easier to develop and maintain. Their theory is: software is expensive, hardware is chea^ 

buy fast enough hardware to support the proper software development environment (Ada) and 

ZlZ'o™ y - STA Sr °“ P USeS Ready SySKms AR ™ Real-Time E^cmfve and 

1.1.2.3 JAEL 

hardware: ^ vion ’ cs Engin “™8 La » OAEL) is responsible for testing the shuttle’s avionics 

• GPC- General Purpose Computers 

• MDM- Multiplexor Demultiplexor 

• MTU- Master Time Unit 

• MCDS- Multi-purpose Display System 

Even though this group is shuttle related and has no Ada mandate, they now use Ada for all their 

tm Her ,^ CaUSe ey have had “ g00d past ex P e ricnces” with Ada They feel Ada has helped 
them deliver their systems on-time as opposed to FORTRAN. P 


Ada Investigation 


Hartstone Benchmark 


1.1.3 General Highlights 

The following are some short excerpts from the symposium: 

• The SSFP has been losing a lot of money for various projects through “scrubs” lately, 
but Ada and projects using Ada have fared very well. 

• Interestingly, Ada was always compared to FORTRAN during the symposium. The C 
language was only mentioned once or twice. 

• Many of the embedded system projects utilize the military’s 1750A microprocessor. 
There were several very positive comments regarding the Ada development 
environments available for the 1750A microprocessor. 

• Many of the real-time projects used run-time environments to improve real-time 
performance and these environments provide additional interprocess communication 
mechanisms other than the Ada rendezvous. 

1.1.4 Non-NASA Highlights 

The following are several short excerpts from the symposium regarding projects outside of NASA: 

• There are over 500 validated Ada compilers. 

• The B2 (stealth bomber) trainer was developed entirely in Ada by Link, and the Boeing 
747-400 contains approximately 500,000 lines of Ada in its fly-by-wire control 
systems. 

• Much of the software in the Sea Wolf ASW missile was written in Ada. 

• Volvo has completed several projects using Ada including all of the software to control 
their assembly plant Automatic Guided Vehicles (AGV). 

• On Monday, November 5, 1990, Congress signed legislation which states that the 
Secretary of Defense must now sign waivers if Ada is not going to be used on a military 
project. Waivers will only be granted if it can be demonstrated that another language 
will be more cost effective over the entire life-cycle of the project. Ada has done very 
well in the past in software life-cycle cost studies, and the new legislation may increase 
the number of DOD projects which use Ada. 

1.2 Hartstone Benchmark 

The second step in the investigation of Ada focused on the relative performance of Ada programs 
on two workstations often used in control center environments. The Graphical Comp Builder 
Prototype is a very user interactive program. The ability of the program to respond quickly to user 
actions is paramount to the program’s acceptance by users. The performance of the Graphical 
Comp Builder Prototype is most critical during graphical symbol placement in the large work area. 
The C language version of the Graphical Comp Builder Prototype has been designed and 
implemented to ensure smooth response to mouse movements in the work area. An Ada version of 
the Graphical Comp Builder Prototype will have to perform symbol placement operations with 
equally acceptable performance. 

The Hartstone Benchmark is being utilized to provide information regarding the performance of 
the executables produced by various Ada compilers. The Hartstone (Hard Real Time) Benchmark 
is an Ada program designed by the Software Engineering Institute (SEI) for the USAF which is 
used to measure a computer system’s ability to support a collection of real-time tasks. The 


Page 4 


Ada Investigation 



Hartstone Benchmark 


^o“l h e m ^ S EaSt t"^' 0 ab ™ a «-»’• ability to 

compilers for the same system The Hartstone nZZh ° e ’[ ecutaWes produced by different 
the ability of two different system' ZlfZ Benchmark can also provide information regarding 

system load. To £reXT a o nfoZlV ^ a Sun) ' ° P“*»» ** samf 

one Ada compiler for either tfT Sun nrZ “ onhasbee "® »ihered due to the availability of only 

available for ehher the Sun or Ma scol htl l° mP ' a “ a Second A<ta compiler become 
will be provided. Masscomp, <ben comparison data of executables on the same system 

1.2.1 Hartstone Benchmark Design 

^fere^r^cUi^are^timVs^Ttem^Each^x 6 ^ 68 ° f ' 4 T” wh “ arc designed to res, a 
must perform a specified amount of comDutaHn* 611 ^ 01 Ut \ lzes a m * n * mum °f 5 Ada tasks which 
Period of each Jthe 5 P~ d time 

measure a different aspect of system performance * dlffercnt experiments to 

Whetstone benchmark to produce and me^T sysh “^es a variant of the 

expenments which comprise the benchmark are numbered S Il s""' PCri0d ^ 4 
followmg aspect of the system: ° 1 4 d th y e desi S ned to test the 

frnl'dLa^ 

Priority task is decreased:’;” Lo„m ™“tcts tmJ W * h 
task switch overhead. CS ncreases consequently the 

EXPenmenI 2 " indicator of a system ’s abilit^E itS 

wEmus! b^otptedwEl £ ri;7 p S n Ex^m 3 is" * 
system's compute perfonnance for a set time penrid mdlca '° r of a 

sysL's^’i^^tTn^n g°nuEr Tmst’*™’ 4 “ “ “““ ° f a 

pmod) wof Etn ea^h <aU0,ttd “ mC 

frequency or computational work ioad of the tasks is th = 

1.2.2 Sun vs. Masscomp Comparison 

CMcmre;^Computer05^or^i”;°Mas^omDlor 0 s me M' enV ' ronmenlS “ *-*— by either 
Benchmark suite was tesred against these twfmacMn.E’^E* works,a ' io "S. The Hartstone 
either of Ute Ada environmems on the e IX ” l ‘ nf0In,ati0n ,owards wh ^er 
verston of the Graphical Comp Builder Prototype Wtat Z ™ pIeme " t arion of an Ada 
implement the Graphical Comp Builder Promt™. X W dows btndmgs which are needed to 
The Haris, one Benchmark betaf „f;rrd e Eine CU ’ Ten,lyaVai ' ab ' e “ ,hc resea rch team. 

characteristics ofAda executables on a Masscomp Ea Sun “ * SCale performa nce 



Ada Investigation 



Hartstone Benchmark 


The Hartstone Benchmark was executed on a Masscomp 6350 and a Sun 4/65 (SPARC Station 1 ). 
Both machines arc mid-level Unix workstations from the product lines of their respective 
manufacturers. The two workstations which were benchmarked share many of the same features. 

• Unix-based workstation 

. 16 megabytes of memory 

. X Windows support 

• SCSI peripherals (hard drive, tape drive, floppy drive) 

• networked via ethemet (NFS and NIS client) 

The two workstations are also very different in some respects. Due to the nature of the real-time 
Hartstone Benchmark, the Real-Time Unix (RTU) of the Masscomp would typically be a benefit 
when compared to the Sun’s version of Unix (SunOS). The Hartstone Ada source code » has ; been 
written wifh portability as a prime objective so the RTU 

program were not employed. Only the real-time features implicitly utilized in RTU were 
employed. The following are some of the other differences between t e two wor s a 10 

. RISC based Sun (SPARC) vs. CISC based Masscomp (68030) 

. desktop Sun (single system board employing high integration, i.e. memory) vs. 
deskside Masscomp (multiboard system, i.e. separate memory and graphics boards) 

. Verdix Sun Ada compiler vs. Masscomp C3Ada compiler 
The resulting benchmark results have been interpreted in a very general fashion to make 
allowances for the differences in the two workstation’s hardware and operating system software. 
The results given in this report will be general statements based on the interpretation of the average 
results of the benchmark. The authors of the Hartstone Benchmark are quick to point out the fact 
that a large number of independent variables affect the results of the benchmark, and that the data 
produced by the benchmark should be used to demonstrate the variations that are possible. The 
specific Hartstone Benchmark results should only be directly compared in situations where most 
independent variables can be controlled. For this report, a direct comparison is not feasible. For 
bot/workstations, the results could be either improved or degraded with optimization and tuning 
for the particular workstation, use of the RTU real-time features within the C3 Ada compiler are an 

example. 

1.2.3 Hartstone Benchmark Results 

The complete reports produced by the Hartstone Benchmark for both the Sun and the Masscomp 
are included in Appendix E of this report and a summary of the results is included in Figures , 

3 and 4. Where possible, the machines were configured as similarly as possible. Each machine was 
configured as follows during the execution of the benchmark: 

• multiuser mode 

• benchmark was executed as “root” 

• disconnected from ethemet 

A single copy of the Hartstone Benchmark source code was used to build each respective 
executable The complete set of experiments (1-4) was executed 3 times for each machine. The 
results of each 3 runs are included in the table in the order in which they were run. 


Page 6 


Ada Investigation 


The Hartstone Benchmark was executed on both machines using the same baseline test* in each 

fubfenT? the Same 30101,111 0f com P utational workload was requested during the first’ test and 
subsequent increments in workload were also the samp f™- thJ ♦ u - o teSt 

observations can be made which are valid for“i.'t“xt ri “ ^ ^ 

Due to the controlled environment in which the experiments wete conducted the results 
for each three runs of each experiment were very close if not exactly the same Slieht 

dUe ,0 ° CCaS10na ' SySKm fU " ctf °" s s “ ch as syste"'® d 

cron tasks The very narrow variations exhibited in most experiment results is an 
indication of very few external factors affecting die experiment results 

' T ntly deVe ' 0PCd R,SC m ' cro P r °cessor used in the Sun delivers better raw 

mos, ,he i 0lder ? SC c in ' he Masscom P' 1" the tables included in 
calculated by one task in one second at thestaf i^ 

computed by the Masscomp The “raw KWTP<;» T double the number 

a /“ e in reponing ° f 

Which is idendfied for ^ 

which rate the system load is increased in c k ‘ ^ tep factor ldentlfies at 
execution of the benchmarks the initial loan h |f qU f m ex P erime nt test. During ihe 

during the experiment if e C ° mpuK loads added 

Masscomp’s lower performance the new l n mi T and dle Masscomp. Due to the 
burden than to the Sun The “step factor” m/ rr 6 1° dleMasscom P were a greater 
Masscomp and the Sun The ”sten ft, or” ' he / a “° of Ioadi "S between the 

(100% utilization) by the compute load f"”“ 

• Dne S, ,o e ,h d ff tha ' ^ ‘ he dUC '° ,hC — trf«e WaS 

sSs^3WSS5 

suggested that the Masscomp’s softwSe (Ada comDile^ a nd/ nd n^ aSSC0^1P, U Can be 
performing the type of test targeted 3L com P ller and/or OS) is more efficient at 

less raw compute ^ Z'Z??*'? 

vanation in the number of tests mmn i«»d • V , „ test ‘ ln cases where the 

determine the nature of the test. The ‘^ercen^C^’MoLT faC ? FS may b ° StUdied t0 

these cases to determine if the Massmmn ic v^ dl ° g indlcator ma y be used in 

the Sun. Masscomp is perfoiming as expected when compared to 


Page 7 


Ada Investigation 



Hartstone Benchmark 


These factors should be kept in mind when studying the Hartstone Benchmark results. Given the 
preceding backdrop, the following observations have been made. 

• Experiment 1 is a good indicator of a system’s ability to task switch five tasks with one 
task increasingly adding task switch overhead. The fifth task gradually increases its 
frequency as its time period decreases. In this experiment, the Masscomp delivered 
similar performance to the Sun even though it has less raw compute performance. This 
may indicate that for the task set in Experiment 1 the Masscomp ’s Real-Time Unix is 
an advantage over Sun OS and other BSD Unix implementations even when RTU’s 
explicit real-time features are not utilized. Investigation of Experiment 3 would indicate 
the opposite is true. For the task set in Experiment 3, the Sun delivered much better 
performance when compared to the Masscomp. 

• The results of Experiment 1 for the Masscomp and the Sun are consistent with the 
findings often observed at the SEI; the highest priority task (task number 5) misses 
deadlines before the lower priority tasks. Both the Masscomp and Sun missed deadlines 
in task 5 in Experiment 1. Due to the priorities assigned by the Hartstone Benchmark, 
the opposite scenario should be the case. The lower priority tasks should miss their 
deadlines first as they are increasingly preempted by higher priority tasks. The SEI is 
currently researching the cause of the “Inverted Task Set Breakdown Pattern” which 
was exhibited by both the Sun and Masscomp. 

. The Masscomp and its RTU operating system produced very good CPU utilization 
figures when compared to the Sun for the Experiment 1 task set. The Masscomp 
consistently delivered approximately 17% CPU utilization as compared to the Sun 
which delivered approximately 8% CPU utilization. 

• The Masscomp also performed very well in Experiment 2. Once again, the Masscomp 
delivered a much higher CPU utilization before deadlines were missed. Although the 
Masscomp delivered higher CPU utilization, the Sun delivered higher performance 
given its greater compute performance from its RISC microprocessor. 

• The Sun performed exceptionally well during Experiment 3 when it achieved 4102 
KWIPS, or approximately 90% of CPU utilization. The Sun also displayed a very even 
distribution of tasks which missed their deadlines as the system was loaded. In 
Experiment 1, both the Masscomp and the Sun missed deadlines in the highest priority 
task. This is not the behavior which is expected or desired. As the load on the Sun 
increased during Experiment 3, the lower priority tasks began to miss deadlines while 
the higher priority tasks missed very few or no deadlines. The task set used in 
Experiment 3 appears to be very well suited for the Sun. 

• There were few surprises in the results of Experiment 4. Once again, the Masscomp 
delivered very good CPU utilization. Once again, the faster Sun CPU delivered higher 
performance than the Masscomp. As in Experiment 3, the Sun delivered very good 
distribution of missed deadlines across lower priority tasks as the system was loaded. 
As the Masscomp CPU was loaded, it did very poorly in distributing missed deadlines 
across lower priority tasks. In the last test attempted by the Masscomp, the highest 
priority task was the only task to miss deadlines. 

The Hartstone Benchmark has provided insights into the relative strengths and weaknesses of the 
two hardware and software systems tested. The Hartstone Benchmark clearly showed the compute 


Page 8 


Ada Investigation 



performance of the Sun and the effectiveness of thp r^i . , 

sr - — - — - - ~ 



Ada Investigation 


Hartstone Benchmark 


Experiment 1 - Last test with no missed/skipped deadlines 



Test # 

Percent CPU 

Task5 Freq. 

Step Size 

KWIPS(raw) 

Masscomp 

1 

16.32% 

32Hz 

1.63% 

1960.79 


1 

16.32% 

32Hz 

1.63% 

1960.79 


1 

15.31% 

32Hz 

1.53% 

2090.62 

Sun 

2 

7.86% 

48Hz 

.71% 

4476.28 


1 

7.17% 

32Hz 

.72% 

4464.29 


1 

7.15% 

32Hz ' 

.71% 

4476.28 


Experiment 1 - First test with missed/skipped deadlines 


Test# 

Percent CPU 

Task5 Freq. 

Step Size 

KWIPS(raw) 

Masscomp 

2 

17.95% 

48Hz 

1.63% 

1960.79 


2 

17.95% 

48Hz 

1.63% 

1960.79 


2 

16.84% 

48Hz 

1.53% 

2090.62 

Sun 

3 

8.58% 

64Hz 

.71 

4476.28 


2 

7.88% 

48Hz 

.72 

4464.29 


2 

7.86% 

48Hz 

.71 

4476.28 


Experiment 1 - Test with 50 or more missed/skipped deadlines 


Test# 

Percent CPU Task5 Freq. 

Step Size 

KWIPS(raw) 

Masscomp 

2 

17.95% 

48Hz 

1.63% 

1960.79 


2 

17.95% 

48Hz 

1.63% 

1960.79 


2 

16.84% 

48Hz 

1.53% 

2090.62 

Sun 

3 

8.58% 

64Hz 

.71 

4476.28 


3 

8.60% 

64Hz 

.72 

4464.29 


3 

8.58% 

64Hz 

.71 

4476.28 


Figure 1 


Page 10 


Ada Investigation 






Hartstone Benchmark 


Experiment 2 - Last test with no missed/skipped deadlines 



Test# 

Percent CPU KWIPS 

Step Size 

KWIPS (raw) 

Masscomp 

2 

17.48% 

352 

1.59% 

2013.42 


3 

19.58% 

384 

1.63% 

1960.79 


3 

18.50% 

384 

1.54% 

2076.11 

Sun 

7 

11.73% 

512 

.73% 

4364.91 


6 

10.72% 

480 

.71% 

4476.28 


6 

10.72% 

480 

.71% 

4476.28 


Experiment 2 - First test with missed/skipped dead! 

ines 


Test# 

Percent CPU KWIPS 

Step Size 

KWIPS (raw) 

Masscomp 

1 

15.89% 

320 

1.59% 

2013.42 


4 

21.22% 

416 

1.63% 

1960.79 


2 

16.95% 

352 

1.54% 

2076.11 

Sun 

2 

8.06% 

352 

.73 

4364.91 


1 

7.15% 

320 

.71 

4476.28 


3 

8.58% 

384 

.71 i 

4476.28 


1 1 

Experiment 2 - Test with 50 or more missed/skipped 

i 

deadlines 


Test# 

Percent CPU 

KWIPS 

Step Size 

KWIPS (raw) 

Masscomp 

4 

20.66% 

416 

1.59% 

2013.42 


4 

21.22% 

416 

1.63% 

1960.79 


4 

20.04% 

416 

1.54% 

2076.11 

Sun 

8 

12.46% 

544 

.73 

4364.91 


8 

12.15% 

544 

.71 

4476.28 

— 

8 

12.15% 

544 

.71 

4476.28 


Figure 2 


Page 11 


Ada Investigation 





Hartstone Benchmark 


Experiment 3 - Last test with no missed/skipped deadlines 


Test# Percent CPU KW1PS Step Size KWIPS(raw) 


Masscomp 

7 

6 

9 

35.29% 

31.29% 

39.03% 

692 

630 

816 

3.16% 

3.08% 

2.97% 

1960.79 

2013.42 

2090.60 

Sun 

55 

84.84% 

3668 

1.43% 

4323.39 


58 

86.10% 

3854 

1.39% 

4476.28 


58 

86.33% 

3854 

1.39% 

4464.29 


Experiment 3 - First test with missed/skipped deadlines 


Test# 

Percent CPU 

KWTPS 

Step Size 

KWIPS(raw) 

Masscomp 

3 

22.64% 

444 

3.16% 

1960.79 


3 

22.05% 

444 

3.08% 

2013.42 


10 

42.00% 

878 

2.97% 

2090.60 

Sun 

2 

8.84% 

382 

1.43% 

4323.39 


10 

19.61% 

878 

1.39% 

4476.28 


8 

16.89% 

754 

1.39% 

4464.29 


Experiment 3 - Test with 50 or more missed/skipped deadlines 


Test# 

Fercent CPU 

KWTPS 

Step Size 

KWIPS(raw) 

Masscomp 

9 

41.62% 

816 

3.16% 

1960.79 


8 

37.45% 

754 

3.08% 

2013.42 


12 

47.93% 

1002 

2.97% 

2090.60 

Sun 

62 

94.88% 

4102 

1.43% 

4323.39 


62 

91.64% 

4102 

1.39% 

4476.28 


62 

91.88% 

4102 

1.39% 

4464.29 


Figure 3 


Page 12 


Ada Investigation 







Experiment 4 - Last test with no missed/skipped deadlines 
Test# Percent CPU Tasks Step Size KWIPS(raw) 


Masscomp 

3 

22.25% 

7 

3.18% 

2013.42 


8 

39.17% 

12 

3.26% 

1960.79 


13 

52.04% 

17 

3.06% 

2090.60 

Sun 

33 

52.90% 

37 

1.43% 

4476.28 


34 

54.33% 

38 

1.43% 

4476.28 


34 

54.33% 

38 

1.43% 

4476.28 

1 


J 

Experiment 4 - First test with missed/skipped deadlines 


Test# 

Percent CPU Tasks 

— 

Step Size 

KWIPS(raw) 

Masscomp 

4 

25.43% 

8 

3.18% 

2013.42 


6 

32.64% 

10 

3.26% 

1960.79 


2 

18.37% 

6 

3.06% 

2090.60 

Sun 

4 

1 1.44% 

| 

8 

1.43% 

4476.28 


1 

7.15% 

5 

1.43% 

4476.28 


8 

17.16% 

12 

1.43% 

4476.28 


Experimem 4 - Test with 50 or more missed/skipped 

deadlines 

_ 

Test# 

Percent CPU 

Tasks 

Step Size 

KWIPS(raw) 

Masscomp 

10 

44.50% 

14 

3.18% 

2013.42 


15 

62.02% 

19 

3.26% 

1960.79 

. 

17 

64.29% 

21 

3.06% 

2090.60 

Sun 

36 

57.19% 

40 

1.43% 

4476.28 


36 

57.19% 

40 

1.43% 

4476.28 

— 

30 

57.19% 

40 

1.43% 

L 

4476.28 


Figure 4 



Ada Investigation 






2.0 Bibliography 


Donohoe, Shapiro, and Weiderman, Hartstone Benchmark User’s Guide Version 1.0, 
Camegie-Mellon University Software Engineenng Institute, March 1990. 

Donohoe, Shapiro, and Weiderman, Hartstone Benchmark Results and Analysis, Camegie- 
Mellon University Software Engineering Institute, June 1990. 

Proceedings of the Third Annual NASA Ada User's Symposium, November 1990. 

Weiderman, Nelson H„ Ada Adoption Handbook: Compiler Evaluation and Selection, 
Version 1.0, Camegie-Mellon University Software Engineenng Institute, 

March 1989. 

Weiderman, Nelson H„ Hartstone: Synthetic Benchmark Requirements for Hard Real-Time 
Applications, Camegie-Mellon University Software Engineenng Institute, 

June 1989. 


Page 14 


Ada Investigation 



SOUTHWEST RESEARCH INSTITUTE 
Post Office Drawer 28510, 6220 Culebra Road 
San Antonio, Texas 78228-0510 


An Investigation and Comparison of the C and Ada 
Programming Languages for Use In the Space Station 
Control Center and Space Station Training Facility 


NASA Grant No. NAG 9-435 
SwRI Project No. 05-3531 


Prepared by: 

Timothy J. Barton 
Steven W. Dellenback, Ph. D. 


Prepared for: 
NASA 

Johnson Space Center 
Houston TX 77058 


Presented on: 
March 8, 1991 




Introduction 

i^M a c 8 k“ n c °r cJ “ r u ~d 

influence the development of Space Station * n fr C C Cy ^ C ° f thc Space Station will also 

long life cycles and To U ^ Which Was desi g" cd «* 

percepdonshave been t^atA^^lmrtht Tr 7* bul ^ 

has been written to provide input to the auestion of «,»,• ifi & ° C ^ several rcas ons. This paper 
n u . . r P mc qucsUon of w hich language to use for the SSCC and SSTF 

l^gefw^Sbte ^L“^ Satf ° n ’ “ in - dep,h perfonM ”« benchmarking of the 
ssrr f Zxm P ? These same time constraints did not permit an in depth studv of Til 
SSCC and SSTF applications which would be affected by the C versus Ada Q „e2™ ™ 
will instead focus on more general discussion* of tk.V 7 Ad quesnon - 11115 paper 

applications with which the researchers have the most “han^o^r 3 ^ f0CUS ° n the 

are specifically the MCCU workstation applications. * expenence. These applications 

^vidfmetotESon £51“"? the , res “" of case s,udies - Tb'se base studies 

languages. ITte follo^^e " P ' n “ C ' 

of this paper prCmded S1 8 nlflcant ‘"P“' mto the recommendations 

^m"e „ A K ) S TJtZ , ”on C r o ?'r n8 ^ W— • **000 

completed on bccausc “ » being 

approximately only 

Thts effort incorporates a large number of COTS produas This S", Vn ^ 
significant because a related ontTma^M proaucts. mis effort is especially 

Adaeffort. comparable project is betng done in C concurrent to the 

Trainer S (CAST)*' Tt!^^ “ 1 "’ plcmcntauon of Combined Arms Service 
of special significance because rhev K P ^f r ‘ llie ex P enen ces of the FDD are 

v . 

T^TngASOTAlm'dlTe^^ 

case studies used in the preparation of this paper. ^ (STGT) 9X6 some of thc other 

discussion concemi^^daT^^The followi^gTe^ 06111 ? Ublidati ° nS provide thc basis for this 


Page 1 


Investigation of Ada vs. C 


Questions 

1 . Does the amount of MCCU C code available for reuse justify the use of C for new SSCC code? 

[Less complex operating (run-time) environment then would be required to handle C Ada, and 
possibly Fortran in TCATS System] 

2. Can the productivity improvement of 2-lines of code per PYE per day claimed by Loral be 
justified when going from Ada to C language? 

[8-linc/day for Ada versus 10-line/day for C] 

3. Can coding in C be done in a way (i.e., using up front software engineering practices and tools) 
that results in a product that is as easily maintained as an Ada code product, i.e., is the life cycle 
cost for C code naturally higher than Ada code? 

4. Does the control center and trainer systems requirements differ sufficiently to justify C 
language for SSCC and Ada language for SSTF (i.e., real-time operation of trainer systems, mostly 
new code required by Trainer; however, some Fortran reuse is expected, etc.)? 

5. Does the future of code development suggest limitations on resources (people and tools) for C 
programming versus Ada programming (next 10-20 years)? 

6. Are the up front costs for Ada (tools, training, and lack of experienced programmers) 
significant compared to that for C? 

7. What are the risk assessments for completion of the SSCC and SSTF on schedule and within 
cost considering use of C versus Ada languages for new code in each facility? 

8. Are COTS products that will be available in the next 1-10 years more likely to be in C or Ada 
language? 

9. Will COTS products in the next 1-5 years be available that will support multiple language 

applications (C, Ada, Fortran)? 6 6 

[i.e„ will COTS tools likely have bindings for Ada, Fortran, and C, such as X windows and 
other system services tools] 

10. What would be your recommendation for language use in the SSCC and SSTF given the desire 
to maximize use from Shuttle, maximize portability across SSFP and within the SSCC/SSTF 
faciliues, independence from hardware constraints, and significant budget pressures to cut up front 
costs and reduce run out costs with minimum risk to delivery capability and schedule? 

[Consider resources availability, etc.] 


Page 


Investigation of Ada vs. C 


1. Does the amount of MCCU C code available for reuse justify the use of C for 
new SSCC code? [Less complex operating (run-time) environment then would 
be required to handle C, Ada, and possibly Fortran in TCATS System] 

This is very dependent on two principle factors, the amount of MCCU C code which can actually 
be reused in SSCC and the benefits of Ada compared to C. If a majority of all Delivery 1 SSCC 
software is directly reused from MCCU, then C might be the best selection for all SSCC code. If 
it is demonstrated that Ada offers significant benefits over C, then Ada might be the best selection 
for all new SSCC code given the expected long life cycle of the SSCC. 

The fust factor in determining whether new SSCC code should be written in Ada is to ensure that 
Ada offers benefits over C for the life cycle of the SSCC. Everyone would agree that it does not 
make sense to use Ada if C is going to provide more benefits over the life cycle. It does not make 
sense to use Ada just because it has been widely associated with the SSFP . For the sake of argument 
for this question, it will be assumed that Ada provides benefits over C which are desired by NASA. 
If this is not the case, then the selection of C would be obvious. The Ada versus C argument will 
be addressed within other questions. 

Given the assumption that Ada provides benefits over C which are desired, the decision to use Ada 
for new SSCC software is dependent on two factors: 

• The amount of MCCU software which will be reused could justify the continued use of 
C in new SSCC software. If 90% of MCCU software could be reused without 
modification, then it would make sense to continue to use C. A completely C based 
SSCC environment would be less complex than a mixed language environment and 
might allow compatibility between SSCC and MCCU applications. Compatibility with 
MCCU is clearly a goal of the SSCC in an effort to reduce development costs for both 
centers. Differences in mission, scope, and data acquisition strategies, may make this 
compatibility goal impossible to attain. If this goal can be realistically attained, it makes 
sense to reuse the existing base of MCCU C code and to develop new SSCC code also 
in C. 

• The differences in mission, scope, and data acquisition strategies will probably mean 
compatibility between MCCU and SSCC will not be maintained beyond Delivery 1 of 
the SSCC software. The amount of MCCU software which can be directly inserted into 
the SSCC without modification is probably very small in light of the modifications 
which are required to meet the SSCC requirements. The following are examples of the 
MCCU workstation software which have been selected for integration into the SSCC 
from MCCU: 

Display Manager 
Display Builder 
Comp Manager 
Comp Builder 

Each of these applications will require modifications before they can be integrated into 
the SSCC. The potential for reuse varies for each of these applications based on the new 
SSCC requirements for each application. The Display Builder and Display Manager ap- 
plications are tentatively scheduled to receive new interfaces (GKS to X Windows), 
new data acquisition strategies, and additional functionality to meet SSCC require- 


Page 3 


Investigation of Ada vs. C 



ments. The new interfaces and data acquisition will require extensive modifications to 
both applications and may limit reuse to as little as 10% of existing MCCU Display 
Manager and Display Builder software. In the case of the Display Manager and Builder 
it may be reasonable to rewrite these applications from scratch using Ada if Ada is de- 
termined to be more desirable than C due to the projected long SSCC life cycle. 

The potential for reuse is much greater for the MCCU Comp Manager and Comp Build- 
er applicauons. These applications require less extensive medications to their user in- 
terfaces to meet SSCC requirements. Modifications are still required to their respective 
user interfaces, but the potential for reuse is probably about 60-70% in the user interface 
portions of these applications. The Comp Manager and Comp Builder applications will 
require extensive modifications for the new data acquisition strategies used in the 
SSCC and to meet new SSCC requirements. These required modifications, and the 
much smaller size of these two applications when compared to the Display Manager 
and Display Builder, also makes it reasonable to rewrite them from scratch in Ada if 

Ada can be shown to provide important benefits over the long life cycle which is oro- 
jected for these applications. v 


One important aspect of converting the Comp Builder to Ada is the translation of comps 
into executables by the Comp Builder. All versions of the Comp Builder use the work- 
station resident C compiler to produce machine executable comps for the Comp Man- 
ager An Ada based Comp Builder will either require the Ada compiler to be resident 
on the Comp Builder workstation, or the executable comps may continue to be gener- 
ated via the C compiler. Converting the Comp Builder to use Ada as the target language 

from which executable comps are produced will have a sizable impact on the Comp 
Builder s translation functions. v 

Extensive modifications will be made to the four existing MCCU applications identified above 
before they are integrated into the SSCC. These modifications have been sholTtol^dv 
impact the percentage of code which can be reused. The relatively low percentage of exfsting code 
which can be reused coupled with the new software which must be developed makes it reasonable 
to consider Ada for use in the SSCC if Ada can be shown to provide benefit o^ C 

n T t ° P ?° n ** ±e of both languages into the SSCC. NASA-Goddard and other 

commercial vendors (Lockheed-Austin as one example) have had very good success utilizing a 
nnxtmc o C and Ada. The nigh, Dynamics Division (FDD) a, Goddard L commtod ,o ^ as 
eir first language of choice. Even with this commitment to Ada, the FDD still reserves the right 

? ““ C P “T nS 0f their sys “ ms where C is ‘■PP'opria.e than Ada. C= TOD fs c^endv 
de J e ‘ opm ‘ m of a *■»» software development effort estimated to be a 300 man-yea^ 
effott. Most of the software will be developed in Ada, but some portions of the system will be 

mmrn' ^FDDfaTihm c *“'5 “ *, be “ r Ch01Ce than Ada for *>"“ P^ons of the entire 
system. The FDD feels that C is a better language for low level graphics operations. 

The Comp Builder may be an excellent application in which to use both Ada and C The Comp 
Builder application may be written in Ada while the comps which it generates may continue to be 
complied C. This would utilize Ada where it is most appropriate, but would stiH utilize C for^ 
portion of the appheauon where it is well suited due to the transparent compilation of comps which 
must occui-. The runtime impacts of the port to Ada would be minimizedfor the Comp Manager 
and a larger portion of existing Comp Manager code could be reused. This would allow 95 


Page 4 


Investigation of Ada vs. C 


Comp Builder/Manager software to be written in Ada, and C could be used for the 5% of software 
where its benefits over Ada could be realized. 


Page 5 


Investigation of Ada vs. C 


2. Can the productivity improvement of 2-lines of code per PYE per dav 

claimed by Loral be justified when going from Ada to C language? [8-line/day 
for Ada versus 10-line/day for C] 6 s 1 ady 

° bjeCti T Snd phUos °P hies of Ada and C languages make an 8 lines per day 
J lines per day comparison difficult. It is reasonable to expect that in one <£y a C 
programmer will wnte more lines of code than an Ada programmer. For smaller projects this has 
been demonstrated and is widely accepted. Over the course of longer projects, the benefits of the 
Ada language compensate for its more complex and larger source files*. 

'?"^' nc ' s of on the SwRI CAST program would indicate that it will rake slightly 

mme time to develop Ada source code than C source code. This is attributed to the fact that the 
anguage is more verbose than C and it is widely acknowledged that Ada is a better self 
^imenttng language than G C was designed torn its beginmng mbe the HOL replacementTor 
assembly language. According to the fathers of C. “C is a relatively 'low level' language." 

“Cis a general-purpose programming language which featuies economy of expression 

... C is not a 'very high level' language, nor a 'big' one, and is not sprro.alraedTo Z 
particular area of application.” [8] p zca 10 

ttlZT Ch 1 f gCr yf dm0re COmplex language than C and ™ source files are as a result typically 
more verbojse than C. Many Ada functions are often written in two source files- the 

PaCkagC Whereas the same function in C would only requt Se 
source code. ^ *° *** ** ** additlonal documentation provided by the more verbose Ada 

to e^pet^ longer ^ ^ ^ ^ 

3?! Sa J ne strong 'ypiog “d documenting that make Ada programs easy to understand 
^“ CUVC t0 — • sometimes make it awkwarfTwnte Lpie“ 

Over the course of larger projects, the same features which make Ada awkward to use on small 


Investigation of Ada vs. C 


but over the entire development cycle, especially the testing and integration phases, Ada compared 
very similarly to C. 

The FDD at Goddard has collected extensive statistics comparing development in Ada to 
FORTRAN. These statistics compare Ada to FORTRAN instead of Ada to C, but the simi ar 
complexity of FORTRAN and C makes the information useful for comparison. The FDD has 
collected comparison data over 5 years during 10 projects, 5 FORTRAN Projects and 5 Ada 
projects They have found that the actual cost per line of code is either the same for FORTRAN 
and Ada, or that Ada is actually cheaper than FORTRAN. These costs do not factor in the 
significant development costs saved through the reuse of existing Ada software. 

For a smaller scale project, most everyone agrees that given a trained Ada programmer aid a 
trained C programmer, the C programmer will be able to complete more new code sooner. For a 
larger, more complex project, most everyone agrees that there wiU be little difference ln ume-to 
completion between Ada and C. Given this theory, and given the fact that most of the apphcauons 
which will be in the SSCC will be fairly large and complex, it would foUow that contractors should 
be able to complete Ada versions of the SSCC applications in the same PYE. Unfortunately, few 
if any contractors have the level of Ada expertise available which will be required. The 25% 
difference estimated by Loral is assumed to cover training time as C programmer transition to Ada 
programmers. This 25% penalty should only be absorbed once. Thereafter, the cost for an Ada 
project should compare very closely to the cost for the same project written m C. 


Page 7 


Investigation of Ada vs. C 


3. Can coding in C be done in a way (i.e., using up front software engineering 
practices and tools) that results in a product that is as easily maintained as an 
Ada code product, i.e., is the life cycle cost for C code naturally higher than Ada 
code? 

Software maintenance is the process of altering computer source code after the initial version of 
the system is placed into production. Software maintenance is a broad term and is used in the 
following context, that is, software maintenance includes: 

• Modification to correct errors and design defects 

• Modification of existing features to improve the software design 

• Adaptation of the software to coexist with new hardware and software (i.e. software 
will need to be retested and possibly modified when new versions of operating systems 
are installed) 

• Modification to basic data sources (such as files, databases, real-time data sources, etc.) 

• Implementation of new features within the basic design 

Any robust and heavily used system will have tremendous requirements for change, particularly 
after the first major release of the system. It has been estimated by many authors, through case 
studies and theoretical evaluation of the software life cycle, that most organizations will devote up 
to 80% of their computer resources to the maintenance of software (the balance of the resources is 
utilized for development of software systems). 

With the proliferation of software systems over the last twenty years, the software industry is 
struggling to maintain the many systems currently in production. The major hurdle for most 
organizations is that the systems developed over the last twenty years lack appropriate 
documentation as well as established (or utilized) procedures to perform software maintenance. As 
a result, many organizations rarely reuse software from previous efforts because of the lack of 
understanding of what exactly exists. 

During the late 1980s, a proliferation of software development environments have been marketed 
by various organizations. These software development environments allow software requirements, 
actual source code, test procedures and user documentation to be integrated into a single 

environment so that the necessary information about the source code is available in a controlled, 
complete manner. 

When selecting a computer programming language for a system to be developed which will need 
to be maintained over a number of years, a careful evaluation of the programming language 
features needs to be made to assure that the selected language will cost effectively serve the 
software life cycle. 

The C programming language was designed to provide system level programming services for the 
UNIX operating system. The environment was initially targeted for a research environment where 
software life cycles were not a concern. The initial design goal of C and UNIX was to provide an 
environment for a researcher to solve research problems. The language is a level of abstraction 
above assembly language which provides the user a language which has the flexibility to fully 
exploit the host computer while not providing many semantic constraints (implying that is easy to 
develop C source code files which behave erratically). The UNDC operating system has matured 


Page 8 


Investigation of Ada vs. C 


and evolved tremendously from its initial design, the C language has essentially not changed since 
its introduction. 

The Ada programming language was conceived by the Department of Defense to solve the problem 
of providing a language for development of embedded systems that could be developed and 
maintained by many people over many years. Ada was designed as an environment, that is, one of 
the primary design goals was to provide a language which encouraged the reuse of software. This 
was achieved by introducing rigid standards on the development of software routines so that the 
difficulty of transporting software between applications is minimized. The Ada language has many 
explicit syntactic and semantic constraints which do not allow a programmer to develop ill- 
behaved source code. 

Many programming environments have been developed for Ada, these environments provide an 
excellent foundation on which long term software programs can be developed. Ada was designed 
from the start to support long term project development (it was not a design goal of the C language), 
the Ada language provides many features which greatly simplify as well as encourage a structured 
software development environment. 

SwRI believes that in the long-term, if correctly utilized, Ada will require fewer software 
maintenance resources than a similar C program. Initial development costs for the C program may 
be less than for an Ada program (particularly for smaller applications) but over the course of the 
entire life cycle it is felt that costs will be less in the case of Ada. Due to the personnel and contract 
turnover present at NASA, it is obvious that any long term project will have numerous personnel 
assigned to the effort. The surest way for NASA to develop a good software product would be to 
choose a development environment in which NASA can establish maximum control of the 
software development process — this environment exists for Ada. 

Additionally, it might be possible to establish an environment for C which would be as rigorous as 
most Ada environments — however that environment is not commercially available today. If this 
C environment were to be established, many manual controls and procedures would have to be 
instilled into the environment in an equivalent manner to many existing Ada environments. While 
these manual controls and procedures may be initially followed, it is difficult to predict whether or 
not they could be maintained over many years. In contrast, many of the Ada controls and 
procedures are natural to the development environment and if they are not followed -- application 
programs will not be completed. 

The answer to this question is both yes and no. Software written in C can be developed in a manner 
similar to Ada. MIT’s X Windows and OSF’s Motif are two examples of programs written in C 
which are designed with some of the Ada mentality. Ada will provide a more natural mechanism 
for this type of decomposition and will enforce certain aspects which are important to the software 
development life cycle. 


Page 9 


Investigation of Ada vs. C 



4. Does the control center and trainer systems requirements differ sufficiently 
to justify C language for SSCC and Ada language for SSTF (i.e., real-time op- 
eration of trainer systems, mostly new code required by Trainer; however, some 
Fortran reuse is expected, etc.)? 

The SwRI researchers who generated this paper have not received as much exposure to the SSTF 
as they have the MCCU workstation applications. There was not enough time to investigate the 
SSTF applications, so a recommendation has not been made specifically for the SSTF applications. 
A blanket endorsement across as large a center as the SSTF for either C or Ada is not 
recommended. 'Each language has its strength and weaknesses. A generic set of metrics should be 
determined which can be applied against any application to determine which language should be 

used. Once the metrics are determined, then they can be applied against applications such as the 
trainer systems. 

One of Ada s strengths is the support within the language which encourages reusability of code. 
Experiences at Goddard and within industry support the claim that Ada encourages reusability of 

code. On the surface, a training system would seem like the ideal type of system in which to reuse 
software. 


Page 10 


Investigation of Ada vs. C 


5. Does the future of code development suggest limitations on resources (people 
and tools) for C programming versus Ada programming (next 10-20 years)? 

There are many indications that both Ada and C will continue to be supported for at least the next 
10 years. The large base of C software and programmers will ensure C’s continued widespread use. 
Ada support and usage is growing steadily, and it is reasonable to assume an increasing availability 
of Ada tools and programmers. 

C has achieved widespread acceptance across a variety of hardware platforms. In the Unix 
workstation arena, C is the dominate language for software development due to the fact that Unix 
itself was written in C. In the PC arena, the popularity of C is evidenced by the sheer number of 
available C compilers, C tool chests, and COTS written in C. There is a large and ever expanding 
pool of trained C programmers due to the demand for applications where C is typically used. Most 
universities in the country offer a C class, and many base their core curriculum around the use of C. 

The next 10 years will see continued widespread support and use of C. University curriculum, and 
the growing PC and workstation markets will ensure C’s continued success. 

Although C has achieved widespread success and support, and this support can not be overlooked 
or under estimated, the projections for C are not without some questions. The recent popularity of 
C++ indicates that “vanilla C” does not fulfill every objective. It is interesting to note that the 
features which are being added to C++ are many of the features which were the basis for the design 

of Ada. 

C++ is a relatively new language when compared to C or even Ada. C++ was developed at AT&T 
by Bjame Stroustrup. The first C++ translator was completed in 1985. C++ adds the object oriented 
Hata encapsulation and abstract data types features of Ada to C. C++ also incorporates other 
important Ada features such as function inlining to improve performance. C++ is evidence of the 
fact that object oriented design and object oriented programming (OOP) are powerful tools in the 
development of complex applications. 

C has always been regarded as a slightly higher level assembly language with the power and 
responsibilities which come with that power. Some even regard C as a more “dangerous” tool than 
assembly language because of the power and freedom permitted within C. The power and freedom 
which are C’s strengths require responsibility and organization by the programmer for even modest 
sized programs. C++ is trying to address these issues: 

“Whereas the C programming language tests a programmer’s inner strength and builds 
character by following an ‘anything goes’ philosophy, C++ is the programmer’s friend, 
providing compile-time error messages that enforce data encapsulation.” [9] 


Products which are coming to market indicate C++’s popularity. More and more compilers are 
becoming available for C++ for both the PCs and the workstations. Even the MOTIF bindings from 
OSF now support C++. It appears that the computer industry has acknowledged the power of OOP. 
The well publicized “vaporwares” and the failures of software companies to deliver products 
ontime may instigate a rapid move toward OOP and C++. 


Page 11 


Investigation of Ada vs. C 


The 1960’s were dominated by assembly language. The 1970’s and 1980’s were dominated by 
structured programming and the popularity of HOL languages such as FORTRAN, C, Pascal, and 
Lisp. The 1990’s may be dominated by OOP and languages such as Ada and C++. 

Ada did not catch on and dominate the industry as it was projected to do during the last five years 
of the 1980’s. The Ada language was developed with much fanfare and was touted as the DoD’s 
answer to its mounting software costs. Unfortunately, too much was expected of Ada before it had 
matured. C language compilers were given the opportunity to mature over several years before C 
became widely used. The fanfare and the expectations placed on Ada did not allow the language 
several years to_maturc, and when the language did not meet the industry’s expectations, it was 
regarded as unusable. This perception of Ada still exists today in the mind of many software 
developers and system designers. 

The Ada language is more complex than C and Ada compilers are as a result necessarily more 
complex than C compilers. The Ada ANSI standard also requires that the complete Ada language 
is implemented before the compiler receives validation. Most of the original Ada compilers were 
expensive, of poor quality, and not very efficient. As a result, the Ada language itself was criticized 
for being inefficient when the implementation of the language was the culprit. This perception still 
exists today. 

Ada compiler technology has improved significantly and continues to improve. 


Technical problems with Ada still exist, although experts say they’re decreasing 
steadily in significance, and could virtually disappear over the next three to five years.” 
[ 6 ] 


The experiences at Cray, the supercomputer manufacturer, are an excellent example of the 
improvements in Ada compiler technology. The Cray Ada compiler currently produces code which 
outperforms the same code written in FORTRAN and compiled using Cray’s FORTRAN 

compiler. The Cray Ada code for the Whetstone and Dhrystone benchmarks outperforms the same 
code written in FORTRAN. 

There are numerous examples of the advancements in Ada compiler technology. It is important to 
remember that the source language has little impact on many operations performed within an 
executable. When two variables are subtracted in a HOL language, it is the compiler’s job to 
convert that subtraction into the CPU’s machine code which performs two register loads from 
memory and then a subtraction of the two registers. The CPU should perform the same task 
independent of the HOL language which was used to build the source code. 


On similar benchmarks I have seen straightforward scalar Ada come very close to 
what C can do on the same code. Indeed I have seen claims that for this kind of code, 
Ada has done better than C. I am very surprised that anyone who halfway understood 
compilers would claim that unadorned, numerical, scalar code from a language A pro- 
gram would necessarily be slower than the same code from language B. I’d be really 
delighted to see these claims debunked forever. On a level playing field, there are only 
X many ways to evaluate a scalar expression. ... The growing maturity of compilers, 
users, and managers is really gratifying! How long do you think it’ll take for the bulk 


Page 12 


Investigation of Ada vs. C 


of the industry to throw away their outdated stereotypes about slow, clunky Ada? It’s 
good to see intelligent debate about what really makes programs slow. It ain’t the 
source language, folks.” [11] 


The performance of a language should not be an issue. The language’s ability to represent these 
operations should be the issue. Ada may in fact offer advantages over C for some applications: 


“... hardware vendors are discovering that Ada may offer an inherent advantage for pro- 
gramming digital signal processors over its arch rival, C.” [7] 


A tremendous amount of effort is being spent on the investigation and improvement of Ada 
performance. Ada has undergone a maturing process during the last five years and it is now 
struggling to dispel the many adverse opinions which were formed by software developers during 
Ada’s formative years. Support for Ada is steadily increasing as more quality Ada compilers 
become available to universities and industry. 

It should be noted that it took C about 10 years to gain wide acceptance after it was written. Just as 
the legacy and installed base of FORTRAN and assembly language systems slowed the acceptance 
of C, so also has the large installed base of C and FORTRAN slowed the acceptance of Ada. 

Ada has always been expected to succeed due to the DoD’s sponsorship of its development and 
subsequent mandate of use in 1983. 

“The birth of a new programming language is rarely celebrated far beyond the imme- 
diate family. But, when the sponsor of the language is the largest consumer of comput- 
ers in the world, then it becomes a major event.” [10] 

The DoD’s 1983 mandate allowed waivers to be granted if Ada compilers were not available or 
when using Ada would be more expensive or might prevent developers from meeting their 
schedules. The poor performance of Ada code and lack of trained Ada programmers resulted in 
many waivers being granted since 1983. The relative ease with which waivers were obtained 
allowed C and FORTRAN to prosper and Ada’s problems to persist. 

The DoD has recently added teeth back into its Ada mandate by extending its mandate to include 
automated data processing in addition to embedded real-time applications. Congress further 
strengthened the DoD’s mandate by adding language to the 1991 Defense Appropriations Act 
which states that after June 1, DoD programs that do not embrace Ada will be breaking the law. As 
before. Congress has left a loophole, but at this time it will be much harder to demonstrate the need 
for an Ada waiver. 

The experiences of the FDD at Goddard are also of special interest. Frank McGarry, the Division 
Chief of the FDD at Goddard has seen the maturing of Ada since the FDD started using Ada in 
1985. The FDD has committed to making Ada their main language by 1995. The FDD has seen an 
increase in the quality of Ada compilers and professionals, and the FDD has also seen an increase 
in the number of contractors bidding Ada in proposals. Mr. McGarry thinks the most encouraging 


Page 13 


Investigation of Ada vs. C 


sign is the number of contractors bidding Ada on their own initiative when Ada was not identified 
as a requirement. 

The next 10 years looks promising for both C and Ada. C’s large base of applications and trained 
programmers will ensure its continued use for many years. Recent developments surrounding C++ 
seem to indicate a shift towards C++ on a large scale over the next few years. C++ may be a better 
option than C itself when the long life cycle of the SSCC and the complexity of the SSCC 
applications is considered. 

The next 10 years also look very promising for Ada. The next 5 years may see a more significant 
growth of Ada .than the last 10 years, due to the availability of quality compilers, the new DoD 
mandate, the increasing interest in OOP, and the increasing complexity of DoD applications. 

This paper has not attempted to project the state of C or Ada past 10 years. The computer industry 
has proven to be too fast paced and uncertain. In 1980, the great language scholar Ellis Horowitz 
predicted that Pascal would be the language of the 1980’s. Pascal did indeed enjoy a large measure 
of success during the 1980’s, but the later part of the 1980’s saw the emergence of C as the 
language of choice for engineering type applications. It is almost impossible to determine whether 
C or Ada will receive greater support 20 years from now. The trends we are observing today are 
the interest in OOP, the emergence of C++, the US Congress continued endorsement of Ada, and 
the increasing quality of Ada compilers. 


Page 14 


Investigation of Ada vs. C 


6. Are the up front costs for Ada (tools, training, and lack of experienced pro- 
grammers) significant compared to that for C? 

The up from costs for Ada will be higher than for C. The size and total cost of the project will once 
again determine whether Ada is a viable option. Ada tools and training are more expensive and are 
fewer in number than C tools or training because Ada is a more complex language with less 
maturity and therefore less industry support. There is a lack of experienced Ada programmers 
when compared to C. The size and nature of the project may mitigate the deficiencies of Ada or 
enhance them. 

The lack of trained programmers is always more of a concern for Ada project managers than C 
project managers, and Ada training often confirms a project manager’s bias against Ada. A survey 
of Ada training courses compared to C training shows that Ada training courses are longer and 
more expensive than C training. A number of video tapes are available for self-paced C training, 
while very few Ada video tapes are available. Ada is definitely a more complex language than C 
and to use the language well typically requires a different design philosophy than is typically used 
with C or FORTRAN. Ada is acknowledged to have a steeper “learning curve” because the 
language is more complex and because Ada incorporates OOP practices which are less prevalent 
than the traditional structured programming techniques. C is a smaller language which is less 
imposing than Ada. It is widely believed that programming in Ada requires much more extensive 
and expensive training. 

NASA Goddard has noticed a change in the nature of Ada training during the last several years. In 
1985 the FDD committed to the use of Ada where possible and as a first step towards Ada the FDD 
programmers enrolled in Ada training. The Ada training at that time was a very intensive training 
in both OOP methodologies and the application of OOP using Ada. During the last several years, 
the FDD has noticed a change in the nature of Ada training toward less intensive training with less 
emphasis placed on “grandiose OOP techniques.” The FDD has noticed a trend toward “C like” 
training, and they feel the effectiveness of this training is comparable to past training methods. This 
trend is one the FDD is watching closely as they progress toward using Ada for 70% - 80% of all 
projects by 1995. 

Interviews with three Ada project managers have discovered a surprising but consistent theme. The 
experiences at SwRI, Lockheed, and NASA-Goddard indicate that the extensive training that was 
generally associated with Ada may not be required for the whole project team, and that the type of 
training now being offered is sufficient for a segment of the programmers on larger projects. This 
recent change in approach to training may lessen the cost and impacts of a lack of skilled Ada 
programmers. 

Man y project teams are using a tiered approach to Ada training. If an Ada project was to be 
composed of 10 programmers, 2 programmers would be skilled Ada programmers. Three 
programmers would be moderately trained, and the other 5 programmers would have little or no 
Ada experience at the start of the project. The layout of the software and the design of the interfaces 
would be recorded in Ada package specifications. The majority of the implementation would be 
completed in Ada package bodies by the 5 novice Ada programmers based on the Ada package 
specifications developed by the more experienced/trained programmers. 

This tiered approach allows the more experienced developers to do the overall system design, the 
mid-level programmers to do the remaining interface design, and the inexperienced programmers 
to do the implementation. This allows the more experienced programmers to have a greater impact 


Page 15 


Investigation of Ada vs. C 


on the design of the entire system, limiting the scope of the inexperienced programmers to 
implementation. Individual package bodies can then be recoded by a more experienced 
programmer if it becomes necessary. The recoding of a package body is less likely to have a “ripple 
effect” when the software is in Ada as opposed to C. The project managers at both SwRI and 
Lockheed feel the tiered approach helps keep projects out of trouble in the area of interfaces. 

This tiered approach has been used at both SwRI and Lockheed with very good results. This 
approach alleviates some of the concerns about a lack of trained Ada programmers. Both Lockheed 
and the SwRI CAST group feel that using a tiered approach, even given a lack of skilled Ada 
programmers, is LESS of a risk factor on a large program then using C. The project managers of 
the SwRI CAST project feel the potentially greater benefits of Ada outweigh the initial training 
which is required and the lack of experienced programmers. 

Ada compilers are in almost all cases more expensive than C compilers. There are several good 
Ada compilers which are comparable in price to C compilers for the same hardware platform, the 
AdaZ compiler for the PC is an example. There are several factors which usually cause Ada 
compilers to cost more than C compilers. The Ada language is more complex than the C language, 
and the resulting Ada compilers are more complex to develop. Ada compiler writers must 
implement the entire A NS I/MIL- STD- 1 8 15 A language to become validated, whereas the C 
language has only recently become an ANSI standard. The lack of a defined standard allowed C 
compiler waters more freedom in the implementation of their compilers. A standard programming 
environment is also specified for Ada, the Ada Programming Support Environment (APSE), and 
the Ada compiler writer must provide these additional tools which may not be bundled with C 
compilers. 

The up front costs for Ada are a very real concern. There is generally a lack of trained Ada 
professionals. This is usually perceived as a very important risk factor. Projects at NASA, SwRI, 
and Lockheed have shown this is not as big a risk factor as previously expected. The more 
complex Ada language dictates that Ada training is more expensive than C training and there are 
fewer sources of Ada training. NASA Goddard has seen a change in emphasis in Ada training 
which may indicate that an intensive study of both the Ada language and OOP design 
methodologies is not needed. NASA Goddard has noticed a trend during the last several years 
toward C language style training. The more complex Ada language and requirement for full 
implementation of the language for validation dictates that Ada compilers are more expensive than 
C compilers and there are fewer Ada compilers available. Smaller scale, less complex projects will 
not be able to offset the additional costs of Ada, but experience has demonstrated that larger 
projects can absorb the up front costs of Ada. The nature of the project will determine if the 
additional costs for Ada training and compilers can be offset by the good software engineering 
principles that are embodied in Ada which allow the management of complex programming tasks. 


Page 16 


Investigation of Ada vs. C 


7. What are the risk assessments for completion of the SSCC and SSTF on 
schedule and within cost considering use of C versus Ada languages for new 
code in each facility? 

There is greater support for C in environments similar to the SSCC and SSTF; C is established and 
has been proven to work. Ada does have risks associated with it when compared to C, but Ada also 
offers benefits in areas that C is suspect. The following table lists many of the factors which will 
be involved in the development and maintenance of the SSCC and SSTF. These factors have been 
grouped according to each language’s strengths. A “+” indicates the language is uniquely superior, 
a indicates the language is clearly more of a risk factor. 

Factor Ada C 


Programmer productivity 
Software development support tools 


Future Usage + 

Widespread acceptance, programmer availability + 

Small program risks for completion, integration + 

Interfaces to COTS + 

Compiler cost, quality + 

Existing MCCU software reuse + 

Training costs, availability + 

DoD Mandate, Congressional support + 

Software error rates, reliability + 

Future software reuse within SSCC, SSTF, SSFP + 

Large program risks for completion, integration + 

Portability + 

Standard language, language features (ANSI - ISO) + 

Maintainability + 


+ + 

+ + 


Page 17 


Investigation of Ada vs. C 



8. Are COTS products that will be available in the next 1-10 years more likely 
to be in C or Ada language? 

For at least the next five years, more COTS products will be written in C than in Ada. There are 
several important reasons why C will dominate COTS product development in both the Unix 
workstation and PC arenas. 

Ada is currently used primarily for large DoD contracts. Some work is being done outside of DoD 
and on smaller scale projects, but for the most part, Ada is used for large scale projects for either 
the military or NASA. These large projects often apply to a very specialized problem domain and 
are not applicable to the general market place. Ada is currently used by large government 
contractors such as GE, Lockheed, and Link. GE is currently working on the TDRSS satellite 
terminal for NASA and Link wrote the B2 trainer entirely in Ada. Both of these Ada systems are 
success stories, but there is little general need for a stealth bomber trainer or satellite terminal. 
There are several exceptions, the STARS Xlib bindings is one example, but for the most part the 
results of most Ada development projects do not become COTS products due to their nature. 

Most COTS products are developed by Independent Software Vendors (IS V) and smaller software 
companies. These companies are most concerned with up-front development costs and quick 
market delivery. There are a number of factors which lead ISVs and smaller software companies 
to develop in C instead of Ada. 

The compiler is the most important tool of software developers and C compilers are traditionally 
less expensive than Ada compilers. In the Unix workstation arena, the C compiler is often bundled 
with the OS or is readily available at a reasonable cost from the OS supplier. A prime example is 
Sun Microsystems workstations. Sun workstations come bundled with a C compiler at no 
additional cost, and the excellent GNU C compiler is also available free of charge for Sun 
workstations. An Ada compiler for the same workstation will cost approximately $5,000 dollars 
and may cost significantly more. 

The compiler situation is even more clear-cut in the PC arena. There are a number of readily 
available excellent C compilers available for the PC. Good C compilers are available for less than 
$100. There are far fewer good Ada compilers available for the PC and the compilers which are 
available are more expensive. As in many areas of comparison between C and Ada, the number 
and quality of Ada compilers for the PC is improving while the cost is declining. Meridian’s AdaZ 
compiler is an example of a good quality Ada compiler for the PC. 

The larger pool of C software developers and the lack of good Ada software developers also causes 
more COTS products to be written in C. The costs associated with the additional hardware 
resources (memory," disk space, processing power) which may be necessary for Ada software 
development also influences COTS developers to use C. 

These factors and others indicate that more COTS products will continue to be available written in 
C than Ada. The way which COTS products are used may reduce the importance of the language 
in which COTS packages are written. The language used to develop shrink wrapped applications 
or OS software which do not contain an Application Program Interface (API) is of little or no 
importance. If Lotus 1-2-3 or “vi” is written in Ada or C, does not matter. In both cases, an API is 
not required, so the language used to develop the application does not matter. 


Page 18 


Investigation of Ada vs. C 


In cases where the API provided by the COTS package is utilized, then the languages supported 
natively by the API become important. This issue is addressed in the next question. 

It is very hard to predict if C’s popularity with ISVs and software companies will continue five 
years from now. The large pool of C programmers, the growth in the Unix based workstation 
market, and the increasing use of C (as opposed to assembly, Pascal, or FORTRAN) on PCs will 
definitely assure the development of more COTS packages in C than Ada. 

The 1990’s appear to be the decade of Object Oriented Programming (OOP) in the way that 
structured programming and the use of High Order Languages (HOL) dominated the late 1970 s 
and 1980’ s. The number of COTS developed in C++, Ada, or even Smalltalk in the next five years 
may increase as OOP is taught in the universities and migrates into the commercial sector. C++ has 
already shown phenomenal growth within the last two years. Examples of this are evident in the 
number of C++ compilers which have recently become available and the recent release of the Motif 
bindings from OSF which support C++. The use of the C++ language may surpass “true” C in the 
development of COTS products during the next 5 years. 


Page 19 


Investigation of Ada vs. C 


9. Will COTS products in the next 1-5 years be available that will support mul- 
tiple language applications ( C, Ada, Fortran )? [i.e., will COTS tools likely have 
bindings for Ada, Fortran, and C, such as X windows and other system services 
tools] 

Currently, more COTS APIs are available for C than for Ada. This trend will continue for at least 
the next 5 years. In the workstation arena, Ada bindings are available for most popular applications. 
If Ada bindings are not available, the Ada pragma construct can be used to interface to the C 
bindings. This approach has been used very successfully by Lockheed with a number of COTS 
packages, including database applications. The following APIs are good examples of the 
availability of APIs for C and Ada: 

• The POSIX standard’s API was originally written in C due largely in pan to Unix’s 
large influence on POSIX. The POSIX bindings are now also available in FORTRAN 
and Ada. 

• The X Window X11R4, MOTIF, and XView APIs were originally written in C. Ada 
bindings are now available for all three. C++ bindings are also now available for 
MOTIF, another indication of the growing popularity of C++. 

Computer Aided Software Engineering (CASE) is one field which has embraced Ada extensively. 
Most leading CASE tools operate well in an Ada environment and many generate Ada code from 
information entered into the CASE tool. CADRE’s Teamwork product is currently being used by 
GE on the STGT project and the results have been very encouraging. 

More COTS bindings will continue to be available for C than Ada. The number of Ada bindings 
which arc available is steadily increasing and the Ada pragma interface is available when bindings 
are not available. 


Page 20 


Investigation of Ada vs. C 


10. What would be your recommendation for language use in the SSCC and 
SSTF given the desire to maximize use from Shuttle, maximize portability 
across SSFP and within the SSCC/SSTF facilities, independence from hard- 
ware constraints, and significant budget pressures to cut up front costs and re- 
duce run out costs with minimum risk to delivery capability and schedule? 
[Consider resources availability, etc.] 

The Ada language was designed for the large, complex, long life-cycle, application domain. The 
C language was designed for freedom, compactness and efficiency. The applications which will be 
written for the SSCC more closely match the goals of Ada than C. From a language viewpoint, Ada 
is the better choice. From an implementation viewpoint, C has traditionally been the best choice 
due to the quality of C compilers and the relative poor quality of Ada compilers. 

The quality of Ada implementations varies even today. Depending on the target hardware platform, 
C may still be the only reasonable choice for large applications because a suitable Ada 
implementation may not exist. Preliminary information may indicate this is still the case for large 
IBM mainframes. Good Ada environments do exist, the DEC environment is one example, and 
more and more quality Ada compilers are becoming available. In the case of the military standard 
1750 A microprocessor, Ada and FORTRAN are the only choice. 

The availability of a good Ada environment is the first question which must be asked. If a good 
Ada environment is not available, then C is the only choice. If a good Ada environment is available, 
th en which language should be used? It is conceivable that both languages should be used. Ada and 
C were designed from their beginnings for different applications and they should be applied to the 
applications for which they were appropriate. C was designed by Dennis Ritchie as a “relatively 
’low level’ language” which is ideally suited for systems programming. Ada was designed through 
an international review process for large, real-time, embedded applications. It appears that most 
applications which will be integrated into the SSCC and SSTF fit the latter category and as a result 
Ada should be used if a good environment is available. 

The SSCC and SSTF should not select a single language unless all applications which will be 
developed for those facilities are similar in nature or unless one of the languages is not a viable 
option due to a lack of quality compilers. Ada and C should be applied in each facility where 
appropriate to meet the priority of requirements identified in question number 10. A 
characterization of the type of applications should be made for each facility, and then the 
appropriate language applied to that type of application which best meets the priorities and 
requirements. 


Page 21 


Investigation of Ada vs. C 



BIBLIOGRAPHY 


[1] Booch, Grady. 1987. Software Components with Ada. Menlo Park, California,: 
Benjamin/Cummings. 

[2] Horowitz, E. and J. Munson, Sept. 1984. An Expansive View of Reusable Software, 
IEEE Transactions of Software Engineering, vol. SE-10 (5), p. 477,479. 

[3] Nise, N., C. McKay, D. Dillehunt, N. Kim, and C Giffin. Oct. 1985. A Reusable 
Software System, Proceedings of the AIAA/ACM/NASA/IEEE Computers in 
Aerospace V Conference, p. 492. Long Beach, California. 

[4] Bryne, Dan, Richard Ham, Winter 1990. Ada Versus FORTRAN Performance 
Analysis Using the ACPS, ACM Ada Letters - Ada Performance Issues Volume 
X, Number 3, p. 139-145. New York, New York. 

[5] Proceedings of the Third NASA Ada User’s Symposium, November 1990, NASA-JSC. 

[6] Keller, John, "When Avoiding Ada Is The Right Thing To Do", Military and 
Aerospace Electronics, February 1991. 

[7] Keller, John, "Ada Is Law, So What Else Is New?", Military and Aerospace 
Electronics, January 1991. 

[8] Kemighan, Brian W. and Ritchie, Dennis M., The C Programming Language, 
Prentice Hall, 1978 

[9] Anderson, Paul and Anderson, Gail, Moving on to C++, UnixWorld, January 1991 

[10] Horowithz, Ellis, Fundamentals of Programming Languages, Computer Science 
Press, 1984 

[11] Mike Feldman, George Washington University 


Page 22 


Investigation of Ada vs. C 



Mass^ultyp 


Experiment : EXPERIMENT_1 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 1 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

NO. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.26 % 

2 

4.00 

16 

64.00 

3.26 % 

3 

8.00 

8 

64.00 

3.26 % 

4 

16.00 

4 

64.00 

3.26 % 

5 

32.00 

2 

64.00 

3.26 % 

Experiment 

step size: 

1.63 % 

320.00 

16.32 % 


Test 1 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 



Experiment : EXPERIMENT_1 

Completion on: Miss /skip 50 deadlines 


Raw speed in Kilo -Whet stone Instructions Per Second (KWIPS) : 1960.79 


Test 2 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

48.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

96.00 


352.00 


Experiment step size: 1.63 % 


Requested Workload 
Utilization 
3.26 % 

3.26 % 

3.26 % 

3.26 % 

4.90 % 


17.95 % 


Test 2 results: 


Test duration (seconds) 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
20.833 


Met 

Deadlines 

20 

40 

80 

160 

240 


Missed 

Deadlines 

0 

0 

0 

0 

120 


Skipped 

Deadlines 

0 

0 

0 

0 

120 


Mlssimultifi 


HARTSTONE BENCHMARK SUMMARY RESULTS 


Baseline test : 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 


Test 1 characteristics: 

Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 2.00 32 

2 4.00 16 

3 8.00 8 

4 16.00 4 

5 32.00 2 


Experiment step size: 1.63 % 


Kilo-Whets 

Requested 1 

Workload 

per second 

Utilization 

64.00 

3.26 

% 

64.00 

3.26 

% 

64.00 

3.26 

% 

64.00 

3.26 

% 

64.00 

3.26 

% 

320.00 

16.32 

% 


'^--rest 1 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

No. 

in msecs 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

2 

250.000 

40 

0 

3 

125.000 

80 

0 

4 

62.500 

160 

0 

5 

31.250 

320 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Last test with no missed/ skipped deadlines: 
See preceding summary of test 1 


Test when deadlines first missed/ skipped: 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 


Test 2 characteristics: 


Task 

NO. 

1 

2 

3 

4 

5 


Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

(Hertz) 

per period 

per second 

Utilization 

2.00 

32 

64.00 

3.26 % 

4.00 

16 

64.00 

3.26 % 

8.00 

8 

64.00 

3.26 % 

16.00 

4 

64.00 

3.26 % 

48.00 

2 

96.00 

4.90 % 


352.00 


17.95 % 


Experiment step size: 1.63 % 


Test 2 results : 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
20.833 


Met 

Deadlines 

20 

40 

80 

160 

240 


Missed 

Deadlines 

0 

0 

0 

0 

120 


Skipped 

Deadlines 

0 

0 

0 

0 

120 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
5.584 




final test performed: 

See preceding summary of test 2 


Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Masscomp 6350 - C3Ada version 1.0 
arget : Masscomp 6350 - dual 33 MHz 68030 

Characteristic of best test for this experiment • 
(no missed/ skipped deadlines) 

Test 1 of Experiment 1 


Raw (non-tasking) benchmark 

speed in KWIPS : 

1960.79 

Full task 

set : 



Total 

Tasks 

5 

Deadlines 
Per Second 
62.00 

Task Set 
Utilization 
16.32 % 

Total 

KWIPS 

320.00 

Highest-f requency task: 



Period 

(msec) 

31.250 

Deadlines 
Per Second 
32.00 

Task 

Utilization 
3.26 % 

Task 

KWIPS 

64.00 

Experiment 

step size: 1.63 

% 






end of hartstone benchmark SUMMARY 


results 






Experiment : EXPERIMENT^ 

Completion on: Miss /skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 


Test 1 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

64.00 


320.00 


Requested Workload 
Utilization 
3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 


15.89 % 


Experiment step size: 1.59 % 


Test 1 results : 

Test duration (seconds) : 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 316 


Missed Skipped Average 

Deadlines Deadlines Late (msec) 
0 0 0.000 

0 0 0.000 

o 0 0.000 

o 0 0.000 

2 2 19.257 





Experiment : EXPERIMENT_2 

Completion on: Miss/skip 50 deadlines 

speed in Kilo Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 2 characteristics : 

Task 
No. 

1 
2 

3 

4 

5 


Frequency 

(Hertz) 

2.20 

4.40 

8.80 

17.60 

35.20 

Kilo-Whets 
per period 
32 
16 
8 
4 
2 

Kilo-Whets 
per second 
70.40 
70.40 
70.40 
70.40 
70.40 

Requested Workload 
Utilization 
3.50 % 

3.50 % 

3.50 % 

3.50 % 

3.50 % 



352.00 

17.48 % 


Experiment step size: 1.5 9 % 


Test 2 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 
454.545 
227.273 
113.636 
56.818 
28.409 


Met 

Deadlines 

23 

45 

89 

177 

353 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment 

: EXPERIMENT_2 




Completion 

on: Miss /skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per Second (KWIPS) 

: 2013.42 

Test 3 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

NO, 

(Hertz) 

per period 

per second 

Utilization 

1 

2.40 

32 

76.00 

3.81 

% 

2 

4,80 

16 

76.00 

3.81 

% 

3 

9.60 

8 

76.00 

3.01 

% 

4 

19.20 

4 

76.00 

3.81 

% 

5 

38.40 

2 

76.00 

3.81 

% 




304.00 

19.07 

% 

Experiment step size: 

1.59 % 




Test 3 results: 





Test duration (seconds) : 10,0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No . 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

416.667 

25 

0 

0 

0.000 

2 

208.333 

49 

0 

0 

0.000 

3 

104.167 

97 

0 

0 

0.000 

4 

52.083 

193 

0 

0 

0.000 

5 

26.042 

383 

1 

1 

4.700 


4 



Mass_multi_2“ 



Experiment: EXPERIMENT 2 

Completion on: Miaa/akip 50 deadlinea 

Raw speed in Kilo-Whetatone Inatructiona Per Second (KWIPS) : 2013.42 
Test 4 characteristics : 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.60 

5.20 

10.40 

20.80 

41.60 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

83.20 

83.20 

83.20 

83.20 

83.20 


Requested Workload 
Utilization 
4.13 % 

4.13 % 

4.13 % 

4.13 % 

4.13 % 


416.00 


20.66 % 


Experiment step size: 1.59 % 



Test 4 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 
384.615 
192.308 
96.154 
48 . 077 
24.038 


Met 

Deadlines 

26 

52 

104 

196 

290 


Missed 

Deadlines 

0 

0 

0 

6 

63 


Skipped 

Deadlines 

0 

0 

0 

6 

63 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.214 
1.537 



HART STONE BENCHMARK SUMMARY RESULTS 


Baseline test: 


Experiment : EXPERIMENT^ 2 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 1 characteristics: 

Requested Workload 
Utilization 
3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 


15.89 % 


Experiment step size: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 
16.00 
32.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 
64.00 
64.00 
64.00 
64.00 
64.00 


320.00 


Test 1 results : 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

316 


Missed 

Deadlines 

0 

0 

0 

0 

2 


Skipped 

Deadlines 

0 

0 

0 

0 

2 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
19.257 



Miss^multi^zr 



Last test with no missed/ skipped deadlines: 


Experiment : EXPERIMENT_2 

Completion on: Miss/skip 50 deadlines 


Raw speed m Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 


Test 2 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 

Frequency 

(Hertz) 

2.20 

4.40 

8.80 

17.60 

35.20 

Kilo-* Whets 
per period 
32 
16 
8 
4 
2 

Kilo-Whets 
per second 
70.40 
70.40 
70.40 
70.40 
70.40 

Requested Workload 
Utilization 
3.50 % 

3.50 % 

3.50 % 

3.50 % 

3.50 % 




352.00 

17.48 % 


Experiment step size: 1.59 % 


Test 2 results: 


''est duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 
454.545 
227.273 
113.636 
56.818 
28.409 


Met 

Deadlines 

23 

45 

89 

177 

353 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Test when deadlines first missed/skipped: 
See preceding summary of test 1 


Final test performed: 


Experiment: EXPERIMENT^ 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 


Test 4 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.60 

2 5.20 

3 10.40 

4 20.80 

5 41.60 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 
83.20 
83.20 
83.20 
83.20 
83.20 


Requested Workload 
Utilization 

4.13 % 

4.13 % 

4.13 % 

4.13 % 

4.13 % 


416.00 


20.66 % 


Experiment step size: 


1.59 % 


Test 4 results : 


Test duration (seconds): 10.0 


Task 

NO. 

1 

2 

3 

4 

5 


Period 
in msecs 
384.615 
192.308 
96.154 
48.077 
24.038 


Met 

Deadlines 

26 

52 

104 

196 

290 


Missed 

Deadlines 

0 

0 

0 

6 

63 


Skipped 

Deadlines 

0 

0 

0 

6 

63 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.214 
1.537 



Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Masscomp 6350 - C3Ada version 1.0 

Target : Masscomp 6350 - dual 33 MHz 68030 

Characteristics of best test for this experiment: 

(no missed/ skipped deadlines) 

Test 2 of Experiment 2 

Raw (non-tasking) benchmark speed in KWIPS : 2013.42 
Full task set: 

Total Deadlines Task Set Total 

Tasks Per Second Utilization KWIPS 

5 68.20 17.48 % 352.00 

Highest-f requency task: 

Period Deadlines Task Task 

(msec) Per Second Utilization KWIPS 

28.409 35.20 3.50 % 70.40 

Experiment step size: 1.59 % 


END OF HARTSTONE BENCHMARK SUMMARY RESULTS 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 1 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency Kilo-Whets Kilo-Whets Requested Workload 
(Hertz) per period per second Utilization 

2.00 32 64.00 3.26 % 

4.00 16 64.00 3.26 % 

0.00 8 64.00 3.26 % 

16.00 4 64.00 3.26 % 

32.00 2 64.00 3.26 % 


320.00 


Experiment step size: 3.16 % 


16.32 % 


Test 1 results : 

Test duration (seconds): 10.0 


Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 0 0.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 



MSssgrntil^^ 


Experiment : EXPERIMENT 3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 


Teat 2 characteristics : 

Task Frequency Kilo-Whets 

No - (Hertz) per period 

1 2.00 33 

2 4.00 17 

3 8.00 9 

4 16.00 5 

5 32.00 3 


Experiment step size: 3.16 % 


Kilo-Whets 
per second 
66.00 
68.00 

72.00 

80.00 
96.00 


382.00 


Requested Workload 
Utilization 
3.37 % 

3.47 % 

3.67 % 

4.08 % 

4.90 % 


19.48 % 


Test 2 results: 

Test duration (seconds) : 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Date (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXP ERIMENT_3 

Completion on: Miaa/akip 50 deadlinea 

Raw apeed in Kilo-Whetatone Inatructiona Per Second (KWIPS) : 1960.79 
Test 3 characteristics: 

Requested Workload 
Utilization 
3.47 % 

3.67 % 

4.08 % 

4.90 % 

6.53 % 


22.64 % 

Experiment step size: 3.16 % 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

0.00 

16.00 

32.00 


Kilo-Whets 
per period 
34 
18 
10 
6 
4 


Kilo-Whets 
per second 
68.00 

72.00 

80.00 
96.00 

128.00 


444.00 


Test 3 results: 

Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
11.963 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 


Test 4 characteristics: 

Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 2.00 35 

2 4.00 19 

3 8.00 11 

4 16.00 7 

5 32.00 5 


Experiment step size: 3.16 % 


Kilo-Whets Requested Workload 
per second Utilization 

70.00 3.57 % 

76.00 3.88 % 

88.00 4.49 % 

112.00 5.71 % 

160.00 8.16 % 


506.00 25.81 % 


Test 4 results : 

Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT_3 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 


Test 5 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

36 

72.00 

3.67 % 

2 

4.00 

20 

80.00 

4.08 % 

3 

8.00 

12 

96.00 

4.90 % 

4 

16.00 

8 

128.00 

6.53 % 

5 

32.00 

6 

192.00 

9.79 % 

Experiment 

step size: 

3.16 % 

568.00 

28.97 % 


Test 5 results : 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXP ERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 6 characteristics : 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
37 
21 
13 
9 
7 


Kilo-Whets 
per second 

74.00 

84.00 

104.00 

144.00 

224.00 


630.00 


Requested Workload 
Utilization 
3.77 % 

4.28 % 

5.30 % 

7.34 % 

11.42 % 


32.13 % 


Experiment step size: 3.16 % 


Test 6 results: 


Test duration (seconds): 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Mass^owilt® 


Experiment : EXPERIMENT_3 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 7 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
38 
22 
14 
10 
8 


Kilo-Whets 
per second 

76.00 

88.00 

112.00 

160.00 

256.00 


Requested Workload 
Utilization 
3.88 % 

4.49 % 

5.71 % 

8.16 % 

13.06 % 


692.00 


35.29 % 


Experiment step size: 


3.16 % 


Test 7 results : 


Test duration (seconds): 10.0 


Task 

NO. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




•• ■ -X-. 




r^$£;: 


Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 8 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
39 
23 
15 
11 
9 


Kilo-Whets 
per second 

78.00 

92.00 
120.00 

176.00 

288.00 


Requested Workload 
Utilization 
3.90 % 

4.69 % 

6.12 % 

8.98 % 

14.69 % 


754.00 


38.45 % 


Experiment step size: 3.16 % 


Test 8 results : 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

314 


Missed 

Deadlines 

0 

0 

0 

0 

3 


Skipped 

Deadlines 

0 

0 

0 

0 

3 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
11.617 




HARTSTONE BENCHMARK SUMMARY RESULTS 


Baseline test: 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 1 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 
64.00 
64.00 
64.00 
64.00 
64.00 


320.00 


Experiment step size: 3.16 % 


Requested Workload 
Utilization 

3.26 % 

3.26 % 

3.26 % 

3.26 % 

3.26 % 


16.32 % 


•’—rest 1 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT_3 

Completion on: Miss /skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 


Test 7 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
38 
22 
14 
10 
8 


Kilo-Whets 
per second 

76.00 

88.00 

112.00 

160.00 

256.00 


692.00 


Requested Workload 
Utilization 
3.88 % 

4.49 % 

5.71 % 

8.16 % 

13.06 % 


35.29 % 


Experiment step size: 3.16 % 


Test 7 results: 


Test duration (seconds) : 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




• ' • • - -h 


12 


rest when deadlines first missed/skipped: 


Experiment : EXPERIMENT 3 

Completion on: Miaa/akip 50 deadlinea 

Baw apeed in Kilo-Wh.taton. Inatructiona Per Seoond (KWiPS, , l S60 . 79 
Test 3 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
34 
18 
10 
6 
4 


Kilo-Whets 
per second 
60.00 

72.00 

80.00 

96.00 

128.00 


Requested Workload 
Utilization 
3.47 % 

3.67 % 

4.08 % 

4.90 % 

6.53 % 


444.00 


Experiment 3tep size: 3.16 % 


22.64 % 



Test 3 results: 


"est duration (seconds) : 


10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
11 * 963 



Final test performed: 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 1960.79 
Test 9 characteristics: 

Requested Workload 
Utilization 
4.08 % 

4.90 % 

6.53 % 

9.79 % 

16.32 % 


41.62 % 

Experiment step size: 3.16 % 


Task 

NO. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 
16.00 
32.00 


Kilo-Whets 
per period 
40 
24 
16 
12 
10 


Kilo-Whets 
per second 
80.00 
96.00 
128.00 

192.00 

320.00 


816.00 


Test 9 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

241 


Missed 

Deadlines 

0 

0 

0 

0 

40 


Skipped 

Deadlines 

0 

0 

0 

0 

39 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.488 


imulii 



Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Masscomp 6350 - C3Ada version 1.0 
Target : Masscomp 6350 - dual 33 MHz 68030 

Characteristics of best test for this experiment : 
(no missed/skipped deadlines) 


Test 7 of Experiment 3 


Raw (non-tasking) benchmark speed in KWIPS: 1960.79 


Full task set : 

Total Deadlines 

Tasks Per Second 

5 62.00 

Highest-frequency task: 

Period Deadlines 

(msec) Per Second 

31.250 32.00 

Experiment step size: 3 


Task Set Total 

Utilization KWIPS 

35.29 % 692.00 


Task Task 

Utilization KWIPS 

13.06 % 256.00 


16 % 


END OF HARTSTONE BENCHMARK SUMMARY RESULTS 




Experiment: EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 1 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 % 

2 

4.00 

16 

64.00 

3.18 % 

3 

8.00 

8 

64.00 

3.18 % 

4 

16.00 

4 

64.00 

3.18 % 

5 

32.00 

2 

64.00 

3.18 % 




320.00 

15.89 % 

Experiment 

step size: 

3.18 % 




Test 1 results: 

Test duration (seconds): 10.0 


Task 

NO. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

peed in Kilo Whetstone Instructions Per Second (KWIPS) : 2013.42 


Teat 2 characterist i 

Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8 . 00 

4 16.00 

5 32.00 

6 8.00 


Experiment step size: 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 


384.00 


3.18 % 


Requested Workload 
Utilization 
3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 


19.07 % 



Test 2 results : 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 

6 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 

125.000 


Met 

Deadlines 

20 

40 

80 

160 

320 

80 


Missed 

Deadlines 

0 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 


Average 
Date (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment: EXPERIMENT 4 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 


Test 3 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 

6 
7 


Frequency 

Kilo-Whets 

Kilo-Whets 

(Hertz) 

per period 

per second 

2.00 

32 

64.00 

4.00 

16 

64.00 

8.00 

8 

64.00 

16.00 

4 

64.00 

32.00 

2 

64.00 

8.00 

8 

64.00 

8.00 

8 

64.00 



448.00 


Requested Workload 
Utilization 
3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 


22.25 % 


Experiment step size: 


3.18 % 


Test 3 results : 

Test duration (seconds) : 10.0 


Task 

No. 

1 

2 

3 

4 

5 

6 
7 


Period 

Met 

Missed 

in msecs 

Deadlines 

Deadlines 

500.000 

20 

0 

250.000 

40 

0 

125.000 

80 

0 

62.500 

160 

0 

31.250 

320 

0 

125.000 

80 

0 

125.000 

80 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 









Experiment 

: EXPERIMENT 4 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per Second (KWIPS) 

: 2013.42 

Test 4 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets Requested Workload 

NO, 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 

% 

2 

4.00 

16 

64.00 

3.18 

% 

3 

8.00 

8 

64.00 

3.18 

% 

4 

16.00 

4 

64.00 

3.18 

% 

5 

32.00 

2 

64.00 

3.18 

% 

6 

8.00 

8 

64.00 

3.18 

% 

7 

8.00 

8 

64.00 

3.18 

% 

8 

8.00 

8 

64.00 

3.18 

% 




512.00 

25.43 

% 

Experiment 

step size 

: 3.18 % 




Test 4 results : 





'’est duration (seconds): 10.0 




Task 

Period 

Met 

Missed Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

312 

4 

4 

0.763 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 5 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets Requested 

Workload 

NO. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 

% 

2 

4.00 

16 

64.00 

3.18 

% 

3 

8.00 

8 

64.00 

3.18 

% 

4 

16.00 

4 

64.00 

3.18 

% 

5 

32.00 

2 

64.00 

3.18 

% 

6 

8.00 

8 

64.00 

3.18 

% 

7 

8.00 

8 

64.00 

3.18 

% 

8 

8.00 

8 

64.00 

3.18 

% 

9 

8.00 

8 

64.00 

3.18 

% 




576.00 

28.61 

% 

Experiment 

step size 

: 3.18 % 




Test 5 results: 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

296 

12 12 

2.075 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 










Experiment : EXP ERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 7 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 

% 

2 

4.00 

16 

64.00 

3.18 

% 

3 

8.00 

8 

64.00 

3.18 

% 

4 

16.00 

4 

64.00 

3.18 

% 

5 

32.00 

2 

64.00 

3.18 

% 

6 

8.00 

8 

64.00 

3.18 

% 

7 

8.00 

8 

64.00 

3.18 

% 

8 

8.00 

8 

64.00 

3.18 

% 

9 

8.00 

8 

64.00 

3.18 

% 

10 

8.00 

8 

64.00 

3.18 

% 

11 

8.00 

8 

64.00 

3.18 

% 




704.00 

34.97 

% 

Experiment step size: 

3.18 % 




Test 7 

results : 





Test duration (seconds) : 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

301 

10 

9 

0.488 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 8 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 

% 

2 

4.00 

16 

64.00 

3.18 

% 

3 

8.00 

8 

64.00 

3.18 

% 

4 

16.00 

4 

64.00 

3.18 

% 

5 

32.00 

2 

64.00 

3.18 

% 

6 

8.00 

8 

64.00 

3.18 

% 

7 

8.00 

8 

64.00 

3.18 

% 

8 

8.00 

8 

64.00 

3.18 

% 

9 

8.00 

8 

64.00 

3.18 

% 

10 

8.00 

8 

64.00 

3.18 

% 

11 

8.00 

8 

64.00 

3.18 

% 

12 

8.00 

8 

64.00 

3.18 

% 




768.00 

38.14 

% 


Experiment step size: 3.18 % 


Test 8 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

71 

1 

8 

941.345 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

62 

2 

2 

941.345 

12 

125.000 

80 

0 

0 

0.000 




Experiment : EXPERIMENT 4 




Completion on: Miss/skip 50 deadlines 



Raw speed in Kilo-Whetstone Instructions Per Second 

. (KWIPS) 

: 2013.42 

Test 10 

characteristics : 




Task 

Frequency 

Kilo-Whets 

Kilo -Whets Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 

% 

2 

4.00 

16 

64.00 

3.18 

% 

3 

8.00 

8 

64.00 

3.18 

% 

4 

16.00 

4 

64.00 

3.18 

% 

5 

32.00 

2 

64.00 

3.18 

% 

6 

8.00 

8 

64.00 

3.18 

% 

7 

8.00 

8 

64.00 

3.18 

% 

8 

8.00 

8 

64.00 

3.18 

% 

9 

8.00 

8 

64.00 

3.18 

% 

10 

8.00 

8 

64.00 

3.18 

% 

11 

8.00 

8 

64.00 

3.18 

% 

12 

8.00 

8 

64.00 

3.18 

% 

13 

8.00 

8 

64.00 

3.18 

% 

14 

8.00 

8 

64.00 

3.18 

% 




896.00 

44.50 

% 

Experiment step size 

: 3.18 % 




Test 10 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec ) 

1 

500.000 

20 

0 o 


0.000 

2 

250.000 

40 

0 o 


0.000 

3 

125.000 

80 

0 0 


0.000 

4 

62.500 

160 

0 0 


0.000 

5 

31.250 

259 

31 30 


0.244 

6 

125.000 

80 

0 0 


0.000 

7 

125.000 

80 

0 0 


0.000 

8 

125.000 

80 

0 0 


0.000 

9 

125.000 

80 

o 0 


0.000 

10 

125.000 

80 

o 0 


0.000 

11 

125.000 

80 

o 0 


0.000 

12 

125.000 

80 

o 0 


0.000 

13 

125.000 

80 

0 0 


0.000 

14 

125.000 

80 

0 0 


0.000 


11 




Massanmlfei:; 





HARTSTONE BENCHMARK SUMMARY RESULTS 


Baseline test : 


Experiment : EXP ERXMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 1 characteristics: 


Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 2.00 32 

2 4.00 16 

3 8.00 8 

4 16.00 4 

5 32.00 2 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

3.18 % 

64.00 

3.18 % 

64.00 

3.18 % 

64.00 

3.18 % 

64.00 

3.18 % 


320.00 15.89 % 


Experiment step size: 


3.18 % 


Test 1 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 


Experiment : EXPERIMENT^ 

Connie t ion on: Miss/skip 50 deadlinea 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 3 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 

8.00 

8.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 
8 
8 


Experiment step size: 3.18 % 


Test 3 results: 


Test duration (seconds): 10.0 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

64.00 

64.00 

64.00 


448.00 


Requested Workload 
Utilization 
3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 


22.25 % 


Period 

Met 

Missed 

in msecs 

Deadlines 

Deadlines 

500.000 

20 

0 

250.000 

40 

0 

125.000 

80 

0 

62.500 

160 

0 

31.250 

320 

0 

125.000 

80 

0 

125.000 

80 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 



MflSSEJJUilti 4- 




13 


Teat when deadlines first missed/ skipped: 


Experiment : EXPERIMENT^ 4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 
Test 4 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

3.18 

% 

2 

4.00 

16 

64.00 

3.18 

% 

3 

8.00 

8 

64.00 

3.18 

% 

4 

16.00 

4 

64.00 

3.18 

% 

5 

32.00 

2 

64.00 

3.18 

% 

6 

8.00 

8 

64.00 

3.18 

% 

7 

8.00 

8 

64.00 

3.18 

% 

8 

8.00 

8 

64.00 

3.18 

% 




512.00 

25.43 

% 

Experiment step size: 

3.18 % 




Test 4 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

312 

4 

4 

0.763 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 


Final test performed 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 2013.42 


Test 10 characteristics: 


Task 

Frequency 

NO. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


896.00 


3.18 % 


Requested Workload 
Utilization 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 

3.18 % 


44.50 % 


Test 10 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

No. 

in msecs 

Deadlines 

1 

500.000 

20 

2 

250.000 

40 

3 

125.000 

80 

4 

62.500 

160 

5 

31.250 

259 

6 

125.000 

80 

7 

125.000 

80 

8 

125.000 

80 

9 

125.000 

80 

10 

125.000 

80 

11 

125.000 

80 

12 

125.000 

80 

13 

125.000 

80 

14 

125.000 

80 


Missed 

Deadlines 

0 

0 

0 

0 

31 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

30 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.244 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 




Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Masscomp 6350 - C3Ada version 1.0 
Target : Masscomp 6350 - dual 33 MHz 68030 


Characteristics of best test for this experiment : 

(no missed/ skipped deadlines) 

Test 3 of Experiment 4 

Raw (non-tasking) benchmark speed in KWIPS: 2013.42 


Full task set: 

Total Deadlines 

Tasks Per Second 

7 78.00 

Highest-frequency task: 

Period Deadlines 

(msec) Per Second 

31.250 32.00 


Task Set Total 

Utilization KWIPS 

22.25 % 448.00 


Task Task 

Utilization KWIPS 

3.18 % 64.00 


Experiment step size: 3.18 % 


END OF HART STONE BENCHMARK SUMMARY RESULTS 





Experiment : EXPERIMENT_1 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 1 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

64.00 


Requested Workload 
Utilization 
1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


320.00 


7.15 % 


Experiment step size: 


0.71 % 


Test 1 results: 

Test duration (seconds) : 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 320 


Missed Skipped Average 
Deadlines Deadlines Late (msec) 

o 0 0.000 
o 0 0.000 
o 0 0.000 
o 0 0.000 
o 0 0.000 



Experiment : EXPERIMENT_1 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 2 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

48.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

96.00 

352.00 


Requested Workload 
Utilization 
1.43 % 

1.43 % 

1.43 % 

1.43 % 

2.14 % 


7.86 % 


Experiment step size: 0.71 % 


Test 2 results: 


Test duration (seconds): 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
20.833 


Met 

Deadlines 

20 

40 

80 

160 

480 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Sfcmuity: 


Experiment : EXPERIMENT^ 

Completion on: Miaa/akip 50 deadlinea 

R.W speed in Kilo-Whetstone Instruotions Pet Second (KWIPS) : 4,76.28 
Teat 3 characteriatica : 


Taak Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 64.00 


Kilo-wheta 
per period 
32 
16 
8 
4 
2 


Experiment step size: 0.71 % 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

128.00 


384.00 


Requested Workload 
Utilization 
1.43 % 

1.43 % 

1.43 % 

1.43 % 

2.86 % 


8.58 % 



Test 3 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250 .000 

125.000 
62.500 
15.625 


Met 

Deadlines 

20 

40 

80 

160 

477 


Missed 

Deadlines 

0 

0 

0 

0 

81 


Skipped 

Deadlines 

0 

0 

0 

0 

82 


Average 
Date (msec) 
0.000 
0.000 
0.000 
0.000 
1.988 





SonjnuItLl 



^ast test with no missed/skipped deadlines: 


Experiment: EXPERIMENT 1 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 2 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

48.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

64.00 

64.00 

64.00 

64.00 

96.00 


352.00 


Requested Workload 
Utilization 
1.43 % 

1.43 % 

1.43 % 

1.43 % 

2.14 % 


7.86 % 


Experiment step size: 


0.71 % 


Test 2 results: 


Test duration (seconds): 10.0 


^ Task 

Period 

Met 

Missed 

No . 

in msecs 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

2 

250.000 

40 

0 

3 

125.000 

80 

0 

4 

62.500 

160 

0 

5 

20.833 

480 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment 

: EXPERIMENT^ 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per ; 

Second (KWIPS) 

: 4476.28 

Test 3 characteristics: 




Task 

Frequency Kilo-Whets 

Kilo -Whets 

Requested Workload 

NO. 

(Hertz) per period 

per second 

Utilization 

1 

2.00 32 

64.00 

1.43 

% 

2 

4.00 16 

64.00 

1.43 

% 

3 

8.00 8 

64.00 

1.43 

% 

4 

16.00 4 

64.00 

1.43 

% 

5 

64.00 2 

128.00 

2.86 

% 



384.00 

8.58 

% 

Experiment 

step size: 0.71 % 





Test 3 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

15.625 

477 

81 

82 

1.988 





'inal test performed: 

See preceding summary of test 3 


Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Verdix 6.0 -> Sun SPARC 

Target : Sun SPARC Station 1+ (25 MHz) - multiuser mode 

Characteristics of best test for this experiment: 

(no missed/ skipped deadlines) 


Test 2 of Experiment 1 

Raw (non-tasking) benchmark speed in KWIPS: 4476.28 


Full task set: 

Total Deadlines 

Tasks Per Second 

5 78.00 

Highest -frequency task: 

Period Deadlines 

(msec) Per Second 

20.833 48.00 


Task Set Total 

Utilization KWIPS 

7.86 % 352.00 


Task Task 

Utilization KWIPS 

2.14 % 96.00 


Experiment step size: 0.71 % 


END OF HARTSTONE BENCHMARK SUMMARY RESULTS 




Teat 1 results: 

Test duration (seconds): 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 320 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Experiment : EXPERIMENT_2 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 


Test 2 characteristics: 

Task Frequency Kilo-Whets Kilo-Whets 

No. (Hertz) per period per second 

1 2.20 32 70.40 

2 4.40 16 70.40 

3 8.80 8 70.40 

4 17.60 4 70.40 

5 35.20 2 70.40 

352.00 

Experiment step size: 0.73 % 


Test 2 results: 


Test duration (seconds) 


Requested Workload 
Utilization 
1.61 % 

1.61 % 

1.61 % 

1.61 % 

1.61 % 

8.06 % 


Period 
in msecs 
454.545 
227.273 
113.636 
56.818 
28.409 


Met 

Deadlines 

23 

45 

88 

177 

350 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
4.000 



Experiment: : EXPERIMENT_2 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 


Test 3 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.40 

4.80 

9.60 

19.20 

38.40 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

76.80 

76.80 

76.80 

76.80 

76.80 


Requested Workload 
Utilization 
1.76 % 

1.76 % 

1.76 % 

1.76 % 

1.76 % 


384.00 


8.80 % 


Experiment step size: 0.73 % 


Test 3 results : 


Test duration (seconds) : 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 
416.667 
208.333 
104.167 
52.083 
26.042 


Met 

Deadlines 

25 

48 

97 

192 

385 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0 . 000 


Experiment : EXPERIMENT_2 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 
Test 4 characteristics: 


Frequency 

(Hertz) 

2.60 

5.20 

10.40 

20.80 

41.60 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 

83.20 

83.20 

83.20 

83.20 

83.20 


416.00 


Requested Workload 
Utilization 
1.91 % 

1.91 % 

1.91 % 

1.91 % 

1.91 % 


9.53 % 


Experiment step size: 


0.73 % 


Test 4 results : 


Test duration (seconds): 10.0 


Period 
in msecs 
384.615 
192.308 
96.154 
48.077 
24.038 


Met 

Deadlines 

26 

53 

104 

208 

414 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
1.000 




Test 5 results: 

Test duration (seconds): 10.0 

Task Period Met Missed 

No* in msecs Deadlines Deadlines 

1 357.143 28 0 

2 178.571 56 0 

3 89.286 113 0 

4 44.643 224 0 

5 22.321 448 0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



SSnrmulO- 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 
Test 6 characteristics: 

Requested Workload 
Utilization 
2.20 % 

2.20 % 

2.20 % 

2.20 % 

2.20 % 


11.00 % 

Experiment step size: 0.73 % 


Task 

No. 

1 

2 

3 

4 

5 


Frequency Kilo-Whets 


(Hertz) 

3.00 

6.00 

12.00 

24.00 

48.00 


per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 
96.00 
96.00 
96.00 
96.00 
96.00 


480.00 


Test 6 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 333.333 

2 166.667 

3 83.333 

4 41.667 

5 20.833 


Met 

Deadlines 

30 

61 

120 

239 

477 


Missed 

Deadlines 

0 

0 

0 

1 

1 


Skipped 

Deadlines 

0 

0 

0 

1 

2 


Average 
Late (msec) 
0.000 
0.000 
0.000 
6.000 
25.000 


experiment : EXPERIMENT_2 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 


Test 7 characteristics: 

Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 3.20 32 

2 6.40 16 

3 12.80 8 

4 25.60 4 

5 51.20 2 


Experiment 3tep size: 0.73 % 


Test 7 results: 

Test duration (seconds): 10.0 

Task Period Met 

No. in msecs Deadlines 

1 312.500 32 

2 156.250 64 

3 78.125 128 

4 39.063 256 

5 19.531 512 


Kilo-Whets Requested Workload 
per second Utilization 

102.40 2.35 % 

102.40 2.35 % 

102.40 2.35 % 

102.40 2.35 % 

102.40 2.35 % 


512.00 11.73 % 


Missed Skipped Average 

Deadlines Deadlines Late (msec) 

0 0 0.000 

0 0 0.000 

0 0 0.000 

0 0 0.000 

0 0 0.000 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 
Test 8 characteristics: 

Task Frequency Kilo-Whets Kilo-Whets Requested Workload 
No. (Hertz) per period per second Utilization 

1 3.40 32 108.80 2.49 % 

2 6.80 16 108.80 2.49 % 

3 13.60 8 108.80 2.49 % 

4 27.20 4 108.80 2.49 % 

5 54.40 2 108.80 2.49 % 


544.00 12.46 % 

Experiment step size: 0.73 % 


Test 8 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

294.118 

35 

0 

0 

0.000 

2 

147.059 

68 

0 

0 

0.000 

3 

73.529 

137 

0 

0 

0.000 

4 

36.765 

271 

1 

1 

11.000 

5 

18.382 

447 

48 

49 

1.688 




hartstone benchmark summary results 


Baseline test: 


Experiment : EXPERIMENT^ 

Completion on: Miss /skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 
Test 1 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 
64.00 
64.00 
64.00 
64.00 
64.00 


Requested Workload 
Utilization 

1.47 % 

1.47 % 

1.47 % 

1.47 % 

1.47 % 


320.00 


7.33 % 


Experiment step size: 0.73 % 


Test 1 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Sun.jimltiJ£ 


10 


Last test with no missed/skipped deadlines: 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4364.91 
Test 7 characteristics: 

Task Frequency Kilo-Whets Kilo-Whets Requested Workload 
No. (Hertz) per period per second Utilization 

1 3.20 32 102.40 2.35 % 

2 6.40 16 102.40 2.35 % 

3 12.80 8 102.40 2.35 % 

4 25.60 4 102.40 2.35 % 

5 51.20 2 102.40 2.35 % 


512.00 11.73 % 

Experiment step size: 0.73 % 


Test 7 results: 

Test duration (seconds): 10.0 

Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 312.500 32 0 0 0.000 

2 156.250 64 0 0 0.000 

3 78.125 128 0 0 0.000 

4 39.063 256 0 0 0.000 

5 19.531 512 0 0 0.000 







• #K$, • : 



Test when deadlines first missed/ skipped: 


Experiment 

: EXPERIMENT 2 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4364.91 

Test 2 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.20 

32 

70.40 

1.61 

% 

2 

4.40 

16 

70.40 

1.61 

% 

3 

8.80 

8 

70.40 

1.61 

% 

4 

17.60 

4 

70.40 

1.61 

% 

5 

35.20 

2 

70.40 

1.61 

% 




352.00 

8.06 

% 

Experiment 

step size 

: 0.73 % 




Test 2 results: 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

454.545 

23 

0 

0 

0.000 

2 

227.273 

45 

0 

0 

0.000 

3 

113.636 

88 

0 

0 

0.000 

4 

56.818 

177 

0 

0 

0.000 

5 

28.409 

350 

1 

1 

4.000 


SunjtnuIO 



rinal test performed: 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo Whetstone Instructions Per Second (KWIPS) : 4364.91 


Test 8 characteristics: 


Task Frequency 
No. (Hertz) 

1 3.40 

2 6.80 

3 13.60 

4 27.20 

5 54.40 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Kilo-Whets 
per second 
108.80 
108.80 
108.80 
108.80 
108.80 


Requested Workload 
Utilization 

2.49 % 

2.49 % 

2.49 % 

2.49 % 

2.49 % 


544.00 


12.46 % 


Experiment step size: 0.73 % 


Test 8 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

No. 

in msecs 

Deadlines 

Deadlines 

1 

294.118 

35 

0 

2 

147.059 

68 

0 

3 

73.529 

137 

0 

4 

36.765 

271 

1 

5 

18.382 

447 

48 


Skipped 

Deadlines 

0 

0 

0 

1 

49 


Average 
Late (msec) 
0.000 
0.000 
0.000 
11.000 
1.688 






SunjnultU 


Experiment : EXPERIMENT_3 

Completion on: Miaa/akip 50 deadlinea 


speed in Kilo Whetatone Inatructiona Per Second (KWIPS) : 4323.39 


Test 1 characteristics: 


Frequency 

(Hertz) 

2.00 


16.00 

32.00 


Kilo-Whets 
per period 
32 
16 
8 
4 
2 


Experiment step size: 1.43 % 


Test 1 results: 

Test duration (seconds) 


Kilo-Whets 
per second 
64.00 
64.00 
64.00 
64.00 
64.00 

320.00 


Requested Workload 
Utilization 
1.48 % 

1.48 % 

1.48 % 

1.48 % 

1.48 % 

7.40 % 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT__3 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 2 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
33 
17 
9 
5 
3 


Kilo-Whets 
per second 

66.00 

68.00 

72.00 

80.00 

96.00 


Requested Workload 
Utilization 
1.53 % 

1.57 % 

1.67 % 

1.85 % 

2.22 % 


382.00 


8.84 % 


Experiment step size: 


1.43 % 


Test 2 results : 


Test duration (seconds) : 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
13.000 


Experiment : EXP ERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 3 characteristics: 


Frequency 

(Hertz) 

2.00 


16.00 

32.00 


Experiment step size: 


Kilo-Whets 
per period 
34 
18 
10 
6 
4 


1.43 % 


Kilo-Whets 
per second 
68.00 

72.00 

80.00 

96.00 

128.00 


444.00 


Requested Workload 
Utilization 
1.57 % 

1.67 % 

1.85 % 

2.22 % 

2.96 % 


10.27 % 


Test 3 results: 


Test duration (seconds) 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 4 characteristics : 


Task 

Frequency 

Kilo-Whet3 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

35 

70.00 

1.62 % 

2 

4.00 

19 

76.00 

1.76 % 

3 

8.00 

11 

88.00 

2.04 % 

4 

16.00 

7 

112.00 

2.59 % 

5 

32.00 

5 

160.00 

3.70 % 

Experiment 

step size: 

1.43 % 

506.00 

11.70 % 


Test 4 

results : 






Test duration (seconds): 10.0 





Task 

Period 

Met 

Missed 

Skipped 

Average 


No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 


1 

500.000 

20 

0 

0 

0.000 


2 

250.000 

40 

0 

0 

0.000 


3 

125.000 

80 

0 

0 

0.000 


4 

62.500 

160 

0 

0 

0.000 


5 

31.250 

320 

0 

0 

0.000 







Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 5 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 

Frequency 

(Hertz) 

2.00 

4.00 

8.00 
16.00 
32.00 

Kilo-Whets 
per period 
36 
20 
12 
8 
6 

Kilo-Whets 
per second 

72.00 

80.00 
96.00 

128.00 

192.00 

Requested Workload 
Utilization 
1.67 % 

1.85 % 

2.22 % 

2.96 % 

4.44 % 




568.00 

13.14 

% 

Experiment 

step size: 

1.43 % 





Test 5 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT 3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 6 characteristics: 

Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 2.00 37 

2 4.00 21 

3 8.00 13 

4 16.00 9 

5 32.00 7 


Kilo-Whets 
per second 

74.00 

84.00 

104.00 

144.00 

224.00 


630.00 


Requested Workload 
Utilization 
1.71 % 

1.94 % 

2.41 % 

3.33 % 

5.18 % 


14.57 % 


Experiment step size: 1.43 % 


Test 6 results: 


Test duration (seconds) : 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Sun_roulti_3 


Experiment 

: EXPERIMENT_3 





Completion 

on: Miss/skip 50 deadlines 




Raw speed 

in Kilo-Whetstone Instructions Per Second (KWIPS) 


4323.39 

Test 7 characteristics: 





Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

38 

76.00 

1.76 

% 


2 

4.00 

22 

88.00 

2.04 

% 


3 

8.00 

14 

112.00 

2.59 

% 


4 

16.00 

10 

160.00 

3.70 

% 


5 

32.00 

8 

256.00 

5.92 

% 





692.00 

16.01 

% 


Experiment 

step size 

: 1.43 % 





Test 7 results : 






Test duration (seconds): 10.0 





Task 

Period 

Met 

Missed Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines Deadlines Late 

: (msec) 

. „ 1 

500.000 

20 

0 

0 


0.000 

2 

250.000 

40 

0 

0 


0.000 

3 

125.000 

80 

0 

0 


0.000 

4 

62.500 

160 

0 

0 


0.000 

5 

31.250 

320 

0 

0 


0.000 




Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 8 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
39 
23 
15 
11 
9 


Kilo-Whets 
per second 

78.00 

92.00 

120.00 

176.00 

288.00 


Requested Workload 
Utilization 
1.80 % 

2.13 % 

2.78 % 

4.07 % 

6.66 % 


754.00 


17.44 % 


Experiment step size: 1.43 % 


Test 8 results : 

Test duration (seconds): 10.0 

Task Period Met Missed Skipped Average 

No. m msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 00 000 

2 250.000 40 0 0 o!oOO 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 




SuitimiltO 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 9 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
40 
24 
16 
12 
10 


Kilo-Whets 
per second 
80.00 
96.00 
128.00 

192.00 

320.00 


816.00 


Experiment step size: 1.43 % 


Requested Workload 
Utilization 
1.85 % 

2.22 % 

2.96 % 

4.44 % 

7.40 % 


18.87 % 


Test 9 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 





Miii 




Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 10 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
41 
25 
17 
13 
11 


Kilo-Whets 
per second 

82.00 

100.00 

136.00 

208.00 

352.00 


Requested Workload 
Utilization 
1.90 % 

2.31 % 

3.15 % 

4.81 % 

8.14 % 


878.00 


20.31 % 


Experiment step size: 1.43 % 


Test 10 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 


10 






Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 11 characteristics: 

Task Frequency Kilo-Whets Kilo-Whets Requested Workload 
No. (Hertz) per period per second Utilization 

1 2.00 42 84.00 1.94 % 

2 4.00 26 104.00 2.41 % 

3 8.00 18 144.00 3.33 % 

4 16.00 14 224.00 s!l8 % 

5 32.00 12 384.00 8.88 % 


940.00 21.74 % 

Experiment step size: 1.43 % 


Test 11 results: 


Test duration (seconds): 10.0 


Task 
No * 
1 
2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

00 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT^ 

Completion on: Miss/ skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 

Test 12 characteristics: 

Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 2.00 43 

2 4.00 27 

3 8.00 19 

4 16.00 15 

5 32.00 13 


1002.00 23.18 % 


Kilo-Whets Requested Workload 
per second Utilization 

86.00 1.99 % 

108.00 2.50 % 

152.00 3.52 % 

240.00 5.55 % 

416.00 9.62 % 


Experiment step size: 1.43 % 


Test 12 results: 

Test duration (seconds): 10.0 


Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 0 0.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 



Experiment : EXPERIMENT J3 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 13 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
44 
28 
20 
16 
14 


Kilo-Whets 
per second 

88.00 

112.00 

160.00 

256.00 

448.00 


Requested Workload 
Utilization 
2.04 % 

2.59 % 

3.70 % 

5.92 % 

10.36 % 


1064.00 


24.61 % 


Experiment step size: 1.43 % 


Test 13 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

318 

1 

1 

8.000 





Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 14 characteristics: 

Task Frequency Kilo-Whets Kilo-Whets Requested Workload 
No. (Hertz) per period per second Utilization 

1 2.00 45 90.00 2.08 % 

2 4.00 29 116.00 2.68 % 

3 8.00 21 168.00 3.89 % 

4 16.00 17 272.00 6.29 % 

5 32.00 15 480.00 11.10 % 


1126.00 26.04 % 

Experiment step size: 1.43 % 


Test 14 results: 

Test duration (seconds): 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 320 


Missed Skipped Averaqe 

Deadlines Deadlines Late (msec) 
0 0 0.000 

0 0 0.000 

0 0 0.000 

0 0 0.000 

0 0 0.000 






Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 16 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

47 

94.00 

2.17 % 

2 

4.00 

31 

124.00 

2.87 % 

3 

8.00 

23 

184.00 

4.26 % 

4 

16.00 

19 

304.00 

7.03 % 

5 

32.00 

17 

544.00 

12.58 % 

Experiment 

step size: 

1.43 % 

1250.00 

28.91 % 


Test 16 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 17 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
48 
32 
24 
20 
18 


Kilo-Whets 
per second 

96.00 

128.00 

192.00 

320.00 

576.00 


Requested Workload 
Utilization 
2.22 % 

2.96 % 

4.44 % 

7.40 % 

13.32 % 


1312.00 


30.35 % 


Experiment step size: 


1.43 % 


Test 17 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
20.000 


Experiment 

: EXPERIMENT 3 




/ 

Completion 

on: Miss/skip 50 deadlines 




Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4323.39 


Test 18 characteristics: 





Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 


No. 

(Hertz) 

per period 

per second 

Utilization 


1 

2.00 

49 

98.00 

2.27 

% 


2 

4.00 

33 

132.00 

3.05 

% 


3 

8.00 

25 

200.00 

4.63 

% 


4 

16.00 

21 

336.00 

7.77 

% 


5 

32.00 

19 

608.00 

14.06 

% 





1374.00 

31.78 

% 


Experiment 

step size: 

1.43 % 






Test 18 results: 

Test duration (seconds): 10.0 

Task Period Met Missed 

No. in msecs Deadlines Deadlines 

1 500.000 20 0 

2 250.000 40 0 

3 125.000 80 0 

4 62.500 160 0 

5 31.250 320 0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 19 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
50 
34 
26 
22 
20 


Kilo-Whets 
per second 
100.00 

136.00 

208.00 

352.00 

640.00 


1436.00 


Experiment step size: 1.43 % 


Test 19 results: 


Test duration (seconds) : 


Requested Workload 
Utilization 
2.31 % 

3.15 % 

4.81 % 

8.14 % 

14.80 % 


33.21 % 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 




Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 20 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
51 
35 
27 
23 
21 


Kilo-Whets 
per second 
102.00 

140.00 

216.00 

368.00 

672.00 


Requested Workload 
Utilization 
2.36 % 

3.24 % 

5.00 % 

8.51 % 

15.54 % 


1498.00 


34.65 % 


Experiment step size: 1.43 % 


Test 20 results: 


Test duration (seconds) : 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 



Sitojnultl_3 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 21 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
52 
36 
28 
24 
22 


Kilo-Whets 
per second 

104.00 

144.00 

224.00 

384.00 

704.00 


Requested Workload 
Utilization 
2.41 % 

3.33 % 

5.18 % 

8.88 % 

16.28 % 


1560.00 


36.08 % 


Experiment step size: 1.43 % 


Test 21 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
1.000 



Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 22 characteristics: 


Task 

NO. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
53 
37 
29 
25 
23 


Kilo-whets 
per second 

106.00 

148.00 

232.00 

400.00 

736.00 


Requested Workload 
Utilization 
2.45 % 

3.42 % 

5.37 % 

9.25 % 

17.02 % 


1622.00 


37.52 % 


Experiment step size: 1.43 % 


Test 22 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 


Experiment : EXPERIMENT^ 

Completion on; Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 23 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
54 
38 
30 
26 
24 


Experiment step size: 1.43 % 


Test 23 results: 


Kilo-Whets 
per second 

108.00 

152.00 

240.00 

416.00 

768.00 

1684.00 


Requested Workload 
Utilization 
2.50 % 

3.52 % 

5.55 % 

9.62 % 

17.76 % 

38.95 % 


Test duration (seconds): 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 24 characteristics: 


Task Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

55 

110.00 

2.54 % 

2 

4.00 

39 

156.00 

3.61 % 

3 

8.00 

31 

248.00 

5.74 % 

4 

16.00 

27 

432.00 

9.99 % 

5 

32.00 

25 

800.00 

18.50 % 




1746.00 

40.38 % 

Experiment 

step size: 

1.43 % 




Test 24 results: 


Test duration (seconds) : 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 


Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 25 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
56 
40 
32 
28 
26 


Kilo-Whets 
per second 
112.00 

160.00 

256.00 

448.00 

832.00 


1808.00 


Requested Workload 
Utilization 
2.59 % 

3.70 % 

5.92 % 

10.36 % 

19.24 % 


41.82 % 


Experiment step size: 1.43 % 


Test 25 results: 


Test duration (seconds) 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 26 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
57 
41 
33 
29 
27 


Kilo-Whets 
per second 

114.00 

164.00 

264.00 

464.00 

864.00 


Requested Workload 
Utilization 
2.64 % 

3.79 % 

6.11 % 

10.73 % 

19.98 % 


1870.00 


43.25 % 


Experiment step size: 1.43 % 


Test 26 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment 

: EXP ERIMENT_3 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per Second (KWIPS) 

: 4323.39 

Test 28 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

59 

118.00 

2.73 

% 

2 

4.00 

43 

172.00 

3.98 

% 

3 

8.00 

35 

280.00 

6.48 

% 

4 

16.00 

31 

496.00 

11.47 

% 

5 

32.00 

29 

928.00 

21.46 

% 




1994.00 

46.12 

% 

Experiment 

step size: 

1.43 % 





Teat 28 reaulta: 

Teat duration (seconds): 10.0 

Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 0 0.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 318 1 1 2.000 






29 


Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 29 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
60 
44 

36 

32 

30 


Kilo-Whets 
per second 
120.00 

176.00 

288.00 

512.00 

960.00 


2056.00 


Experiment step size: 1.43 % 


Requested Workload 
Utilization 
2.78 % 

4.07 % 

6.66 % 

11.84 % 

22.20 % 


47.56 % 


Test 29 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Date (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 30 characteristics: 


Task 

NO. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
61 
45 
37 
33 
31 


Kilo-Whets 
per second 
122.00 

180.00 

296.00 

528.00 

992.00 


2118.00 


Requested Workload 
Utilization 
2.82 % 

4.16 % 

6.85 % 

12.21 % 

22.94 % 


48.99 % 


Experiment step size: 1.43 % 


Test 30 results: 

Test duration (seconds): 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 158 

5 31.250 318 


Missed Skipped Average 

Deadlines Deadlines Late (msec) 

0 0 0.000 

0 0 0.000 

0 0 0.000 

1 1 2.000 

1 1 22.000 





m- 






SunjnuJtiJ 





Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 31 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
62 
46 
38 
34 
32 


Kilo-Whets 
per second 

124.00 

184.00 

304.00 

544.00 
1024.00 


Requested Workload 
Utilization 
2.87 % 

4.26 % 

7.03 % 

12.58 % 

23.69 % 


2180.00 


50.42 % 


Experiment step size: 1.43 % 


Test 31 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



SunjnultU 




32 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323,39 
Test 32 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
63 
47 
39 
35 
33 


Kilo-Whets 
per second 

126.00 

188.00 

312.00 

560.00 

1056.00 


Requested Workload 
Utilization 
2.91 % 

4.35 % 

7.22 % 

12.95 % 

24.43 % 


2242.00 


51.86 % 


Experiment step size: 1.43 % 


Test 32 results: 


Test duration (seconds): 10.0 


Task 

NO. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
21.000 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 33 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

64 

2 

4.00 

48 

3 

8.00 

40 

4 

16.00 

36 

5 

32.00 

34 

Experiment step size 

: 1.43 % 

Test 33 

results : 


Test duration (seconds): 10.0 

Task 

Period 

Met 

No. 

in msecs 

Deadlines 

1 

500.000 

20 

2 

250.000 

40 

3 

125.000 

80 

4 

62.500 

160 

5 

31.250 

320 


Kilo-Whets 
per second 
128.00 

192.00 

320.00 

576.00 
1088.00 


2304.00 


Requested Workload 
Utilization 
2.96 % 

4.44 % 

7.40 % 

13.32 % 

25.17 % 

53.29 % 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 








SiSSillllf 


*:S::>&:^W:::W: 


*XA 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 34 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
65 
49 
41 
37 
35 


Kilo-Whets 
per second 

130.00 

196.00 

328.00 

592.00 

1120.00 


2366.00 


Requested Workload 
Utilization 
3.01 % 

4.53 % 

7.59 % 

13.69 % 

25.91 % 


54.73 % 


Experiment step size: 1.43 % 


Test 34 results: 

Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
6.000 



Suh_multi_3 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 35 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
66 
50 
42 
38 
36 


Kilo-Whets 
per second 

132.00 

200.00 

336.00 

608.00 
1152.00 


Requested Workload 
Utilization 
3.05 % 

4.63 % 

7.77 % 

14.06 % 

26.65 % 


2428.00 


56.16 % 


Experiment step size: 1.43 % 


Test 35 results : 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 





Test 37 results: 

Test duration (seconds) : 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 


38 






Experiment : EXPERIMENT^ 

Completion on: Miss /skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 38 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
69 
53 
45 
41 
39 


Kilo-Whets 
per second 

138.00 

212.00 

360.00 

656.00 

1248.00 


Requested Workload 
Utilization 
3.19 % 

4.90 % 

8.33 % 

15.17 % 

28.87 % 


2614.00 


60.46 % 


Experiment step size: 1.43 % 


Test 38 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 39 characteristics: 

Kilo-Whets Kilo-Whets Requested Workload 
per period per second Utilization 

70 140.00 3.24 % 

54 216.00 5 . 00 % 

46 368.00 8.51 % 

42 672.00 15.54 % 

4 0 1280.00 29.61 % 


2676.00 61.90 % 

Experiment step size: 1.43 % 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Test 39 results : 

Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 

Met 

Missed 

in msecs 

Deadlines 

Deadlines 

500.000 

20 

0 

250.000 

40 

0 

125.000 

80 

0 

62.500 

160 

0 

31.250 

320 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




smmms: 


Experiment 

: EXPERIMENT_3 





Completion 

on: Miss/skip 50 deadlines 




Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4323.39 


Test 40 characteristics: 





Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 


No. 

(Hertz) 

per period 

per second 

Utilization 


1 

2.00 

71 

142.00 

3.28 

% 


2 

4.00 

55 

220.00 

5.09 

% 


3 

8.00 

47 

376.00 

8.70 

% 


4 

16.00 

43 

688.00 

15.91 

% 


5 

32.00 

41 

1312.00 

30.35 

% 





2738.00 

63.33 

% 


Experiment 

step size: 

1.43 % 






Test 40 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 





Experiment : EXPERIMENT_3 

Completion on: Mias/skip 50 deadlinea 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 41 characteristics: 

Task Frequency Kilo-Whets Kilo-Whets Requested Workload 
No. (Hertz) per period per second Utilization 

1 2.00 72 144.00 3.33 % 

2 4.00 56 224.00 5.18 % 

3 8.00 48 384.00 8.88 % 

4 16.00 44 704.00 16.28 % 

5 32.00 42 1344.00 31.09 % 


2800.00 64.76 % 

Experiment step size: 1.43 % 


Test 41 results: 

Test duration (seconds) : 10.0 

Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 0 0.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 




Experiment: EXPERIMENT 3 




Completion on: Miss/skip 50 deadlines 



Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) 

: 4323.39 

Test 42 

characteristics : 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

73 

146.00 

3.38 

% 

2 

4.00 

57 

228.00 

5.27 

% 

3 

8.00 

49 

392.00 

9.07 

% 

4 

16.00 

45 

720.00 

16.65 

% 

5 

32.00 

43 

1376.00 

31.83 

% 




2862.00 

66.20 

% 

Experiment step size 

: 1.43 % 




Test 42 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 








Experiment 

: EXPERIMENT 3 




Completion 

on: Miss /skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per Second (KWIPS) 

: 4323.39 

Test 43 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No • 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

74 

148.00 

3.42 

% 

2 

4.00 

58 

232.00 

5.37 

% 

3 

8.00 

50 

400.00 

9.25 

% 

4 

16.00 

46 

736.00 

17.02 

% 

5 

32.00 

44 

1408.00 

32.57 

% 




2924.00 

67.63 

% 

Experiment 

step size 

: 1.43 % 




Test 43 results: 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed Skipped 

Averaqe 

No . 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

78 

1 

1 

2.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

318 

1 

1 

26.000 


Experiment 

: EXPERIMENT 3 





Completion 

on: Miss/skip 50 deadlines 




Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4323.39 


Test 44 characteristics: 





Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 


No. 

(Hertz) 

per period 

per second 

Utilization 


1 

2.00 

75 

150.00 

3.47 

% 


2 

4.00 

59 

236.00 

5.46 

% 


3 

8.00 

51 

408.00 

9.44 

% 


4 

16.00 

47 

752.00 

17.39 

% 


5 

32.00 

45 

1440.00 

33.31 

% 





2986.00 

69.07 

% 


Experiment 

step size: 

1.43 % 






Test 44 

results : 






Test duration (seconds): 10.0 





Task 

Period 

Met 

Missed 

Skipped 

Average 


NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 


1 

500.000 

20 

0 

0 

0.000 


2 

250.000 

40 

0 

0 

0.000 


3 

125.000 

80 

0 

0 

0.000 


4 

62.500 

160 

0 

0 

0.000 


5 

31.250 

320 

0 

0 

0.000 





Experiment 

Completion 

Raw speed 

: EXPERIMENT^ 

on: Miss /skip 50 deadlines 

in Kilo-Whetstone Instructions Per ; 

Second (KWIPS) 

: 4323.39 

Test 45 characteristics: 

Task Frequency Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

. per second 

Utilization 

1 

2.00 

76 

152.00 

3.52 

% 

2 

4.00 

60 

240.00 

5.55 

% 

3 

8.00 

52 

416.00 

9.62 

% 

4 

16.00 

48 

768.00 

17.76 

% 

5 

32.00 

46 

1472.00 

34.05 

% 

Experiment 

step size: 

1.43 % 

3048.00 

70.50 

% 


Test 45 

results : 





Test duration (seconds) 

: 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

158 

1 

1 

25.000 

5 

31.250 

318 

1 

1 

28.000 



Experiment : EXPERIMENT_3 

Completion on: Miss/akip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 46 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
77 
61 
53 
49 
47 


Kilo-Whets 
per second 

154.00 

244.00 

424.00 

784.00 

1504.00 


Requested Workload 
Utilization 
3.56 % 

5.64 % 

9.81 % 

18.13 % 

34.79 % 


3110.00 


71.93 % 


Experiment step size: 


1.43 % 


Test 46 results: 


Test duration (seconds): 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

320 


Missed 

Deadlines 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 47 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
78 
62 
54 
50 
48 


Kilo-Whets 
per second 

156.00 

248.00 

432.00 

800.00 

1536.00 


Requested Workload 
Utilization 
3.61 % 

5.74 % 

9.99 % 

18.50 % 

35.53 % 


3172.00 


73.37 % 


Experiment step size: 1.43 % 


Test 47 results; 


Test duration (seconds): 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

150 

318 


Missed 

Deadlines 

0 

0 

0 

1 

1 


Skipped 

Deadlines 

0 

0 

0 

1 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 

27.000 

20.000 




Experiment : EXPERIMENT_3 




Completion on: Miss/skip 50 deadlines 



Raw speed in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4323.39 

Test 48 

characteristics : 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

79 

158.00 

3.65 

% 

2 

4.00 

63 

252.00 

5.83 

% 

3 

8.00 

55 

440.00 

10.18 

% 

4 

16.00 

51 

816.00 

18.87 

% 

5 

32.00 

49 

1568.00 

36.27 

% 




3234.00 

74.80 

% 

Experiment step size 

: 1.43 % 




Teat 48 

results : 





Test duration (seconds) : 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 


»• 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 49 characteristics: 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
80 
64 
56 
52 
50 


Kilo-Whets 
per second 

160.00 

256.00 

448.00 

832.00 

1600.00 


Requested Workload 
Utilization 
3.70 % 

5.92 % 

10.36 % 

19.24 % 

37.01 % 


3296.00 


76.24 % 


Experiment step size: 1.43 % 


Test 49 results: 

Test duration (seconds): 10.0 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
9.000 





Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 50 characteristics: 


Task Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

81 

162.00 

3.75 % 

2 

4.00 

65 

260.00 

6.01 % 

3 

8.00 

57 

456.00 

10.55 % 

4 

16.00 

53 

848.00 

19.61 % 

5 

32 . 00 

51 

1632.00 

37.75 % 




3358.00 

77.67 % 

Experiment 

step size: 

1.43 % 




Test 50 results: 

Test duration (seconds): 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 320 


Missed Skipped Average 

Deadlines Deadlines Late (msec) 

0 0 0.000 

0 0 0.000 

0 0 0.000 

0 0 0.000 

o 0 0.000 



51 




Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 51 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
82 
66 
58 
54 
52 


Kilo-whets 
per second 

164.00 

264.00 

464.00 

864 . 00 

1664.00 


Requested Workload 
Utilization 
3.79 % 

6.11 % 

10.73 % 

19.98 % 

38.49 % 


3420 . 00 


79.10 % 


Experiment step size: 1.43 % 


Test 51 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

0 

2 

250.000 

40 

0 

0 

3 

125.000 

80 

0 

0 

4 

62.500 

158 

1 

1 

5 

31.250 

318 

1 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
2.000 

17.000 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 52 characteristics: 


Task 

Frequency 

Kile 

• -Whet s 

Kilo-whets 

Requested Workload 

No. 

(Hertz) 

per 

period 

per second 

Utilization 

1 

2.00 


83 

166.00 

3.84 

% 

2 

4.00 


67 

268.00 

6.20 

% 

3 

8.00 


59 

472.00 

10.92 

% 

4 

16.00 


55 

880.00 

20.35 

% 

5 

32.00 


53 

1696.00 

39.23 

% 





3482.00 

80.54 

% 

Experiment 

step size: 

1 . 

43 % 





Test 52 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 





Experiment 

: EXPERIMENT 3 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4323.39 

Test 53 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

84 

168.00 

3.89 

% 

2 

4.00 

68 

272.00 

6.29 

% 

3 

8.00 

60 

480.00 

11.10 

% 

4 

16.00 

56 

896.00 

20.72 

% 

5 

32.00 

54 

1728.00 

39.97 

% 




3544.00 

81.97 

% 

Experiment 

step size: 

1.43 % 





Test 53 results: 

Test duration (seconds): 10.0 

Task Period Met Missed Skipped 

No. in msecs Deadlines Deadlines Deadlines 

1 500.000 20 0 0 

2 250.000 40 0 0 

3 125.000 80 0 0 

4 62.500 160 0 0 

5 31.250 320 0 0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 




lliBBiHI 


Experiment 

: EXPERIMENT 3 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4323.39 

Teat 54 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

85 

170.00 

3.93 

% 

2 

4.00 

69 

276.00 

6.38 

% 

3 

8.00 

61 

488.00 

11.29 

% 

4 

16.00 

57 

912.00 

21.09 

% 

5 

32.00 

55 

1760.00 

40.71 

% 




3606.00 

83.41 

% 

Experiment 

step size: 

1.43 % 





Test 54 

results : 






Test duration (seconds): 10.0 





Task 

Period 

Met 

Missed 

Skipped 

Average 


No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 


1 

500.000 

20 

0 

0 

0.000 


2 

250.000 

40 

0 

0 

0.000 



3 

125.000 

80 

0 

0 

0.000 


4 

62.500 

160 

0 

0 

0.000 


5 

31.250 

320 

0 

0 

0.000 



Suiumilti^S 


Experiment 

: EXPERIMENT^ 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per ; 

Second (KWIPS) 

: 4323.39 

Test 55 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

86 

172.00 

3.90 

% 

2 

4.00 

70 

280.00 

6.48 

% 

3 

8.00 

62 

496.00 

11.47 

% 

4 

16.00 

58 

928.00 

21.46 

% 

5 

32.00 

56 

1792.00 

41.45 

% 




3668.00 

84.84 

% 

Experiment 

step size: 

1.43 % 





Test 55 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec 

1 

500.000 

20 

0 

0 

0 . 000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 




Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 56 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
87 
71 
63 
59 
57 


Kilo-whets 
per second 

174.00 

284.00 

504.00 

944.00 
1824.00 


Requested Workload 
Utilization 
4.02 % 

6.57 % 

11.66 % 

21.83 % 

42.19 % 


3730.00 


86.27 % 


Experiment step size: 1.43 % 


Test 56 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

302 


Missed 

Deadlines 

0 

0 

0 

0 

9 


Skipped 

Deadlines 

0 

0 

0 

0 

9 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.222 





SunjtnuItL3 


Experiment : EXPERIMENT_3 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 57 characteristics: 

Task Frequency Kilo-Whets Kilo-Whet 3 Requested Workload 
No. (Hertz) per period per second Utilization 

1 2.00 88 176.00 4.07 % 

2 4.00 72 288.00 6.66 % 

3 8.00 64 512.00 11.84 % 

4 16.00 60 960.00 22.20 % 

5 32.00 58 1856.00 42.93 % 


Experiment step size: 1.43 % 


3792.00 


87.71 % 


Test 57 results: 

Test duration (seconds) : 10.0 


Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 18 1 i 1.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 



SuiunultU 


58 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 58 characteristics: 


Task 

NO. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
89 
73 
65 
61 
59 


Kilo-Whets 
per second 

178.00 

292.00 

520.00 

976.00 

1888.00 


Requested Workload 
Utilization 
4.12 % 

6.75 % 

12.03 % 

22.57 % 

43.67 % 


3854.00 


89.14 % 


Experiment step size: 1.43 % 


Test 58 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

20 

38 

80 

158 

318 


Missed 

Deadlines 

0 

1 

0 

1 

1 


Skipped 

Deadlines 

0 

1 

0 

1 

1 


Average 
Late (msec) 
0.000 

70.000 
0.000 

34.000 

31.000 



Experiment : EXPERIMENT^ 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 59 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

90 

2 

4.00 

74 

3 

8.00 

66 

4 

16.00 

62 

5 

32.00 

60 

Experiment step size 

: 1.43 % 

Test 59 

results : 


Test duration (seconds): 10.0 

Task 

Period 

Met 

No. 

in msecs 

Deadlines 

_ 1 

500.000 

14 

2 

250.000 

32 

3 

125.000 

80 

4 

62.500 

160 

5 

31.250 

320 


Kilo-Whets 
per second 
180.00 

296.00 

528.00 

992.00 
1920.00 


3916.00 


Requested Workload 
Utilization 
4.16 % 

6.85 % 

12.21 % 

22.94 % 

44.41 % 


90.58 % 


Missed 

Deadlines 

3 

4 
0 
0 
0 


Skipped 

Deadlines 

3 

4 

0 

0 

0 


Average 
Late (msec) 
40.333 
49.250 
0.000 
0.000 
0.000 



Experiment 

: EXPERIMENT_3 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per : 

Second (KWIPS) 

: 4323.39 

Test 60 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

91 

182.00 

4.21 

% 

2 

4.00 

75 

300.00 

6.94 

% 

3 

8.00 

67 

536.00 

12.40 

% 

4 

16.00 

63 

1008.00 

23.32 

% 

5 

32.00 

61 

1952.00 

45.15 

% 




3978.00 

92.01 

% 

Experiment 

step size: 

1.43 % 





Test 60 results: 

Test duration (seconds): 10.0 

Task Period Met Missed 

No. in msecs Deadlines Deadlines 

1 500.000 10 5 

2 250.000 40 0 

3 125.000 80 0 

4 62.500 140 10 

5 31.250 311 4 


Skipped 

Deadlines 

5 

0 

0 

10 

5 


Average 
Late (msec) 
369.200 
0.000 
0.000 
4.300 
8 .000 





Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 61 characteristics: 


Task Frequency 
No. (Hertz) 

1 2.00 

2 4.00 

3 8.00 

4 16.00 

5 32.00 


Kilo-Whets 
per period 
92 
76 
68 
64 
62 


Kilo-Whets 
per second 

184.00 

304.00 

544.00 

1024.00 

1984.00 


Requested Workload 
Utilization 
4.26 % 

7.03 % 

12.58 % 

23.69 % 

45.89 % 


4040.00 


93.45 % 


Experiment step size: 1.43 % 


Test 61 results: 


Test duration (seconds): 10.0 


Task Period 
No. in msecs 

1 500.000 

2 250.000 

3 125.000 

4 62.500 

5 31.250 


Met 

Deadlines 

0 

36 

80 

160 

320 


Missed 

Deadlines 

4 

2 

0 

0 

0 


Skipped 

Deadlines 

16 

2 

0 

0 

0 


Average 
Late (msec) 
1812.750 
69.500 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 


Test 62 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

93 

186.00 

4.30 

% 

2 

4.00 

77 

308.00 

7.12 

% 

3 

8.00 

69 

552.00 

12.77 

% 

4 

16.00 

65 

1040.00 

24.06 

% 

5 

32.00 

63 

2016.00 

46.63 

% 




4102.00 

94.88 

% 

Experiment step size: 

1.43 % 




Test 62 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

500.000 

3 

9 

8 

176.222 

2 

250.000 

10 

15 

15 

56.000 

3 

125.000 

56 

12 

12 

1.750 

4 

62.500 

158 

1 

1 

12.000 

5 

31.250 

318 

1 

1 

29.000 





Experiment : EXPERIMENT_3 

Completion on: Miss/ skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 55 characteristics: 


Task 

NO. 

1 

2 

3 

4 

5 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-Whets 
per period 
8 6 
70 
62 
58 
56 


Kilo-Whets 
per second 

172 . 00 

280.00 

496.00 

928.00 

1792.00 


Requested Workload 
Utilization 
3.98 % 

6.48 % 

11.47 % 

21.46 % 

41.45 % 


3668.00 


84.84 % 


Experiment step size: 1.43 % 


Test 55 results: 

Test duration (seconds): 10.0 

Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 0 0.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 




Experiment : EXPERIMENT_3 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4323.39 
Test 2 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 


Frequency 

{Hertz) 

2.00 

4.00 

8.00 

16.00 

32.00 


Kilo-whets 
per period 
33 
17 
9 
5 
3 


Kilo-Whets 
per second 

66.00 

68.00 

72.00 

80.00 

96.00 


382.00 


Requested Workload 
Utilization 
1.53 % 

1.57 % 

1.67 % 

1.85 % 

2.22 % 


8.84 % 


Experiment step size: 1.43 % 


Test 2 results: 


Test duration (seconds): 10.0 


Task 

NO. 

1 

2 

3 

4 

5 


Period 
in msecs 

500.000 

250.000 

125.000 
62.500 
31.250 


Met 

Deadlines 

20 

40 

80 

160 

318 


Missed 

Deadlines 

0 

0 

0 

0 

1 


Skipped 

Deadlines 

0 

0 

0 

0 

1 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
13.000 



Sunjmilti_3 




Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Verdix 6.0 -> Sun SPARC 

Target : Sun SPARC Station 1+ (25 MHz) - multiuser mode 

Characteristics of best test for this experiment: 

(no missed/skipped deadlines) 

Test 55 of Experiment 3 

Raw (non-tasking) benchmark speed in KWIPS: 4323.39 
Full task set: 


Total 

Tasks 

5 


Deadlines 
Per Second 
62.00 


Highest-f requency task: 

Period Deadlines 

(msec) Per Second 

31.250 32.00 


Task Set 
Utilization 
84.84 % 


Task 

Utilization 
41.45 % 


Total 

KWIPS 

3668.00 


Task 

KWIPS 

1792.00 


Experiment step size: 1.43 $ 



END OF HARTSTONE BENCHMARK SUMMARY RESULTS 









Experiment 

: EXPERIMENT 4 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

: 4476.28 

Test 1 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No, 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 




320.00 

7.15 

% 

Experiment 

step size 

: 1.43 % 




Test 1 results: 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No . 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 

Test 2 characteristics: 

Task Frequency Kilo-Whets 

No. (Hertz) per period 

1 2.00 32 

2 4.00 16 

3 8.00 8 

4 16.00 4 

5 32.00 2 

6 8.00 8 


384.00 8.58 % 


Requested Workload 
Utilization 
1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


Experiment step size: 1.43 % 


Test 2 results : 

Test duration (seconds): 10.0 


Task Period Met Missed Skipped Average 

No. in msecs Deadlines Deadlines Deadlines Late (msec) 

1 500.000 20 0 0 0.000 

2 250.000 40 0 0 0.000 

3 125.000 80 0 0 0.000 

4 62.500 160 0 0 0.000 

5 31.250 320 0 0 0.000 

6 125.000 80 0 0 0.000 




siimiiil 



Experiment 

: EXPERIMENT 4 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per Second (KWIPS) 

: 4476.28 

Test 3 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 




448.00 

10.01 

% 

Experiment 

step size 

: 1.43 % 




Test 3 results: 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed Skipped 

Average 

No . 

in msecs 

Deadlines 

Deadlines Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 4 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 




512.00 

11.44 

% 


Experiment step size: 1.43 % 


Test 4 results: 

Test duration (seconds) : 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

318 

1 

1 

2.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 




Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 5 characteristics: 

Task Frequency Kilo-Wheta Kilo-Wheta Requeated Workload 
No. (Hertz) per period per aecond Utilization 

1 2.00 32 64.00 1.43 % 

2 4.00 16 64.00 1.43 % 

3 8.00 8 64.00 1.43 % 

4 16.00 4 64.00 1.43 % 

5 32.00 2 64.00 1.43 % 

6 8.00 8 64.00 1.43% 

7 8.00 8 64.00 1.43% 

8 8.00 8 64.00 1.43% 

9 8.00 8 64.00 1.43 % 

576.00 12.87 % 


Skipped 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 



Sfcjmiltr 4 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Test 6 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 

9 

8.00 

8 

64.00 

1.43 

% 

10 

8.00 

8 

64.00 

1.43 

% 




640.00 

14.30 

% 

Experiment step size: 

1.43 % 




Test 6 

results : 





Test duration (seconds) : 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 


7 


Experiment : EXPERIMENT^ 4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Test 7 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

Experiment 

step size: 

1.43 % 


Kilo-Whets 

Requested 

Workload 

per second 

Utilization 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

704.00 

15.73 

% 


Test 7 results: 


Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 

6 

7 

8 


Period 

Met 

in msecs 

Deadlines 

500.000 

20 

250.000 

40 

125.000 

80 

62.500 

160 

31.250 

320 

125.000 

80 

125.000 

80 

125.000 

80 

125.000 

80 

125.000 

80 

125.000 

80 


Missed 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 


9 

10 

11 





Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Test 8 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No * 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 

9 

8.00 

8 

64.00 

1.43 

% 

10 

8.00 

8 

64.00 

1.43 

% 

11 

8.00 

8 

64.00 

1.43 

% 

12 

8.00 

8 

64.00 

1.43 

% 




768.00 

17.16 

% 

Experiment step size: 

1.43 % 




Test 8 

results : 





Test duration (seconds) : 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 













Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 11 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

No. 

(Hertz) 

per period 

per second 

1 

2.00 

32 

64.00 

2 

4.00 

16 

64.00 

3 

8.00 

8 

64.00 

4 

16.00 

4 

64.00 

5 

32.00 

2 

64.00 

6 

8.00 

8 

64.00 

7 

8.00 

8 

64.00 

8 

8.00 

8 

64.00 

9 

8.00 

8 

64.00 

10 

8.00 

8 

64.00 

11 

8.00 

8 

64.00 

12 

8.00 

8 

64.00 

13 

8.00 

8 

64.00 

14 

8.00 

8 

64.00 

15 

8.00 

8 

64.00 




960.00 

>eriment step size 

: 1.43 % 


^ 11 

results : 



t duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

No. 

in msecs 

Deadlines 

Deadlines D 

1 

500.000 

20 

0 

2 

250.000 

40 

0 

3 

125.000 

80 

0 

4 

62.500 

160 

0 

5 

31.250 

320 

0 

6 

125.000 

80 

0 

7 

125.000 

80 

0 

8 

125.000 

80 

0 

9 

125.000 

80 

0 

10 

125.000 

80 

0 

11 

125.000 

80 

0 

12 

125.000 

80 

0 

13 

125.000 

80 

0 

14 

125.000 

80 

0 

15 

125.000 

80 

0 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


21.45 % 


Skipped 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 










^mM 


12 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 12 characteristics: 


Task 

Frequency 

Kilo-whets 

Kilo-Whets 

Requested Workload 

No. 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 

9 

8.00 

8 

64.00 

1.43 

% 

10 

8.00 

8 

64.00 

1.43 

% 

11 

8.00 

8 

64.00 

1.43 

% 

12 

8.00 

8 

64.00 

1.43 

% 

13 

8.00 

8 

64.00 

1.43 

% 

14 

8.00 

8 

64.00 

1.43 

% 

15 

8.00 

8 

64.00 

1.43 

% 

16 

8.00 

8 

64.00 

1.43 

% 




1024.00 

22.88 

% 

Experiment 

step size: 

1.43 % 





Test 12 

results : 





Test duration (seconds): 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Test 13 characteristics: 


Task 

Frequency 

No. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


1088.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


24.31 % 


Test 13 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

No. 

in msecs 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

2 

250.000 

40 

0 

3 

125.000 

80 

0 

4 

62.500 

160 

0 

5 

31.250 

320 

0 

6 

125.000 

80 

0 

7 

125.000 

80 

0 

8 

125.000 

80 

0 

9 

125.000 

80 

0 

10 

125.000 

80 

0 

11 

125.000 

80 

0 

12 

125.000 

80 

0 

13 

125.000 

80 

0 

14 

125.000 

80 

0 

15 

125.000 

80 

0 

16 

125.000 

80 

0 

17 

125.000 

80 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 14 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

NO. 

(Hertz) 

per period 

per second 

Utilization 

1 

2. 

00 

32 

64.00 

1 

.43 

% 

2 

4. 

00 

16 

64.00 

1 

.43 

% 

3 

8. 

00 

8 

64.00 

1 

.43 

% 

4 

16. 

00 

4 

64.00 

1 

.43 

% 

5 

32. 

00 

2 

64.00 

1 

.43 

% 

6 

8. 

00 

8 

64.00 

1 

.43 

% 

7 

8. 

00 

8 

64.00 

1 

.43 

% 

8 

8. 

00 

8 

64.00 

1 

.43 

% 

9 

8. 

00 

8 

64.00 

1 

.43 

% 

10 

8. 

00 

8 

64.00 

1 

.43 

% 

11 

8. 

00 

8 

64.00 

1 

.43 

% 

12 

8. 

00 

8 

64.00 

1 

.43 

% 

13 

8 . 

00 

8 

64.00 

1 

.43 

% 

14 

8. 

00 

8 

64.00 

1 

.43 

% 

15 

8. 

00 

8 

64.00 

1 

.43 

% 

16 

8. 

00 

8 

64.00 

1 

.43 

% 

17 

8. 

00 

8 

64.00 

1 

.43 

% 

18 

8. 

00 

8 

64.00 

1 

.43 

% 





1152.00 

25 

.74 

% 


Experiment step size: 1.43 % 


Test 14 results: 


Test duration (seconds) : 10.0 


rask 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125 . 000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 




Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 15 characteristics: 


Task 

Frequency 

No. 

(Hertz ) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


1216.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


27.17 % 



Test 15 results 


Test duration (seconds): 10.0 


rask 

Period 

Met 

Missed 

Skipped 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

0 

2 

250.000 

40 

0 

0 

3 

125.000 

80 

0 

0 

4 

62.500 

160 

0 

0 

5 

31.250 

318 

1 

1 

6 

125.000 

80 

0 

0 

7 

125.000 

80 

0 

0 

8 

125.000 

80 

0 

0 

9 

125.000 

80 

0 

0 

10 

125.000 

80 

0 

0 

11 

125.000 

80 

0 

0 

12 

125.000 

80 

0 

0 

13 

125.000 

80 

0 

0 

14 

125.000 

80 

0 

0 

15 

125.000 

80 

0 

0 

16 

125.000 

80 

0 

0 

17 

125.000 

80 

0 

0 

18 

125.000 

80 

0 

0 

19 

125.000 

80 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
10.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT_4 

Completion on: Mias/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 16 characteristics: 


Task 

Frequency 

No. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

8 . 00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


1280.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


28.60 % 


F" 



III: liiiWiil - 

■■Fir 

Test 16 

results : 





Test duration (seconds) 

: 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

NO . 

in msecs Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 




Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 17 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo -Whets 

No. 

(Hertz) 

per period 

per second 

1 

2.00 

32 

64.00 

2 

4.00 

16 

64.00 

3 

8.00 

8 

64.00 

4 

16.00 

4 

64.00 

5 

32.00 

2 

64.00 

6 

8.00 

8 

64.00 

7 

8.00 

8 

64.00 

8 

8.00 

8 

64.00 

9 

8.00 

8 

64.00 

10 

8.00 

8 

64.00 

11 

8.00 

8 

64.00 

12 

8.00 

8 

64.00 

13 

8.00 

8 

64.00 

14 

8.00 

8 

64.00 

15 

8.00 

8 

64.00 

16 

8.00 

8 

64.00 

17 

8.00 

8 

64.00 

18 

8.00 

8 

64.00 

19 

8.00 

8 

64.00 

20 

8.00 

8 

64.00 

21 

8.00 

8 

64.00 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


1344.00 


30.02 % 


Experiment step size: 


1.43 % 





Test 17 results: 

Test duration (seconds) : 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

318 

1 

1 

4.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 


21 


Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 18 characteristics: 


Task 

Frequency 

No. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

8.00 

21 

8.00 

22 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64 . 00 


1408 . 00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


31.45 % 




Test 18 results 


Test duration (seconds): 10.0 


rask 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 




Sun_multi_4 : 


Experiment : EXPERIMENT_4 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 19 characteristics: 


Task 

Frequency 

Kilo-Whets 

NO. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64 . 

00 

1.43 

% 

64. 

00 

1.43 

% 

64 . 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64 . 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

64. 

00 

1.43 

% 

1472 . 

00 

32.88 

% 


Experiment step size: 


1.43 % 





y am 

• y • ' / , ' . ■ • ' 

— 

m=r . : - . 

:■ * ■. : ;.v.| . . 


. 

Test 19 

results : 






Test duration (seconds): 10.0 




w 

Task 

Period 

Met 

Missed 

Skipped 

Average 


No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 


1 

500.000 

20 

0 

0 

0.000 


2 

250.000 

40 

0 

0 

0.000 


3 

125.000 

80 

0 

0 

0.000 


4 

62.500 

160 

0 

0 

0.000 


5 

31.250 

318 

1 

1 

7.000 


6 

125.000 

80 

0 

0 

0.000 


7 

125.000 

80 

0 

0 

0.000 


8 

125.000 

80 

0 

0 

0.000 


9 

125.000 

80 

0 

0 

0.000 


10 

125.000 

80 

0 

0 

0.000 


11 

125.000 

80 

0 

0 

0.000 


12 

125.000 

80 

0 

0 

0.000 


13 

125.000 

80 

0 

0 

0.000 


14 

125.000 

80 

0 

0 

0.000 


15 

125.000 

80 

0 

0 

0.000 


16 

125.000 

80 

0 

0 

0.000 


17 

125.000 

80 

0 

0 

0.000 


18 

125.000 

80 

0 

0 

0.000 


19 

125.000 

80 

0 

0 

0.000 


20 

125.000 

80 

0 

0 

0.000 


21 

125.000 

80 

0 

0 

0.000 


22 

125.000 

80 

0 

0 

0.000 


23 

125.000 

80 

0 

0 

0.000 





25 



Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 20 characteristics: 


Task 

Frequency 

NO. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

8.00 

21 

8.00 

22 

8.00 

23 

8.00 

24 

8 . 00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64 .00 

8 

64.00 


1536.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


34.31 % 



Test 20 results: 





Test duration (seconds): 10.0 


rask 

Period 

Met 

Missed 

Skipped 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

0 

2 

250.000 

40 

0 

0 

3 

125.000 

80 

0 

0 

4 

62.500 

160 

0 

0 

5 

31.250 

320 

0 

0 

6 

125.000 

80 

0 

0 

7 

125.000 

80 

0 

0 

8 

125.000 

80 

0 

0 

9 

125.000 

80 

0 

0 

10 

125.000 

80 

0 

0 

11 

125.000 

80 

0 

0 

12 

125.000 

80 

0 

0 

13 

125.000 

80 

0 

0 

14 

125.000 

80 

0 

0 

15 

125.000 

80 

0 

0 

16 

125.000 

80 

0 

0 

17 

125.000 

80 

0 

0 

18 

125.000 

80 

0 

0 

19 

125.000 

80 

0 

0 

20 

125.000 

80 

0 

0 

21 

125.000 

80 

0 

0 

22 

125.000 

80 

0 

0 

23 

125.000 

80 

0 

0 

24 

125.000 

80 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 




Experiment : EXPERIMENT_4 

Completion on: Mias/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Test 21 characteristics: 


Task 

Frequency 

Kilo-Whets 

NO. 

(Hertz ) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 


Kilo-Whets 

Requested 

Workload 

per second 

Utilization 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

1600.00 

35.74 

% 


Experiment step size: 


1.43 % 



Test 21 results: 


Test duration (seconds): 10.0 


?ask 

Period 

Met 

Missed 

Skipped 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

0 

2 

250.000 

40 

0 

0 

3 

125.000 

80 

0 

0 

4 

62.500 

160 

0 

0 

5 

31.250 

318 

1 

1 

6 

125.000 

80 

0 

0 

7 

125.000 

80 

0 

0 

8 

125.000 

80 

0 

0 

9 

125.000 

80 

0 

0 

10 

125.000 

80 

0 

0 

11 

125.000 

80 

0 

0 

12 

125.000 

80 

0 

0 

13 

125.000 

80 

0 

0 

14 

125.000 

80 

0 

0 

15 

125.000 

80 

0 

0 

16 

125.000 

80 

0 

0 

17 

125.000 

80 

0 

0 

18 

125.000 

80 

0 

0 

19 

125.000 

80 

0 

0 

20 

125.000 

80 

0 

0 

21 

125.000 

80 

0 

0 

22 

125.000 

80 

0 

0 

23 

125.000 

80 

0 

0 

24 

125.000 

80 

0 

0 

25 

125.000 

80 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
18.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0 . 000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 










Experiment 

: EXPERIMENT 4 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) 

i : 4476.28 

Test 22 characteristics: 




Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No . 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 

9 

8.00 

8 

64.00 

1.43 

% 

10 

8.00 

8 

64.00 

1.43 

% 

11 

8.00 

8 

64.00 

1.43 

% 

12 

8.00 

8 

64.00 

1.43 

% 

13 

8.00 

8 

64.00 

1.43 

% 

14 

8.00 

8 

64.00 

1.43 

% 

15 

8.00 

8 

64.00 

1.43 

% 

16 

8.00 

8 

64.00 

1.43 

% 

17 

8.00 

8 

64.00 

1.43 

% 

18 

8.00 

8 

64.00 

1.43 

% 

19 

8.00 

8 

64.00 

1.43 

% 

20 

8.00 

8 

64.00 

1.43 

% 

21 

8.00 

8 

64.00 

1.43 

% 

22 

8.00 

8 

64.00 

1.43 

% 

23 

8.00 

8 

64.00 

1.43 

% 

24 

8.00 

8 

64.00 

1.43 

% 

25 

8.00 

8 

64.00 

1.43 

% 

26 

8.00 

8 

64.00 

1.43 

% 




1664.00 

37 . 17 

% 

Experiment 

step size: 

1.43 % 







Test 22 results: 


Test duration (seconds): 10.0 


rask 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 



SunomiltL^ 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 23 characteristics: 


Task 

Frequency 

No. 

(Hertz ) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

8.00 

21 

8.00 

22 

8.00 

23 

8.00 

24 

8.00 

25 

8.00 

26 

8.00 

27 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64 . 00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


1728.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


38.60 % 




Teat 23 results: 

Test duration (seconds) : 10.0 


NO. 

in msecs 

Deadlir 

1 

500.000 

20 

2 

250.000 

40 

3 

125.000 

80 

4 

62.500 

160 

5 

31.250 

320 

6 

125.000 

80 

7 

125.000 

80 

8 

125.000 

80 

9 

125.000 

80 

10 

125.000 

80 

11 

125.000 

80 

12 

125.000 

80 

13 

125.000 

80 

14 

125.000 

80 

15 

125.000 

80 

16 

125.000 

80 

17 

125.000 

80 

18 

125.000 

80 

19 

125.000 

80 

20 

125.000 

80 

21 

125.000 

80 

22 

125.000 

80 

23 

125.000 

80 

24 

125.000 

80 

25 

125.000 

80 

26 

125.000 

80 

27 

125.000 

80 


Missed 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 



: 



Snn_multi_4 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 24 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz ) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

o 

o 

00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 


Kilo-Whets 

Requested i 

Workload 

per second 

Utilization 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64 .00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 


1792.00 40.03 % 


Experiment step size: 


1.43 % 



Test 2 4 results: 


Sunimulti^4 



Test duration (seconds) : 


10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

80 

0 

0 

0.000 

28 

125.000 

80 

0 

0 

0.000 







Sun_multi_4 


35 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 25 characteristics: 


Task 

Frequency 

NO. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

8.00 

21 

8.00 

22 

8.00 

23 

8.00 

24 

8.00 

25 

8.00 

26 

8.00 

27 

8.00 

28 

8.00 

29 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


1856.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


41.46 % 








Test 25 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

80 

0 

0 

0.000 

28 

125.000 

80 

0 

0 

0.000 

29 

125.000 

80 

0 

0 

0.000 


— - 






Experiment 

: EXPERIMENT 4 




Completion 

on: Miss/skip 50 deadlines 



Raw speed 

in Kilo-Whetstone Instructions Per 

Second (KWIPS) : 4476.28 

Teat 26 characteristics: 




Task 

Frequency 

Kilo-Wheta 

Kilo-Whets 

Requested 

Workload 

No . 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 

9 

8.00 

8 

64.00 

1.43 

% 

10 

8.00 

8 

64.00 

1.43 

% 

11 

8.00 

8 

64.00 

1.43 

% 

12 

8.00 

8 

64.00 

1.43 

% 

13 

8.00 

8 

64.00 

1.43 

% 

14 

8.00 

8 

64.00 

1.43 

% 

15 

8.00 

8 

64.00 

1.43 

% 

1 6 

8.00 

8 

64.00 

1.43 

% 

17 

8.00 

8 

64.00 

1.43 

% 

18 

8.00 

8 

64.00 

1.43 

% 

_ 19 

8.00 

8 

64.00 

1.43 

% 

20 

8.00 

8 

64.00 

1.43 

% 

21 

8.00 

8 

64.00 

1.43 

% 

22 

8.00 

8 

64.00 

1.43 

% 

23 

8.00 

8 

64.00 

1.43 

% 

24 

8.00 

8 

64.00 

1 . 43 

% 

25 

8.00 

8 

64.00 

1.43 

% 

26 

8.00 

8 

64.00 

1.43 

% 

27 

8.00 

8 

64.00 

1.43 

% 

28 

8.00 

8 

64.00 

1.43 

% 

29 

8.00 

8 

64.00 

1 . 43 

% 

30 

8.00 

8 

64.00 

1.43 

% 




1920 .00 

42.89 

% 

Experiment 

step size: 

1.43 % 







SteBCWlltti 


38 


Test 26 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

80 

0 

0 

0.000 

28 

125.000 

80 

0 

0 

0.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

80 

0 

0 

0.000 


Sfojiiultr^ 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 27 characteristics: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested 

Workload 

No . 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 

% 

2 

4.00 

16 

64.00 

1.43 

% 

3 

8.00 

8 

64.00 

1.43 

% 

4 

16.00 

4 

64.00 

1.43 

% 

5 

32.00 

2 

64.00 

1.43 

% 

6 

8.00 

8 

64.00 

1.43 

% 

7 

8.00 

8 

64.00 

1.43 

% 

8 

8.00 

8 

64.00 

1.43 

% 

9 

8.00 

8 

64.00 

1.43 

% 

10 

8.00 

8 

64.00 

1.43 

% 

11 

8.00 

8 

64.00 

1.43 

% 

12 

8.00 

8 

64.00 

1 . 43 

% 

13 

8.00 

8 

64.00 

1.43 

% 

14 

8.00 

8 

64.00 

1.43 

% 

15 

8.00 

8 

64.00 

1 . 43 

% 

1 6 

8.00 

8 

64.00 

1 . 43 

% 

17 

8.00 

8 

64.00 

1.43 

% 

18 

8.00 

8 

64.00 

1 . 43 

% 

19 

8.00 

8 

64.00 

1 . 43 

% 

20 

8.00 

8 

64.00 

1 . 43 

% 

21 

8.00 

8 

64.00 

1.43 

% 

22 

8.00 

8 

64.00 

1 . 43 

% 

23 

8.00 

8 

64.00 

1 . 43 

% 

24 

8.00 

8 

64.00 

1 . 43 

% 

25 

8.00 

8 

64.00 

1.43 

% 

26 

8.00 

8 

64.00 

1 . 43 

% 

27 

8.00 

8 

64.00 

1 . 43 

% 

28 

8.00 

8 

64.00 

1 . 43 

% 

29 

8.00 

8 

64.00 

1 . 43 

% 

30 

31 

8.00 

8.00 

8 

8 

64.00 

64.00 

1.43 

1.43 

% 

% 




1984.00 

44.32 

% 


Experiment step size: 


1.43 % 





40 


. 27 

results : 





. duration (seconds) 

: 10.0 




'ask 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

80 

0 

0 

0.000 

28 

125.000 

80 

0 

0 

0.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

80 

0 

0 

0.000 

31 

125.000 

80 

0 

0 

0.000 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlinea 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Teat 28 characteristics : 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

Requested Workload 

No . 

(Hertz) 

per period 

per second 

Utilization 

1 

2.00 

32 

64.00 

1.43 % 

2 

4.00 

16 

64.00 

1.43 % 

3 

8.00 

8 

64.00 

1.43 % 

4 

16.00 

4 

64.00 

1.43 % 

5 

32.00 

2 

64.00 

1.43 % 

6 

8.00 

8 

64.00 

1.43 % 

7 

8.00 

8 

64.00 

1.43 % 

8 

8.00 

8 

64.00 

1.43 % 

9 

8.00 

8 

64.00 

1.43 % 

10 

8.00 

8 

64.00 

1.43 % 

11 

8.00 

8 

64.00 

1.43 % 

12 

8.00 

8 

64.00 

1.43 % 

13 

8.00 

8 

64.00 

1.43 % 

14 

8.00 

8 

64.00 

1.43 % 

15 

8.00 

8 

64.00 

1.43 % 

1 6 

8.00 

8 

64.00 

1.43 % 

17 

8.00 

8 

64.00 

1.43 % 

18 

8.00 

8 

64.00 

1.43 % 

19 

8.00 

8 

64.00 

1.43 % 

20 

8.00 

8 

64.00 

1.43 % 

21 

8.00 

8 

64.00 

1.43 % 

22 

8.00 

8 

64.00 

1.43 % 

23 

8.00 

8 

64.00 

1.43 % 

24 

8.00 

8 

64.00 

1.43 % 

25 

8.00 

8 

64.00 

1.43 % 

2 6 

8.00 

8 

64.00 

1.43 % 

27 

8.00 

8 

64.00 

1.43 % 

28 

8.00 

8 

64.00 

1.43 % 

29 

8.00 

8 

64.00 

1.43 % 

30 

8.00 

8 

64.00 

1.43 % 

3 1 

8.00 

8 

64.00 

1.43 % 

32 

8.00 

8 

64.00 

1.43 % 




2048.00 

45.75 % 


Experiment step size: 


1.43 % 




Test 28 results: 

Test duration (seconds): 10,0 


rask 

Period 

Met 

Missed 

Skipped 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

0 

2 

250.000 

40 

0 

0 

3 

125.000 

78 

1 

1 

4 

62.500 

160 

0 

0 

5 

31.250 

318 

1 

1 

6 

125.000 

80 

0 

0 

7 

125.000 

80 

0 

0 

8 

125.000 

80 

0 

0 

9 

125.000 

80 

0 

0 

10 

125.000 

78 

1 

1 

11 

125.000 

80 

0 

0 

12 

125.000 

80 

0 

0 

13 

125.000 

80 

0 

0 

14 

125.000 

80 

0 

0 

15 

125.000 

78 

1 

1 

16 

125.000 

80 

0 

0 

17 

125.000 

78 

1 

1 

18 

125.000 

80 

0 

0 

19 

125.000 

80 

0 

0 

20 

125.000 

78 

1 

1 

21 

125.000 

80 

0 

0 

22 

125.000 

80 

0 

0 

23 

125.000 

80 

0 

0 

24 

125.000 

80 

0 

0 

25 

125.000 

80 

0 

0 

26 

125.000 

80 

0 

0 

27 

125.000 

80 

0 

0 

28 

125.000 

80 

0 

0 

29 

125.000 

80 

0 

0 

30 

125.000 

80 

0 

0 

31 

125.000 

80 

0 

0 

32 

125.000 

80 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
22.000 
0.000 

16.000 
0.000 
0.000 
0.000 
0.000 

25.000 
0.000 
0.000 
0.000 
0.000 

27.000 
0.000 

30.000 
0.000 
0.000 

11.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 



Experiment : EXPERIMENT^ 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 29 characteristics: 


Task 

Frequency 

No. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

o 

o 

00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

oo 

o 

o 

21 

8.00 

22 

8.00 

23 

8.00 

24 

8.00 

25 

8.00 

26 

8.00 

27 

8.00 

28 

8.00 

29 

8.00 

30 

8.00 

31 

8.00 

32 

8.00 

33 

o 

o 

00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


2112.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


47.18 % 


I 


Teat 29 results: 


Test duration (seconds) : 10.0 


Task Period Met Missed 

No . in msecs Deadlines Deadlines 


1 

500.000 

2 

250.000 

3 

125.000 

4 

62.500 

5 

31.250 

6 

125.000 

7 

125.000 

8 

125.000 

9 

125.000 

10 

125.000 

11 

125.000 

12 

125.000 

13 

125.000 

14 

125.000 

15 

125.000 

16 

125.000 

17 

125.000 

18 

125.000 

19 

125.000 

20 

125.000 

21 

125.000 

22 

125.000 

23 

125.000 

24 

125.000 

25 

125.000 

26 

125.000 

27 

125.000 

28 

125.000 

29 

125.000 

30 

125.000 

31 

125.000 

32 

125.000 

33 

125.000 


20 0 
40 0 
80 0 
160 0 
320 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 
80 0 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0,000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 30 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8,00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

8.00 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 


2176.00 48.61 % 


Experiment step size: 


1.43 % 






SwujiultLJ :| fe . 

— 46 1 

Test 30 

results : 





Teat duration (seconds) : 10.0 




Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

318 

1 

1 

5.000 

6 

125.000 

78 

1 

1 

11.000 

7 

125.000 

78 

1 

1 

96.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

78 

1 

1 

30.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

78 

1 

1 

27.000 

20 

125.000 

78 

1 

1 

15.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

78 

1 

1 

24.000 ^ 

26 

125.000 

78 

1 

1 

18.000 

27 

125.000 

78 

1 

1 

21.000 

28 

125.000 

80 

0 

0 

0.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

80 

0 

0 

0.000 

31 

125.000 

80 

0 

0 

0.000 

32 

125.000 

80 

0 

0 

0.000 

33 

125.000 

80 

0 

0 

0.000 

34 

125.000 

80 

0 

0 

0.000 




Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 31 characteristics: 


Task 

Frequency 

No. 

(Hertz) 

1 

2.00 

2 

4.00 

3 

8.00 

4 

16.00 

5 

32.00 

6 

8.00 

7 

8.00 

8 

8.00 

9 

8.00 

10 

8.00 

11 

8.00 

12 

8.00 

13 

8.00 

14 

8.00 

15 

8.00 

16 

8.00 

17 

8.00 

18 

8.00 

19 

8.00 

20 

8.00 

21 

8.00 

22 

8.00 

23 

8.00 

24 

8.00 

25 

8.00 

26 

8.00 

27 

o 

o 

00 

28 

8.00 

29 

8.00 

30 

8.00 

31 

8.00 

32 

8.00 

33 

8.00 

34 

8.00 

35 

8.00 

Experiment 

step size 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


2240.00 


1.43 % 


Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


50.04 % 


Test 31 results: 


Test duration (seconds): 10.0 


rask 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

80 

0 

0 

0.000 

28 

125.000 

80 

0 

0 

0.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

80 

0 

0 

0.000 

31 

125.000 

80 

0 

0 

0.000 

32 

125.000 

80 

0 

0 

0.000 

33 

125.000 

80 

0 

0 

0.000 

34 

125.000 

80 

0 

0 

0.000 

35 

125.000 

80 

0 

0 

0.000 




isn 




49 


Experiment : EXPERIMENT^ 

Completion on: Mias/skip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Teat 32 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

8.00 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 

35 

8.00 

8 

36 

8.00 

8 

Experiment 

step size: 

1.43 % 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

2304.00 

51.47 % 



Test 32 results: 


Test duration (seconds): 10.0 


?ask 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in maec3 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

318 

1 

1 

15.000 

6 

125.000 

78 

1 

1 

33.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

78 

1 

1 

120.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

78 

1 

1 

35.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

78 

1 

1 

23.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

78 

1 

1 

39.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

78 

1 

1 

29.000 

28 

125.000 

78 

1 

1 

20.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

80 

0 

0 

0.000 

31 

125.000 

80 

0 

0 

0.000 

32 

125.000 

78 

1 

1 

26.000 

33 

125.000 

80 

0 

0 

0.000 

34 

125.000 

78 

1 

1 

2.000 

35 

125.000 

80 

0 

0 

0.000 

36 

125.000 

80 

0 

0 

0.000 



Stuorii®P 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 33 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

8.00 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 

35 

8.00 

8 

36 

8.00 

8 

37 

8.00 

8 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64 . 00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 


2368.00 52.90 % 


Experiment step size: 


1.43 % 





52 


Test 33 results: 


Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

NO. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

80 

0 

0 

0.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

80 

0 

0 

0.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

80 

0 

0 

0.000 

28 

125.000 

80 

0 

0 

0.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

80 

0 

0 

0.000 

31 

125.000 

80 

0 

0 

0.000 

32 

125.000 

80 

0 

0 

0.000 

33 

125.000 

80 

0 

0 

0.000 

34 

125.000 

80 

0 

0 

0.000 

35 

125.000 

80 

0 

0 

0.000 

36 

125.000 

80 

0 

0 

0.000 

37 

125.000 

80 

0 

0 

0.000 



Sun^multi_4 


Experiment : EXPERIMENT_4 

Couplet ion on: Miss/3kip 50 deadlines 


Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 34 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

8.00 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 

35 

8.00 

8 

36 

8.00 

8 

37 

8.00 

8 

38 

8.00 

8 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64,00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 


2432.00 54.33 % 


Experiment step size: 


1.43 % 




Teat 34 results: 

Teat duration (seconds) : 10.0 


'ask 

Period 

Met 

Missed 

Skipped 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

1 

500.000 

20 

0 

0 

2 

250.000 

38 

1 

1 

3 

125.000 

78 

1 

1 

4 

62.500 

160 

0 

0 

5 

31.250 

318 

1 

1 

6 

125.000 

80 

0 

0 

7 

125.000 

80 

0 

0 

8 

125.000 

78 

1 

1 

9 

125.000 

78 

1 

1 

10 

125.000 

78 

1 

1 

11 

125.000 

80 

0 

0 

12 

125.000 

78 

1 

1 

13 

125.000 

78 

1 

1 

14 

125.000 

78 

1 

1 

15 

125.000 

80 

0 

0 

16 

125.000 

80 

0 

0 

17 

125.000 

80 

0 

0 

18 

125.000 

80 

0 

0 

19 

125.000 

80 

0 

0 

20 

125.000 

80 

0 

0 

21 

125.000 

80 

0 

0 

22 

125.000 

78 

1 

1 

23 

125.000 

80 

0 

0 

24 

125.000 

80 

0 

0 

25 

125.000 

80 

0 

0 

26 

125.000 

80 

0 

0 

27 

125.000 

80 

0 

0 

28 

125.000 

80 

0 

0 

29 

125.000 

80 

0 

0 

30 

125.000 

78 

1 

1 

31 

125.000 

78 

1 

1 

32 

125.000 

78 

1 

1 

33 

125.000 

78 

1 

1 

34 

125.000 

78 

1 

1 

35 

125.000 

80 

0 

0 

36 

125.000 

80 

0 

0 

37 

125.000 

80 

0 

0 

38 

125.000 

80 

0 

0 


54 


Average 
Late (msec) 
0.000 

127.000 

1.000 
0.000 

7.000 
0.000 
0.000 

31.000 

8.000 

38.000 

0.000 

21.000 

2.000 

35.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 

46.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 

18.000 

43.000 

27.000 

5.000 

24.000 
0.000 
0.000 
0.000 
0.000 


Experiment : EXPERIMENT^ 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 35 characteristics: 


Task 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

8.00 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 

35 

8.00 

8 

36 

8.00 

8 

37 

8.00 

8 

38 

8.00 

8 

39 

8.00 

8 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64.00 

1.43 

% 

64 . 00 

1.43 

% 


2496.00 55.76 % 


Experiment step size: 


1.43 % 




ij: :j 


56 


Test 35 results: 

Test duration (seconds): 10.0 


Task 

Period 

Met 

Missed 

Skipped 

Average 

No. 

in msecs 

Deadlines 

Deadlines 

Deadlines 

Late (msec) 

1 

500.000 

20 

0 

0 

0.000 

2 

250.000 

40 

0 

0 

0.000 

3 

125.000 

80 

0 

0 

0.000 

4 

62.500 

160 

0 

0 

0.000 

5 

31.250 

320 

0 

0 

0.000 

6 

125.000 

80 

0 

0 

0.000 

7 

125.000 

80 

0 

0 

0.000 

8 

125.000 

78 

1 

1 

2.000 

9 

125.000 

80 

0 

0 

0.000 

10 

125.000 

80 

0 

0 

0.000 

11 

125.000 

80 

0 

0 

0.000 

12 

125.000 

80 

0 

0 

0.000 

13 

125.000 

80 

0 

0 

0.000 

14 

125.000 

80 

0 

0 

0.000 

15 

125.000 

80 

0 

0 

0.000 

16 

125.000 

80 

0 

0 

0.000 

17 

125.000 

80 

0 

0 

0.000 

18 

125.000 

78 

1 

1 

1.000 

19 

125.000 

80 

0 

0 

0.000 

20 

125.000 

80 

0 

0 

0.000 

21 

125.000 

80 

0 

0 

0.000 

22 

125.000 

80 

0 

0 

0.000 

23 

125.000 

80 

0 

0 

0.000 

24 

125.000 

80 

0 

0 

0.000 

25 

125.000 

80 

0 

0 

0.000 

26 

125.000 

80 

0 

0 

0.000 

27 

125.000 

78 

1 

1 

2.000 

28 

125.000 

78 

1 

1 

12.000 

29 

125.000 

80 

0 

0 

0.000 

30 

125.000 

78 

1 

1 

2.000 

31 

125.000 

80 

0 

0 

0.000 

32 

125.000 

80 

0 

0 

0.000 

33 

125.000 

80 

0 

0 

0.000 

34 

125.000 

80 

0 

0 

0.000 

35 

125.000 

80 

0 

0 

0.000 

36 

125.000 

80 

0 

0 

0.000 

37 

125.000 

80 

0 

0 

0.000 

38 

125.000 

80 

0 

0 

0.000 

39 

125.000 

80 

0 

0 

0.000 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

speed xn Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Teat 36 characteristics: 


Task 

No. 

1 

2 

3 

4 

5 

6 

7 

8 
9 

10 

11 

12 

13 

14 

15 

16 

17 

18 

19 

20 
21 
22 

23 

24 

25 

26 

27 

28 

29 

30 

31 

32 

33 

34 

35 

36 

37 

38 

39 

40 


Frequency 

(Hertz) 

2.00 

4.00 

8.00 
16.00 

32.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 

8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 
8.00 


Experiment step size: 


Kilo-Whets 

Kilo-Whets 

per period 

per second 

32 

64.00 

16 

64.00 

8 

64.00 

4 

64.00 

2 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 

8 

64.00 


2560.00 


1.43 % 


Requested Workload 
Utilization 
1-43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


57.19 % 






Teat 36 results: 


duration (seconds) 

: 10. 

ask 

Period 

Met 

tfo. 

in msecs Deadline 

1 

500.000 

16 

2 

250.000 

32 

3 

125.000 

80 

4 

62.500 

160 

5 

31.250 

318 

6 

125.000 

78 

7 

125.000 

80 

8 

125.000 

78 

9 

125.000 

78 

10 

125.000 

78 

11 

125.000 

80 

12 

125.000 

76 

13 

125.000 

76 

14 

125.000 

76 

15 

125.000 

76 

16 

125.000 

78 

17 

125.000 

78 

18 

125.000 

78 

19 

125.000 

78 

20 

125.000 

78 

21 

125.000 

80 

22 

125.000 

78 

23 

125.000 

78 

24 

125.000 

78 

25 

125.000 

80 

26 

125.000 

76 

27 

125.000 

80 

28 

125.000 

78 

29 

125.000 

78 

30 

125.000 

78 

31 

125.000 

78 

32 

125.000 

80 

33 

125.000 

76 

34 

125.000 

78 

35 

125.000 

78 

36 

125.000 

78 

37 

125.000 

74 

38 

125.000 

78 

39 

125.000 

80 

40 

125.000 

78 


Missed 

Deadlines 

2 

4 

0 

0 

1 

1 

0 

1 

1 

1 

0 

2 

2 

2 

2 

1 

1 

1 

1 

1 

0 

1 

1 

1 

0 

2 

0 

1 

1 

1 

1 

0 

2 

1 

1 

1 

3 

1 

0 

1 


Skipped 

Deadlines 

2 

4 

0 

0 

1 

1 

0 

1 

1 

1 

0 

2 

2 

2 

2 

1 

1 

1 

1 

1 

0 

1 

1 

1 

0 

2 

0 

1 

1 

1 

1 

0 

2 

1 

1 

1 

3 

1 

0 

1 


Average 
Late (msec) 

250.000 

1.500 
0.000 
0.000 

11.000 

4.000 

0.000 

31.000 

37.000 

12.000 
0.000 

60.500 

22.000 

115.000 

1.000 

1.000 

1.000 

112.000 

123.000 

1.000 
0.000 

15.000 

111.000 

53.000 
0.000 

1.500 
0.000 

44.000 

56.000 

47.000 

50.000 
0.000 

12.500 

5.000 

1.000 

27.000 

7.000 

21.000 

0.000 

1.000 




Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 1 characteristics: 


Task 
No - 
1 
2 

3 

4 

5 

Frequency 

(Hertz) 

2.00 

4.00 

8.00 
16.00 
32.00 

Kilo-Whets 
per period 
32 
16 
8 
4 
2 

Kilo-Whets 
per second 
64.00 
64.00 
64.00 
64.00 
64.00 

Requested Workload 
Utilization 
1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 




320.00 

7.15 % 

Experiment 

step size: 

1.43 % 




Test 1 results : 


Test duration (seconds): 10.0 

Task Period Met 

No. in msecs Deadlines 

1 500.000 20 

2 250.000 40 

3 125.000 80 

4 62.500 160 

5 31.250 320 


Missed Skipped Average 

Deadlines Deadlines Late (msec) 
0 0 0.000 

0 0 0.000 

0 0 0.000 

0 0 0.000 

0 o 0.000 





Last test with no missed/ skipped deadlines: 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 33 characteristics: 


’ask 

Frequency 

Kilo-Whets 

No. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

8.00 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 

35 

8.00 

8 

36 

8.00 

8 

37 

8.00 

8 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64 .00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

2368.00 

52.90 % 


Experiment step size: 


1.43 % 


Test 33 results: 

Test duration (seconds): 10.0 


Task 

Period 

No. 

in msecs 

1 

500.000 

2 

250.000 

3 

125.000 

4 

62.500 

5 

31.250 

6 

125.000 

7 

125.000 

8 

125.000 

9 

125.000 

10 

125.000 

11 

125.000 

12 

125.000 

13 

125.000 

14 

125.000 

15 

125.000 

16 

125.000 

17 

125.000 

18 

125.000 

19 

125.000 

20 

125.000 

21 

125.000 

22 

125.000 

23 

125.000 

24 

125.000 

25 

125.000 

26 

125.000 

27 

125.000 

28 

125.000 

29 

125.000 

30 

125.000 

31 

125.000 

32 

125.000 

33 

125.000 

34 

125.000 

35 

125.000 

36 

125.000 

37 

125.000 


Missed 
Deadlines 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 

80 o 


Met 

Deadlines 

20 

40 

80 

160 

320 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 

80 


Skipped 

Deadlines 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 
0.000 





iiiiuiii 


62 


Test when deadlines first missed/ skipped: 


Experiment : EXPERIMENT 4 

Completion on: Miss /skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 


Test 4 

characteristics 

: 


Task 

Frequency 

Kilo-Whets 

Kilo-Whets 

NO. 

(Hertz) 

per period 

per second 

1 

2.00 

32 

64.00 

2 

4.00 

16 

64.00 

3 

8.00 

8 

64.00 

4 

16.00 

4 

64.00 

5 

32.00 

2 

64.00 

6 

8.00 

8 

64.00 

7 

8.00 

8 

64.00 

8 

8.00 

8 

64.00 




512.00 

Experiment step size: 

1.43 % 



Requested Workload 
Utilization 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 

1.43 % 


11.44 % 


Test 4 results: 

Test duration (seconds): 10.0 


Task 

No. 

1 

2 

3 

4 

5 

6 

7 

8 


Period 

Met 

Missed 

in msecs 

Deadlines 

Deadlines 

500.000 

20 

0 

250.000 

40 

0 

125.000 

80 

0 

62.500 

160 

0 

31.250 

318 

1 

125.000 

80 

0 

125.000 

80 

0 

125.000 

80 

0 


Skipped 

Deadlines 

0 

0 

0 

0 

1 

0 

0 

0 


Average 
Late (msec) 
0.000 
0.000 
0.000 
0.000 
2.000 
0.000 
0.000 
0.000 


Final teat performed 


Experiment : EXPERIMENT_4 

Completion on: Miss/skip 50 deadlines 

Raw speed in Kilo-Whetstone Instructions Per Second (KWIPS) : 4476.28 
Test 36 characteristics: 


Task 

Frequency 

Kilo-Whets 

NO. 

(Hertz) 

per period 

1 

2.00 

32 

2 

4.00 

16 

3 

8.00 

8 

4 

16.00 

4 

5 

32.00 

2 

6 

8.00 

8 

7 

8.00 

8 

8 

8.00 

8 

9 

8.00 

8 

10 

8.00 

8 

11 

8.00 

8 

12 

8.00 

8 

13 

8.00 

8 

14 

8.00 

8 

15 

8.00 

8 

16 

8.00 

8 

17 

8.00 

8 

18 

8.00 

8 

19 

8.00 

8 

20 

8.00 

8 

21 

8.00 

8 

22 

8.00 

8 

23 

8.00 

8 

24 

8.00 

8 

25 

8.00 

8 

26 

8.00 

8 

27 

8.00 

8 

28 

8.00 

8 

29 

8.00 

8 

30 

8.00 

8 

31 

CO 

o 

o 

8 

32 

8.00 

8 

33 

8.00 

8 

34 

8.00 

8 

35 

8.00 

8 

36 

8.00 

8 

37 

8.00 

8 

38 

8.00 

8 

39 

8.00 

8 

40 

8.00 

8 

xperiment 

step size: 

1.43 % 


Kilo-Whets 

Requested Workload 

per second 

Utilization 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

64.00 

1.43 % 

2560.00 

57.19 % 


Test 36 results: 





Test duration (seconds) : 10.0 


Task Period Met Missed 

No. in msecs Deadlines Deadlines 


1 

500.000 

2 

250.000 

3 

125.000 

4 

62.500 

5 

31.250 

6 

125.000 

7 

125.000 

8 

125.000 

9 

125.000 

10 

125.000 

11 

125.000 

12 

125.000 

13 

125.000 

14 

125.000 

15 

125.000 

16 

125.000 

17 

125.000 

18 

125.000 

19 

125.000 

20 

125.000 

21 

125.000 

22 

125.000 

23 

125.000 

24 

125.000 

25 

125.000 

26 

125.000 

27 

125.000 

28 

125.000 

29 

125.000 

30 

125.000 

31 

125 .000 

32 

125 . 000 

33 

125.000 

34 

125.000 

35 

125.000 

36 

125.000 

37 

125.000 

38 

125.000 

39 

125 .000 

40 

125.000 


16 2 

32 4 

80 0 

160 0 

318 1 

78 1 

80 0 

78 1 

78 1 

78 1 

80 0 

76 2 

76 2 

76 2 

76 2 

78 1 

78 1 

78 1 

78 1 

78 1 

80 0 

78 1 

78 1 

78 1 

80 0 

76 2 

80 0 

78 1 

78 1 

78 1 

78 1 

80 0 

76 2 

78 1 

78 1 

78 1 

74 3 

78 1 

80 0 

78 1 


Skipped 

Deadlines 

2 

4 

0 

0 

1 

1 

0 

1 

1 

1 

0 

2 

2 

2 

2 

1 

1 

1 

1 

1 

0 

1 

1 

1 

0 

2 

0 

1 

1 

1 

1 

0 

2 

1 

1 

1 

3 

1 

0 

1 


Average 
Late (msec) 

250.000 
1.500 
0.000 
0.000 

11.000 

4.000 
0.000 

31.000 

37.000 

12.000 
0.000 

60.500 
22.000 

115.000 

1.000 
1.000 
1.000 

112.000 

123.000 
1.000 
0.000 

15.000 

111.000 

53.000 
0.000 
1.500 
0.000 

44.000 

56.000 

47.000 

50.000 
0.000 

12.500 

5.000 

1.000 

27.000 

7.000 

21.000 
0.000 

1.000 




Benchmark : Hartstone Benchmark, version 1.0 
Compiler : Verdix 6.0 -> Sun SPARC 

Target : Sun SPARC Station 1+ {25 MHz) - multiuser mode 

Characteristics of best test for this experiment: 

(no missed/skipped deadlines) 

Test 33 of Experiment 4 

Raw (non-tasking) benchmark speed in KWIPS: 4476.28 
Full task set: 


Total 

Tasks 

37 


Deadlines 
Per Second 
318.00 


Task Set Total 

Utilization KWIPS 

52.90 % 2368.00 


Highest-f requency task: 

Period Deadlines 

(msec) Per Second 

31.250 32.00 


Task 

Utilization 
1.43 % 


Task 

KWIPS 

64.00 


Experiment step size: 1.43 % 


END OF HARTSTONE BENCHMARK SUMMARY RESULTS 





