N94-11437 


STGT Program: 
Ada Coding and 
Architecture 
Lessons Learned 


Paul Usavage and Don Nagurney 
GE Management and Data Systems Engineering, 
P.O. Box 8048, Phila. PA, 19101 
Phone: (215) 354-3165 
Fax: (215) 354-3177 


STGT (Second TDRSS Ground Terminal) is currently halfway 
through the System Integration Test phase (Level 4 Testing). To 
date , many software architecture and Ada language issues 
have been encountered and solved. This paper, which is a 
transcript of the presentation at the December 3rd meeting , 
attempts to define these lessons plus others learned regarding 
software project management and risk management issues, 
training, performance, reuse, and reliability. Observations are 
included regarding the use of particular Ada coding 
constructs, software architecture trade-offs during the 
prototyping, development and testing stages of the project and 
dangers inherent in parallel or concurrent Systems, Software, 
Hardware and Operations Engineering. 


SEL-92-004 page 366 



Introduction 

STGT is the first major Ada development 
program for M&DSO, which has devel- 
oped other large ground stations in FOR- 
TRAN and C. in addition to the use of Ada, 
GE Management and Data Systems Oper- 
ations faced other software development 
risks in the implementation of STGT. Some 
of these risk items are itemized below: 

• A heavily distributed system ( > 30 
processing nodes and >100 worksta- 
tions in previous ground stations) 

• High real-time system content (vs. 
40% real-time, 60% batch process- 
ing) 

• First on a DEC/VAX platform (vs. IBM 
mainframes and Sun/Unix worksta- 
tions) 

• High-availability/high-reliability archi- 
tecture (99.99% availability required) 

• High hardware content ( > 350 racks 
of ground communication equipment) 

• Heavily automated, X-Windows, 
workstation-based user interface 

• First artificial intelligence (Al) based 
hardware fault detection/fault isolation 

• Short development lead time (3 years 
from start to delivery) 


Risk items like the above don’t usually 
translate into the impossible, they just have 
a way of eating into cost and schedule mar- 
gins. Several steps were taken to mitigate 
the risks involved. An Ada Core Team was 
formed prior to program startup to develop 
language expertise. An Ada training pro- 
gram was developed and its completion 
required for ail software engineers 
employed on the program. Despite these 
efforts, many lessons were learned on the 
job through prototyping, development and 
testing. This paper is intended to be a 
chronicle of these risk issues and (hopeful- 
ly) their resolutions. 

Project Composition 

The Second TDRSS (Tracking and Data 
Relay Satellite System) Ground Terminal 
(STGT) is a new ground station and an up- 
grade to an existing ground station in White 
Sands, New Mexico. These ground sta- 
tions will provide command and data com- 
munications from user control facilities 
through the TDRS, and on to the various 
user satellites and the Space Shuttle. 

The breakdown of thousands of source 
lines of code developed for each Comput- 
er Software Configuration Item (CSC!) for 
the project is shown in Table 1 . 


2 


SEL-92-004 page 367 



CS-CI 

Size (Lines of 

Thousands of Hours 1 

LOC / Hour 

TTC (Satellite Control) 

100k 

115k 

0.86 

DIS (Communication) 

76 

79 

0.96 

USS (Ground Equip.) 

71 

58 

1.22 

EXC (Scheduling) 

26 

23 

1.13 ”1 

WKS (Workstation Inter- 
face) 

152 

56 

2.70 

COM (Infrastructure) 

23 

37 

0.62 

MDS (Development Env.) 

100 

36 

2.77 

SIM (Simulators) 

40 

40 

1.00 

Totals 

588 

444 

1.32 


Note: 

1 - Requirements Analysis through Software Test 


Descriptions of the CSCIs are as follows: 

• TTC: 

Tracking, Telemetry and Command 
CSCI, responsible for controlling the 
Tracking and Data Relay Satellites 
(TDRS) used by NASA to relay user 
satellite and space shuttle telemetry 
and command data. Responsible for 
commanding the satellite, monitoring 
its health, and controlling the ground 
antenna in order to point at the satel- 
lite. 

• DIS: 

Data Interface Subsystem, responsi- 
ble for interfacing with the NASA com- 
munication network, accepting sched- 
uling orders from NASA, and 
switching the inputs and outputs from 
the ground station to data links be- 
tween STGT and the other NASA lo- 
cations. 

• USS: 

User Services Subsystem, responsi- 
ble for controlling most of the ground 


communications equipment (GCE) 
and supporting communications to 
the TDRS and to various user satel- 
lites. 

Executive, responsible for scheduling 
of a single Space to Ground Link Ter- 
minal (SGLT) controlling a single 
TDRS satellite. There will be six 
SGLTs overall in the two ground sta- 
tion installations. 

• WKS: 

Workstation, responsible for operator 
interface, including intelligent graphi- 
cally-oriented displays, operation 
alert messages and operator com- 
manding capabilities. 

• COM: 

Common Run-time Environment, 
provides common capabilities across 
all computers including communica- 
tions within and between computers, 
data logging, startup/shutdown/ 
failover control, and device driver in- 
terfaces. 


3 


SEL-92-004 page 368 








• MDS: 

Maintenance and Development Sub- 
system, provides COTS tools for de- 
velopment and maintenance environ- 
ment, database displays/editors, and 
configuration management software. 

• SIM: 

Simulations, provides simulations of 
the NASA scheduling interface, 
ground hardware, and the TDRS. 
Simulators are used in testing, train- 
ing and problem investigation. 


Software Architectural issues 

Architectural Reuse 

STGT attempted a high level of reuse and 
incorporated reuse into its architecture, 
and in many ways succeeded. Attempts 
were made in object-oriented design, 
some of which succeeded in providing reli- 
able, understandable, reusable products, 
and some of which only caused major 
headaches. Those that were problematic 
were usually related to lack of understand- 
ing of the scope and breadth of the situa- 
tions in which the code would be reused, 
the computers on which the code would 
run, and the environments on these com- 
puters. For example, code reused on a 
workstation found itself in a rather different 
environment than on the large VAXes, due 
to lack of availability of large local data- 
bases. 

Reuse was attempted on both large and 
small scales. Small-scale reuse was of 
course more easily planned than large- 


scale reuse. Large-scale reuse was more 
likely to result in complicated error condi- 
tions, where different subsystems (and 
their engineers and programmers) wanted 
to operate in different ways but were con- 
strained by identical implementations due 
to code reuse. 

Ada Reuse 

In the early days we had “reuse evange- 
lists” who proposed massive, complex, 
self-initializing generics for everyone. Al- 
most every case that was ever implem- 
ented was later disabled, deleted, gutted 
or otherwise rewritten. Generics proved 
very difficult to debug using a source-level 
interactive debugger, relatively slow to ex- 
ecute in real-time, and very hard to write. 
Elaboration time-initialization code was 
also difficult to debug and prone to excep- 
tion handling difficulties. Simple generics, 
on the other hand, were often very effective 
and easy to reuse. Complicated generics 
(including generics within generics within 
generics) were seldom worth the cost un- 
less the designer and sole user were one- 
and-the-same, and the designer was well 
above-average in terms of proficiency and 
experienced at writing generics. That’s not 
to say that we didn’t have proficient pro- 
grammers. With 100 or more program- 
mers, just don’t expect everyone to be a 
generics expert and design generics well. 

Our best use of complex Ada generics in- 
volved data logging and retrieval software. 
This software utilized a high number of ge- 
nerics starting with primitive types (strings, 
integers, reals) and built up by instantiation 


4 


SEL-92-004 page 369 



into complex, compound record struc- 
tures in various sizes and formats. This 
worked very well, provided a single desig- 
ner/programmer was responsible for both 
the generic capability and it’s uses. 

Other good choices for Ada generics were 
design elements which clearly had a high 
degree of parallelism , such as our commu- 
nications package which treated all mes- 
sages the same, regardless of individual 
message formats. These even utilized de- 
clare blocks, which instantiated the generic 
on-the-fly for differing sizes or other re- 
cord discriminants based on run-time val- 
ues. These met with good success and 
surprisingly good performance on VAX 
Ada. Poor choices included the hardware 
simulators, which attempted a very high 
degree of generics ( > 50% of code was 
within a generic) which suffered from se- 
vere performance penalties and lack of 
flexibility in dealing with specific hardware 
behaviors. 

Coding to a common source template is 
actually a low-tech form of reuse that 
should not be overlooked. It worked very 
easily (as long as the template was correct) 
and served to promulgate good examples 
for coding and error-handling. Templates 
were used for declaring, sending and re- 
ceiving message objects. They worked 
well, until limitations in the templates were 
found. A more extensive effort in develop- 
ing the template would have payed off 
handsomely in our experience. 

Avoid “Monolithic” Ada packages. Trying 
to be all things to all people will most likely 


be nothing to anybody. Thinking that ob- 
ject-oriented design translates into “throw 
everything into one package” is similarly 
misguided. Use a layered approach in- 
stead. Define a package with just type defi- 
nitions. Then define a package that pro- 
vides basic operations on these types. 
Define higher-level packages as neces- 
sary to define more complex operations, 
building on lower-level packages. A care- 
ful architecture like this can help you reap 
big reuse benefits as new uses are found. 

Following this approach allows different 
programs to access the object at different 
layers of abstraction. Some just need a 
type definition. Others need basic routines 
to manipulate the types. Some need ad- 
vanced routines composed out of basic 
routines. Others could benefit from auto- 
matic initialization of objects at elaboration 
time (tends to be very trouble-prone, 
should be carefully controlled by a stan- 
dards committee). All uses of a complex 
object, especially potential future ones, 
may suffer if the only view presented is a 
single complete monolithic view. A pro- 
gram wishing access to a type definition 
ends up with pages of “hidden”, unused 
code and data, and maybe even automatic 
creation/initialization of objects at startup 
time, referencing databases defined on 
one computer and not others. 

Variable-length strings were another good 
reusable package. We implemented them 
with a generic package, pre-instantiated 
sized to 256 characters. Use of a pre-ins- 
tantiated package allowed easier sharing 
of types. However, this also encouraged 


S EL-92-004 page 370 



waste (programmers were encouraged to 
use 256-byte strings where only 16 char- 
acters were necessary). 

Ada Architecture issues 

Error handling was our number-one archi- 
tecture problem. We definitely could have 
benefitted from better up-front design and 
more prototyping. Ada tasks complicated 
the error handling picture drastically. 

There is a lot of functional overlap between 
the capabilities provided by Ada excep- 
tions and those provided by VAX/VMS 
Condition handlers. There were points of 
interference or undesirable interplay be- 
tween the two as well. You need to design 
error handling into all system service calls. 
Know which exceptions are worth handl- 
ing, and which you WANT to be unhandled 
(because they show up obvious coding or 
environment problems). 

Taking advantage of the operating sys- 
tem’s capabilities for calling stack trace- 
backs on unhandled exceptions, for ex- 
ample, can provide lots of power for 
debugging. These are especially useful if 
integrated into the debugging environ- 
ment, as is the case with most DEC/VAX 
software. 

Concurrency 

Ada Tasks 

Much fear was generated during early de- 
sign phases concerning the trade-offs be- 
tween concurrent operating system pro- 
cesses, and concurrent Ada tasks. During 


implementation, use was made of both 
single and multiprocessor machines, with 
varying results. Software testing and mod- 
ification history have allowed us to con- 
struct better guidelines for process versus 
task trade-offs. In many cases, processes 
were used as an aid to work breakdown 
rather than based on strong architectural 
need. In some cases these choices 
caused problems later, and limited the 
range of available solutions for require- 
ment or design changes. Ada tasking 
would have been more flexible. 

However, increased use of Ada tasking 
would have required a different develop- 
ment support structure. This support 
structure would have had to allow separate 
development and testing of task-based 
functional work packages independently. 
The tasks could then be integrated into a 
single process resulting in a more reliable 
system. 

In general, tasks were well-used and 
caused relatively few problems. Among 
the problems were prioritization, blocking, 
proliferation of tasks required to synchro- 
nize between other tasks, and increased 
rigor in defining/testing the tasking archi- 
tecture. Tokens (Ada “private” objects 
containing pointers and flags used in the 
interface packages between application 
and service layers) were used to define 
message addresses. These later became 
a problem since they were not designed to 
be shared, yet were shared in some appli- 
cation programs among various tasks. 
The sheer number of tokens used in the 
system prevented us from embedding a 


6 


SEL-92-004 page 371 



task within all token types for synchroniza- 
tion (because of the amount of memory 
used for task stacks, etc.)* but we later em- 
bedded “token in-use” flags to help detect 
instances of sharing. Earlier recognition of 
the problem would have allowed a range of 
more elegant solutions. 

The following are some additional observa- 
tions regarding Ada tasks: 

• Task context switches are a LOT fast- 
er than process context switches. If 
you’re thinking of adding more pro- 
cesses, tasks are better. However, 
processes are easier to split up the 
work among multiple independent 
programmers. Tasks in the same 
process require more programmer 
coordination during development. 

• Tasks are like lawyers. If you have no 
tasks, you probably won’t need any. 
However, once you have two tasks, 
you will probably need another five or 
ten more to handle coordination be- 
tween those two tasks plus synchro- 
nize any shared inputs, outputs, re- 
sources, etc. This means that if you 
start out thinking that you’ll write a 
program with a few tasks, you’ll prob- 
ably end up writing lots. However, 
this didn’t appear to have been a 
problem. The number of tasks did 
not affect performance as long as 
they were event-driven. You may 
have to spend more time maintaining 
relative priorities of tasks as the num- 
ber increases. 

• We avoided PRAGMA TIME_SLICE, 
since we understood it to add signifi- 
cant overhead. We were successful 


in avoiding it. Several times we were 
tempted to use it to alleviate other 
tasking problems, but it was never 
absolutely necessary and in the end 
was successfully avoided. 

• Multiprocessor problems were en- 
countered, which required us to use 
PRAGMA SHARED and PRAGMA 
VOLATILE, which are implementation 
dependent. These relied on archi- 
tecture-dependent features of VMS 
processors. The features worked well 
in our two-CPU environment. 

• We would have liked to prioritize dif- 
ferent entry points in the same task 
(e.g. to handle the same type of ren- 
dezvous, but from different sources), 
but Ada doesn’t allow it. We found a 
kludgy way of doing it. Instead of at- 
tempting reuse, we should have dupli- 
cated the task code ( i.e. via task 
types) and prioritized them differently. 
Maybe we did this because we were 
attempting excessive reuse, or we 
were afraid of proliferating tasks. 
Simpler would have been better. 

• We worried a lot about "fairness” of 
tasking, however all fears appeared to 
be groundless. If you’re worried 
about fairness of tasking, what you 
really may be worried about is that 
you need more CPU power. Or you 
may have tasks polling when instead 
you need to turn them around into an 
interrupt-driven approach. 

• Beware of non-reentrant servers, ser- 
vices, etc. Accesses to Rdb, the rela- 
tional database we used, had to be 
serialized by routing all task’s re- 
quests through a single Rdb server 
task (gateway) which in turn provided 


7 


SEL-92-004 page 372 



the sole control of the Rdb server. 

This is a fairly common problem inter- 
facing with non-Ada facilities for 
which you should watch. Our COTS 
Graphical User Interface (GUI) non- 
reentrancy problem was solved with 
the opposite approach. We ran four 
copies of it, one for each operator 
window. 

• There was still some question for us 
about what Delay 0.0 really did, or if it 
was necessary. It was documented 
as a way to break the execution of a 
long-running task and allow a context 
switch to another waiting task. When 
we attempted to verify this behavior 
through benchmarks however, we 
met with mixed results. We eventually 
opted not to use the feature. Instead 
we broke problematic long-running 
tasks into multiple shorter tasks. 

We also had reports of problems with 
the fairness of allocation of CPU time 
among tasks. When we investigated 
with benchmarks, however, all we 
found were problems with the bench- 
marks. For each case of purported 
probems with Delay 0.0 and tasking 
fairness, programmers who thought 
they had a problem with an Ada fea- 
ture were instead using too much 
CPU time. The ultimate fix was to 
rearchitect the program to respond to 
events or Asynchronous System 
Traps (ASTs) rather than poll. 

Compile-time vs. Run-Time Binding 

• You can use unchecked_conversion 
to convert between system. address 
and object_access types. You’d bet- 


ter be very careful when using this, 
though. A LOT of errors were com- 
mitted in this area. Need careful code 
review and on-the-job indoctrination, 
perhaps through programmer peer 
group inspections/walkthroughs, etc. 
Watch out for things like unintentional- 
ly overlayed objects and other C code 
type pointer errors. 

• Anytime you use access types or sys- 
tem addresses in variables it opens 
the door for memory leaks around al- 
location/deallocation . 

• The Ada compile-time binding of re- 
cord types was an early problem 
when data logging record types were 
very volatile. Many low-worth recom- 
pilations were performed. Configura- 
tion management and test computer 
system performance were impacted 
by the need to accept the many new 
executables images that were gener- 
ated. A run-time-binding architecture 
might have been better in these highly 
volatile report-writing cases. Once 
the formats stabilized, the structure 
did provide for ease of checking. 
Compilation tests for code impact to 
changing interface or record format 
become both routine and precise. 

Message Passing Architectures 

Ada Interface Definitions 

Internal interface definitions, between 
computers and software subsystems, 
were captured in Ada. In most cases, re- 
presentation clauses were not used. In- 
stead the message record definition code 
was reused in each subsystem. Software 
configuration management mechanisms 


8 


SEL-92-004 page 373 



ensured that interfaces were modified con- 
sistently. This was reliable since all com- 
puters used the same hardware architec- 
ture and the same compiler. 

Platform Dependencies 

Operating System Dependencies 

Many unknown, unforseen platform de- 
pendencies cropped up during the devel- 
opment and test phases. In many cases, 
these problems were the most astounding 
and difficult to predict of any we encoun- 
tered. There is a high degree of functional 
overlap between the Ada compiler/lan- 
guage run time environment (VAX/VMS 
Ada 2.2-41 at this writing) and the host/tar- 
get operating system (VMS 5.5-1). This 
overlap caused problems in error handl- 
ing; Ada exception handling interfered with 
the generation of otherwise automatic op- 
erating system calling-tree tracebacks. It 
also appeared in process management 
(computer operators couldn’t reliably can- 
cel processes with some types of tasking 
structures), and debugging (generics and 
tasks increased difficulty of source-level 
debugging and thus were unpopular with 
programmers) . While many of these are 
platform-dependent, they point to the 
overall problem of overlap between Ada’s 
functionality and the functionality of the op- 
erating system upon which it’s running. If 
you’re running on a bare-bones proces- 
sor, or a primitive operating system, then 
there may be little or no problem. Using a 
sophistcated and feature-rich operating 
system like VAX/VMS, on the other hand, 


can lead to limitations and unforeseen 
problems when you use Ada’s advanced 
features and the operating system’s ad- 
vanced features in the same program. 

We ended up having our DEC consultants 
write a sophisticated assembler routine 
embedded in each executable which de- 
tects unhandled exceptions in any task, 
forces a traceback, and terminates the 
image. This has provided us with vastly im- 
proved turn-around time for fixing fatal er- 
rors found during testing. 

Some particulars we found: 

• The VAX Ada Run Time Library dis- 
ables certain features of VMS (like the 
capability of a computer operator to 
stop a process gracefully, unless 
you’ve coded-in your own user-de- 
fined exception handler and a means 
to signal termination). Also, VAX 
Ada’s memory deallocation/stack un- 
wind during exception propogation 
interfere with VMS’s capability to do a 
call tree traceback, which would 
otherwise have shown a stack dump 
from the line raising the problem all 
the way back up to the top of the pro- 
gram. This was especially trouble- 
some when some tasks failed due to 
unhandled exceptions, (coding er- 
rors), but other tasks and the process 
as a whole, continued to function, 
making it difficult to detect and isolate 
the problem. 

• Writing debug or error messages us- 
ing Put_Line caused a performance 
problem in real-time processes, when 
all tasks in the process hang behind 
an operating system output request 


9 


S EL-92-004 page 374 



queued to the disk device. We 
couldn’t tolerate this in many of our 
hard-real-time executables, so we 
converted these into shared memory 
messages between the real-time pro- 
cesses and a lower priority server 
process, who performed output on 
behalf of the real-time processes. 

We used tuned Record Management 
Services (RMS) Input/Output instead 
of vanilla Ada TEXTJO or SEQUEN- 
TIALJO. This was because of the 
need for heavy-duty tuning, including 
buffering control and management. 
We implemented a Mixed l/O-like ca- 
pability using discriminated records, 
where each record in the file con- 
tained its own embedded record for- 
mat identifier. This worked quite well, 
except when the formats were under 
early development and changed of- 
ten. Then backward compatibility of 
current software and previously ar- 
chived data files became tedious. 

SHARED images (a sophisticated 
VMS Feature) wouid have been good 
to use in certain areas where reusable 
code made up almost a Megabyte of 
each executable image, but the inte- 
gration with Ada was not smooth. By 
the time we developed a good work- 
ing approach we had to abandon it 
because of the retrofit cost. This 
might have helped Ada’s perform- 
ance some, in decreasing the 
memory required, if it could have 
been done earlier with benefits amor- 
tized over more of the development 
phase, it would have saved money 
and time. We had initial misgivings 
about the ability to debug an installed 


shared image, which later appeared 
to have been unfounded. 

• VMS has a very nice software pseu- 
do-interrupt capability (Asynchronous 
System Traps or ASTs). The Ada 
run-time library uses these to do it’s 
own synchronization, and instead 
converts each application AST into a 
task rendezvous. As a result, running 
Ada as a part of a “real” AST such as 
in a call from a device driver written in 
another language was a difficult prop- 
osition (couldn’t use tasking, perform 
any I/O, etc.). However, the run time 
libary’s conversion of ASTs to tasks 
(PRAGMA AST ENTRY) was quite ac- 
cessible to programmers. Tasks 
seemed to be quite easy (and even 
natural) to use for this purpose. This 
enabled anyone to make use of ASTs, 
whereas without this we probably 
would have had to restrict their use to 
an elite group of the most experi- 
enced programmers. 

• Make use of platform capabilities. 
Don’t be an Ada zealot, thinking you 
have to write pure Ada code and du- 
plicating functionality otherwise avail- 
able more cheaply or efficiently in the 
operating system (100% code porta- 
bility wasn’t an issue for us - and it 
may not be for you either). Examples 
are character and numeric utilities. 
Just write good (portable) package 
specs, and implement the bodies of 
these in the most efficient manner, 
even utilizing operating system ser- 
vice calls or non-Ada utility packages. 
This is especially appropriate on com- 
plex instruction set computers (CISC) 
like the VAX. You can always rewrite 


10 


SEL-92-004 page 375 



the bodies for each new platform to 
which you port. That way you’ve ad- 
dressed performance, reusibility and 
reduced risk while making good prog- 
ress and leveraging the capabilities 
and strong points of your underlying 
platform. 

COTS Dependencies and Integration 

During the proposal phase of STGT we 
identified several areas where Commer- 
cial Off-The-Shelf (COTS) software could 
be used. We then deleted costs based 
on the difference between developing the 
application from scratch and the cost of 
the COTS product. However, the follow- 
ing concerns arose: 

• We did not allocate necessary addi- 
tional costs to continually evaluate 
and incorporate periodic updates/up- 
grades of these COTS products. This 
turned out to be a big ticket item over 
the life of STGT. 

• Purchase good quality COTS bind- 
ings. This is a LOT of work. Availabil- 
ity/maturity of Ada bindings should be 
a significant discriminator during 
COTS evaluations (e.g., XWindows/ 
Motif binding problems, Distributed 
File Service (DFS) bindings, device 
driver bindings, etc.). As usual, pro- 
ductivity may be gained for many at 
the expense of hard work by a few, or 
by the purchase of a proper bindings. 
Consider the trade-offs. 


Performance 

Ada Performance Characteristics 

Many performance problems were en- 
countered which required various mitiga- 
tion approaches. Performance modelling 
was only as good as the input received 
(much guess work was necessary early on 
in the life-cycle). This lead to big surprises 
and varying types of late changes. Eventu- 
ally larger CPUs and more memory were 
purchased. 

There appears to be a SERIOUS dichoto- 
my in Ada between coding for perform- 
ance and coding for what most consider to 
be a “good” Ada style. “Good” Ada was 
subject to our interpretation of the current 
literature and to the lessons developed 
during prototypes by the Ada Core Team. 
What might be considered “good” Ada of 
course will change over time. Examples 
are: 

• The generic string package was pre- 
instantiated for (discriminated record 
structures) of 256 bytes. This affords 
maximum reusability and similarity, 
but appears to waste memory and 
disk space due in certain cases to 
needlessly large structures. 

• Proponents of “good” Ada often 
stress deeply nested procedure calls 
for modularity and reuse. “Fast” Ada 
is often relatively flat, with a shallow 
call depth. 

• “Good” Ada makes maximum use of 
local variables. “Fast” Ada allocates 


11 


SEL^92-004 page 376 



variables once in package bodies, 
then carefully reuses them within 
package procedure and function bo- 
dies. 

• “Good” Ada makes maximum use of 
Generics. “Fast” Ada avoids complex 
generics. 

• Good Ada makes minimum use of im- 
plementation-dependent PRAGMAS. 
Fast Ada utilizes some PRAGMAS, 
e.g., PRAGMA ELABORATE to force 
elaboration of packages before the 
routines are called for real-time ex- 
ecution. 

• As a result of the apparent quandry 
between “good” and “fast” Ada, it 
seems that Ada right out of the ob- 
ject-oriented training book can be 
quite slow. You either need to allocate 
a bigger CPU, know very accurately 
the performance characteristics in ad- 
vance, or plan on a tuning phase to 
increase the performance of your 
code once it’s written. 

Schedule pressures made us opt for the 
quickest solutions in most cases, that is, 
larger CPU’s. We had some success in op- 
timizing Ada for performance. In some 
cases the re-coding or reimplemetation of 
a component saved 50-100% of CPU or 
Memory resources. In one case it saved a 
factor of 5X CPU for a compute-intensive 
satellite orbit prediction function. 

Configuration Management 

Ada Configuration Management 

• Ada dependencies are GRAPHS, 
most library structures/directory hier- 


archies are TREES. Therefore, if you 
lock yourself into a library structure 
that mimics the Ada dependency 
structure, you’ll be disappointed 
eventually. We used a simple tree of 
SHARED code at the top, with CSCIs 
or subsystems below. 

• Sublibraries were used versus the 
VAX Ada Compilation System (ACS) 
ENTERED units. This allowed auto- 
matic recompilation for dependent 
units when root units changed. The 
downside was that massive recompi- 
lations were forced when not all de- 
pendent libraries (and groups using 
those libraries) were ready to see the 
change. An alternative approach 
might have been to develop a tool for 
automatically re-entering changed 
units into dependent libraries. That 
also could have allowed for library de- 
pendencies more complicated than a 
tree. 

• We used separate/duplicate libraries 
to reflect differing levels of software 
test maturity. For instance, we had 
one shared set of libraries in which 
developed code. We only updated 
the reused components of that library 
once a week. People affected by in- 
terface changes only had to support 
(or suffer) changes once a week. 

• We could have used hierarchical li- 
braries for test, but the computational 
requirements were too great. Our de- 
velopment CPU resources were never 
great enough to compile the same 
source code multiple times for differ- 
ent hierarchical libraries supporting 
different test maturities. Consequent- 


12 


SEL-92-004 page 377 



ly all tests were forced to the same 
maturity - fresh from the programmer. 

• We had to write a program to extract 
a cross-reference containing "where- 
used” information. ACS did not pro- 
vide this information. 

Ada Compilation Performance 

We did a LOT of work to improve compila- 
tion speed. Some of the things we did 

were: 

• Faster CPUs - went from VAX 8250s 
(1 .5 MIPS) to VAX 6610s (25 MIPS). 

• More memory - from 64 to 256 Mb 

• Tuning of system quotas, batch 
queues etc. 

• RAM DISK and/or semiconductor disk 
for shared code Ada library (most crit- 
ical compilation library) 

• Spread I/O over multiple disks to re- 
duce bottlenecks 

• We didn’t persue but maybe should 
have experimented further with the ef- 
fects of smaller and larger directory /li- 
brary sizes on compilation speed. 

Ada Compiler 

• We found relatively few bugs. Most 
were in code generation, a few for 
floating point types and others which 
optimized away variables or code. 

One involved different Ada library unit 
interfaces depending on whether 
code was compiled in debug or non- 
debug. All were resolved in quite 
good order by excellent DEC support. 
The lesson was that compiler maturity 


(for VAX/VMS Ada) was not a risk fac- 
tor. We also learned that run-time (vs. 
compile-time) bindings for certain 
rapidly and persistantly changing 
functions would have been a much 
better design from an operational and 
CM point of view. 

• On the other hand, the maturity of 
ACS was less evident. We have had 
numerous problems and “features”. 

A good Ada Program Support Envi- 
ronment would be greatly appre- 
ciated. We wrote 30,000 lines of 
"tool” and configuration management 
scripts. This is significantly more than 
we anticipated supporting. A good 
COTS tool available in a timely man- 
ner would have been a big productiv- 
ity enhancement. 

• The design of our parent libraries and 
sublibraries were important. We 
found ourselves re-creating libraries 
because library parent/child relation- 
ships were hard-coded rather than 
logical. We redid all libraries with 
PSEUDO-DEVICE logicals so that 
successive changes were less painful. 

Project Management 

Equally as important as the Ada lessons 
learned were the lessons we learned in 
managing and controlling a large Ada soft- 
ware development effort. Some of these 
lessons are: 

Standards 

• Our Software Standards and Practic- 
es Manual (SSPM) was HUGE. Far 
too big to be understood or enforced. 


13 


SEL-92-004 page 378 



• Should have made better use of auto- 
mated standards checkers or pretty- 
printer tools. 

• Should have tailored the Language 
Sensitive Editor (LSE) more aggres- 
sively for our local standards and in- 
cluded more templates 

• Standards should be issued, proven, 
taught, understood, reviewed, repro- 
ven, and well documented before any 
code is written. 

Architecture and Schedule 

• Allocate the Right CSCIs. We 
changed the allocation of CSCI’s ear- 
ly in the development effort. Changes 
(reallocations) are difficult to make. 

• Avoid Early Split into CSCI Production 
Groups. We set up a Work Break- 
down Structure (WBS) and Manage- 
ment structure on day one. Therefore 
shifting of work from CSC! to CSCI 
became a continuous struggle. Work 
overall system architecture first before 
parochialism sets in. Set up a mech- 
anism to provide for the overall proj- 
ect good at expense of an individual 
group. 

• Avoid the pressure to accelerate 
schedules. Believe the “Rule of Tens” 
(errors found in a later phase take 1 0 
times longer to fix). Missed goals can 
not be made up. Insist on operation’s 
concepts and equipment (mission 
equipment) designs prior to software 
designs. 

• View interfaces as a “contract” not as 
a goal. Interfaces that change are 
painful. 


• Understand tools required and decide 
on their use well in advance of needs. 
We developed Configuration Manage- 
ment DCL on-the-fly, did not under- 
stand the complexities of Ada CM, 
and shared interface packages (which 
are a good idea, but caused massive 
recompiles). Understand and plan the 
role of tools throughout the whole life- 
cycle. 

• Define and stick to a fixed methodolo- 
gy. We were guilty of making it up as 
we go. Much of the heritage we had 
from our Ada Core Team did not scale 
up into larger development efforts. 
Tools did not easily transition between 
phases. 

• Do more prototyping - especially for 
performance. Make performance esti- 
mates based on Executed Lines Of 
Code (ELOCs) from actual prototypes 
rather than from Lines Of Code 
(LOCs) written or predicted to be writ- 
ten. Consider living (nonjhrowaway) 
prototypes for broadly used “infra- 
structure” code. 

• Use the right language for the right 
function. We made some changes to 
use macro assembler in some critical 
high frequency applications. Device 
driver type functions were very slow in 
Ada as was the high use interprocess 
communication processes. 

• Put Some Teeth into allocating and 
enforcing performance requirements. 
We allocated only very high level re- 
quirements to the CSCIs for CPU and 
Memory performance. These were 
not allocated to lower level compo- 
nents and were therefore untestable 
and unenforceable. 


14 


SEL-92-004 page 379 



• Do Code Walkthrus - set aside a 
team to execute. We relied on peer 
reviews of code. This became a sig- 
nificant schedule pressure on the 
CSCI who concentrated more on their 
own efforts then in a thorough review 
of another CSCIs code. 

• Understand and don’t underestimate 
the entire domain. Understand the 
performance aspects of the COTS 
products and prototype their use. Er- 
rors in COTS are harder to fix be- 
cause of 3rd party involvement. Work 
with COTS can begin earlier since de- 
sign effort is usually not required. The 
effects of the operating system and 
hardware platform are significant, pro- 
topying and an early start is recom- 
mended. 

• Know what you are buying and where 
to use it. For Example, Booch com- 
ponents were excellent at improving 


productivity. However know their per- 
formance characteristics before de- 
ciding where to use them and other 
similar COTS software. 

• Hire Experts - utilize vendor consul- 
tants. On site expertise is the best 
way to fix problems and to get prefer- 
ential access to vendor guru’s and 
other experts. Often you fix problems 
before they happen, since consultants 
can help you with that most difficult 
assessment, determining what it is 
that you don’t know. 

These Lessons Learned represent only a 
small subset of the potential data that can 
be gleaned from GE’s experience on 
STGT. The main lesson to take away from 
this paper is that the language, platform, 
COTS products, tools, etc. are just a 
means to an end and in themselves are re- 
sponsible for neither success nor failure. 


15 


SEL-92-004 page 380 



■Ml 

STGT Ada Lessons Learned 

STGT 



Second TDRSS 
Ground Terminal 

Dec 2-3. 1992 


NASA Goddard Software Engineering Laboratory 


Software Engineering Workshop 


STGT Project 
Ada Lessons Learned 


Tod Kahrfl 
BUI Manley 
Scott Brown 
Brian Bauman 
Paul Usavag e 
Don Nafurney 


Chart 1 


■Ml 

STGT Ada Lessons Learned 

STGT 

HI] 

Agenda 

Second TDRSS 
Ground Terminal 

Dec 2-3. 1992 


• Project Overview 

• Software Configuration 

• Software Metrics 

• Ada Project Management Lessons Learned 

- Project Schedule/Structure 

- General Issues 

- Performance/Sizing 

- Reusability 

• Ada Lessons Learned 

- Generics 

- Tasking 

- COTS/PIatform Dependencies 

- Package Structuring/Record Formats 

- Exceptions 


SEL-92-004 page 3^2 




STGT Ada Lessons Learned 

Project Overview 


STGT 

Second TDRSS 
Ground Terminal 


Dec 2-3. 1992 




STGT Ada Lessons Learned 

STGT 


Software Configuration 

Second TDRSS 
Ground Terminal 

Dec 2-3. 1992 


|WKS CSCI | 

/ 7 — ^ 


DISADPE 
D1S CSCI 
COM CSCI 


SGLT1 EXEC ADPE 
EXC CSCI 
COM CSCI 


K-bandTTC 

USSSA1 

USSSA2 

USSMA 

TTCCSCI 
COM CSCI 


USS CSCI 
COM CSCI 


USS CSCI 
COM CSCI 


USS CSCI 
COM CSCI 


COM CSCI Common Sorvicoe 

DIS CSCI NCC Interface 

EXC CSCI SGLT SchoduOng 

USS CSCI Equipment CMD/MON 

7TC CSCI TDRS/Antenna Control 

WKS CSCI Operator Interfaoe 

SIM CSCI SMTF Simulation 

MDS CSCI SMTFTooU 


SEL-92-004 page 382 


Cnaft4 








HI 

STGT Ada Lessons Learned 

STGT 

yu 

Software Metrics 

Second TDRSS 
Ground Terminal 

Dec 2-3. 1992 


CSCI 

Size.(LCLG) 

TTC 

100000* 

D1S 

76000* 

USS 

71000* 

EXC 

26000 

WKS 

152000 

COM 

23000 

MDS 

100000 

SIM 

40000 

Total 

588000 


Hours ’ LOC/Hour 


115000: 

.86 

79000 

.96 

58000 

1.22 

23000 

1.13 

56000 

2.7 

37000 

.62 

36000 

2.77 

400001 

1.0 

444000 

1.32 


1 - RaquirMMfit Analysis thru Software l)Mt 

2 - meludM Coat of Common Ground ControUMonttor and Fat* Dateetton 

3 - IndudM Common Ground Controt/Monltor and Fat* Detection 


Chart 5 


■HI 

STGT Ada Lessons Learned 

STGT 


Ada Project Management 

Second TDRSS 

■Ml 

Lessons Learned 

Ground Terminal 

Dec 2-3. 1992 


• Ada Project Management Lessons Learned 

- Project Schedule/Structure 

- General Issues 

- Performance/Sizing 

- Reusability 


SEl^92-004 page 3^6 




STGT Ada Lessons Learned 

STGT 

mUjrm 

Ada Project Management 

Egjjl 

Lessons Learned 
Project Schedulel Structure 

Second TDRSS 
Ground Terminal 

Dec 2-3. 1992 


• Allocate the Right CSCIs 

Changes (Reallocation) are Difficult to Make 

• Avoid Early Spilt into CSCI Production Groups 

Work Overall System Architecture First 

Set up a Mechanism to Provide for the Overall 
Good at Expense of an Individual Group 

• Avoid the Pressure to Accelerate Schedule 

Believe the “Rule of Tens” 

Missed Goals Can Not Be Made Up 

Insist on Operation’s Concepts and Equipment 
Designs Prior to Software Designs 

• View Interfaces as a “Contract” not as a Goal 

Interfaces That Change Are Painful 


Chart 7 



STGT Ada Lessons Learned 

STGT 


Ada Project Management 

lln oQ) m 

Lessons Learned 

Second TDRSS 

mu 

General Issues 

Ground Terminal 

Dec 2-3. 1992 


• Understand Tools Required and Decide on their Use 
Well in Advance of Needs 

CM Developed DCL on-the-fly : did not under- 
stand the Complexities of Ada : Shared Interface 
Packages (A Good Idea) Caused Massive Recom- 
piles 

Understand and Plan the Role of Tools Through- 
out the Whole Lifecycle 

• Understand and Don’t Underestimate the Entire Do- 
main 

COTS 

DEC/VMS 

• Prototype and Utilize Prototype Code Everywhere 

• Hire the Right People Then Train/Train/Train 


SEL-92-004 page 384 


Charts 



STGT Ada Lessons Learned 

STGT 


Ada Project Management 

■ jsj ■ 

Lessons Learned 

Second TDRSS 


General Issues 

Ground Terminal 



Dec 2-3. 1992 


• Define and Stick to A Fixed Methodology 

Define in Advance and Don’t Experiment 
Educate User’s 

• Keep the SSPM Simple - Useful and Easy to Enforce 

• Do Code Walkthrus - Set Aside a Team to Execute 


ctiaite 



STGT Ada Lessons Learned 

Ada Project Management 
Lessons Learned 
Performance! Sizing 


STGT 

Second TDRSS 
Ground Terminal 

Dec 2-3, 1992 


• More Prototyping - Estimates Based on Executed 

• Complex Generics Proved to be Extremely Slow 

• Understand Compile and Link Process (e.g. Compiler 
Eliminates Dead Code But Linker Does Not) 

• Use the Right Language for the Right Function 

• Bad Ada Is Real Baaaaad 

• Put Some Teeth Into allocating and enforcing Perform- 
ance Requirements 


SEL-92-004 page 3^5^ 




STGT Ada Lessons Learned 



Ada Project Management 

STuT 


Lessons Learned 

Second TDRSS 
Ground Terminal 


Reusability 

Dec 2-3. 1992 


• Know What You are Buying and Where to Use it 

Booch Components - Not Optimized for Perform- 
ance 

• Don’t Attempt High Level Generics Yet 

Ground Equipment Simulation Is the Wrong 
Choice 

• Provide for Project Wide Reuse Czar 

Avoid Parochialism 

Proactive Search for Opportunities 


Chan 11 


■Ml 

STGT Ada Lessons Learned 

STGT 

■1* /7(0 Mp 

Ada Lessons Learned 

Second TDRSS 



Ground Terminal 



Dec 2-3. 1992 


• Ada Lessons Learned 

- Generics 

- Tasking 

- COTS/Platform Dependencies 
Package Structuring/Record Formats 


SEL-92-004 page 386 


Chart 12 




■PI 

STGT Ada Lessons Learned 

STGT 

Second TDRSS 

jjK fiTct ill 

Ada Lessons Learned 

H)j H 

Generics 

Ground Terminal 

Dec 2-3. 1992 


• Can be a Performance Problem 

• Are to Debug with Interactive Source Level Debugger 

• Keep Small : Don't Attempt a Reusable Ground Station 

• Restrict Usage to Types as Formal Parameters 

• Keep Them out of the Hands of Amateurs 

Limit to Your Most Experienced People 

Review/Review/and Then Again - Prototype Per- 
formance 


Crtart 13 


■H ■ 

STGT Ada Lessons Learned 

STGT 

Second TDRSS 

1 loton 

Ada Lessons Learned 

■Ml 

Tasking 

Ground Terminal 

Dec 2-3. 1992 


• Mistrusted at First - Found Many Appropriate Uses 

Understand the Target Environment/Prototype 

• Provide for Terminate Alternatives - Make Sure a Par- 
ent can Terminate Children 

• Exceptions Must Be Propagated Upward (Free Run- 
ning Tasks Need Some Control) 

• Don’t Substitute Tasks Where Procedures Would Suf- 
fice 

• When Using Tasks - Centralize Control (one writer) 

• If You Plan on a Few Expect Many More 


SEL-92-004 page 387 




STGT Ada Lessons Learned 

STGT 

Second TDRSS 

By 

Ada Lessons Learned 

HSlfl 

COTSIPlatform Dependencies 

Ground Terminal 

Dec 2-3. 1992 


• Understand Compiler/Linker and Their Interaction 

Don’t Count on Default Order of Elaboration 

• Understand The Whole Domain 

VMS Services Better Than Ada Features 

• Pick COTS With Ada Bindings (Avoid Multiple Transla- 
tions) 

• SQLMODS Proved to Be Workable Interface 

Imbedded SQL was Impossible to Debug 

• Hire Experts - Utilize Vendor Consultants 

• Product Upgrades are Large Undertakings and Come 
at the Most Inopportune Times 

Properly Plan for and Fund Product Upgrades 

• Avoid the Creation of Processes Without Justification 


Chart 15 



STGT Ada Lessons Learned 

STGT 


Ada Lessons Learned 

Second TDRSS 


PackagelRecord Formats 

Ground Terminal 

Dec 2-3. 1992 


• Limit Scope of Packages - Don’t Try to Encapsulate 
and Entire Object in One Package 

Use Multiple Packages - Each With a Purpose 

Know the Intended Use of the Packages (e.g. 
Senders vs Receivers) 

Avoid Monoliths 

• Don’t Put Database Access into Interface Packages 

• Don’t Combine Loosely Related Types 

• Create Null Instances of a Type as an Initial Value 

• Avoid String Types - Usually Masking an Enumerated 
Type 

• Renaming - Many Differences of Opinions: 

Be Careful 


SEL-92-004 page 388 


Chart 10 




STGT Ada Lessons Learned 

STGT 

■V 

Ada Lessons Learned 

Second TDRSS 

Hil 

Exceptions 

Ground Terminal 

Dec 2-3. 1992 


• Use Only For Real Errors - Very Expensive for Use As 
GOTOs 

• “When Others” obscures origin of exceptions 

• Understand and Plan for Unhandled Exceptions 

Tracebacks and Stack Dumps are Good Debug- 
ging Tools 

Process/System Dumps Have Their Place 

• Specify and Design Expected Levels of Error Handling 


Chart 17 


■m 

STGT Ada Lessons Learned 

STGT 

u 

Summary 

Second TDRSS 
Ground Terminal 

Dec 2-3. 1992 




Project Pressures Force Old Habits to Return 
Solidify Interfaces Under Penalty of Death 
Prototype Everything and Always 
Enforce Performance Allocations 
Focus Reuse and Dedicate Resources 
Restrict Generics 
Don't Be Afraid of Tasks 

Understand the Domain - and Hire Where Necessary 
Limit Scope of Packages 
Be Prepared to Upgrade COTS 


SEL-92-004page^89 18 



SEL-92-004 page 390 



Panel: Is Ada Dying? 


Marv Zelkowitz, University of Maryland, Facilitator 
Stu Feldman, Executive Director of Computer Systems Research, Bellcore 
John Foreman, Director of STARS Program, Department of Defense 
Susan Murphy, AAS Software Manager, IBM 
Tom Velez, President and CEO, CTA 


rhtCfcD UNita PAGE BLANK NOT FILMED 


SEL-92-004 page 391 



SEL-92-004 page 392 



Panel: is Ada Dying? 


m 


• Facilitator: 

- Marvin V. Zelkowitz. NIST/CSL and Department of Computer Science, 
University of Maryland 


• Panelists: 

- Stu Feldman, Executive Director, Computer Systems Research, Bellcore 

- John Foreman, Director of STARS Program, DARPA 

- Susan Murphy, AAS Software Manager, IBM FSC 

- Tom Velez, President and CEO, CTA 


SEL interest in Ada 



• Why SEL interest in Ada? 

- SEL has broadest experience with Ada within NASA 

- SEL has collected much data on the use of Ada (as well as many other 
technologies) 

- SEL has analyzed Ada usage from various perspectives (e,g., see last 
few Workshop proceedings) 

• Results of SEL studies: 

- Value of Ada not unconditionally shown 

- Need to assess current status and plan future processes 


PRECEDING PAGE BLANK NOT FILMED 


SEL-92-004 page 393 



SEL Ada Projects 



Ongoing FAST 66K} 


I COMPASS 1500K7 


Ada Studies 

POW1TS 68K 



1 parallel Study Completed 
9 Ada Production Products Completed 
All Projects Provide Full SEL Data 
Numerous Studies Completed 

SMEXTELS 61 K 



TONS 38K 

1— — — — — — — 




EUVEDSIM 184lv 
EUVETELS 67K 



jUARSTELS 68 k] 


c 

FDAS 68K | 


GOESIM 92K 


1 GOADA 170K 



naveloDment - Ada and FORTRAN j 1 


i “I 1 

-r J \ 


1/85 1/86 1/87 

V. SOFTWARE ENGWEHWC LABORATORY — — 


1/88 


1/89 


1/90 


1/91 


1/92 

SIM* 2-32 
toaooa**-«o60 


Ada (and OOD) Impacts on Cost 


Cost To Develop 
Effort per Developed Statement* 


jjgg) FORTRAN 



Cost To Deliver 
Effort per Delivered Statement 



•Ada : Developed Size = 100% New + 30% Old Statements 
FORTRAN: Developed Size = 100% New + 20% Old Statements 


* Development cost per statement has been no cheaper tor Ada 
« Resue potential of Ada Is significant 

• Reuse cost factor has changed in Ada systems 


V SOFTWARE EHQNEERMS LABORATORY 


SEL 


SIM* 2*33 I 

iooo>aM-cfl»i J 


S EL-92-004 page 394 






Language use in Code 500 at Goddard 



Existing New 


SEL-92-004 page 395 



NASA IBM mainframe Ada evaluation 


m 


• Need more development and testing support 

- Two compilers evaluated 

- Multiple source file compilation limited 

- Ada library can be corrupted 

- Inflexible Ada library manager 

- Need better debugger 

- One compiler failed to even compile some modules 

• Need improvement in error handling and error messages 

• Need improvement in performance 

• Result: Could not use IBM mainframe for large-scale NASA Goddard 
development 


Onboard embedded Ada application 



• Goal: Dual 1750 A processors with shared memory to handle onboard 
navigation 

• Environment: T1 1750A hardware. Tartan cross compiler system on VAX 

• Problems: Intermittent communication and shared memory problems. 
Hardware and software vendors could not solve problems. 

• Resolution: Had to fly uniprocessor system with reduced functionality. 


S EL-92-004 page 396 



Positive attributes of Ada 


• Language syntax and semantics are in mainstream language design - an 
outgrowth of FORTRAN, ALGOL and Pascal 

• Language features to aid in large system design, reuse and maintenance 
(e.g., packages, tasking, exceptions, generics) 

• Over 250 validated compilers 

• University use growing — 14 Ada textbooks and use at perhaps 10% of U.S. 
universities (from: November, 1992 Comm, of the ACM) 

• Millions of lines of Ada code for commercial non- military applications - _ 
Examples: Shell Oil for exploration. Motorola for ceBiilar telephones, Boeing 
for 747-400, GE for automated steel manufacturing, NTT (Japan) for 
commercial telecommunications applications. Nokia SoftPlan (Finland) for a 
banking system, plus others 

• Ada-9X revision to solve many of the Kngering problems 


Negative attributes of Ada 



• Hard to team to use well 

• Lack of production quality compilers 

• Performance penalty in certain critical applications 

• Doesn’t handle object oriented design - Impact of C++ 


SEL-92-004 page 397 



Observations 


After 10 years of development ... 

• Growth of courses and textbooks in Ada seems very slow. 

• Does not seem to be a lame scale movement to Ada within non-DoD 
segments of the industry. Most examples are anecdotal. 

• Ada does not yet seem ready within the large mainframe environment at 
Goddard. 

• Yet. seems to be a natural attraction to C and C++. Both have attained 
huge unsupported growth. 

WiH there be supported Ada products in 10 years? 


Summary of issues 


m 


• “Many of the perceived problems with Ada were due to the immaturity of 
early implementations, rather than Raws of the language itself. Some of 
these perceptions linger, even though mature Ada implementations are 
available today and most of the previously identified shortcomings have 
disappeared." - Erhard Ploedereder, Comm, of the ACM, Nov., 1992 


• Is Ada today an economically viable language for buHding software systems? 

• if so, for what dass of projects is it appropriate? 

• if not. what criteria are needed for determining the economic viability of 
Ada (and when should they be met) 


SEL-92-004 page 398 



Panel organization 


m 


• Opening statements: 

- What is your position and why? 

- What are the objective or subjective criteria supporting your position? 

- What actions should the principles be taking (i.e., DoD, NASA, 
contractors) and what w9l Ada be in the next century? 


• Each panelist will talk for up to 10 minutes; then a 5 minute comment by 
panelists on other statements; then general comments or questions from 
workshop attendees 


SEL-92-004 page 399 



Fddran I 


Uses and Future 


Niche 

1980 

=> 



2000 

Commercial 

COBOL 

+4GL 

+QUERY LANGUAGE 

+ C++ 

| Scientific/Engineering 

FORTRAN 

+C 

FORTRAN 90, C++ 
C++ 

I Systems 

ASM, C 

C 

Prototyping 

LISP, 

SMALLTALK 

C, PROLOG 

... 

Embedded/Real Time 

ASM, ADA 

C, ADA 

C++, ADA 

S/W Engineering 

ADA 


C++, ADA,...? 

CS Research 

C, LISP 

[ 

CLOS, ML 



txMaun 2 

Sociology 


Lifecycle 

Born/Stillbom 
Born Again? 


Nurture 

Phoenix/Bride of Frankenstein? 


Kinship 

None Allowed 


Support System jn 

Ada Industry «= — Defense Budget 
dt n 


Ecology 

Niches and Competition 


SEL-92-004 page 400 


I cklman A 


Unproven Comparisons 


Software Maintainability 

Ada>C 
Ada > C++ 


C++ 


Language Complexity 

Ada 9X > FORTRAN 90 > C++ » C - FORTRAN 77 


Simple - Compiler Difficulty 

Ada 9X > Ada » C++ » C 
Excellent - Compiler Difficulty 

C++ > C » Adas > FORTRAN 


lxMnun4 

Ada Properties 


+ Complete 
+ Supported 
+ Sponsored 
+ Real-Time 
+ Software-Engineering 
? Configuration Support 


Syntax 

Garbage Collection 
Complexity 
Software Support 
Use in Systems ("open") 
Love 


SEL-92-004 page 401 



IS ADA DYING? 


John Foreman 
DARPA/SISTO 
( 703 ) 243-8655 
jtf@scixmu.edu 

kMttjkta n i inn iir man 


posmoN 


• NOT dying, generally in good shape 

— Still maturing 

— Still potential for growth 

— Re al tech insertion and transfer takes long time 

— Is the receptor community mature? 

— Too much ‘over expectation’ 

— DoD still has unique requirements to satisfy 


SEL-92-004 page 402 





CRITERIA FOR JUDGEMENT 


• Ibol quality continually better 

• HW base much improved (32 bit processors, etc) 

• Real projects/real results 

• Use of language for large projects 

• Overseas use 

• Stability and validation are important 


- v^r ~ i ii t" — ■— tmo 


GETTING TO THE YEAR 2000 

• Planned 9X insertion and use (bindings) 

• Case studies 

• Do something about people: education 

• Need changes to acquisition process 

- life— cycle perspective 

- incremental builds 

- product evolution 

• Process/product considerations 

• Software product line management 

- software architectures 
-COTS 

• Consider effects of downsizing 

- niche market 

- polylingualism 


tastm* mff Hi ii in mm 


SEL-92-004 page 403 





FAA No OTFA0188C 00042 



ADA 

IS 

ALIVE AND HELL 
ON THE 

FAA'S ADVANCED AUTOMATION SYSTEM (AAS) 


SEL-92-004 page 404 



OVER 2.5 MILLION LINES OF NEWLY DEVELOPED CODE (MOSTLY ADA) 

FOUR SEMIS 

KSLOCS 

INITIAL SECTOR SUITE SYSTEM (ISSS) 

1058 

TERMINAL ADVANCED AUTOMATION SYSTEM (TAAS) 

716 

TOWER CONTROL COMPUTER COMPLEX (TCCC) 

257 

AREA CONTROL COMPUTER COMPLEX (ACCC) 

448 



- 4 ! 

,-AA - IBM I 


AAS PROGRAM HJSHLIGHIS (CON'T) 

BY YEAR 2000/ AAS SEGMENTS WILL BE IN USE THROUGHOUT THE USA 
AND FOR FORESEEABLE FUTURE 

-- 432 TOWERS 

- 186 TERMINALS (TRACOH) 

23 ENROUTE CENTERS (ARTCC) 

MANY HUNDREDS OF ADA PROGRAMMERS INVOLVED WITH AAS OVER LIFE OF THE PROGRAM 

AAS IS BASIS OF WORLDWIDE ATC PROGRAMS/BIDS 

— REPUBLIC OF CHINA (TAIWAN) 

— U.K.'S NEW ENROUTE CENTER (NERO 

- GERMANY 
— SWEDEN 

-- EUROCONTROL (ODS) 

- MEXICO 
— BELGIUM 



SEL^92-004 page 405 



FOR ADA TO GROM: 

ADA 9X MUST BE FULLY DOWNWARD COMPATIBLE WITH ADA 83 
(NO CODING CHANGES REQUIRED) 

ELSE 

THESE PRODUCTION SYSTEMS WILL NOT TRANSITION TO Ada 9X 

- HUNDREDS OF Ada PROGRAMMERS WILL NOT EVOLVE TO USE OF 
ADA 9X FEATURES 


SEL-92-004 page 406 


AIR FORCE ADA PROJECTION 


lNCOKTOlATZB 


MAJOR TOM CROAK, USAF 


1991 SURVEY?. 
COBOL 
ADA 

FORTRAN/ 

JOVIAL 

C 

OTHER 


1995 PROJECTION 

40 % 20 % 

10% 40% 

30% 25% 

3 % 10 % 

17% (450 LANG'S.) 5% (250 LANG'S.) 


THERE HAVE BEEN NO ADA WAIVERS SINCE JULY 1090 

•ALL OPERATIONAL SYSTEMS; ADDITIONAL 32M OF ADA CODE UNDER DEVELOPMENT 


r7*= r 

ADA 

INFORMATION CLEARINGHOUSE 

INCORPORATED 



ADA PROJECTS 

EXAMPLES 

• ACADEMIA 

4 

"SUB-SIM" ATTACK SUB SIMULATOR 

• ARMY 

62 

ADVANCE FIELD ARTILLERY TACTICAL DATA SET 
(AFATDS) 

• NAVY 

220 

ADVANCE SURVEILLANCE WORKSTATION 

• MARINE CORPS 

41 

NAVAL FLIGHT RECORD SUBSYSTEM 

• AIR FORCE 

151 

ADVANCED TACTICAL FIGHTER (F22) 

* COMMERCIAL 

111 

BOEING 777 

• GOVT. (NON-DoD) 

58 

ADVANCED AUTOMATION SYSTEM (AAS) 

* INTERNATIONAL 

68 

NETHERLANDS TELEPHONE CONTROL & 
MONITORING SYSTEM 

• OTHER DoD 

7 

SINGLE CHANNEL OBJECTIVE TACTICAL 
TERMINAL (SCOTT) 

TOTAL 

722 



SEL'92-004 page 407 



MYSTIC 


AWK 


ALOOL 


ADA & C++ • BUSINESS CASE ANALYSIS* 


IHCOUOIA1H) 

ADA 

28 COMPANIES W/VAUDATED PRODUCTS 


MARKET AVAILABILITY. 


C*+ 

18 VENDORS OFFER 
C+* 


GOVT. CONTROLLED/ANSI & tSO 
STANDARDS 

YES 

22 UNIVERSITIES & 13 DoD INSTALLATIONS 
78.8 


210 (SLOC/MM) 

<153 DATA POINTS) 


65 (VSLOC) 

(153 DATA POINTS) 


24 <153 DATA PTS.) 


1 (153 DATA PTS) 


1631 

(23% HIGHER) 
1738 

(24% HIGHER) 


STRONG 

ST AP ARP1Z ATJflM 

CROSS COMPILATION 


EDUCATION/TRAINING 

FEATURE COMPARISON * 
(OUT OF 100) 

PRO DU CTI VI T Y 

(NORM: 183 ALL LANG. 


COST 

(NORM: 70 ALL LANGUAGES) 


NO VALIDATION OR 
STANDARD EXIST 

NO 

4 UNIVERSITIES 
63.9 

187 (SLOC/MM) 

(38 DATA PTS.) 

55 

(23 DATA PTS.) 


AVOt ERROR bates (PER KSLPC1 4 

INTEGRATION 31 (23 DATA PTS.) 

(33: NORM ALL LANGUAGES) 


FORMAL QUAL TEST 

(3: NORM ALL LANGUAGES.) 


3 (23 DATA PTS.) 


ADA COCOMO COST ANALYSIS 
MIS 1324 

C3 SYSTEMS 1401 


• BASED ON U3. AIR FORCE STUDY 

~ BY SEI FOR APPLICATIONS INFO R NATION/ C3 SYSTEMS 


JOVIAL 


SEL-92-004 page 408 


nCOtfOMKD 


ADA AN EIGHTEEN YEAR SCOREBOARD 


OBJECTIVE 


RESULT 


SCORE 


SINGLE (DoD-1) HOL 


WE (CTA) SEE ADA MANDATED IN 
VIRTUALLY 100% OF DoD RFPs + 


SUPPORT MODERN 
SOFTWARE ENGINEERING 
TECHNIQUES 


YES: THROUGH STRONG TYPING 
PACKAGING, AND OTHER FEATURES + 


PROVIDE AN “ADA" 
ORIENTED PROGRAMMING 
ENVIRONMENT 


NO: CLEARLY, THE PROMISES OF 
CAIS, APSE, NOT REALIZED 


INCREASE OF PRODUCTIVITY NO CLEAR, CONCLUSIVE RESULTS 

• APPARENT RESULT IS SAME AS 

OTHER LANGUAGES NEUTRAL 


DECREASE LC SOFTWARE EVIDENCE IS POSITIVE - LESS 

MA1NTENACE (EVOLUTION) COST ERRORS IN OAM 4 


STANDARDIZATION 


YES: ANSI A ISO 


+ 


CONTROLLED, STABLE YES: THROUGH GOVT. SUPPORT 

COMPILER IMPLEMENTATION + 


CLEAR “GRASS ROOTS" USAGE NO: CERTAINLY NOT LIKE "C" 

(IN COMMERCE, ACADEMIA) 


OVERALL RESULT: POSITIVE 


SEL-92-004 page 409 



SEL-92-004 page 410 



Appendix A: Attendees 


Abd-El-Hafiz, Salwa K., 
University of Maryland 

Addelston, Jonathan D., 
Planning Research Corp. 

Agresti, Bill W., MITRE 
Corp. 

Aikens, Stephen D., DoD 

Allen, Julia, Software 
Engineering Institute 

Allen, Russ, IRS 

Anderman, Al, Rockwell 
SSD 

Anderson, Barbara, Jet 
Propulsion Lab 

Anderson, Jim, IRS 

Angier, Bruce, Institute for 
Defense Analyses 

Arnold, Robert S., Sevtec 

As till, Pat, Centel Federal 
Services 

Austin, James L., IRS 

Ayers, Everett, Ayers 
Associates 

Bachman, Scott, DoD 

Bacon, Beverly, Computer 
Sciences Corp. 

Bailey, Carmine M., 
McDonnell Douglas 

Bailey, John, SEL 

Balick, Glenn, DoD 

Barbara, Edward K., U.S. Air 
Force 

Barbour, Ed, U.S. Air Force 

Barnes, Bruce H., National 
Science Foundation 

Barnette, Randy, Hughes 
STX 

Barnhart, Don, Boeing 
Aerospace Co. 

Basch, Bill, Boeing 
Computer Support 
Services Co. 

Basili, Vic, University of 
Maryland 

Bates, Bob G., Lockheed 
Space Operations 

Baumert, John H., Computer 
Sciences Corp. 


Bearchell, Deborah J., 
Computer Sciences 
Corp. 

Beatty, Kristin, HT Research 
Institute 

Belle, Jeffery C., Logicon, 

Inc. 

Beswick, Charlie A., Jet 
Propulsion Lab 

Billick, Ron, Bell Atlantic 

Binegar, Scott, Computer 
Sciences Corp. 

Biondi, Marisa, IRS 

Bishop, Steven, Naval Air 
Warfare Center 

Bisignani, Margaret, MITRE 
Corp. 

Bissonette, Michele, 
Computer Sciences 
Corp. 

Blackwelder, Jim, Naval 
Surface Warfare Center 

Blagmon, Lowell E., Naval 
Center for Cost Analysis 

Blankenship, Donald D., U.S. 
Air Force 

Blankenship, Gordon, U.S. 
Air Force 

Bloodgood, Pete, IRS 

Blough, Lyn, Computer 
Sciences Corp. 

Blum, Bruce I., Applied 
Physics Lab 

Bogdan, Robert J., Computer 
Sciences Corp. 

Boger, Jacqueline, Computer 
Sciences Corp. 

Boland, Dillard, Computer 
Sciences Corp. 

Bond, Jack, DoD 

Boon, Dave, Computer 
Sciences Corp. 

Booth, Eric, Computer 
Sciences Corp. 

Borger, Mark W., Software 
Engineering Institute 

Boyce, Glenn W., MITRE 
Corp. 

Bozenski, Richard, DoD 

Bozoki, George J., Lockheed 


Bradley, Stephen, MMS 
Systems 

Bradshaw, Royce, NATO 

Brandt, Thomas C., Software 
Engineering Institute 

Bredeson, Mimi, Space 
Telescope Science 
Institute 

Briand, Lionel, University of 
Maryland 

Brill, Gary, IRS 

Brisco, Phil C., Hughes STX 

Brown, Robert E., Hughes 
Aircraft Co. 

Brownsword, Lisa L., 
Computer Sciences 
Corp. 

Brownsword, Robert J., 
Rational 

Bruhn, Anna, Jet Propulsion 
Lab 

Bullock, Steve, IBM 

Bunch, Aleda, Social 

Security Administration 

Burell, Billie, IBM 

Bums, Patricia, Computer 
Sciences Corp. 

Butler, Sheldon, Computer 
Sciences Corp. 

Butterworth, Paul, Hughes 
STX 

Button, Janice, DoD 

Button, Judee, IRS 


Caldiera, Gianluigi, 

University of Maryland 

Calvo, Robert, Paramax 
Aerospace Systems 

Cantalupo, Joy, IIT Research 
Institute 

Capraro, Gerald T., Karman 
Sciences 

Card, Dave, Computer 
Sciences Corp. 

Carlin, Catherine M., Dept, 
of Veterans Affairs 

Carlisle, Candace, 
NASA/GSFC 


PRECEDING PAGE BLANK NOT FILMED 


SEL-92-004 page 41 1 


Carlson, J., Computer 
Sciences Corp. 

Carpenter, Maribeth B., 
Software Engineering 
Institute 

Carruthers, Mary W., BT 
Research Institute 

Carter, Mike, U.S. Air Force 

Cecil, Robert W., Computer 
Sciences Corp. 

Cheramie, Randy, Loral 
Space Information 
Systems 

Cheung, Helen, Tandem 
Computers, Inc. 

Chiem, I-Ming Annie, 
Computer Sciences 
Corp. 

Chimiak, Reine A., 
NASA/GSFC 

Chittister, Clyde, Software 
Engineering Institute 

Chiverella, Ron, PA Blue 
Shield 

Cho, Kenneth, U.S. Air Force 

Choquette, Carl, BT 
Research Institute 

Choudhary, Rahim, Hughes 
STX 

Christophe, Debou, Alcatel- 
Elin Research Centre 

Chu, Martha, Computer 
Sciences Corp. 

Chu, Richard, Loral AeroSys 

Church, Vic, Computer 
Sciences Corp. 

Clapp, Judith A., Ml'lRE 
Corp. 

Clark, Carole A., Dept of 
Veterans Affairs 

Clark, Peter G., TASC 

Clarke, Margaret J., IBM 

Coleman, Carolyn, IIT 
Research Institute 

Condon, Steven E., 
Computer Sciences 
Corp. 

Connor, David, Computer 
Sciences Corp. 

Cook, John F., NASA/GSFC 

Coon, Richard, Computer 
Sciences Corp. 

Cornett, Lisa K., U.S. Air 
Force 


Couchoud, Carlton B., Social 
Security Administration 

Cover, Donna, Computer 
Sciences Corp. 

Crafts, Ralph E., Ada 
Software Alliance 

Creecy, Rodney, Hughes 
Aircraft Co. 

Crehan, Dennis J., Loral 
AeroSys 

Crops, Dick, Paramax 
Aerospace Systems 

Cuesta, Ernesto, Computer 
Sciences Corp. 


D’Agostino, Jeff, The 
Hammers Co. 

Dabrowski, Christopher, 
NIST 

Daku, Walter, Paramax 
Aerospace Systems 

Daney, William E„ 
NASA/GSFC 

Dangerfleld, Olie B., 
Computer Sciences 
Corp. 

Daniels, Charles B., Paramax 
Aerospace Systems 

Daniels, Helen, IRS 

Davis, Ann, Computer 
Sciences Corp. 

Davis, C., Computer 
Sciences Corp. 

Day, Nancy A., Naval 

Surface Warfare Center 

Day, Orin, Hughes STX 

Decker, William, Computer 
Sciences Corp. 

Denney, Valerie P., Martin 
Marietta 

Dhaliwal, Avtar, SEER 
Systems Corp. 

DiNunno, Donn, Computer 
Sciences Corp. 

Dikel, David, Applied 
Expertise, Inc. 

Diskin, Barbara N., Census 
Bureau 

Diskin, David H., Defense 
Information Systems 
Agency 

Diven, Jeff, IRS 

Doland, Jerry T., Computer 
Sciences Corp. 


Dolgaard, Jon, Sunquest 
Information Systems 

Donnelly, Richard E., DoD 

Dortenzo, Don, Fairchild 
Space Co. 

Dowen, Andrew, Jet 
Propulsion Lab 

Drake, Anthony M., 

Computer Sciences 
Corp. 

Driesman, Debbie, Computer 
Sciences Corp. 

Duncan, Scott P., 

BELLCORE 

Duniho, Mickey, DoD 

Dunn, Joseph, Computer 
Sciences Corp. 

Durak, Tom, TAD 
Consulting 

Duvall, Lorraine, Syracuse 
University 

Dyer, Michael, IBM 

Edelson, Robert, Jet 
Propulsion Lab 

Edlund-OMahony, Sheryl J., 
USA, ISSOCW 

Eichmann, David, University 
of Houston-Clear Lake 

Ellis, Walter, IBM 

Elovitz, Honey, MITRE 
Corp. 

Elston, Judson R., Boeing 
Aerospace Co. 

Elwood, Todd W., Computer 
Sciences Corp. 

Emerson, Curtis, 
NASA/GSFC 

Emery, Richard D., Vitro 
Corp. 

Engelmeyer, William J., 
Computer Sciences 
Corp. 

Evan co, William, MURE 
Corp. 

Evers, J. W., Paramax 
Aerospace Systems 

Fagan, Michael, Michael 
Fagan Associates 

Faller, Ken, HTASC 

Farah, Jocelyne, U.S. Air 
Force 


S EL-92-004 page 412 



Farrell, Mary Ann, Logicon, 
Inc. 

Farrell, William T., DSD 
Laboratories, Inc. 

Fauerby, John, Computer 
Sciences Corp. 

Feldman, Stuart, 

BELLCORE 

Ferguson, Frances, Stanford 
Telecommunications, 

Inc. 

Fenigno, Peter M., RJO- 
Enterprises, Inc. 

Fink, Mary Louise A., 
Treasury Department 

Finley, Doug, Paramax 
Aerospace Systems 

Fleming, Barbara 

Fleming, Judy K., IBM 

Foreman, John, Software 
Engineering Institute 

Forsythe, Ron, 

NASA/Wallops Flight 
Facility 

Fouser, Thomas J., Jet 
Propulsion Lab 

Fox, Raymond, DoD 

Franklin, Jude E., Planning 
Research Corp. 

Friedman, Seymour R., 
MITRE Corp. 

Fuentes, Wilfredo, Logicon, 
Inc. 

Gallagher, Barbara, DoD 

Gaylord, Jerry, HT Research 
Institute 

Gehrmann, Paul, IBM 

Geil, Ester, Westinghouse 

Geil, Leana M., Dept Of 
Veterans Affairs 

Gieser, Jim, Paramax 
Aerospace Systems 

Gillam, Michael, OAO Corp. 

Gire, Carey, Loral AeroSys 

Giusti, Ronald V., MITRE 
Corp. 

Glascock, Robin, Tandem 
Computers, Inc. 

Glass, Robert L., Computing 
Trends 

Godfrey, Sally, NASA/GSFC 

Gogia, B. K., Datamat 
Systems Research, Inc. 


Golden, John R., Rochester 
Institute of Technology 

Golding, Annetta, Census 
Bureau 

Gordon, Del, Paramax 
Aerospace Systems 

Gonnally, John M., TRW 

Gosnell, Arthur B., U.S. 

Army Missile Command 

Gotteibam, Donald, East 
Tennessee State 
University 

Graham, Robert P., U.S. Air 
Force 

Gray, Carmella, CRM 

Gray, James H., Computer 
Sciences Corp. 

Green, David, Computer 
Sciences Corp. 

Green, Scott, NASA/GSFC 

Greene, Joseph B., Booz, 
Allen & Hamilton, Inc. 

Gregory, John G., 
Westinghouse 

Grondalski, Jean F., 

Computer Sciences 
Corp. 

Groveman, Brian S., 
Computer Sciences 
Corp. 

Gu, Dechang, North Carolina 
A&T State University 

Guillebeau, Pat, New 
Technology, Inc. 

Gupta, Lakshmi, Loral 
AeroSys 

Hall, Dana L., SAIC 

Hall, John E., DoD 

Hall, Ken, Computer 
Sciences Corp. 

Hall, Susan M., SofTech, Inc. 

Halpine, Scott, Loral 
AeroSys 

Halterman, Karen, 
NASA/GSFC 

Hankins, Dick, General 
Dynamics 

Hanna, Susan, Beckman 
Instruments, Inc. 

Harrington, Keith, U.S. Air 
Force 

Harris, Barbara, IRS 


Harris, Bernard, 

NASA/GSFC 

Harris, Mary, Hughes 
Aircraft Co. 

Hashmi, Awais A., Digital 
Systems 

Hatch, Ada, IRS 

Hausler, Philip A., IBM 

Hazle, Marlene, MITRE 
Corp. 

Hearn, Rick, Ollila Industries 

Heller, Gerard H., Computer 
Sciences Corp. 

Hendrick, Christine, 
Computer Sciences 
Corp. 

Hendrick, Robert B., 
Computer Sciences 
Corp. 

Hendrzak, Gary, Booz, Allen 
& Hamilton, Inc. 

Hetmanski, Christopher, 
University of Maryland 

Hill, Ken, Paramax 
Aerospace Systems 

Hilldrup, Kerry C., Hughes 
STX 

Hills, Frederick, Software 
Productivity Consortium 

Hladry, John, Boeing 
Computer Support 
Services Co. 

Ho, N., Computer Sciences 
Corp. 

Hoffman, Dan, University of 
Victoria 

Hoffman, John C., Sunquest 
Information Systems 

Hoffmann, Kenneth, Ryan 
Computer Systems 

Holmes, Barbara, CRM 

Holmes, Joseph A., IRS 

Hover, Karen E., Martin 
Marietta 

Hsiah, K., Computer 
Sciences Corp. 

Huang, Bing, FAA 

Hull, Larry, NASA/GSFC 

Hung, Joshua C., FAA 

Huza, Marilyn, IRS 

Hynes, Lois, IRS 

Hgenftttz, Charles, IRS 


SEL-92-004 page 413 



Ippolito, Laura, NIST 

Iscoe, Neil, EDS Research, 

Inc. 

Iskow, Lany, U.S. Census 
Bureau 

Jackson, Ann, University of 
Victoria 

Jackson, Lyn, Logicon, Inc. 

Jackson, Steve, U.S. Air 
Force 

James, Chris, Computer 
Sciences Corp. 

James, Jason S., DoD 

Jay, Elizabeth M., 
NASA/GSFC 

Jeletic, Jim, NASA/GSFC 

Jeletic, Kelly A., 

NASA/GSFC 

Jenkins, John O., City 
University 

Jenkins, Jr, Robert, Computer 
Sciences Corp. 

Jepsen, Paul L., Jet 
Propulsion Lab 

Jessen, William J., General 
Electric 

Jilek, Simi S., U.S. Dept, of 
Energy 

Johnson, Kent A., Software 
Productivity Consortium 

Jones, Christopher C., HT 
Research Institute 

Jones, Deborah M., FAA 

Jones, Mel, Applied 
Expertise, Inc. 

Jones, Nancy A., MITRE 
Corp. 

Jordano, Tony J., S AIC 

Kavanagh, Dennis M., 
Computer Sciences 
Corp. 

Kelly, John C., Jet Propulsion 
Lab 

Kelly, Sharon C., Hanis 
Corp. 

Kemp, Dennis, Hughes STX 

Kemp, Kathryn M., 
NASA/HQ 

Kester, Rush, Computer 
Sciences Corp. 

Kieckhefer, Ron, Computer 
Sciences Corp. 


SEI^92'004 page 414 


Kim, Seung, Computer 
Sciences Corp. 

Kirkendall, Thomasin, NIST 

Kirkpatrick, Diane, Ball 
Aerospace 

Kistler, David M., Computer 
Sciences Corp. 

Klitsch, Gerald, Computer 
Sciences Corp. 

Knapp, Andy, Bell Atlantic 

Knoell, Roger, U.S. Air 
Force 

Koeser, Ken, Vitro Corp. 

Konopka, Joseph J., 

Computer Sciences 
Corp. 

Kontson, Kalle R., ITT 
Research Institute 

Kopperman, Stuart, Systems 
Research & Applications 
Corp. 

Kosloski, Joe, IRS 

Kovin, Steven E., Computer 
Sciences Corp. 

Kramer, Nancy, Viar & Co. 
/Dyncoip 

Kramer, Teresa L., DoD 

Kristof, Dave, U.S. Air Force 

Kudlinski, Robert A., 
NASA/LaRC 

Kurihara, Tom, Logicon, Inc. 

Lai, R., Chi Tau, 

International S/W 
Process Constellation 

Lai, Nand, NASA/GSFC 

Lam, Vincent, IMS 

Lane, Sherry, CRM 

Lang, John, Computer 
Sciences Corp. 

Langston, James H., 
Computer Sciences 
Corp. 

Laubenthal, Nancy, 
NASA/GSFC 

Lawlor, Tran, Bell Atlantic 

Lawrence, Raymond, 
LMcDonnell Douglas 

Lawrence-Pfleeger, Shari, 
MITRE Corp. 

Ledford, Rick, McDonnell 
Douglas 

Lee, Raymond H., Computer 
Sciences Corp. 


Lee, Thomas S., Paramax 
Aerospace Systems 

Lehman, Meir, Imperial 
College of Science 

Lemmon, Doug, University 
of Maryland 

Leone, Rick, Hughes STX 

Levitt, David S., Computer 
Sciences Corp. 

Lewicki, Scott A., Jet 
Propulsion Lab 

Li, Ningda Rorry, University 
of Maryland 

Liebrecht, Paula, Computer 
Sciences Corp. 

Lijewski, Mike, Hughes STX 

Likness, Mark, Martin 
Marietta 

Lindsay, Orlando, Computer 
Sciences Corp. 

Lindvall, Mikael, Linkoping 
University 

Lippens, Gary A., U.S. Air 
Force 

Litz, Deborah, DoD 

Liu, Jean C., Computer 
Sciences Corp. 

Liu, Kuen-san, Computer 
Sciences Corp. 

Loesh, Bob E., Software 
Engineering Sciences, 
Inc. 

Loftin, Donald R., GE 
Aerospace 

Long, Roger, LTASC 

Loomis, Todd, Booz, Allen 
& Hamilton, Inc. 

Loy, Patrick H., Loy 
Consulting, Inc. 

Lucas, Janice P., Dept of 
Treasury 

Luczak, Ray, Computer 
Sciences Corp. 

Lupinetti, Martin, Computer 
Sciences Corp. 

Luppino, Fred, IBM 

Lyle, William, TASC 

Maccannon, Cecil, FAA 

Madden, Joseph A., U.S. Air 
Force 

Majane, John A., EG & G 
WASC, Inc. 

Manicka, Gary, Hughes STX 



Manter, Keith, Computer 
Sciences Corp. 

Marciniak, John, Computer 
Technology Associates, 
Inc. 

Marcoux, Darwin, DoD 

Marquiss, Terri, Computer 
Sciences Corp. 

Martin, Carol, TRW 

Mashiko, Yasuhiro, 

University of Maryland 

Mauney, Mike, Census 
Bureau 

Maury, Jesse, Gmitron, Inc. 

McConnel, Pat, IRS 

McCreary, Julia M., IRS 

McGarry, Frank E., 
NASA/GSFC 

McGarry, Mary Ann, HT 
Research Institute 

McGarry, Peter, General 
Electric 

McGovern, Dan, FAA 

McKay, Judith A., Census 
Bureau 

McKinney, Cathy, IRS 

McKinney, Jimmie, 
USAFISA 

McNeill, Justin F., Jet 
Propulsion Lab 

McSharry, Maureen, 
Computer Sciences 
Corp. 

Mehta, Shilpa, American 
Systems Corp. 

Meick, Douglas, Library of 
Congress 

Mendonca, Manoel G., 
University of Maryland 

Merry, Paul, Harris Space 
Systems Corp. 

Miller, Ronald W., 
NASA/GSFC 

Miller, Sharon E., AT&T 
Bell Lab 

Miller, Terrence, Project 
Engineering, Inc. 

Mills, John P„ Booz, Allen & 
Hamilton, Inc. 

Mohallatee, Michael, 
Computer Sciences 
Corp. 

Moleski, Laura, CRM 

Moleski, Walt, NASA/GSFC 


Moniuszko, Charles, DoD 

Moore, Betty, IRS 

Moore, Kathryn J., 
USAISSDC-A 

Moore, Paula, NOAA/SPOx3 

Moortgat, Jean-Jacques, 
Booz, Allen & Hamilton, 
Inc. 

Morasca, Sandro, University 
of Maryland 

Morgan, Elizabeth, Bendix 
Field Engineering Corp. 

Morusiewicz, Linda M., 
Computer Sciences 
Corp. 

Mostoller, Brad, Sunquest 
Information Systems 

Moxley, Fred L, DIS A/CFS 

Mucha, John F., IRS 

Muckel, Jerry, Computer 
Sciences Corp. 

Mulville, Daniel, NASA/HQ 

Munkeby, Steve, Martin 
Marietta 

Murphy, Susan, IBM 

Murtha, Kimberly N., 
Sunquest Information 
Systems 

Myers, Philip I., Computer 
Sciences Corp. 

Myers, Robert M., MURE 
Corp. 


Narrow, Bemie, Bendix Field 
Engineering Corp. 

Nassau, Dave, Applied 
Expertise, Inc. 

Newman, Phillip A., 
NASA/GSFC 

Nishimoto, Theresa, Coopers 
& Lybrand 

Nola, Charles L., 
NASA/MSFC 

Noonan, Carolina, Computer 
Sciences Corp. 

Noone, Estelle, Computer 
Sciences Corp. 

Norcio, Tony F., University 
of Maryland Baltimore 
County 


O’Brien, Robert L., Paramax 
Aerospace Systems 


O’Connor, Sean, Martin 
Marietta 

O'Neill, Don 

O’Neill, Patrick, U.S. Army 
AMSAA 

O’Neill, Peter, PA Blue 
Shield 

Ohlmacher, Jane A., Social 
Security Administration 

Okupski, Scott, U.S. Air 
Force 

Olson, Lenoard, Hughes STX 

Osifchin, Tammy, Hughes 
Aircraft Co. 


Padgett, Kathy, Census 
Bureau 

Page, Gerald, Computer 
Sciences Corp. 

Pajerski, Rose, NASA/GSFC 

Palmer, Regina, Martin 
Marietta 

Paluzzi, Paul, Computer 
Sciences Corp. 

Pang, Les, FAA 

Panlilio-Yap, Nikki M., IBM 
Canada Ltd. 

Park, Robert, Computer 
Sciences Corp. 

Patrick, Debora, HT Research 
Institute 

Patterson, F., G., NASA 
SSFPO 

Patton, Kay, Computer 
Sciences Corp. 

Pavnica, Paul, 

Treasury /Fincen 

Pecore, Joseph N., Vitro 
Corp. 

Peeples, Ron L., IBM 

Pendergrass, Vicki, 
NASA/GSFC 

Pendley, Rex, Computer 
Sciences Corp. 

Peng, Wendy, NIST 

Peng, Yuh-Fen, Computer 
Sciences Corp. 

Perry, Brendan, Hughes STX 

Peters, Jeffrey, U.S. Air 
Force 

Pettijohn, Margot, IRS 

Philpot, Donn E., 
Technology 
Applications, Inc. 


SEL-92-004 page 415 



Philpot, Fred, Dept of the 
Air Force 

Plett, Michael E., Computer 
Sciences Corp. 

Plonk, Glenn, DoD 

Polly, Mike, Raytheon 

Poms, B., Computer Sciences 
Corp. 

Porter, Adam A., University 
of Maryland 

Potter, Marshall R., Dept, of 
the Navy 

Pottinger, David L., S AIC 

Powers, Larry, Unisys Corp. 

Presbury-Bush, Anna, DoD 

Preston, Dick 

Provenza, Clint, Booz, Allen 
& Hamilton, Inc. 

Quann, Eileen S., Fastrak 
Training, Inc. 

Quindlen, Brian, Computer 
Sciences Corp. 

Quinn, Harold, Computer 
Sciences Corp. 

Rager, William J., Computer 
Sciences Corp. 

Rahmani, Donna, Computer 
Sciences Corp. 

Rajlich, Vaclav, Wayne State 
University 

Raney, Dale, LTRW 

Ransdell, William G., 
Research Triangle 
Institute 

Ray, Julie, New Technology, 
Inc. 

Raymond, Jack, Computer 
Sciences Corp. 

Reddy, Swami, Hughes STX 

Reed, Lee Scott, Software 
Engineering Institute 

Regardie, MyraaL., 
Computer Sciences 
Corp. 

Reifer, Don J., Reifer 
Consultants, Inc. 

Repsher, Marie, IRS 

Rhoads, Thomas E., 
Computer Sciences 
Corp. 

Rhodes, Tom, NIST 


Rice, Mary K., USAF 

Ridgeway, Roland M., 
NASA/HQ 

Risser, Gary E., Dept. of 
Veterans Affairs 

Rizer, Stephani, NAWC-AD 

Rizzello, John, Loral 
AeroSys 

Roberts, Becky L., CBIS 
Federal Inc. 

Roberts, Geraldine, 

Computer Sciences 
Corp. 

Robertson, Laurie, Computer 
Sciences Corp. 

Robinett, Susan, Systems 
Research & Applications 
Corp. 

Robinson, Alice B., 

NASA/HQ 

Rohr, John A., Jet Propulsion 
Lab 

Rombach, H. Dieter, 
University of 
Kaiserslautern 

Rose, Lois A., Bell Atlantic 

Rosenberg, Linda H., 
NASA/GSFC 

Roth, Karen, Paramax 
Aerospace Systems 

Rouff, Chris, NASA/GSFC 

Roy, Dan M., Software 
Engineering Institute 

Rudiger, Karen S., Boeing 
Computer Support 
Services Co. 

Russell, Wayne M., GTE 

Russo Waters, Olga, 

Logicon, Inc. 

Rymer, John, IBM 

Sabarre, Nick, IRS 

Sahady, Phil, Booz, Allen & 
Hamilton, Inc. 

Saisi, Robert, ODSD 
Laboratories, Inc. 

Sal win, Arthur, MITRE 
Corp. 

Sanden, Bo I., George Mason 
University 

Santiago, Richard, Jet 
Propulsion Lab 

Schappelle, Sam, IBM 


Schilling, Mark, Project 
Engineering, Inc. 

Schneidewind, Norman F., 
Naval Postgraduate 
School 

Schoen, BiU, HT Research 
Institute 

Schuler, Pat M., 

NASA/LaRC 

Schwartz, Karen D., 

Government Computer 
News 

Schwarz, Henry, NASA/KSC 

Scott, Rhonda M., IBM 

Seaman, Carolyn B., 

University of Maryland 

Seaver, David P., Project 
Engineering, Inc. 

Seidewitz, Ed, NASA/GSFC 

Shammas, Barbara A., IRS 

Sheets, Teresa B., 
NASA/GSFC 

Sheppard, Sylvia B., 
NASA/GSFC 

Shirey, Carl L., ITT 

Shockey, Donna, IRS 

Short, Cathy, IRS 

Siddalingaiah, Vimala, 
Computer Sciences 
Corp. 

Siegel, Karla, MITRE Corp. 

Simenson, Norman, FAA 

Singer, Carl A., BELLCORE 

Singh, Prakash, EER Systems 
Corp. 

Singleton, Frank L., Jet 
Propulsion Lab 

Skrivan, James A., Boeing 
Computer Support 
Services Co. 

Sledge, Carol, Software 
Engineering Institute 

Smith, David, Computer 
Sciences Corp. 

Smith, Diana, ITT Research 
Institute 

Smith, Donald, NASA/GSFC 

Smith, Shawn D., American 
Systems Corp. 

Smith, Vivian, AFAA 

Snook, Judy, Computer 
Sciences Corp. 

Song, Fu-Fu, Computer 
Sciences Corp. 


SEL-92-004 page 416 



Sorensen, Steven, Martin 
Marietta 

Sova, Don, NASA/HQ 

Spangler, Alan R., IBM 

Spence, Bailey, Computer 
Sciences Corp. 

Spencer, Mike, Naval Air 
Warfare Center 

Spool, Peter R., Siemens 
Corporate Research, Inc. 

Spom, Patricia A., 

NASA/HQ 

Squires, Burton E., 

Mnemonic Systems Inc. 

Srivastava, Alok, Computer 
Sciences Corp. 

Stanton, Faye, IRS 

Stark, Michael, NASA/GSFC 

Stauffer, Mike P., General 
Electric 

Stevens, Jan, Systems 

Research & Applications 
Corp. 

Stewart, Barbara C., U.S. Air 
Force 

Strano, Caroline, FAA 

Sugumaran, Vijayan, George 
Mason University 

Svara, Allan C., USAF/7th, 
Comm, Group 

Swain, Barbara, University of 
Maryland 

Szulewski, Paul S., Draper 
Labs, Inc. 

Tasaki, Keiji, NASA/GSFC 

Tausworthe, Robert C., 
NASA/JPL 

Tavakoli-Shiraji, Iraj, George 
Mason University 

Tervo, Betsy, Computer 
Sciences Corp. 

Thackrey, Kent, Planning 
Analysis Corp. 

Theeke, Patrick, Electronic 
Warfare Associates, Inc. 

Theofanos, Mary, Martin 
Marietta 

Thomas, Donna C., 
Computer Sciences 
Corp. 

Thomas, Isac, Computer 
Sciences Corp. 


Thomas, William, MITRE 
Corp. 

Thomen, Marie, IBM 

Thrasybule, Wesner, 
Computer Sciences 
Corp. 

Tipparaju, Suri, Hughes STX 

Tisnado, Gilberto M. 

Tran, Dennis A., MITRE 
Corp. 

Tran, Tuyet-Lan, Jet 
Propulsion Lab 

Trujillo, Nelson W., 
NDU/IRMC 

Truong, Son, NASA/GSFC 

Tsagos, Dinos 

Tupman, Jack R., Jet 
Propulsion Lab 

Ullman, Richard, Hughes ST 
Systems Corp. 

Usavage, Paul, General 
Electric 


Valett, Jon, NASA/GSFC 

Valleni, Bob R., TRW 

Van Meter, David, Logicon, 
Inc. 

Van Verth, Patricia B., 
Canisius College 

VanHom, Wendy J., IRS 

Varklett, Vanessa, IIT 
Research Institute 

Vaughan, Joe, Social 

Security Administration 

Vause, David G., IBM 

Vazquez, Federico, 

Computer Sciences 
Corp. 

Velez, Tom E., Computer 
Technology Associates, 
Inc. 

Verducci, Anthony J., AT&T 
Bell Lab 

Viola, Ken W., IRS 

Voit, Eric, Bell Atlantic 

Votta, Lawrence G., AT&T 
Bell Lab 


Wagoner, Raelene, Systems 
Research & Applications 
Corp. 


Waligora, Sharon R., 

Computer Sciences 
Corp. 

Wallace, Charles J., 

Integrated Systems 
Analysts, Inc. 

Wallace, Dolores, NIST 

Walsh, Bob, IRS 

Walsh, Chuck, NASA Center 
for Aerospace 
Information 

Waszkiewicz, Mary Lily, 
Computer Sciences 
Corp. 

Weber, Paul A., Technology 
Planning, Inc. 

Weiss, Peter, Arthur D., 

Little, Inc. 

Weiss, Sandy L., GTE 

Wells, Robert, Computer 
Sciences Corp. 

Werling, Richard, Software 
Productivity Consortium 

Wessale, William, CAE-Link 
Corp. 

Weston, William, 
NASA/GSFC 

Weszka, Joan, IBM 

Wheeler, J. L., Computer 
Sciences Corp. 

White, Cora P., New 
Technology, Inc. 

Whitehead, John W., 
NAVSEA 06D3 

Whitfield, Josette, ITT 
Research Institute 

Whitman, Cynthia B., 
USAISSDC-A 

Wilkins, Elsie C., USAFISA 

Williamson, Jim, S unquest 
Information Systems 

Wilson, Jim, Applied 
Expertise, Inc. 

Wilson, Randy D., Naval 
Center For Cost Analysis 

Wingfield, Lawrence D., 
Computer Sciences 
Corp. 

Wisdom, Rex, U.S. Air Force 

Wise, Charles F., Technology 
Applications, Inc. 

Wong, Sha, IMS 

Wong, Yee, Computer 
Sciences Corp. 


SEL-92-004 page 417 



Wood, Richard, Computer 
Sciences Coip. 

Wood, Terri, NASA/GSFC 
Woodward, Herbert P., TRW 

Worley, Patricia W., Boeing 
Computer Support 
Services Co. 

Wortman, Kristin, Hughes 
STX 


Yin, Sandra, IRS 

Youman, Charles, SETA 
Corp. 

Young, Andy, Bendix Field 
Engineering Corp. 

Yu, Anna, NCA&T State 
University 


Zavaleta, Henry M., 
Computer Sciences 
Corp. 

Zaveler, Saul, U.S. Air Force 

Zelkowitz, Marv, University 
of Maryland 

Zimet, Beth, Computer 
Sciences Corp. 

Zucconi, Lin, Lawrence 
Livermore National 
Laboratory 

Zvegintzov, Nicholas, 
Software Maintenance 
News Inc. 


SEL-92-004 page 418 



Appendix B: Standard Bibliography of SEL Literature 


SEL-92-004 page 419 



SEL-92-004 page 420 



STANDARD BIBLIOGRAPHY OF SEL UTERATURE 


The technical papers, memorandums, and documents listed in this bibliography are or- 
ganized into two groups. The first group is composed of documents issued by the Soft- 
ware Engineering Laboratory (SEL) during its research and development activities. 
The second group includes materials that were published elsewhere but pertain to SbL 

activities. 

SEL-ORIGINATED DOCUMENTS 

SEE-76-001, Proceedings From the First Summer Software Engineering Workshop, 
August 1976 

SEL-77-002, Proceedings From the Second Summer Software Engineering Workshop , 
September 1977 

SEL-78-005, Proceedings From the Third Summer Software Engineering Workshop , 
September 1978 

SEL-78-006, GSFC Software Engineering Research Requirements Analysis Study, 
P. A. Scheffer and C. E. Velez, November 1978 

SEL-78-007, Applicability of the Rayleigh Curve to the SEL Environment , T. E. Mapp, 
December 1978 

SEL-78-302, FORTRAN Static Source Code Analyzer Program (SAP) User f s Guide 
(Revision 3), W. J. Decker, W. A. Thylor, et al., July 1986 

SEL-79-002, The Software Engineering Laboratory: Relationship Equations , 

K. Freburger and V. R. Basili, May 1979 

SEL-79-004, Evaluation of the Caine, Farber, and Gordon Program Design Language 
(PDL) in the Goddard Space Flight Center ( GSFC) Code 580 Software Design Environ- 
ment , C. E. Goorevich, A. L. Green, and W. J. Decker, September 1979 

SEL-79-005, Proceedings From the Fourth Summer Software Engineering Workshop , 
November 1979 

SEL-80-002, Multi-Level Expression Design Language-Requirement Level (MEDL-R) 
System Evaluation , W. J. Decker and C. E. Goorevich, May 1980 

SEL-80-005,>l Study of the Musa Reliability Model , A. M. Miller, November 1980 

SEL-80-006, Proceedings From the Fifth Annual Software Engineering Workshop, 
November 1980 

SEL-80-007, An Appraisal of Selected Cost/Resource Estimation Modeb for Software 
Systems, J. F. Cook and F. E. McGany, December 1980 

BI-1 


preceding page bunk not filmed 


SEL-92-004 page 421 



SEL-80-008, Tutorial on Models and Metrics for Software Management and Engineering, 
V. R. Basili, 1980 

SEL-81-011, Evaluating Software Development by Analysis of Change Data, 
D. M. Weiss, November 1981 

SEL-81-012, The Rayleigh Curve as a Model for Effort Distribution Over the Life of 
Medium Scale Software Systems, G. O. Picasso, December 1981 

SEL-81-013, Proceedings of the Sixth Annual Software Engineering Workshop, December 
1981 


SEL-81-014, Automated Collection of Software Engineering Data in the Software Engi- 
neering Laboratory (SEL), A. L. Green, W. J. Decker, and F. E. McGarry, September 

1981 

SEL-81-101, Guide to Data Collection, V. E. Church, D. N. Card, F. E. McGarry, et al., 
August 1982 

SEL-81-104, The Software Engineering Laboratory, D. N. Card, F.E. McGarry, 
G. Page, et al., February 1982 

SEL-81-1 10, Evaluation of an Independent Verification and Validation (IVS^) Methodol- 
ogy for Flight Dynamics , G. Page, F. E. McGarry, and D. N. Card, June 1985 

SEL-S1-305, Recommended Approach to Software Development, L. Landis, S. Waligora, 
F. E. McGarry, et al., June 1992 


SEL-82-001, Evaluation of Management Measures of Software Development, G. Page, 
D. N. Card, and F. E. McGarry, September 1982, vols. 1 and 2 

SEL-82-004, Collected Software Engineering Papers: Volume 1, July 1982 

SEI^82-007, Proceedings of the Seventh Annual Software Engineering Workshop, 
December 1982 


SEL-82-008, Evaluating Software Development by Analysis of Changes: The Data From 
the Software Engineering Laboratory, V. R. Basili and D. M. Weiss, December 198 


SEL-82-102 FORTRAN Static Source Code Analyzer Program (SAP) System Description 
(Revision 1), W. A. Tkylor and W. J. Decker, April 1985 

SEL-82-105, Glossary of Software Engineering Laboratory Terms, T. A. Babst, 
M. G. Rohleder, and F. E. McGarry, October 1983 


SEL-82-1106, Annotated Bibliography of Software Engineering Laboratory Literature, 
L. Morusiewicz and J. Valett, November 1992 

SEL-83-001, An Approach to Software Cost Estimation, F. E. McGarry, G. Page, 
D. N. Card, et al., February 1984 


BI-2 


SEL-92-004 page 422 



SEL-83-002, Measures and Metrics for Software Development , D. N. Card, 
F. E. McGany, G. Page, et al., March 1984 

SEL-83-003, Collected Software Engineering Papers: Volume II, November 1983 

SEL-83-006, Monitoring Software Development Through Dynamic Variables, 
C. W. Doerflinger, November 1983 

SEL-83-007, Proceedings of the Eighth Annual Software Engineering Workshop, 
November 1983 

SEL-83-106, Monitoring Software Development Through Dynamic Variables (Revi- 
sion 1 ), C. W. Doerflinger, November 1989 

SEL-84-003, Investigation of Specification Measures for the Software Engineering Labora- 
tory (SEL), W. W. Agresti, V. E. Church, and F. E. McGany, December 1984 

SEL-84-004, Proceedings of the Ninth Annual Software Engineering Workshop, 
November 1984 

SEL-84-101, Manager’s Handbook for Software Development (Revision 1), L. Landis, 
F. E. McGany, S. Waligora, et al., November 1990 

SEL-85-001, A Comparison of Software Verification Techniques, D.N. Card, 
R. W. Selby, Jr., F. E. McGany, et al., April 1985 

SEL-85-002, Ada Training Evaluation and Recommendations From the Gamma Ray 
Observatory Ada Development Team, R. Murphy and M. Stark, October 1985 

SEL-85-003, Collected Software Engineering Papers: Volume III , November 1985 

SEL-85-004, Evaluations of Software Technologies: Testing, CLEANROOM, and 

Metrics, R. W. Selby, Jr., and V. R. Basili, May 1985 

SEL-85-005, Software Verification and Testing, D. N. Card, E. Edwards, F. McGany, 
and C. Antle, December 1985 

SEL-85-006, Proceedings of the Tenth Annual Software Engineering Workshop, 
December 1985 

SEL-86-001, Programmer’s Handbook for Flight Dynamics Software Development, 
R. Wood and E. Edwards, March 1986 

SEL-86-002, General Object-Oriented Software Development, E. Seidewitz and 
M. Stark, August 1986 

SEL-86-003, Flight Dynamics System Software Development Environment (FDSISDE) 
Tutorial, J. Buell and P. Myers, July 1986 

SEL-86-004, Collected Software Engineering Papers: Volume TV, November 1986 

BI-3 


SEL-92-004 page 423 



SEL-86-005, Measuring Software Design , D. N. Card et al., November 1986 

SEL-86-006, Proceedings of the Eleventh Annual Software Engineering Workshop , 
December 1986 

SEL-87-001, Product Assurance Policies and Procedures for Flight Dynamics Software 
Development , S. Perry et al., March 1987 

SEI^87-002, Ada® Style Guide (Version 1.1), E. Seidewitz et al.. May 1987 

SEL-87-003, Guidelines for Applying the Composite Specification Model (CSM), 
W. W. Agresti, June 1987 

SEL-87-004, Assessing the Ada® Design Process and Its Implications: A Case Study , 
S. Godfrey, C. Brophy, et al., July 1987 

SEL-87-009, Collected Software Engineering Papers: Volume V, November 1987 

SEL-87-010, Proceedings of the Twelfth Annual Software Engineering Workshop , 
December 1987 

SEL-88-001, System Testing of a ProductionAda Project The GRODY Study, J. Seigle, 
L. Esker, and Y. Shi, November 1988 

SEL-88-002, Collected Software Engineering Papers: Volume VI, November 1988 

SEL-88-003, Evolution of Ada Technology in the Flight Dynamics Area: Design Phase 
Analysis, K. Quimby and L. Esker, December 1988 

SEL-88-004, Proceedings of the Thirteenth Annual Software Engineering Workshop, 
November 1988 

SEL-88-005, Proceedings of the First NASA Ada User’s Symposium, December 1988 

SEL-89-002, Implementation of a Production Ada Project: The GRODY Study, 

S. Godfrey and C. Brophy, September 1989 

SEL-89-004, Evolution of Ada Technology in the Flight Dynamics Area: Implementation / 
Testing Phase Analysis, K. Quimby, L. Esker, L. Smith, M. Stark, and F. McGany, 
November 1989 

SEL-89-005, Lessons Learned in the Transition to Ada From FORTRAN at NASA / 
Goddard, C. Brophy, November 1989 

SEL-89-006, Collected Software Engineering Papers: Volume VII, November 1989 

SEL-89-007, Proceedings of the Fourteenth Annual Software Engineering Workshop, 
November 1989 

SEL-89-008, Proceedings of the Second NASA Ada Users y Symposium, November 1989 

BI-4 


SEL-92-004 page 424 



SEL-89-103, Software Management Environment (SME) Concepts and Architecture 
( Revision 1), R. Hendrick, D. Kistler, and J. Valett, September 1992 

SEL-89-201, Software Engineering Laboratory (SEL) Database Organization and Users 
Guide (Revision 2), L. Morusiewicz, J. Bristow, et al., October 1992 

SEL-90-001, Database Access Manager for the Software Engineering Laboratory 
(DAMSEL) User's Guide, M. Buhler, K. Pumphrey, and D. Spiegel, March 1990 

SEL-90-002, The Cleanroom Case Study in the Software Engineering Laboratory: Project 
Description and Early Analysis, S. Green et al,, March 1990 

SEL-90-003,^4 Study of the Portability of an Ada System in the Software Engineering Labo- 
ratory (SEL), L. O. Jun and S. R. Valett, June 1990 

SEL-90-004, Gamma Ray Observatory Dynamics Simulator in Ada (GRODY) Experi- 
ment Summary , T. McDermott and M. Stark, September 1990 

SEL-90-005, Collected Software Engineering Papers: Volume VIII, November 1990 

SEL-90-006, Proceedings of the Fifteenth Annual Software Engineering Workshop, 
November 1990 

SEL-91-001, Software Engineering Laboratory (SEL) Relationships, Models, and Man- 
agement Rules, W. Decker, R. Hendrick, and J. Valett, February 1991 

SEL-91-003, Software Engineering Laboratory (SEL) Ada Performance Study Report, 
E. W. Booth and M. E. Stark, July. 1991 

SEL-91-004, Software Engineering Laboratory (SEL) Cleanroom Process Model, 
S. Green, November 1991 

SEL-91-005, Collected Software Engineering Papers: Volume DC, November 1991 

SEL-91-006, Proceedings of the Sixteenth Annual Software Engineering Workshop, 
December 1991 

SEL-9 1-102, Software Engineering Laboratory (SEL) Data and Information Policy (Revi- 
sion 1), F. McGarry, August 1991 

SEL-92-001, Software Management Environment (SME) Installation Guide, D. Kistler 
and K. Jeletic, January 1992 

SEL-92-002, Data Collection Procedures for the Software Engineering Laboratory (SEL) 
Database, G. Heller, J. Valett, and M. Wild, March 1992 

SEL-92-003, Collected Software Engineering Papers: Volume X, November 1992 

SEL-92-004, Proceedings of the Seventeenth Annual Software Engineenng Workshop, 
December 1992 


BI-5 


SEL-92-004 page 425 



SEL-RELATED LITERATURE 

'°Abd-El-Hafiz, S. K., V. R. Basili, and G. Caldiera, ‘Towar^ Automated SuppOTl for 
Extraction of Reusable Components,” Proceedings of the IEEE Conference on Softwa 
Maintenance-1991 (CSM91), October 1991 

4 Aeresti W. W V. E. Church, D. N. Card, and P. L. Lo, “Designing With Ada for Sat- 
ellite Simulation: A Case Study,” Proceedings of the First International Symposium on 
Ada for the NASA Space Station, June 1986 

’Aeresti W W F. E. McGarry, D. N. Card, et al., “Measuring Software Technology,” 

P%gr am Transformation and Programming Environments . New York: Spnnger-Verlag, 

1984 

iRailev J W and V R. Basili, “A Meta-Model for Software Development Resource 
Expenditures,” Proceedings of the Fifth International Conference on Software Engineer- 
ing. New York: IEEE Computer Society Press, 1981 

^Bailey, J. W„ and V. R. Basili, “Software Reclamation: Improving 

Reusability,” Proceedings of the Eighth Annual National Conference on Ada Technology, 

March 1990 

10 Bailey, J. W., and V. R. Basili, “The Software-Cycle Model for Re-Engineering and 
Reuse,” Proceedings of the ACM Tri-Ada 91 Conference, October 1991 

'Basili, V. R., “Models and Metrics for Software Management and Engineering,” 
ASME Advances in Computer Technology, January 1980, vol. 1 

Basili, V. R., Tutorial on Models and Metrics for So^reManagen^t^E^eering. 
New York: IEEE Computer Society Press, 1980 (also designated SEL-80 008) 

3 Basili, V. R., “Quantitative Evaluation of Software Methodology,” Proceedings of the 
First Pan-Pacific Computer Conference, September 1985 

’Basili, V. R., Maintenance = Reuse-Oriented Software Development, University of 
Maryland, Technical Report TR-2244, May 1989 

’Basili, V. R., Software Development: A Paradigm forthe Future, University of Maryland, 
Technical Report TR-2263, June 1989 

8 Basili, V. R., “Viewing Maintenance of Reuse-Onented Software Development, 
IEEE Software , January 1990 

'Basili, V. R„ and J. Beane, “Can the Parr Curve Help With Manpower Distribution 
and Resource Estimation Problems?,” Journal of Systems and Software, February 198 , 

vol. 2, no. 1 

^Basili V. R.,G. Caldiera, and G. Cantone, “A Reference Architecture for the Compo- 
nent Factory, ’’ACM Transactions on Software Engineenng and Methodology, January 

1992 


BI-6 


SEL-92-004 page 426 



10 Basili, V., G. Caldiera, F. McGany, et al., “The Software Engineering Laboratory— 
An Operational Software Experience Factory,” Proceedings of the Fourteenth Interna- 
tional Conference on Software Engineering (ICSE 92), May 1992 

1 Basili, V. R., and K. Freburger, “Programming Measurement and Estimation in the 
Software Engineering Laboratory,” Journal of Systems and Software, February 1981, 
vol. 2, no. 1 

3 Basili, V. R., and N. M. Panlilio-Yap, “Finding Relationships Between Effort and 
Other Variables in the SEL,” Proceedings of the International Computer Software and 
Applications Conference, October 1985 

4 Basili, V. R., and D. Patnaik,^! Study on Fault Prediction and Reliability Assessment in 
the SEL Environment, University of Maryland, Technical Report TR-1699, August 1986 

2 Basili, V. R., and B. T. Penicone, “Software Errors and Complexity: An Empirical 
Investigation,” Communications of the ACM, January 1984, vol. 27, no. 1 

1 Basili, V. R., and T. Phillips, “Evaluating and Comparing Software Metrics in the Soft- 
ware Engineering Laboratory,” Proceedings of the ACM SIGMETRICS Symposium/ 
Workshop: Quality Metrics, March 1981 

3 Basili, V. R., and C. L. Ramsey, “ARROWSMITH-P — A Prototype Expert System for 
Software Engineering Management,” Proceedings of the IEEE /Ml 1 RE Expert Systems 
in Government Symposium, October 1985 

Basili, V. R., and J. Ramsey, Structural Coverage of Functional Testing, University of 
Maryland, Technical Report TR-1442, September 1984 

Basili, V. R., and R. Reiter, “Evaluating Automatable Measures for Software Develop- 
ment,” Proceedings of the Workshop on Quantitative Software Models for Reliability, 
Complexity, and Cost. New York: IEEE Computer Society Press, 1979 

5 Basili, V. R., and H. D. Rombach, “Thiloring the Software Process to Project Goals 
and Environments,” Proceedings of the 9th International Conference on Software Engi- 
neering, March 1987 

5 Basili, V. R., and H. D. Rombach, ‘TAME: Thiloring an Ada Measurement Envi- 
ronment,” Proceeding s of the Joint Ada Conference, March 1987 

5 Basili, V. R.,andH. D. Rombach, “TAME: Integrating Measurement Into Software 
Environments,” University of Maryland, Technical Report TR-1764, June 1987 

6 Basili, V. R., and H. D. Rombach, “The TAME Project: Tbwards Improvement- 
Oriented Software Environments,” IEEE Transactions on Software Engineering, June 
1988 

7 Basili, V. R., and H. D. Rombach, Towards A Comprehensive Framework for Reuse: A 
Reuse-Enabling Software Evolution Environment, University of Maryland, Technical 
Report TR-2158, December 1988 


BI-7 


SEl^92-004 page 427 



8 Basili V. R., and H. D. Rombach, Towards A Comprehensive Framework for Reuse: 
Model-Based Reuse Characterization Schemes , University of Maryland, Technical 
Report TR-2446, April 1990 

Vasili, V. R., and H. D. Rombach, “Support for Comprehensive Reuse,” Software En- 
gineering Journal, September 1991 

3 Basili V. R-, and R. W. Selby, Jr., “Calculation and Use of an Environment’s Charac- 
teristic Software MetricSet ? Proceedings of the Eighth International Conference on Soft- 
ware Engineering. New York: THEE Computer Society Press, 1985 

Basili, V. R., and R. W. Selby, “Comparing the Effectiveness of Software Testing Strat- 
egies ” IEEE Transactions on Software Engineering , December 1987 

3 Basili V. R., and R. W. Selby, Jr., “Four Applications of a Software Data Collection 
and Analysis Methodology,” Proceedings of the NAT&Advanced Study Institute, August 

1985 

5 Basili, V. R., and R. Selby, “Comparing the Effectiveness of Software Testing Strate- 
gies,” IEEE Transactions on Software Engineering , December 1987 

Vasili, V. R., and R. W. Selby, “Paradigms for Experimentation and Empirical Studies 
in Software Engineering,” Reliability Engineering and System Safety, January 1991 

4 Basili, V. R., R. W. Selby, Jr., and D. H. Hutchens, “Experimentation in Software 
Engineering,” IEEE Transactions on Software Engineering, July 1986 

2 Basili, V. R., R. W. Selby, and T. Phillips, “Metric Analysis and Data Validation Across 
FORTRAN Projects,” IEEE Transactions on Software Engineering, November 1983 

2 Basili, V. R., and D. M. Weiss, A Methodology for Collecting Valid Software Engineering 
Data, University of Maryland, Technical Report TR-1235, December 1982 

3 Basili, V. R., and D. M. Weiss, “A Methodology for Collecting Valid Software Engi- 
neering Data,” IEEE Transactions on Software Engineering , November 1984 

1 Basili, V. R., and M. V. Zelkowitz, “The Software Engineering Laboratory: Objec- 
tives,” Proceedings of the Fifteenth Annual Conference on Computer Personnel Research, 
August 1977 

Basili, V. R., and M. V. Zelkowitz, “Designing a Software Measurement Experiment, 
Proceedings of the Software Life Cycle Management Workshop, September 1977 

1 Basili V. R., and M. V. Zelkowitz, “Operation of the Software Engineering Labora- 
tory,” 'Proceedings of the Second Software Life Cycle Management Workshop, August 
1978 

1 Basili, V. R., and M. V. Zelkowitz, “Measuring Software Development Characteristics 
in the Local Environment,” Computers and Structures, August 1978, vol. 10 


BI-8 


SEL-92-004 page 428 



Basili, V. R., and M. V. Zelkowitz, “Analyzing Medium Scale Software Development/’ 
Proceedings of the Third International Conference on Software Engineering. New York: 
IEEE Computer Society Press, 1978 

9 Booth, E. W., and M. E. Stark, “Designing Configurable Software: COMPASS Imple- 
mentation Concepts,” Proceedings of Tri-Ada 1991, October 1991 

10 Booth, E. W., and M. E. Stark, “Software Engineering Laboratory Ada Performance 
Study — Results and Implications,” Proceedings of the Fourth Annual NASA Ada User’s 
Symposium , April 1992 

10 Briand, L. C., and V. R. Basili, “A Classification Procedure for the Effective Manage- 
ment of Changes During the Maintenance Process,” Proceedings of the 1 992 IEEE Con- 
ference on Software Maintenance (CSM 92), November 1992 

10 Briand, L. G, V. R. Basili, and C. J. Hetmanski, “Providing an Empirical Basis for 
Optimizing the Verification and Testing Phases of Software Development,” Proceed- 
ings of the Third IEEE International Symposium on Software Reliability Engineering 
(ISSRE 92), October 1992 

^riand, L. G, V. R. Basili, and W. M. Thomas, A Pattern Recognition Approach for Soft- 
ware Engineering Data Analysis, University of Maryland, Technical Report TR-2672, 
May 1991 

5 Brophy, C. E., W. W. Agresti, and V. R. Basili, “Lessons Learned in Use of Ada- 
Oriented Design Methods,” Proceedings of the Joint Ada Conference, March 1987 

6 Brophy, C. E., S. Godfrey, W. W. Agresti, and V. R. Basili, “Lessons Learned in the 
Implementation Phase of a Large Ada Project,” Proceedings of the Washington Ada 
Technical Conference, March 1988 

2 Card, D. N., “Early Estimation of Resource Expenditures and Program Size,” 
Computer Sciences Corporation, Technical Memorandum, June 1982 

2 Card, D. N., “Comparison of Regression Modeling Techniques for Resource Estima- 
tion,” Computer Sciences Corporation, Technical Memorandum, November 1982 

3 Card, D.N., “A Software Technology Evaluation Program,” Annais do XVIII 
Congresso Nacional de Informatica, October 1985 

5 Card, D. N., and W. W. Agresti, “Resolving the Software Science Anomaly,” Journal 
of Systems and Software, 1987 

6 Card, D. N., and W. W. Agresti, “Measuring Software Design Complexity,” Journal of 
Systems and Software , June 1988 

4 Card, D. N., V. E. Church, and W. W. Agresti, “An Empirical Study of Software Design 
Practices,” IEEE Transactions on Software Engineering, February 1986 


BI-9 


SEL-92-004 page 429 



Card. D. N„ V. E. Church, W. W. Agresti, and Q. L. Jordan, “A Software Engineering 
View of Flight Dynamics Analysis System,” Parts I and n. Computer Sciences Corpora- 
tion, Technical Memorandum, February 1984 

Card, D. N„ Q. L. Jordan, and V. E. Church, “Characteristics of FORTRAN Modules,” 
Computer Sciences Corporation, Tfechnical Memorandum, June 1984 

5 Card, D.N., F.E.McGany, and G.TPage, “Evaluating Software Engineering 
Technologies,” IEEE Transactions on Software Engineering, July 1987 

3 Card, D. N., G. T. Page, and F. E. McGarry, “Criteria for Software Modularization,” 
Proceedings of the Eighth International Conference on Software Engineering. New York: 
TF.F.F. Computer Society Press, 1985 

1 Chen, E., and M. V. Zelkowitz, “Use of duster Analysis To Evaluate Software Engi- 
neering Methodologies,” Proceedings of the Fifth International Conference on Software 
Engineering. New York: IEEE Computer Society Press, 1981 

“Church, V.E., D.N.Card, W.W. Agresti, and Q.L. Jordan, “An Approach for 
Assessing Software Prototypes,” A CM Software Engineering Notes, July 1986 

2 Doer£linger, C. W., and V. R. Basili, “Monitoring Software Development Through 
Dynamic Variables,” Proceedings of the Seventh International Computer Software and 
Applications Conference. New York: IEEE Computer Society Press, 1983 

Doubleday, D., ASAP: An Ada Static Source Code Analyzer Program, University of 
Maryland, Technical Report TR-1895, August 1987 (NOTE: 100 pages long) 

6 Godfrey, S., and C. Brophy, “Experiences in the Implementation of a Large Ada 
Project,” Proceedings of the 1988 Washington Ada Symposium, June 1988 

5 Jeffery, D. R., and V. Basili, Characterizing Resource Data: A Model for Logical 
Association of Software Data, University of Maryland, Tfechnical Report TR-1848, May 
1987 

6 Jeffery, D. R., and V. R. Basili, “Validating the TAME Resource Data Model,” Pro- 
ceedings of the Tenth International Conference on Software Engineering, April 1988 

5 Mark, L., and H. D. Rombach, A Meta Information Base for Software Engineering, 
University of Maryland, Tfechnical Report TR-1765, July 1987 

6 Mark, L., and H. D. Rombach, “Generating Customized Software Engineering 
Information Bases From Software Process and Product Specifications,” Proceedings of 
the 22nd Annual Hawaii International Conference on System Sciences, January 1989 

5 McGarry, F. E., and W. W. Agresti, “Measuring Ada for Software Development in the 
Software Engineering Laboratory (SEL),” Proceedings of the 21st Annual Hawau 
International Conference on System Sciences, January 1988 

BI-10 


SEL-92-004 page 430 



7 McGany,F.,L. Esker.andK. Quimby, “Evolution ofAdaTechnologyinaProduction 
Software Environment,” Proceedings of the Sixth Washington Ada Symposium 
(WADAS), June 1989 

3 McGarry, F. E., J. Valett, and D. Hall, “Measuringthe Impact of Computer Resource 
Quality on the Software Development Process and Product,” Proceedings of the 
Hawaiian International Conference on System Sciences, January 1985 

3 Page, G., F. E. McGarry, and D. N. Card, “A Practical Experience With Independent 
Verification and Validation,” Proceedings of the Eighth International Computer Software 
and Applications Conference, November 1984 

5 Ramsey, C. L., and V. R. Basili, “An Evaluation of Expert Systems for Software Engi- 
neering Management,” IEEE Transactions on Software Engineering, June 1989 

3 Ramsey, J., and V. R. Basili, ‘Analyzing the Test Process Using Structural Coverage,” 
Proceedings of the Eighth International Conference on Software Engineering. New York: 
IEEE Computer Society Press, 1985 

5 Rombach, H. D., “A Controlled Experiment on the Impact of Software Structure on 
Maintainability,” IEEE Transactions on Software Engineering, March 1987 

8 Rombach, H. D., “Design Measurement: Some Lessons Learned,” IEEE Software, 
March 1990 

9 Rombach, H. D ., “Software Reuse: A Key to the Maintenance Problem,” Butterworth 
Journal of Information and Software Technology, January/February 1991 

6 Rombach, H. D., and V. R. Basili, “Quantitative Assessment of Maintenance: An 
Industrial Case Study,” Proceedings From the Conference on Software Maintenance, 
September 1987 

6 Rombach, H. D., andL. Mark, “Software Process and Product Specifications: ABasis 
for Generating Customized SE Information Bases,” Proceedings of the 22nd Annual 
Hawaii International Conference on System Sciences, January 1989 

7 Rombach, H. D., and B. T. Ulery, Establishing a Measurement Based Maintenance 
Improvement Program : Lessons Learned in the SEL, University of Maryland, Technical 
Report TR-2252, May 1989 

10 Rombach, H. D., B. T. Uleiy, and J. D. Valett, “Ibward Full Life Cycle Control: 
Adding Maintenance Measurement to the SEL,” Journal of Systems and Software, 
May 1992 

6 Seidewitz, E., “Object-Oriented Programming in Smalltalk and Ada,” Proceedings 
of the 1987 Conference on Object-Oriented Programming Systems , Languages, and 
Applications, October 1987 


BI-11 


SEL-92-004 page 431 



5 Seidewitz, E„ “General Object-Oriented Software Development: Background and 
Experience,” Proceedings of the 21st Hawaii International Conference on System 

Sciences , January 1988 


6 Seidewitz, E., “General Object-Oriented Software Development with Ada: A Life 
Cycle Approach,” Proceedings of the CASE Technology Conference, Apnl 1988 

9 Seidewitz, E., “Object-Oriented Programming Through Type Extension in Ada 9X, 
Ada Letters , March/April 1991 


10 Seidewitz, E., “Object-Oriented Programming With Mixins in Ada,” Ada Letters , 
March/April 1992 

4 Seidewitz, E, and M. Stark, “Tbwards a General Object-Oriented Software Develop- 
ment Methodology,” Proceedings of the First International Symposium on Ada for the 
NASA Space Station, June 1986 

9 Seidewitz, E., and M. Stark, “An Object-Oriented Approach to Parameterized Soft- 
ware in Ada,” Proceedings of the Eighth Washington Ada Symposium, June 1991 

8 Stark, M., “On Designing Parametrized Systems Using Ada,” Proceedings of the 
Seventh Washington Ada Symposium, June 1990 


7 Stark, M. E. and E. W. Booth, “Using Ada to Maximize Verbatim Software Reuse, 
Proceedings ofTRI-Ada 1989, October 1989 


5 Stark, M., and E. Seidewitz, “Tbwards a General Object-Oriented Ada lifecycle,” 
Proceedings of the Joint Ada Conference, March 1987 

10 Straub, P. A, and M. V. Zelkowitz, “On the Nature of Bias and Defects in the Soft- 
ware Specification Process,” Proceedings of the Sixteenth International Computer Soft- 
ware and Applications Conference (COMPSAC 92), September 1992 

8 Straub, P. A., and M. V. Zelkowitz, “PUC: A Functional Specification Language for 
Ada,” Proceedings of the Tenth International Conference of the Chilean Computer Science 

Society, July 1990 

7 Sunazuka, T„ and V. R. Basili, Integrating Automated Support for a Software Manage- 
ment Cycle Into the TAME System, University of Maryland, Technical Report TR-Z289, 

July 1989 

10 Tian, J. A. Porter, and M. V. Zelkowitz, “An Improved Classification Tree Analysis of 
High Cost Modules Based Upon an Axiomatic Definition of Complexity,” Proceedings 
of the Third TF.FF. International Symposium on Software Reliability Engineenng 
(ISSRE 92), October 1992 

Turner, C., and G. Caron, A Comparison of RADC and NASAISEL Software Develop- 
ment Data, Data and Analysis Center for Software, Special Publication, May 1981 


BI-12 


S EL-92-004 page 432 



10 Valett, J. D., “Automated Support for Experience-Based Software Management,” 
Proceeding s of the Second Irvine Software Symposium (ISS ’92), March 1992 

5 Valett, J. D., and F. E. McGarry, “A Summaiy of Software Measurement Experiences 
in the Software Engineering Laboratory,” Proceedings of the 21st Annual Hawaii 
International Conference on System Sciences , January 1988 

3 Weiss, D. M., and V. R. Basili, “Evaluating Software Development by Analysis of 
Changes: Some Data From the Software Engineering Laboratory,” IEEE Transactions 
on Software Engineering , February 1985 

5 Wu, L., V. R. Basili, and K. Reed, “A Structure Coverage Tbol for Ada Software Sys- 
tems,” Proceedings of the Joint Ada Conference, March 1987 

1 Zelkowitz, M. V., “Resource Estimation for Medium-Scale Software Projects,” Pro- 
ceedings of the Twelfth Conference on the Interface of Statistics and Computer Science. 
New York: IEEE Computer Society Press, 1979 

2 Zelkowitz, M. V, “Data Collection and Evaluation for Experimental Computer 
Science Research,” Empirical Foundations for Computer and Information Science (Pro- 
ceedings), November 1982 

6 Zelkowitz, M. V., “The Effectiveness of Software Prototyping: A Case Study,” Pro- 
ceedings of the 26th Annual Technical Symposium of the Washington , D. C., Chapter of the 
ACM, June 1987 

6 Zelkowitz, M. V., “Resource Utilization During Software Development,” Journal of 
Systems and Software, 1988 

8 Zelkowitz, M. V., “Evolution Towards Specifications Environment: Experiences With 
Syntax Editors,” Information and Software Technology, April 1990 


BI-13 


SEL-92-004 page 433 



NOTES: 

°This document superseded by revised document. 

iThis article also appears in SEL-82-004, Collected Software Engineering Papers: 
Volume I, July 1982. 

2 This article also appears in S EL-83-003, Collected Software Engineering Papers. 
Volume II, November 1983. 

3 This article also appears in SEL-85-003, Collected Software Engineering Papers. 
Volume III, November 1985. 

4 This article also appears in SEL-86-004, Collected Software Engineering Papers: 
Volume IV, November 1986. 

5 This article also appears in SEL-87-009, Collected Software Engineering Papers: 
Volume V, November 1987. 

6rhis article also appears in SEL-88-002, Collected Software Engineering Papers: 
Volume VI, November 1988. 

7 This article also appears in SEL-89-006, Collected Software Engineering Papers: 
Volume VII, November 1989. 

8 This article also appears in SEL-90-005, Collected Software Engineering Papers: 
Volume VIII, November 1990. 

9rhis article also appears in SEL-91-005, Collected Software Engineering Papers: 
Volume DC, November 1991. 

lOxhis article also appears in SEL-92-003, Collected Software Engineering Papers: 
Volume X, November 1992. 


BI-14 


SEL-92-004 page 434 



