NASA Technical Memorandum 100999 



Systems Autonomy Technology 
Executive Summary and 
Program Plan 

Ames Research Center 



(llASl-Tfl-1C0999) SSSIiaS ICICJCEX 1189-160^5 

IICBkCICGY: EXECCIIVE £011BA£1 AMD fBOG£Afi 
tlAS (KASl) U7 p CSCi. 09b 

Unclas 
G3/59 0191235 



December 1987 



fVI/NSA 

National Aeronautics and 
Space Adnninistration 



NASA Technical Memorandum 100999 



Systems Autonomy Technology 
Executive Summary and 
Program Plan 



Ames Research Center 
Goddard Space Flight Center 
Jet Propulsion Laboratory 
Johnson Space Center 
Kennedy Space Center 
Langley Research Center 
Lewis Research Center 
Marshall Space Flight Center 



December 1987 



ru/NSA 

National Aeronautics and 
Space Administratbn 



Ames Research Center 

IVIoffett Field, California 94035 



PREFACE 

This document was originally prepared and written as a Program Plan without the 
normal publication standards of a NASA Technical Memorandum. 

Because of its significance as an Agency Plan, and to make it a more retriev- 
able document, it is being reproduced in its original form as a NASA TM. 



PRECEDING PAGE BUNK NOT FILMED 



111 



INTENTIONALLY 8LANR 



EXECUTIVE SUMMARY 



PRECEDING PAGE BLANK NOT FJUiSD 



ufflUiL 



JNTENTIONALU 81ANS 



SYSTEMS AUTONOMY TECHNOLOGY EXECUTIVE SUMMARY 
TABLE OF CONTENTS 

Page 

GOALS AND OBJECTIVE 1 

PROGRAMMATIC AND TECHNICAL JUSTIFICATION 1 

PROGRAM CONTENT 2 

Demonstrations 2 

Q Space Station Demonstrations 2 

o Operations Demonstrations 3 

Core Technology 4 

Q Planning and Reasoning 4 

o Control Execution 6 

o Operator Interface 6 

o Systems Architecture and Integration 6 

COLLABORATION WITH OTHER AGENCIES/ INDUSTRY 7 

SCHEDULE 7 

FUNDING 9 

MANPOWER 11 



PUEQLDm^ PAGE BLANK NOT FILN4Ei 



u 



vil 

iifi^ y 1 I NIENTiONAlU BUNi 



SYSI'EMS AUTONOMY TECHNOLOGY PROGRAM PLAN 
EXECUTIVE SUMMARY 

(30AL AND UBJEC FIVES 

Program Bgal 

The Systems Autonomy Technology Program (SATP) is an aggressive new 
program with the overall Program Goal to develop, integrate, and 
demonstrate the technology to enable Intelligent Autonomous Systems for 
future NASA missions. Some of the more important space missions which 
will require this technology are those future national space challenges 
recommended by the Report of the Presidential Commission on Space: (i) 
establishment of a permanent presence in space through the Space Station, 
(2) establishment of a lunar outpost by 2005 to serve as a base for 
future exploration of the solar system, and (3) establishment of a Mars 
outpost by 2015 far further manned and robotic exploration of Mars. 

Pco..y.r.=>.ffl.....Qbiec t i ves 

F"'rogram Objectives to achieve this Goal are: 

(1) Significantly advance the technologies for cooperating 
intelligent systems; 

(2) Demonstate, evaluate, and validate technologies in operational 
environments ; 

(3) Transfer the technology for user implementation. 

PROGRAMMATIC AND TECHNICAL JUSTIFICATION 

E.LQ3r3!B!Mtic Justif icatipri 

To preserve the nation's leadership position in space, it is necessary 
that NASA provide a research and development focus for development and 
application of intelligent autonomous systems technology. This 
technology is crucial to successful accomplishment of the national 
space challenges, and to remain ahead of international competition. 

The NASA Office of Aeronautics and Space Technology (OAST) has initiated 
the Systems Autonomy Technology Program (SATP) to provide this focus on 
Intelligent Autonomous Systems technology, and to provide the required 
technology for successfully accomplishing the National Space Challenges. 

lec.!;! n i c:.a 1 J.u s t i . f i c a t i o n. 

For NASA to be successful in these future space programs it is 
imperative that space operations be more efficient and less costly. For 
example, inadequate automation on Space Station will mean that 
astronaut flight crews will spend more time on "house-keeping" chores 
and less timp on scientific research. With inadequate automation, 
ground support operations and ground mission operations will become 
larger and costlier to support a permanent presence in space. With 
inadequate autuniation, mission success rate will be low due to impact 
of unanticipated anomalies. 

State-of-the-Art: Current intelligent knowledge-based systems in 
operational use Bre generally small standalone systems which are slow 
and static. TFiat is, they are not integrated with other systems, s.re 
too slow for critical real-time performance, and have no capability to 
improve or e;;pand their knowledge autonomously. 



1 



ORIGINAL PAGE IS 
OF POOR QUALITY 



Knowledge-based systems currently are also "fragile". That is, they 
begin to fail rapidly when used at the limits of their knowledge. 
Another serious limitation is the lack of insight in how to validate 
knowledge-based systems. Current validation methodologies have not 
had to deal with scenarios which include unanticipated environments. 

Technical Challenges - Technical challenges to achieve program 
objectives include: 

(1) Real-time Knowledge-based Systems. 

Diagnosis and planning decisions in milliseconds. 

(2) Dynamic Knowledge Acquisition. 

Automated knowledge base expansion in real time (learning). 

(3) Robust Planning and Reasoning. 

Reliable decisions in unanticipated environments. 

(4) Cooperating Knowledge-based Systems. 

Mutual re<50urce planning decisions between intelligent systems. 

(5) Validation Methodologies. 

Evaluation criteria for decision quality based on fundamental theory, 

Payoffs - Automation through Intelligent Autonomous Systems will 
provide significant piayoffs in the follov-jing areas; 

(1) Reduced mission operations costs through automation of labor 
intensive operations (Reduce manpower); 

(2) Increased mission productivity through automation of routine 
onboard housekeeping functions (Offload astronaut time); 

(3) Increased mission success probability through automation of 
real-time contingency replanning (Save experiments or possibly entire 
missions) . 

PROGRAM CaNTENT 

The program objectives will be accomplished by a Core Technology 
research program closely coupled with several major Demonstration 
Projects. The Demonstration Projects provide a means to evaluate and 
validate concepts developed through scientific and engineering 
research in the Core Technology. 

Technology transfer will occur through design criteria from 
Demonstrations and functional criteria from Core being transferred to 
user organisations for operational implementation. 

Bemoostratioj IB 

1. Space Station Demonstrations (SADP) . 

a. Thermal Control Systems (TCS). This joint effort between ARC and 
JSC will demonstrate technologies in 1988 for autonomous thermal 
control system operation on the Space Station. This demonstration 
is significant in that it will be one of the first knowledge-based 
systems to control a large complex system in real-time and with real 
operational hardware. Key technology capabilities to be 
demonstrated include fault diagnosis and correction advice of 
anticipated faults, incipient failure prevention through trend 
analysis, and explanation displays. Key technology thrusts include 
causal modeling of a complex electrical/mechanical system, and 
combined causal models and heuristic rules for more intelligent 
reasoning, trend analysis heuristic rules, and validation 
me 1 1 »od o 1 og i es . 



b. Thermal /Pov^er Control System. This joint effort between ARC, 
LeRC, MSFC, and JSC will demonstrate technologies in 1990 for 
autonomous control of the thermal and power system operation on 
Space Station. This demonstration is significant in that it will 
show coordinated simultaneous control of two large complex systems. 
There is great potential for significant operation cost reduction 
through the use of a mature autonomous power system due to its 
unique role among tlie onboard systems. Specific technology 
capabilitie??, to be demonstrated include fault 

detection/classification and isolation methodologies, system 
restoration strategies, replanning in the face of uncertainty, and 
operator training methodologies. Key technology thrusts include 
causal modeling of complex electrical/mechanical systems, 
cooperation of two knowledge-based systems, and validation 
methodolgies . 

c. Hierarchical Knowledge-Based Systems. In this SADP 1993 
demonstration, the key technology thrust will be to evaluate and 
validate met fiodologies for expert system control of more than two 
Space Station subsytems through hierarchical architectural 
strategies. 

d. Distributed Knowledge-Based Systems. In this SADP 1996 
demonstration, the key technology thrust will be to evaluate and 
validate methodologies for expert system control of multiple Space 
Station subsystems through distributed architectural strategies. 

I. Operations Demonstrations. 

A set of specific Domain Demonstrations has been planned to 
facilitate technology transfer to domains other that Space Station 
and to insure that generic technology developed on Space Station 
testbeds is practical for many NASA applications. 

a. Shuttlt? Flight Control Room Operations. A rule-based integrated 
communications officer (INCO) online expert system will be developed 
and demonstrated in 1988, and advanced powerful graphics 
capabilities will be incorporated in 1989. This demonstration is 
significant in that it will be the first hJASA knowledge-based system 
to be implemented into a real— time operational environment. The 
expert system will aid Flight Control operations at JSC with minimal 
backroom support during STS missions, thus reducing manpower 
requirements for flight controllers who support Space Shuttle system 
operations. 

b. Launch Cljaerations. The demonstrations at KSC will include 
systems software and hardware for autonomous diagnostics and control 
of interactive complex electro/mechanical launch processing systems 
that vjill perform better than system engineers. Key technology 
capabilities demonstrated will include goal-directed 

control /recon figuration , fault recognition /warning /diagnosis, 
systems scheduling/rescheduling, automated trend failure analysis, 
and intelligent user interfaces. Key technology thrusts include 
model -bas.FHl siiiiu la tiun , CAD/CAM knowledge— base capture, explanation 
displays, Jimited uncertainty management, and validation techniques. 



ORmimi PAGE !S 
OF FOOR QUA, TV 



c. Mission Operations Ground Data Systems. Demonstrations will 
develop and demonstrate technologies which will enable and enhance 
the mul ti -mission monitoring and diagnosis of ground data systems 
for unmariiiRd sp;irecraft by emphasizing tools commonly applicable to 
the automated monitoring of spacecraft telemetry and space flight 
operation? ground data systems. The technology demonstrations at 
JPL include a multi-mission telemetry monitoring workstation for 
spacecraft engineering telemetry in 1988, automated monitoring of 
Voyager/Nepti.me encourtter in 1989/90, automatic command verification 
and monitoring for spacecraft in 1992/93, and dynamically 
configurable and teachable ground data system controller in 1994/95. 

Cor'e TechriolcMiy 

3. Intentionally Blank. 

4. Planning and Reasoning. 

4.1 Reascming Under Uncertainty — The ability to make sensible 
judgements and carry out reasonable actions when world knowledge is 
imprecise or incomplete, or heuristics and models have built— in 
uncertainty, or actions have uncertain effects. 

Ongoing interna] research will focus on probabilistic methods for 
uncertainty management. External collaborations will include research 
on fuzzy logic and integration of decision theoretic and heuristic 
methods. Work will also be sponsored in developing methodologies and 
tools for combining classical methods with AI methods. 

4.2 Learning - The ability to alter and improve all functionalities 
as conditi'ins change and knowledge is added over time. Learning may 
occur manually by being taught or automatically by experimentation, 
generalization, or discovery. 

Internal work will be in the areas of learning by discovery and 
e;<planatinn based generalization. External collaborations with 
Carnegie-Mellon on learning by experimentation, and with the 
University of Michigan on learning by search will continue. Major 
milestones include an initial demonstration of learning by 
experimentation in a robotic environment during 1989 and 
sel f — impr oving knowledge bases as part of the 1990 Systems Autonomy 
Demonstration Project. During 1991-1992 discovery-based learning by 
introspection will he demonstrated on a large database of sensor— based 
information on a testbed for Space Station such as the Data Management 
System. 

4.3 Causal Modeling - The ability to utilize structural and 
functional information about a device, along with the physical laws 
that govern tlie device, to simulate and reason about the device. 

Internally, the 1988 SADP Space Station Thermal System will be used 
as a test iJomain for the combination of heuristic and model— based 
methods in diagnosing flaws in complex systems. Externally the 
University of Arizcina will be funded in integration of 
knowledge— based and traditional simulation methods and Stanford 
University in logical representations of structure and function. A 
major miles I one is the successful demonstration of these methods 
during thp 1988 SADP Thermal System demonstration. More 
sophisticated methods will be employed in work on the Hubble Space 
Telescopt? BriiJ other projects that involve modeling complex devices. 

4 



l^l. 






4.4 KnowlpcJqB Acquisition - The ability to preserve the "corporate 
memory", i.e. to ensure that all the facts, heuristics, and other 
information gained during the design, construction, and testing of a 
device sre available in a practical and usable form during the 
operational life of the device. 

Internal work will be focused on studying the Hubble Space 
Telescope { HBT ) and the Space Infrared Telescope Facility (SIRTF) as 
test domains for three research areas: integration of knowledge 
acquisiLion into the design, construction, and testing process, 
acquisition of knowledge from large numbers of experts, and large 
knowledge base technology. MSFC, in collaboration with ARC and 
Stanford, will concentrate on the latter two topics in the HST 
domain, while AR(" will utilize SIRTF for explorations in the first 
area. It will be shown how the products of traditional engineering 
activities supjjorting design and testing in major products can be 
utilized in knowledge acquisition during 1988 and 1989. A very 
large knowledge base system will be demonstrated during 1991. 
Methodologies for the combination of expertise from at least a dozen 
experts will be presented during 1990. 

4.5 Advanced Planrtiny Methods — The ability to take a set of 
goals, design a plan to utilize existing and potential resources to 
achieve titose goals, monitor the execution of that plan, and 
dynamically alter the plan when initial assumptions prove incorrect. 

Behavioral net architectures will be investigated at LaRC for 
application to the problem of planning and scheduling, and for the 
develoment of a prototype domain-independent planning and 
sclieduling tool. At ARC, internal work will proceed on testing the 
limits of current Al-based scheduling methodologies applied to NASA 
problems, particular ly in space science. Work on dynamic 
replanning will continue and research will be initiated on the 
application ci f skeletal planning and plan refinement to NASA 
domains. Externally there will be collaboration with work at JPL 
in sensor— based planning, with industry in the development of a 
Truth Mair»tenance System-based planner, and at USC— ISI in the 
application of DARPA-sponsored methods to NASA problems. Current 
methodologies for lieuristic scheduling will be demonstrated in a 
Pioneer— Verii.is experiment for automated "orbit building". The JPL 
work has milestones in a sensor— rich subsystem of Space Station 
during 19B8 and 1989. That work and other internal and external 
efforts will be derrione-t rated as part of scheduling the power 
subsystem <jf Space Btation during the 1990 SADP demonstration. 

4.6 Cooperat ifig Knovjledge Based Systems — The ability to provide 
for synergistic cooperation among several significant 
knowledge- based sy steals in a complex environment. 

Internal rf.>SEart:h focus will be on the 1990 SADP demonstration; a 
demonstration of coordinated control of thermal and power 
subsystems. The use of the Hubble Space Telescope will be 
considered as a second domain for cooperative systems. Externally 
work: will be supported at the Stanford Knowledge Systems Laboratory 
in blackiioard architectures for distributed control of 
knowledge-based systems, at the University of Maryland in potential 
hierarchical control methods, and MIT in languages for command of 
multiple Fiystems. In addition, a major new effort, jointly 
sponsored with DARPA, will begin at Stanford, SRI, and Rockwell in 
methodologies for interacting intelligent agents in the domain of 
Space Station Construction. Blackboard architectures will be 
demonstraled in NASA domains during 1988. 



ORIGINAL PAGE IS 
OF POOR QUAUTY 



4.7 Val id'^tior) Mel.hodologies — The ability to validate the 
correctneBB of the facts, heuristics, and models used by a 
knov^ledge-based system and to verify that the knowledge has been 
correctly represensen ted within the system. 

Reliability and performance validation methods for life-critical 
knowledge-based systems will be investigated at LaRC. Proposed 
techniques and prototype tools will he applied to knowledge-based 
systents underdevelopment at LaRC such as rule-based systems for 
fault prp?dictian and trend analysis, and model-based systems for 
fault diagncisis and recovery planning. Activities at ARC include 
a NASA/ Indus I rial workshop which was held in 1987 to begin to 
understand in<3 the practical issues of knowledge— based system 
validation in NASA domains with a particular focus on Space Station. 
The result of titat workshop will be a detailed report to appear in 
early fiscal 19B8. Ilie first major milestone will be the development 
of an accefitefl validation methodology for the 1988 SAUP Thermal 
Systein demnnstration . Validation work will also occur as part of the 
work described above on multiple-expert knowledge acquisition and 
large knowledge base technology. This will produce results in 
parallel with those milestones in 1989 and 1990. 

5. Control Execution - The possibility of developing a mathematical 
theory will he e«p.lr)red that enables the design of symbolic 
controllers for dynamic systems. The approach through in— house 
research and university grants will be to build up predicate 
calculus to include time and dynamics concepts within the syntax. 
Specific research products include (1) ways for translating 
sentences of the command sequences into arithmetic functions of 
time, (2) ways for- representing estimated states and time histories 
symbolically, and (3) means for expressing global system properties 
such as staljility, robustness, and disturbance rejection. 

6. Operator Interface - Human machine interfaces will be developed 
that enable communication with intelligent, autonomous systems in 
space in a manner natural to the human operator. Emphasis will be 
placed on "intelligent" systems which satisfy human factors 
reqt.iiremen ts, and v-jhere tfie distribution of the workload between 
human and machine is optimized. Specific research products include 
(1) design decision aids and rapid prototyping tools, (2) more 
natural human— computer dialog systems, (3) advanced display/control 
concepts, and (4) computer aided interface design system. 

7. Systems Architecture and Integration - ARC objective is to 
develop system?; r.oncepts required for the implementation of robust 
knowledge-based systems in spaceborne applications. Specific tasks 
include (.1) design and development of the spaceborne integrated 
symbol ic/numoric multiprocessor computer; (2) definition and 
developmemt of tfie network interfaces and data transmission 
protocol fur a vendor independent environment; (3) development of 
the software protocol and management for large, distributed 
knowledge-based data systems; (4) development of software compilers 
and translators for use in development and operational 
envir-onmen ts; (5) and design and development of verification and 
validation methodologies for faul t— tolerant reconf igurable 

mu 1 tiprocesr.or architectures. Milestones for the spaceborne 
processor includp conceptual design by mid FY-88, detailed design 
by mid FY-9C), with development and qualification by FY-94 . 
Complefrier. tar y to the ARC effort, BSFC will develop knowledge-base 
management tecluiologies needed for automated control center 
operatioiiH througli use of distributed expert systems. 

6 



ORiGfNAL PAGE IS 
OF POOR QUALITY 



COLLABORATIDU WITH OTHER ABENCIES/INDUSTRY 

Significant collaborative efforts have been established with DARPA 
in the area of cooperating intelligent systems, with the Air Force 
in the demon?;tratian and evaluation of automated systems for ground 
mission cimtrol and operation of multiple satellites, and with DARPA 
and DOD in the development of spaceborne processors. Significant 
collaborative ef for+fi have also been established with industry to 
tra.n^fer the automalion technologies for use in highly automated 
commercial spaceborne payloads such as the Industrial Space Facility 
and Space Habitat. 



SCHEDULE 



SYSTEMS AUTONOMY PROBRAM SCHEDULE 



FY 
Demonstrations 

1. Spa. Sta. Demos (SADP) 

2. Operations Demonstrations 

Core Technology 

3. Intentionally Blank 

4. Planning and Reasoning 

4.1 Reas. under Uncert. 

4.2 Learning 

4.3 Causal Modeling/Sim. 

4.4 Knowledge Acquisition 

4.5 Adv. Planning Meth. 

4.6 Coop. K— B Systems 

4.7 Validation Meth. 



5. Control E;;ecutioit 

5.1 Symbolic Control 



: 98 


! 89 


90 


. 91 


: 92 : 


: 1 




2: 




3 : 


: 4 5- 




6: 


78: 





15 



9 
13 
16 



6 
8 
10 



17 



11 



14 
18 



Requirements/ Boa Is 



Eval. & Valid, of 
coop. K-B Sys. 

Alternate domain 
benchmark sys. 



Decision 

robustness. 
Automated K-B 

expansion . 
High qualilty 

decisions. 
Dynamic K-B Acq. 

Real-time 

contingency plan; 
Interactive coop. 

planning . 
Methodology based 

fund, theory. 



Symbolic-algorith. 
cont. interface. 



6. Operator Interface 

6.1 Human Int. Design 



7. Systems Arch./Integ. 
7.1 Symbolic Processor 



Dist. K-B Mgmt 



: 1 : 


4- 


2 3 


5 ! 





Comp. aided inter, 
design tool . 



Real-time 

performance. 
Large K-B software 

to applic. engg . 



ORfGJNAL PASS [£ 
OF POOR QUALITY 



SYSTEMS AUTONOMY PROGRAM SCHEDULE MILESTONES 

Demonstrations 

1. Space Station DemonstrationB (SADP) 

1. Control of single subsystem (Thermal). 

2. Control of two subsystems. (Thermal/Power). 

3. Demo plan for hierarchical control of multiple subsystems. 

2. Operations Demonstrations 

4. Shuttle flight control room automation (INCO). 

5. Shuttle launch ops diagnostics/control automation (ECS). 

6. Space Station ground multi-system diag./cont. auto. (PPCU). 

7. Spac p Station ground hier./dist. diag./cont, auto. (SDMS). 

8. Planf?tary mission ops. automation (Bround Data Systems). 
Core Technology 

3. Intentionally BJ ank 

4. Planning artd Reasoning. 

4.1 Reasoning under Uncertainty. 

1. Major review document of current methdologies. 

2. Demonstration of uncertainty management in 1990 SADP Demo. 

4.2 Learning. 

3. Demonstration of learning by e;;periment, 

4. Demonstration of learning by discovery. 

4.3 Causal Muriel ing/Bimulation . 

5. Df?mo of combined causal models ?< heuristics in 1988 SADP Demo. 

6. Demo of complex modeling of Hubble Space Telescope. 

4.4 Knovj ledge Acquisition. 

7. Demo of design and testing tools. 

8. Demci of combined expertise from over ten experts. 

4.5 Adv. F] arming Metliodologies . 

9. Demo of scheduling in 1990 SADP Demo. 

10. Demo of behavioral network architectures. 

11. Integration of learning with planning methodologies. 

4.6 Cooperating Knowledge— Based Systems. 

12. Demo of blackboard architectures. 

13. Demo of two cooperating subsystems in 1990 SADP Demo. 

14. Hierarchical methodologies for control of multiple subsystems. 

4.7 Validation Methodologies. 

15. Report of Validation Workshop. 

16. Validation methodology for single subsystems. 

17. Validation methodology for multiple subsystem. 

18. Establishment of fundamental validation theory. 

5. Control E;;ecution. 
5.1 Symbol ir Control. 

1. Algorithmic supervisors of arithmetric controllers. 

2. Demo of global sys. prop, of symbolic/algorithmic interfaces. 

6. Operator Interface. 

6.1 Human Interface Design. 

1. Design decision aids and rapid prototyping tools. 

2. Natural human-computer dialog systems. 

3. Advanced display/control concepts. 

4. Computer aided interface design (CAID) system. 

7. Systems Architecture and Integration. 

7.1 Symbolic Processor. 

1. Complete conceptual design. 

2. Com|j]ete detailed design. 

3. Initiate development, testing, and qualification. 

7.2 Distributed K-B Management. 

4. Large distributed Knowledge base models. 

5. Large 1^— B management development tools. 



ORlGfNAL PAGE IS 
OF POOR QUALITY 



FUNDING (*K) 



SYSTEMS AUTUNUMY PRDBRAM FUNDING SUMMARY 



FY 
DEMONSTRATIUNS 

1. Space Station Demos 
a Thermal 

o Thermal /Power 
a Hierarchical 
o Distributed 

2. Operations Demos 

o STS Fit Cont Room Ups 
o Launch Operations 
o Ground Data Systems 



88 


89 


90 


91 


92 


Total 


4763 


4700 


4280 


4300 


3850 


21893 


3399 


3500 


3500 


3500 


3500 


17399 


1905 


500 











2405 


1125 


2300 


2500 


700 





6625 


369 


700 


1000 


2700 


3100 


7869 





O 





lod 


400 


500 


1364 


12O0 


780 


800 


350 


4494 


620 


350 











970 


397 


500 


430 


450 





1777 


347 


350 


350 


350 


350 


1747 



CORE TECHNULUL-iV 



6366 



6948 



7643 



7900 



8583 



37390 



3. Intentionally Blank 



4.7 
4.; 



4. Planning and Reasoning 
4.1 Uncertainty Mgmt. 
Learning 
Causal Modeling 

4.4 Knowledge Acq. 

4.5 Adv. Planning Meth. 

4.6 Coop. K-B Systems 

4.7 Validation Meth. 



3701 


4050 


4090 


4250 


4583 


20674 


140 


200 


240 


300 


400 


1280 


500 


500 


500 


500 


600 


2600 


250 


300 


300 


300 


300 


1450 


971 


lOOu 


1000 


1000 


lOOO 


4971 


647 


650 


650 


700 


700 


3347 


753 


800 


800 


750 


783 


3886 


440 


600 


600 


700 


800 


3140 



5. Control E;;ecutian 

5.1 Symbolic Control 



96 



150 



200 



BOO 



100 



846 



6. Operator Interface 
6.1 H— M Inter. Design 

7. Systems Arch. /In teg. 

7.1 Symbol ic— Num. Arch. 

7.2 Dist. K-B Mgmt. 



585 



400 



4o; 



500 



500 



IIBB 



2184 


2348 


2950 


2950 


3250 


13682 


1986 


2000 


2500 


2500 


2750 


11736 


198 


348 


450 


450 


500 


1946 



Total (Net) 



11129 11648 11923 12200 12383 



59283 



Program Support 1195 

HO Unique Requirements O 



973 


994 


1014 


1028 


5204 


179 


183 


186 


189 


737 



lotal (Gross) 12324 12800 13100 13400 13600 



65224 



OF POOR QUALITY 



FUNDING 



(*K) 



SYSTEMS AUrONOMY PROGRAM FUNDING SUMMARY 
(ElE?ment Funding by Center) 



DEMONSTRATIUNS 

1. Spa. Sta. Dpmos (ARC) 
o Thermal 
ARC 
JSC 

o Thermal /Power 

ARC 

JSC 

LeRC/MSFC 
a Hierarchical 

ARC 
D Distributed 

ARC 

'2. Operations Demos 

o STS Fit (Jcjnt Room (INCO) 

JSC 
o Launch Uperations 

KSC 
o Miss Cont Gnd Data Sys 

JPL 

CORE TECHNOLUGY 

3. Intentionally Blank 



88 


89 


90 


91 


92 


Total 


4763 


4700 


4280 


4300 


3850 


21893 


3399 


3500 


3500 


3500 


3500 


17399 


1905 


500 











2405 


1305 


300 











1605 


600 


200 











800 


1125 


2300 


2500 


700 





6625 


575 


1250 


1400 


400 





3625 





300 


300 


100 





700 


550 


750 


800 


200 





2300 


369 


700 


1000 


2700 


3100 


7869 











100 


400 


500 


1364 
) 
620 


120U 


780 


BOO 


350 


7869 


350 


O 








970 


397 


500 


430 


450 


O 


1777 


347 


350 


350 


350 


350 


1747 


6366 


6948 


7643 


7900 


8533 


37390 



Planning and Reasoning 


3701 


4050 


4090 


4250 


4583 


20674 


ARC 


2883 


30UO 


3050 


3150 


3483 


15556 


LaRC 


347 


550 


550 


600 


600 


2647 


MSFC 


471 


500 


500 


500 


500 


2471 


Control Execution 














ARC 


96 


150 


200 


200 


200 


846 



Operator Interface 
ARC 

Systems Arch/Integ 

ARC 

eSFC 



385 

2184 

1986 

198 



400 

2343 

200(_) 

348 



403 

2900 

2500 

400 



500 

2950 

2500 

450 



500 

3250 

27 50 

500 



2188 

13682 

11736 

1946 



total (Net) 11129 11648 11923 



ZOO 1238; 



59283 



10 



ORIGINAL PAGE IS 
OF POOR QUALITY 



MANPOWER (my) 



SYSTEMS AUTONOMY PROGRAM MANPOWER SUMMARY 
(Element Civl Service Manpower by Center) 



DEMONSTRATIONS 

1. Space Station Demanstratians 

D Thern>al 

ARC 

JSC 
D Thermal /Power 

ARC 

JSC 

LeRC 
Q Hierarchical 

ARC 
o Distributed 

ARC 

2. Operations DemanstrationB 

o STS Fit Cant Room (INCO) 

JSC 
o Launch Operations 

KSC 
o Miss Cant Gnd Data Sys 

JPL 



SB 


89 


90 


91 


92 


Total 


39 


41 


43 


38 


17 


178 


24 


24 


25 


21 


l-* 


108 


12 


9 


3 


1 





25 


B 


7 


■—• 


1 





19 


4 


2 











6 


11 


14 


21 


16 


1 


63 


1 


4 


9 


9 





23 








2 


1 


1 


4 


10 


10 


10 


6 





36 


1 


1 


1 


4 


9 


16 














4 


4 


15 


17 


IB 


17 


3 


70 


2 


2 











4 


10 


12 


15 


14 





51 


3 


3 


3 


3 


3 


15 



CORE TECHNOLOGY 

3. Intentionally Blank 

4. Planning and Reasoning 
ARC 

LaRC 
MSFC 



26 



3B 



39 



40 



175 



15 


20 


25 


27 


29 


116 


8 


12 


16 


IB 


20 


74 


3 


4 


5 


5 


5 


22 


4 


4 


4 


4 


4 


20 



5. Control Execution 
ARC 

6. Operator Interface 
ARC 



10 



7. Systems Arch/Integ 
ARC 
GSFC 



Systems Autonomy Total (NY') 



8 

5 



73 



8 



81 



7 


6 


36 


4 


3 


22 


.\ 


3 


14 


- 






7 


57 


353 



11 



ORIGINAL PAGE IS 
OF POOR QUALITY 



PROGRAM PLAN 



PRECEDING PAGE BLANK NOT FILMED 



13 



PAG|.J,i__tNTENTIONALLY 8LANR 



SYSTEMS AUTONOMY TECHNOLOGY PROGRAM (SATP) 

PLAN 
Ames Research Center 
National Aeronautics and Space Administration 
Moffett Field, California 94035 
December 1987 



AMES RESEARCH CENTER 
GODDARD SPACE FLIGHT CENTER 
JET PROPULSION LABORATORY 
JOHNSON SPACE CENTER 



KENNEDY SPACE CENTER 
LANGLEY RESEARCH CENTER 
LEWIS RESEARCH CENTER 
MARSHALL SPACE FLIGHT CENTER 



15 



PRECEDir^ti PAGE BLANK NOT FILMED 



iic^ I'j INIENIlONAm 81ANK 



ORIGINAL PAGE [S 
OF POOR QUAUTY 

SYSTEM AUTONOMY TECHNOLOGY PROGRAM PLAN 



NASA CENTER CONCURRENCES 



ARC 



'.J^lt/U' ^/LJmajCC 



/John S. Bull, Deputy Chief 
Information Sciences Division 



GSFC 



inrormation Sciences D 



Joitn T. Dalton, Chief 

Data Systems Technology Division 

KSC: IVJ^^^WxkU.^qA:! \\bl67 

William H. Rnnlc^ Mananoi- • ' 



William H. Rock, Manager 

Adv. Projects, Technology, and Commer. Off. 



JPL! 



i^ /. 




Giuli^^ Varsi , Manager 
Automation and Robotics Program 



JSC 



: ^^-tt!!i.~.a.'^.iJu- 



Kathleen J. Re^aley, Chiei 

Intelligent /Systems Techiliology Branch 



LaRC; ^^ /:^SA^ -.J^^ 



H. Milton Holt, Chief 
InfoBm/tion svs^ems Division 




Le RC : _^ 

i^rl AT Faymoryi/' Technical Assistant 
Power Technology Division 



MSEC 



= ii/Ofh. 



W. C. Bradford, Director 

Information and Electronic Systems Lab. 



SATP PROGRAM OFFICE APPROVAL: 



NASA HEADQUARTERS APPROVAL: 



/■>A^>x r-^ -4-'-^v. X 



,^Jr., c'hi^. 



Henry Lura/ 

Informatiori Sciences Division, ARC. 




^ 



Melvin D. Montemerlo, Manager, 
Automation and Robotics Program 



h-j^ %lfi}cl<^Jr 



Lee B. Holcorab, Director, 
Information Sciences and Human 
Factors Division. 



16 



FOREWORD 

The National Space Strategy approved by the President and Con- 
gress in 1984 sets for NASA a major goal of conducting effective 
and productive space applications and technology programs which 
contribute materially toward U.S. leadership and security. To 
contribute to this goal OAST has the responsibility within NASA 
to support the Nations' civil and defense space programs and 
overall economic growth. OAST objectives are to ensure timely 
provision of new concepts and advanced technologies, to support 
both the development of NASA missions in space and the space 
activities of industry and other organizations, to utilize the 
strengths of universities in conducting the NASA space research 
and technology program, and to maintain NASA's centers in posi- 
tions of strength in critical space technology areas. 

In line with these objectives, the National Aeronautics and Space 
Administration has established an ambitious new program in space 
automation and robotics. This program will result in the develop- 
ment and transfer of advanced automation technology to increase 
the capabilities, productivity, and safety of future NASA space 
programs including the Space Station, automated space platforms, 
lunar bases, Mars missions, and other deep space ventures. 

The NASA/OAST Automation and Robotics program is currently subdi- 
vided into two roughly equal parts. The Ames Research Center has 
the lead role for that portion of the program that seeks to 
develop and demonstrate System Autonomy capabilities for space 
systems that need to make their own decisions and do their own 
planning. The Jet Propulsion Laboratory has the lead research, 
development, and demonstration role for Telerobotics , i.e., that 
portion of the program that has a strong human operator component 
in the control loop and some remote handling requirement in 
space. 

This Program Plan is intended to be a working document for NASA 
Headquarters, Program Offices, and implementing Project Manage- 
ment. It is thus a living document that should be reviewed and 
updated at least once every year. 

This Program Plan has been prepared with contributions from all 
participating NASA Centers. The final version of the document has 
been reviewed and concurred with by each NASA Center as indicated 
on the signature page. 



17 



SYSTEMS AUTONOMY TECHNOLOGY PROGRAM PLAN 
TABLE OF CONTENTS 



Page 
17 



FOREWORD 

TABLE OF CONTENTS I9 

LIST OF FIGURES 22 

GLOSSARY 23 

PROGRAM ABSTRACT 24 

1. INTRODUCTION 26 

1.1. Document Purpose and Scope 26 

1.2. Program Goal and Objectives 28 

1.3. Program Approach and Elements 28 

1.4. Program Background and Need 33 

2. AUTONOMOUS SYSTEM CHARACTERISTICS 35 

2.1. Operational Characteristics 35 

2.2. System Functional Architecture 38 

3. SPACE APPLICATIONS AND TARGET CAPABILITIES 43 

3.1. Ground-Based Applications 43 

3.2. Space-Based Applications 43 

3.3. Broader Opportunities 44 

3.4. Required Target Capabilities 44 

3.4.1. Goal Oriented Behavior 45 

3.4.2. Self Maintenance 45 

3.4.3. Information Extraction and Interpretation 45 

3.4.4. Servicing and Repair 46 

3.4.5. In-Space Assembly 46 

3.5. Technological Challenges 46 

4. TECHNOLOGY AREAS 49 

4.1. Critical Technologies 49 

4.1.1. Task Planning and Reasoning 49 

4.1.1.1. Reasoning under Uncertainty 50 

4.1.1.2. Learning 50 

4.1.1.3. Causal Modeling 51 

4.1.1.4. Knowledge Acquisition 51 

4.1.1.5. Advanced Planning Methods 53 

4.1.1.6. Cooperating Knowledge Base Systems 54 

4.1.1.7. Validation Methodologies 54 

4.1.2. Control Execution 55 

4.1.3. Operator Interface 55 

4.1.4. System Architecture and Integration 56 

4.2. Technology Breakdown Structure 56 

4.2.1. Technology Demonstrations 56 

4.2.2. Core Technology Developments 57 

4.2.3. SATP Technology Breakdown Structure 57 

19 



FRECEDiuQ PACE ELAr=K NOT FILMED f«Glii_tN"''ENTIONAtLY BLANK 



5. TECHNOLOGY DEVELOPMENT PLAN 59 

5.1. Programmatic Activities 59 

5.2. Technical Goals and Objectives 59 

5.3. Demonstration Projects 60 

5.3.1. Space Station Test Beds 61 

5.3.1.1. Thermal Control System 61 

5.3.1.2. Thermal and Power Control System 62 

5.3.1.3. Hierarchical Systems 62 

5.3.1.4. Distributed Systems 62 

5.3.2. Specific Domain Demonstrations 62 

5.3.2.1. STS Flight Control Room Operations 62 

5.3.2.2. Launch Operations 63 

5.3.2.3. Mission Operations Ground Data System 63 

5.4. Core Technology Developments 63 

5.4.1. Task Planning and Reasoning 63 

5.4.1.1. Reasoning Under Uncertainty '64 

5.4.1.2. Learning 64 

5.4.1.3. Causal Modeling 64 

5.4.1.4. Knowledge Acquisition 65 

5.4.1.5. Advanced Planning Methods 65 

5.4.1.6. Cooperating Knowledge Base Systems 66 

5.4.1.7. Validation Methodologies 66 

5.4.2. Control Execution 66 

5.4.3. Operator Interface 67 

5.4.4. System Architecture and Integration 67 

5.5. Traceability of Technology Developments and Demonstration 67 

6. PROGRAM MANAGEMENT 70 

6.1. Organization 70 

6.1.1. SATP Office at ARC 70 

6.1.2. Interfaces with Other NASA Centers 70 

6.1.3. Collaboration with Other Organizations 72 

6.2. Milestones and Schedule 72 

6.2.1. Technology Demonstration Milestones 72 

6.2.2. Core Technology Schedule 75 

6.2.3. Reporting 75 

6.3. Resources 78 

6.4. Facilities 81 

7. RELATED NASA AND DOD PROGRAMS 82 

7.1. NASA Aircraft Automation Program 82 

7.2. Army-NASA Aircrew/Aircraft Integration Program 82 

7.3. DARPA Information Science Technology Office 83 

REFERENCES 84 

APPENDICES 85 



20 



LIST OF FIGURES 

Page 

Fig. 1 How Times Change 27 

Fig. 2 Systems Autonomy Program - Goal 29 

Fig. 3 National Space Challenges 30 

Fig. 4 Systems Autonomy Program - Objectives 31 

Fig. 5 Systems Autonomy Program - Approach 32 

Fig. 6 The Evolution of Machines that Think 36 

Fig. 7 Characteristics of Intelligent Autonomous Systems 37 

Fig. 8 Intelligent Autonomous System Architecture 42 

Fig. 9 Systems Autonomy Program Technology Challenges 

a. Where we are today 17 

b. Where we need to go 18 

Fig. 10 SATP - Technology Breakdown Structure 58 

Fig. 11 Evolutionary Development of Core Technology Capabilities • 68 
in Support of Increasing Technology Demonstration Levels 

Fig. 12 SATP - Organization 71 

Fig. 13 SATP - Milestone Schedule 

a. Technology Demonstrations 73 

b. Core Technology 71 

Fig. 11 Systems Autonomy Program Schedule 76 

Fig. 15 Systems Autonomy Program Resource Summary 

a. Funding by Program Element 78 

b. Element Funding by Center 79 

c. Element Manpower by Center 80 



21 



GLOSSARY 



AI 

ARC 

ATAC 

CAD 

CAM 

CPM 

DARPA 

DOD 

FCR 

FY 

GSFC 

JPL 

JSC 

KB 

KSC 

LaRC 

LeRC 

MSFC 

NASA 

OAST 

SADP 

SAIWG 

SATP 

STS 



Artificial Intelligence 

Ames Research Center 

Advanced Technology Advisory Committee 

Computer Aided Design 

Computer Aided Manufacturing 

Critical Path Method 

Defence Advanced Research Projects Agency 

Department of Defence 

Flight Control Room 

Fiscal Year 

Goddard Space Flight Center 

Jet Propulsion Laboratory 

Johnson Space Center 

Knowledge Base 

Kennedy Space Center 

Langley Research Center 

Lewis Research Center 

Marshall Space Flight Center 

National Aeronautics and Space Administration 

Office of Aeronautics and Space Technology 

System Autonomy Demonstration Program 

System Autonomy Intercenter Working Group 

System Autonomy Technology Program 

Space Transportation System 



23 



PRECEDING PAGE BLANK NOT FILMED 



?^§«2.i»JN«NTI0NALL1f BIAWK 



PROGRAM ABSTRACT 

NASA's Office of Aeronautics and Space Technology has implemented 
through its Ames Research Center a System Autonomy Technology 
Program that will sponsor and pursue the required research, 
developments, and technology demonstrations for integration of 
Intelligent Autonomous Systems into space systems. This document 
is the System Autonomy Technology Program Plan with a horizon of 
approximately ten years starting in 1988. The general goal to 
establish and maintain NASA as a world leader in intelligent, 
autonomous systems for space applications will be achieved by 
significantly advancing the required technologies, by validating 
these technologies in operational environments, and by developing 
and maintaining world-class technical expertise, facilities and 
tools within the NASA organization. 

Autonomous systems are generally characterized by sensing and 
perception units, databases, control computers, actuators, and an 
operator interface for human intervention, if required. They are 
operationally characterized by their ability to communicate at 
high levels with humans and with other intelligent machines. They 
are. able to recognize and resolve human-induced errors that would 
inadvertently endanger the system or its performance. They can 
operate autonomously for extended periods of time by virtue of 
knowledged-based systems which have capabilities of acquiring and 
understanding dynamic world knowledge, of learning, and of deduc- 
ing reliable decisions in uncertain environments. 

More than any other project, the Space Station will be a driver 
of system autonomy in the near future. The importance of system 
autonomy will increase for the success of future complex space 
missions, such as unmanned lunar bases or Mars sample return 
missions. To satisfy more mundane requirements, system autonomy 
will also become pervasive in less conspicuous areas of the space 
program, as for example, in design, testing, launch and mission 
operations, and in-space servicing and construction. 

To maintain general validity, the critical technologies for re- 
search and development are identified on the basis of a paradigm 
of intelligent autonomous systems. The core technology areas for 
research, development, and demonstration are: (1) task planning 
and reasoning (with subareas: reasoning under uncertainty, lear- 
ning, causal modeling, knowledge acquisition, advanced planning 
methods, cooperating knowledge base systems, and validation 
methodologies) (2) control execution, (3) operator interface, and 
(5) system architecture and integration. These core technologies 
will be developed in research laboratories to the point of bread- 
board integration and testing at component and subsystem levels. 

At suitable time intervals, the core technologies will be aggre- 
gated and integrated into meaningful technology demonstration 
projects. Prototype subsystems and systems will be tested in the 
context of realistic application scenarios. The implementation of 

2k 



these demonstration projects will assure technology relevancy and 
maturity for space mission applications. Prototype test and 
demonstration projects currently under development are: (1) Space 
Station testbeds covering a broad spectrum of systems technology 
including a single thermal control system, a multiple thermal and 
power control system, a hierarchical system, and a distributed 
system; and (2) specific domain demonstrations including STS 
flight control room operations, launch operations, and mission 
operations ground data systems. 

The demonstrations will be designed to validate intelligent con- 
trol operations of single subsystems in 1988, intelligent, 
coordinated control of several subsystems in 1990, intelligent, 
hierarchical control in 1993, and intelligent control of several 
distributed subsystems in 199 6. The prototype tests and demon- 
strations identified in the previous paragraph will exercise 
required technical capabilities in all technology areas and their 
elements, i.e., in task planning and reasoning, control execu- 
tion, operator interface , and systems architecture and integra- 
tion . 

The System Autonomy Technology Program is managed by the Chief of 
the Information Sciences Division at ARC. He interfaces opera- 
tionally directly with the Director of the Information Sciences 
and Human Factors Division at NASA/HQ. The Program Manager is 
Chairman of the Systems Autonomy Intercenter Working Group which 
has a representative from each NASA Center and advises on program 
plans and implementation. 

The following table gives the funding resources for SATP. 

SYSTEMS AUTONOMY PROGRAM FUNDING (NET $K) 

FISCAL YEAR 
88 89 90 91 92 

CORE TECHNOLOGY 6366 6948 7643 7900 8533 



DEMONSTRATION PROJECTS 4763 4700 4280 4300 3850 



SATP TOTAL 11129 11648 11923 12200 12383 



25 



1. INTRODUCTION 

Striking changes have occurred in the way we monitor, con- 
trol, and operate modern systems of all types. For example, 
aircraft and spacecraft once had a much higher human-to-machine 
functional ratio than exists today. In the past, individual 
subsystems were monitored and controlled by operators linked to a 
supervisor or operations director. Today, the decision speed and 
complexity of many systems calls for a new approach based on 
computer and software technology. Machines equipped with artifi- 
cial intelligence will be developed to perform autonomously many 
of the functions previously done by human operators (Fig.l). Some 
people will still be in the loop, but their actions are oversight 
control and functional mode selection. 

In recognition of the requirement for increased developments 
toward automated systems, and in particular intelligent autono- 
mous systems, the National Aeronautics and Space Administration 
(NASA) has taken steps to provide the means and develop the 
necessary technologies for applications in space missions. NASA's 
Office of Aeronautics and Space Technology (OAST) has decided to 
implement through the Ames Research Center (ARC) a System Au- 
tonomy Technology Program that will sponsor and significantly 
advance the required technologies and in-house capabilities for 
transfer and integration into space system operations. 

1.1. Document Purpose and Scope 

The purpose of this document is to establish a framework 
and guidelines for the definition and implementation of specific 
research, development, and technology demonstration work at ARC 
and other NASA Centers in areas pertaining to system autonomy 
and autonomous systems. The specific objective is to present a 
NASA Systems Autonomy Technology Program (SATP) Plan with a 
horizon of approximately ten years, i.e., FY 1987 through FY 
1996. As much as possible, the plan is based on the requirements 
of NASA missions projected to the end of this century and beyond. 
It also takes into account related technology programs for lever- 
age, notably those sponsored by DOD. 

The scope of this document covers broad policies and proce- 
dures for managing the System Autonomy Technology Program. It 
establishes a framework for resource deployments within NASA 
based on specific technical, management, procurement, and sched- 
ule considerations for basic research, technology developments, 
integrated technical demonstrations, and testing. Specifically, 
this SATP Plan: 

a. Establishes program goals and objectives, 

b. Describes the overall approach to implementation, 

c. Establishes organizational relationships, 

d. Identifies program resources by fiscal year, 

e. Establishes major program milestones through 1996, 

f. Defines the program-level management approach, and 

g. Establishes program management control mechanisms. 

26 



LU 
O 



o 

C/) 
LU 



ORIGINAL PAGE IS 
OF POOR QUALITY 




3 

o 

X 




3 



27 



This SATP Plan also includes specific plans for the core 
research and demonstration projects which are implemented at 
various NASA Centers. These plans provide detailed visibility and 
tcaceability of accomplishments and resource expenditures. 

1.2. Program Goal and Objectives 

The overall goal of the SATP is the development of intelli- 
gent, autonomous system technologies that will enable the suc- 
cessful accomplishment of the national space challenges such as a 
permanent presence in space, a lunar outpost, and the exploration 
of Mars (Figs. 2 and 3). The scope of this goal requires an 
Agency-wide effort involving all NASA Centers to establish and 
maintain NASA as a leader in intelligent autonomous systems for 
space applications • In the context of such NASA programs, intel- 
ligent autonomous systems will contribute to significant payoffs 
in terms of increasing mission effectiveness, productivity, and 
success probability, and of reducing mission operation costs. 

The objectives of the SATP are: (1) significantly advance 
technologies for intelligent autonomous systems; (2) demonstrate, 
evaluate, and validate technologies in operational environments; 
and (3) develop and maintain NASA world-class in-house capability 
in technical expertise and facilities (Fig. 4). 

1.3. Program Approach and Elements 

The SATP concept includes two major program elements, 
namely core technology research and system autonomy demonstra- 
tion projects as depicted in Fig. 5. The demonstration projects 
give focus to the technology developments. The products of the 
core technology research feed into the definition of the techno- 
logy demonstration projects, where the developed techniques are 
tested and validated. The Program provides to NASA an in-house 
capability of technical expertise, facilities, and tools. 

The technical scope of the SATP comprises systems autonomy 
at various hierachical levels including the automation of the 
corresponding supervisory systems, the interface systems, the 
man-machine interface technologies, and the behaviour of humans 
within man-machine systems. The Program is concerned with the 
system design and production phases, as well as with the system 
operation phases. The technology areas identified for research, 
development, and demonstration are the "core technologies" and 
are designated as task planning and reasoning, operator inter- 
face, sensing and perception, control execution, and system ar- 
chitecture and integration. The core technologies feed into two 
demonstration programs, namely system autonomy and telerobotics 
which in turn enable a broad spectrum of target capabilities 
germain to a wide variety of applications in space systems. 
Peripheral technologies, such as power, propulsion, materials, 
structures, etc., are here of concern only to the degree to which 
they influence the automation and autonomy characteristics of the 
operational systems. 

28 




< 

o 
o 

q: 

>- 



o 

< 
CO 

UJ 

H- 
(O 

>■ 

CO 

< 

CO 

< 



< 
o 



o 




h- 




> 




i 


_J 
< 


X 

o 

UJ 


Z 


1- 


UJ 




f 


LJJ 


U- 


1- 


O 




Z 
UJ 


CO 


^ 


Z) 


T 


o 


0) 


2 


_J 


o 


CL 


2 


2 


R 


C^ 


D 


(") 


< 


< 


1- 


_i 


Z 


-) 


LU 


U. 


o 


^ 


_J 


CO 


_J 


UJ 


HI 


o 


1- 


C) 


z: 


=> 


UJ 


CO 


Q 


u. 


> 


OQ 


O 


< 


DC 


Z 


Ql 


m 



X 

< 



00 



< 

CO 



CO 

UJ 

CD 

z 

y 
_j 
< 

o 
m 
o 

CO 



UJ 

o 
< 

Q. 
CO 



UJ 

UJ O 

CO |_ iZ 

E ? s 

!^ O X 

< cc ^ 

^ < CO 

iz5 

m =) < 

Ql -J 2 




(0 

o 

e 
flj 

tiO 

o 
u 
a, 

>. 

e 
o 
c 
o 

■p 

< 

10 

(D 
+J 
(0 
>> 
01 

I 

4) 

D 
bD 

•H 



29 



CO 
LU 

O 

z 

LU 

-J 
< 

I 

o 

LU 
O 

CO 

< 

z 
o 

!5 

z 

LU 

I 
H 








OJ 




cn 




c 




01 




1— t 




rH 




ra 




JC 


z 


u 


g 


01 


V- 


u 


< 


11 


oc 


a 


O 


en 


_j 




Q. 




X 


[^ 


LU 





(/) 


•H 


cc 


4J 


< 


z 



I 
ro 

01 
L 






i'ijL'H t^'J'' 



I TV 



30 




(0 

o 
> 

u 

o 

O 

E 
ra 

O) 

o 



E 
o 

c 
o 

< 
(0 

E 
o 

tn 
0) 



a> 

V. 

iZ 



31 




o 

(0 

o 
a. 

Q. 

< 
E 

(0 
O 

a 

>. 
E 
o 
c 
o 

*^ 
< 

v> 

E 
o 

(0 



in 



32 



.^rf 



ORIGINAL PAGE !S 
OF POOR QUALITY 

This SATP Plan is primarily concerned with system autonomy demon- 
strations and the corresponding supporting core technologies 
managed by the NASA Ames Research Center. The telerobotics demon- 
strations and related core technologies managed by the Jet 
Propulsion Laboratory are not part of this Plan. Nevertheless, in 
view of an anticipated (necessary) merger of these two programs 
in the future, the discussions on autonomous system characteris- 
tics, space applications, and target capabilities in the fol- 
lowing two chapters take an integrated point of view. 

1.4. Program Background and Need 

System autonomy research and development at NASA/OAST are 
the result of several years of study, planning, and advocacy. 
This resulted in a number of related technical study reports, 
e.g. Refs. 1 and 2, which concluded that the adoption of automa- 
tion technology can, to an appreciable degree, increase the 
effectiveness and productivity of the development and operation 
of NASA-sponsored systems and missions. The potential benefits in 
terms of increased capability, reliability, efficiency, and cost 
savings for operational systems in space or on the ground gave 
impetus to a research and development program for related techno- 
logies. Recently, however additional strong motivations were 
stimulated by the report and recommendations to Congress of the 
Advanced Technology Advisory Committee (ATAC) which stated: "The 
development of the Space Station offers a chance both to advance 
the technology of automation and robotics as proposed by Congress 
and to put that technology to use. The use of advanced automation 
and robotics technology in the Space Station would greatly en- 
hance its capabilities. And the Space Station would thereby 
provide a logical driving force for a new generation of machine 
intelligence, robotics, computer science, and microelectronics" 
(Ref.3). Of course, NASA's needs for automation and robotics are 
not limited to Space Station applications. They extend to the 
space program as a whole, and the recommendations by ATAC are 
here considered applicable to the entire space program. 

For example, needs for system autonomy became especially 
evident for deep space exploration missions with long communica- 
tion distances. The signal delay times, ranging between seconds 
to the moon and hours to the outer planets, require that the 
spacecraft be capable of managing its affairs autonomously at 
least for the signal's round-trip time. At the existing state of 
technology, this requires that the spacecraft be preprogrammed in 
advance for all its actions. In the space program, it has only 
recently become practically possible to cope with some unforeseen 
situations in which the spacecraft had to make limited autonomous 
diagnostic decisions on its own. This was feasible through the 
application of advanced automation technologies including artifi- 
cial intelligence techniques (Ref.4). 

The ATAC also recommended that the various versions of the 
Space Station should incorporate, to the degree permitted by time 
and resources, significant elements of automation and robotics 

33 



technology through designs which allow for expansion and evolu- 
tion. The verification of the performance of automated equipment 
should be stressed, including terrestrial and space demonstra- 
tions to validate technology for space use. Satellites and their 
payloads accessible from the Space Station should be designed, as 
far as possible, to be serviced and repaired by robots. Maximum 
use should be made of technology developed for industry and 
Government, and a vigorous program of technology transfer to U.S. 
industries and development communities should be pursued. 



3M 



2. AUTONOMOUS SYSTEM CHARACTERISTICS 

2.1. Operational Characteristics 

The effect of introducing system autonomy through AI is to 
remove entirely or partially the human element from the control 
loops of the system, thus achieving autonomous or semiautonomous 
operations, respectively. The state of current technology in AI 
is such that it might be possible to delegate complete autonomy 
to relatively simple, well-defined subsystems, but not to systems 
of appreciable complexity. One expects therefore, for the fore- 
seeable future, to be faced with the design, development and 
operation of systems which function in a man-machine symbiotic, 
semiautonomous mode. In this mode, humans will make the high- 
level decisions and will, at times, also be able to engage in 
low-level control processes, if required. The computer, on the 
other hand, will evolve by virtue of new developments to higher 
levels of intelligent capabilities. Fig. 6. It will take over 
those decision and control functions which will be enabled by 
available and validated AI technology. These systems are then 
operated in the so-called supervisory mode. 

The concept of system autonomy as used here implies inde- 
pendence from the outside world in terms of problem solving and 
decision making, i.e., perception, planning, diagnosis, activa- 
tion, etc. The systems under consideration are autonomous with 
respect to detailed human information input, but not necessarily 
with respect to information output and energy or material ex- 
changes. For excimple, a space station, with or without astronauts 
on board, is in an autonomous state while there is no communica- 
tion to the space station, although communication from the space 
station may occur at any time. The same holds for unmanned space- 
craft. Similarly, a subsystem on the Space Station is autonomous, 
if it does not receive messages from the astronauts or other 
subsystems, although it sends messages out. At lower levels in 
the system hierarchy, a component system is autonomous, if it 
does not receive messages from other components or subsystems, 
although it sends messages out. Current technology does not allow 
the construction of completely autonomous systems; and in most 
cases, it would for various economic or complexity reasons not 
even be desirable. The concern here is therefore primarily with 
semiautonomous systems which receive at least some control infor- 
mation from humans or other systems. The degree of systems auton- 
omy is thus a function of the characteristics of the required 
control inputs - their information content, their frequency, etc. 

Hence, autonomous systems, as envisioned in this Program 
Plan, are artificially created operational systems which are able 
for extended periods of time to govern themselves and make their 
own decisions in accomplishing given objectives. These capabili- 
ties derive from their ability to reason based on information 
acquired from other systems and/or sensory inputs, make reliable 
decisions in uncertain environments, learn from experience, and 
resolve human induced errors (Fig. 7). In accomplishing the given 
objectives, the systems manage their resources and maintain their 



35 



I 
I- 

I 

(/) 
LU 



O 
< 



LL 
O 



Z) 

-1 

O 

LU 

UJ 

I 
I- 




c 



CO 



01 

c 



c 
o 



o 



<u 

JZ 

I- 

0) 

ai 



36 



ORIGINAL PAGE IS 
OF POOR QUALITY 



ORIGINAL PAQE ,^ 

°^ POOR Qj?^^,y^ 





o 





g 














P 




CO 














U. 




111 












J2 


O 




Q 












cc 


CO 




Z 


C/3 

Z 
LLI 










O 


Q 




3 
Q 












Q 

0: 




z 


S 










Uj 


Ul 




<t 


Z 










Q 


51 




z 
O 


^ 










i 


S 




H 


> 










:d 


d 




r/) 


z 










9 


2^ 


^ 


ID 

§ 

O 

n 


LU 

z 

i 

LU 
O 

z 

Z 
CO 

z 
o 




CO 




CO 
LU 

z 


1 


1 

Uj 


to 

Cl 


LL 

i 


_J 
CQ 


UJ 

•J 
a: 

CD 

3: 




LU 


•4 


^ 

^ 

i 




Q 

_l 

i 

o 


CO 

o 

LU 

a 

LU 

_J 


< 
CL 
< 

o 

z 


lii 


CO 

■z. 
< 


LU 
h- 

z 
cc 

LU 

n: 


DC 

!;H 


i 


l!j 


< 


CQ 

< 


z 
nr 


1 


=) 1- 
I O 


H 


H 




_J 


< 


I 


I 


(5 


? 


^ 


>- 


LU 


LU 


h- 


h- 


O 


o 


Q 


DC 


_J 


§ 


55 


O 


lU 


^ 


n 


n 


o 


o 


O 


o 


yy 


Q. 


i«: 








o 






QC 


O 



(0 

E 

(f) 
in 

3 
O 

E 
o 

c 
o 

*^ 
3 

< 



c 
a> 

D) 
0) 



o 

<-• 
<0 

o 

(0 
(0 

x: 
o 



(U 

3 
O) 




37 



integrity. At the highest level of abstraction, an operating 
autonomous system consists of four elements: 

(1) Sensing and Perception System - The sensor system acquires 
data and information about the internal state of the 
autonomous system, about its environment, and about its 
relationship to its environment. The data and information 
are packaged into symbolic descriptions or their constitu- 
ent parts. 

(2) Database System - The database of the autonomous system 
includes all data, information and knowledge necessary to 
plan system actions, perform diagnoses, and simulate sys- 
tem performance. The database contains factual and heuris- 
tic information such as CAD/CAM data, system configuration 
data, dynamic environmental data from sensory inputs, 
heuristic rules, and general declarative and procedural 
knowledge . 

(3) Control Computer System - Based on newly acquired data 
through sensory inputs and/or database and knowledge base 
search, the control computer system assesses the current 
state of the autonomous system with respect to the desired 
goal state, continuously updates the database and existing 
plans, and performs a planning process which results in a 
set of decisions for immediate and/or future actions, for 
control, and for recovery from errors and faults. 

(4) Actuator System - The implementation of the decisions 
prepared by the control computer system is carried out by 
the actuator system, resulting in sensible and measurable 
effects within prescribed and controlled operational lim- 
its . 

The ultimate setting of goals for, and supervision of, 
autonomous systems is done by humans. For simple systems this may 
be done directly by setting a switch or the like. For complex 
systems, such as an autonomous robot vehicle, the goal setting 
and supervision may be done by a team of operators with the help 
of an off-line or integrated computer system. The human opera- 
tor (s), together with the supporting computer system and other 
peripheral equipment, are collectively referred to as the "super- 
visory system". In general, one is dealing with a hierarchy of 
autonomous systems, where the higher level (echelon) elements are 
the supervisors of collections of elements at the next lower 
level. By extension, at the highest level in the hierarchy is 
(are) the human operator (s). If there are many human operators, 
as is the case, for example, in ground-based mission operations, 
they too will be organized into a suitable hierarchical organiza- 
tion, where the lowest level, the operator level, is usually at 
the machine interface. 

2.2. System Functional Architecture 

System autonomy for space systems is additive in the sense 

.38 

ORIGEf^AL PAGE kS 
OF POOR QUALITY 



that as the technology advances, more autonomous capabilities can 
be incorporated into the system, provided the system has been 
designed accordingly. This implies a possible evolutionary devel- 
opment for the space system, where a manually operated system 
evolves into a highly autonomous system in time. The modular 
architecture postulated below will support such evolutionary 
developments, because of the built-in capability to exchange 
functional modules at any level and at any time. An example of 
such intelligent autonomous systems may be the Space Station 
including auxiliary subsystems, or it may be a free flying 
service robot with manipulators and propulsion units. It may also 
be an intelligent controller for a specific subsystem or a col- 
lection of subsystems, or it may be an expert system that advises 
human operators on the ground or astronauts in space about deci- 
sions of planning, diagnosis and other functions. 

In order to establish a coherent framework that aids in the 
identification and definition of the technical areas, it is 
convenient to use a system architecture which displays the major 
subsystem functional blocks and their interrelations. To conduct 
a generally valid discussion, a paradigm of a functional archi- 
tecture is used that shows subsystem modules and information 
flows and captures general, but essentially characteristic, as- 
pects of a representative intelligent, autonomous system as shown 
in Fig. 8. Note that while the system excludes the human operator 
and the outside world, both are, nevertheless, a major considera- 
tion in determining technology requirements and system capabili- 
ties. 

At this level of abstraction, it is possible to depict a 
hierarchical system architecture and integration scheme of paral- 
lel information processing subsystems which work concurrently and 
asynchronously on different aspects of the overall task assigned 
to the intelligent autonomous system. These subsystems communi- 
cate the appropriate results, at the appropriate time, to those 
subsystems which are in need of these data to perform their 
functions. Note that at this level the human operator is part of 
the control loop and represents the decision making element at 
the highest level. There are provisions envisioned (not shown in 
Fig. 8) for the operator to have direct access through the opera- 
tor interface to all subsystems at lower levels in the hierarchy 
in task planning and reasoning , in control execution and in sen- 
sing and perception . This enables the operator to work directly 
with each individual subsystem, or groups of subsystems, to 
perform local manual control, diagnosis, debugging, and the like. 

During system operations, the operator obtains and main- 
tains, by virtue of displayed perceptor and modeling information 
and his own a priori knowledge, a more or less representative 
model of the external and internal world in his head. When the 
need arises, he decides in broad terms what tasks should be 
accomplished, and what "intelligent autonomous system" has the 
appropriate capabilities. The operator then formulates a high- 
level implementation strategy taking into account overall system 
capabilities, resources and time constraints. Using a high-level 

39 



language, the strategy will be transmitted to the controls module 
and will then be automatically converted into a task, description 
for the planner . Calling upon the knowledge base , for detailed 
planning data (world state data) , the planner prepares a detailed 
implementation plan for the system. Before execution, the plan is 
usually sent to the simulator for checkout and validation by the 
operator via displays ^ In this process, the simulator uses world 
state information from, and may make corrective changes to, the 
knowledge base. After validation, the plan is sent to the execu- 
tor , where detailed command sequences are prepared and sent to 
control execution . The actuators then perform the planned actions 
on the system itself or on the outside world. The perceptor 
subsystem consisting of various different sensors and associated 
data interpretation computers, observes the task implementation 
process and sends the appropriate state observables to the moni- 
tor subsystem. Here, the actual observables are selected and sent 
via the simulator to the displays, and actual world states are 
identified and sent to the knowledge base for updating. Also, the 
monitor makes a comparison with the expected states from the 
simulator. For minor performance deviations due to drifts, uncer- 
tainties, etc., the monitor will send vernier control information 
to the executor for corrective action. Information on faulty 
behaviour, on the other hand, will be sent to the diagnoser , 
where the anomalies and their causes will be deduced and correc- 
tive task descriptions will be prepared, both with the help of 
data from the knowledge base. The resulting world states will be 
used to update the knowledge base, and the corrective task des- 
criptions will be sent to the planning subsystem, thus initiating 
a new process cycle. 

As has been indicated above, the content of the knowledge 
base is subject to continuous change due to various updates 
before and during system operation. This ensures that at all 
times current data and the correct representations about the 
physical, environmental and operational characteristics of the 
system are in the knowledge base. It follows that the development 
of a reliable, updatable knowledge base is crucial for intelli- 
gent autonomous systems. 

During operation of the system, the most important informa- 
tion for the knowledge base update comes from the ever changing 
environment via the sensing and perception subsystem. The percep- 
tor subsystem receives inputs from a real and fuzzy external 
environment and from a relatively well-structured internal world, 
namely the system itself. The word 'perceptor' is to be viewed 
here in a broad sense, i.e., it includes all sensors required to 
operate the system effectively. The main task for the perceptor 
is to package the sensory information into prototype images or 
simple symbolic descriptions of such images or their constituent 
parts and send them to the monitor. Again, by image we mean a 
representation based on any one or several sensory modalities. An 
important feature of this architecture is that the perceptor 
passes on information to the knowledge base and the operator, and 
the knowledge base and/or operator can also control the perceptor 
by recognizing a need and by initiating the corresponding effec- 



tor action through the planner and executor. A typical example is 
when the system's knowledge base recognizes that a greater reso- 
lution of the image is necessary and effects a readjustment of 
the focusing mechanism. 

Another source of knowledge base update is the diagnoser. 
After a fault has been diagnosed, the system must be restored to 
an operating state which will preserve/protect its output to the 
best extent possible with the least deleterious effect on its 
integrity, reliability, and operating lifetime. Otherwise, the 
system will work at a degraded condition which requires a corres- 
ponding update of the knowledge base by sensed and/or inferred 
information. A third source for knowledge base update is the 
simulator, which may cause corrections to the information as a 
result of the validation process. And finally, the operator is 
able to make knowledge base changes as required by high-level 
strategic decisions. 

The system architecture in Fig. 8, does not take into con- 
sideration that for space missions, one often deals with two 
systems separated by a communication link. First, there is the 
proximal control system or ground-based operations center which 
usually includes the human operator(s), the operator interfaces, 
the operations simulator and perhaps a portion of the knowledge 
base. Second, there is the remote system in space including 
everything else. In many cases it does not matter, from an infor- 
mation handling point of view, whether the task planning and 
reasoning abilities reside in the proximal or in the remote 
system, or are distributed in both. It seems that when the commu- 
nication delay time is small compared to the allowable time for 
action at the remote site, most of the intelligence, at least the 
higher-level intelligence, may be kept in the proximal system. 
How the system's intelligence should be distributed in such 
subdivided systems is still an open and vexing research question. 
Its solution is expected to have considerable influence on 
approaches to system architecture and integration. For example, 
it might prove appropriate to duplicate certain units, such as 
the knowledge base, at both ends of the overall control loop. It 
is expected that future technology demonstrations will shed light 
on some of these questions. 

At the next and lower levels of abstraction within each 
subsystem of the intelligent autonomous system shown in Fig. 8, 
the architectures may be combinations of parallel and hierarchi- 
cal structures. Presently, it is envisioned that the modules 
within the subsystems are a reflection of the major operational 
functions of the space system, such as navigation, position 
control, power management, etc., and that these modules will be 
able to communicate with one another and with a coordination and 
decision making element (e.g., subsystem executive) at the next 
higher level in the hierarchy. 



41 



LU 

cc 

D 
H 
U 
LU 

I 
O 

< 



CO 

> 

Vi 

CO 

D 

o 

O 

z 
o 

y- 

D 

< 

Z 

LU 
U 

-J 
-J 
LU 




0) 

D 

o 

9 
+i 

-H 

x: 
o 

< 

B 
4.1 

4J 
(0 
>. 

U3 

(Q 

3 
O 

a 
o 
c 
o 
+i 

3 
< 



+5 

C 

t)0 



0) 

c 



I 

D 

CX4 



12 



3. SPACE APPLICATIONS AND TARGET CAPABILITIES. 

The effective development and demonstration of technology for 
autonomous systems are profoundly dependent on the context of the 
prospective applications. For example, system autonomy may be, 
and already is extensively being, incorporated by industry in 
CAD/CAM/CAE facilities to provide intelligent aides in the form 
of expert systems. These developments support not only the com- 
mercial sector, but also contribute directly to the design, 
manufacture, and test capabilities for space systems. These 
application contexts will therefore not be of primary concern in 
the definition of this SATP. The emphasis in this program is on 
the operational aspects of space systems and missions, where 
intelligent aides in the form of expert diagnosers, planners, 
simulators, etc., will be used by human operators, or where such, 
or similarly intelligent, systems will be used as parts of an 
intelligent autonomous system, such as an autonomous free-flying 
robot, an autonomous space platform, or a major autonomous sub- 
system of the Space Station. Below, brief statements for major 
potential application areas are given for orientation. 

3.1. Ground-Based Applications 

Major mission developmental and operational applications of 
autonomous systems on the ground are expected to be in the form 
of expert planning, monitoring, diagnostic, control and simula- 
tion systems in support of ground based responsibilities such as: 

(1) Launch operations at KSC, 

(2) Space Station and STS operations at JSC, 

(3) Command/Control at GSFC for Earth orbital spacecraft, 

(4) Mission control at JPL for deep space missions, 

(5) Propulsion systems testing and space laboratory systems 

at MSEC. 

3.2. Space-Based Applications 

Autonomous systems in space may be auxiliary subsystems of 
major system complexes, or they may function as the major consti- 
tuent of an autonomous robot, such as in: 

(1) Space Shuttle applications as knowledge-based systems 
support for astronauts in the control of the Shuttle, 
the Shuttle manipulator, and other operational equip- 
ment. 

(2) Space Station applications as knowledge-based systems 
support for astronauts in the control of the Space 
Station, associated IVA equipment, and auxiliary EVA 
space vehicles. 

(3) Autonomous robot applications, including sensors, ac- 
tuators, and control computers as orbiting maneuvering 
vehicles and other free flyers for in-orbit operations. 



^3 



(4) Deep Space applications of autonomous robots function- 
ing as planetary fly-bys, orbiters, planetary surface 
explorers, and the like. 

Some specific benefits expected from applying intelligent 
autonomous systems in the space program are summarized in the 
following statements. Intelligent autonomous systems will con- 
tribute to: 

(1) Reduce the work load for users and operators of ground- 
based systems (e.g., documentation, maintenance, man- 
agement) ; 

(2) Limit the amount of required communication with remote 
systems (e.g., because of planetary occultation, two- 
way light time, chance of detection); 

(3) Compensate for technical limitations of communications 
with remote systems (e.g., limited bandwidth, error 
rate, response time of equipment); 

(4) Sustain reliable performance of ground-based and remote 
systems (e.g., fault tolerance, self maintenance). 

These benefits include both technical and economical compo- 
nents. The primarily technical components aim at system or mis- 
sion enablement, while the primarily economical components focus 
on cost effectiveness. 

3.3. Broader Opportunities 

The technologies developed for autonomous systems will have 
potential applications in the automation of manufacturing proces- 
ses, nuclear plant operations, underground mining, and undersea 
work. In addition, autonomous systems will find extensive appli- 
cations in a variety of military operations. 

3.4. Required Target Capabilities 

In reviewing a comprehensive set of goals and mission 
objectives in the space program, one can identify a spectrum of 
functions that require, or may benefit from, system autonomy and, 
hence, from artificial intelligence technology. The assumption 
here is that before such technologies are available, these func- 
tions will either not be performed because of their difficulty, 
or they will be accomplished in a manual mode to the degree 
possible with only little or no assistance from system autonomy. 
It is further assumed that by virtue of developing technologies 
during the planning period of this Plan, the corresponding func- 
tional arrangements will be able to evolve from such initial 
circumstances into intelligent autonomous systems. 

The projected applications of autonomous systems require a 
dedicated effort of technology development and a well-implemented 
plan for technology testing and demonstrating. The technology 



HH 



developments and demonstrations ace planned to achieve certain 
target capabilities which are necessary to insure that progres- 
sively more capable space systems can be designed. The following 
target capabilities are representative of the major technology 
drivers in this program. The corresponding technologies are ex- 
pected to be available within the current planning horizon of 
about ten years, and the plan outline for their development is 
presented in Chapters 5 and 6 of this document. 

3.4.1. Goal-Oriented Behavior 

Intelligent autonomous systems operating in space or on 
the ground are able to arrange their activities and allocate 
their resources in order to achieve prescribed goals. The goals 
are communicated to the systems at correspondingly high levels 
by human operators or by other systems that are placed higher in 
the control hierarchy. In turn, the. systems communicate back at 
compatible levels to these agents about their states and opera- 
tions. In striving toward the given goals, the systems must cope 
with new and unanticipated situations. They must be able to 
accept dynamically changing data from sensors and perceptors and 
accordingly develop new operation plans; they must replan exis- 
ting strategies automatically to accommodate new objectives and 
uncertain environmental changes. 

3.4.2. Self Maintenance 

Intelligent autonomous systems operating in space and on 
the ground must be able to maintain themselves in working condi- 
tion, so that their stated goals can be achieved. A primary 
attribute of these systems is their ability to recognize and 
resolve human-induced errors, faulty commands, unrealistic goal 
statements, etc. In addition, intelligent autonomous systems 
monitor themselves, detect and identify faults to the subsystem 
and component levels, and diagnose the faulty state with respect 
to the mission objectives. The corresponding status monitoring 
data is collected routinely for telemetry and crew display. 
Maintenance actions and periodic calibration of subsystems and 
components are done routinely. Faults at the system and subsystem 
levels are diagnosed from available sensor data, and relevant 
details are displayed to the human operators. Strategies for self 
recovery and/or self repair are then planned automatically or by 
the human operators with the help of associated expert systems. 

3.4.3. Information Extraction and Interpretation 

Services and science missions require a tremendous capa- 
bility to handle and interpret sensory data. Autonomous systems 
based on artificial intelligence techniques must be able to 
perform automatic scene analysis and recognition, pattern recog- 
nition and identification, and contextual data interpretation. 
Data from several sensory modalities must be integrated and 
interpreted in the context of overall system functions and pack- 
aged for diagnostic and operations planning purposes. 



1)5 



3.4.4. Servicing and Repair 

Servicing and repair of satellites, spacecraft, and space 
stations require remotely operated or autonomous robots to accom- 
plish the required tasks. Such robots require autonomous handling 
and manipulative capabilities to perform module exchanges, test 
operations, and act with the required dexterity. For these auto- 
nomous operations, the target capabilities under 3.4.1. to 3.4.3. 
are a prerequisite. 

3.4.5. In-space Assembly 

The in-space assembly of large space systems, such as 
space stations or large antennas, generally requires multiple 
robots working in a coordinated and cooperative process to accom- 
plish necessary construction. This requires advanced artificial 
intelligence and systems integration techniques which build on 
the target capabilities identified in 3.4.1. to 3.4.4. 

3.5. Technological Challenges 

The target capabilities of greatest and most urgent concern 
in the SATP Plan are goal-oriented behaviour and self mainte- 
nance. These capabilities are extensions (although, in some cases 
large extensions) of current knowledge-based systems. The techno- 
logies of knowledge-based systems provide the foundation for 
future intelligent autonomous systems which also include sensor 
and perceptor units and control execution units as implied by the 
target capabilities identified in 3.4.4. to 3.4.5. 

The development of systems with capabilities of goal- 
oriented behaviour and self maintenance represents considerable 
technological challenges. These are primarily in artificial 
intelligence related areas and include such items as real-time 
knowledge-based systems, dynamic knowledge acquisition, robust 
planning and reasoning, cooperating knowledge-based systems, and 
validation methodologies. Fig. 9 summarizes for each of these 
areas some indicators of the current state of technology and of 
anticipated future achievements. 

It must be noted that the level of competency on the part 
of the intelligent, autonomous system to perform the above target 
capabilities or to meet any or all of the more detailed chal- 
lenges in Fig. 9 has not been specified. All that has been given 
are general technical goal and trend statements in more or less 
overlapping areas based on heuristic judgements by experts in the 
field. It is difficult if not impossible to establish, at this 
time, criteria that would provide a general yardstick for mea- 
suring the degree of proficiency at which a target function can 
be executed by autonomous capabilities. The development of such 
measures is strongly dependent on the application contexts. It is 
part of each specific research area and must be derived in con- 
junction with postulated and verified technology capabilities 
during laboratory testing and technology demonstrations. 



^6 



X 



a. 

< 
w 
m 



< 

cc 

O 
n < 

>-o 

s ^ 

z < 

O LU 

< DC 

LU 

LU 

> 
CO 



I 

CO 
CO 

til 

s 
i 



s 



w 
en 
o 

CO 
CO 

LU 

8 

tr 
o 

DC 
LU 

Z 

6 

_j 
o 

m 

>- 

CO 

_j 

LU 



< 

Q. 



CO 

2 t w 

in < LiJ 

LU Ltl 2: 
S O 2 

^^:^ 

o z 

:^i CO 

lU - z 
cc LU o 

1 "^ CD 

CO ^ 
LU ZJ ? 
CO -J z 

D- S < 
CC W -J 
350- 
Q- W Q 

< 2 < 

CO fc O 

-^ C_J 2! 
CO Q. Q 



CQ 



CO 

o 

2 

o 

i 

C3 



o 

CO 

< 

CL 
X 

LU 

Q 
LU 



< b 



O 

I- 

< 

o 



LU 

Z 

O 

CL 

O 
O 
o 
o 
o 

CM 



Q CO 
lU lU 
"^ _l 
13 
OC 
o 
o 
o 
in 



m 



g 



o 

EC h- 

^ CO 

LU LU 

CC CD 

DL CC 



o^ 



col 
< o 

2 LU 

CO Q 



C3 

I 



CQ 
O 
CC 



o 

co2 
-J z: CO 






UJ 
Q 
O 



< 
CO 
3 
< 

o 

I 

—I 

< 

X 
CO 



o 

O 
CO 

i 

Q O 

5 CO 
^ LU 

Z3 
CC 

o 



CC 

LU 

X 



3g 

Q. < 

ai Li. 

CC LU 



CO 

Q 
LU 

H 
< 

.0 

CD ■ 
S < 

>- 



§ O 

o t^ 

Q LU 



CC 

> 

CC 

o 



OC 
LU 

o 

z 

LU 

D 

o 

LU 
CO 
LU 

a: 

Q 

ai 



w E 2 Q 



Q. 



CC 

a. 

^-co h- 
cn — Ll 

lU ^ 

CO 

3 



CO 

z 

< 



_l 
n 







LI. 


z 








CO 


CO 
CO 


CO 




^ 


z 


III 


CD 


CC 


<J. 


Q. 


Q 



CD 

is 



CC 

o 

lU 



>-: ^ 2 o o g 



< 

Q. 
CO 

CC 
O 

> 



f.. W P 
lU LU 



Q. 

-3 



LU < 



CO 

8 

CO 

o 

s 

I 
I 

Ul 

o 
o 



O 



LU 



CO 

5 

LU 

H 

CO CO 

^^ 

>- LU 

CO o 

Q Zi 



o 

LU 
Q. 
CO 



LU 

H 



< >: 



o 

Q 
UJ 

z 

3 
< 

a 






o 



LU 



CO 

LU 

_l 

o 

z 

CO 



z 
< 

X 



CO 

UJ 

CO 

>- 
CO 

o 



DC 

o 

< 

DC 

o 

LL 

CO 

LU 

CO ^ 

UJ Q 



O 
Q 
O 

s 

o 
5 



X 

o 

LU 
h- 



o 



UJ 

> 

Z 

o 

O 



>. 

ns 
-a 
o 

H 

O) 

< 

(D 

5 



0) 

5 



0) 
O) 

c 

"re 
O 

>. 

CJ> 

o 
o 

c 

o 

<u 



O) 






^7 



I 

2 



0. 

< 

05 



o 

go 

So 

< UJ 

UJ 

{^ 

>- 
(0 



I 

lii 

s 

00 
UJ 

I 

I 

I 

•J 



CO 

Q. 

8 

m 

CO 
LU 

m 



CO 

cr 
O 

CO 
CO 
lU 

o 
o 

cc 

QL 

o 
cc 

UJ 

:g 
z) 
z 

I 

o 



o 




Q 


H 






5 
2 




O 
UJ 
CO 


LU 






-J 




_l 


_J 
UJ 




2 


o 

z 


$ 


z 


CO 
UJ 


C3 

z 


CO 


i 


1 


oc 


CL 


CL 


o 


CO 


O 




z 
< 

CO 
CO 

O 



I 

CO 

=> 
O 
O 

o 

I 
I 



O 

z 

z 

UJ 

-J, 

UJ 



is 

^ i 
<E 

ql ^~ 
>< fQ 
UJ o 

QQ 
>^ 
Q 5 
UJ Z 

o o 



g 



I 

i 
I 



CD 



h Sb 



S5 



I 

s 

Ul 

I 
i 

o 

8 



I — 

Q 
CO < 

^S 

s| 

Q O 

Z=^ 
? UJ 

^s 

Q Q 

o ^ 

DC Z 

1 1 



C3 
O 

o 

I 
§ 

•J 

5 



< 

D 
O 

Z 

o 

CO 

o 

UJ z 
Q Q 

i§ 



m 

DC 

> 
o 
o 



< 
o 

cc 
o 

UJ 




(3 



•O 
OJ 
01 

z 

01 
3 

01 

L 
01 

x: 

3 



in 

01 

cr 

c 

01 



(0 

JZ 

u 

en 


r-H 


c 
x: 
u 

01 



XI 
Ch 

01 

L 
3 
D> 

•r-t 

Ul 



148 



4 . TECHNOLOGY AREAS 

Research and developments in critical technology areas will 
achieve the target capabilities and meet the technology chal- 
lenges identified in the previous chapter. Some of these areas 
are already part of the existing NASA Program and others will be 
initiated. The critical technologies identified and described in 
this chapter take into account the present state of technology, 
the projected needs in space missions, currently available 
talents in research and development, organizational factors and 
system architectural considerations. 

4.1. Critical Technologies 

Technologies for system autonomy, funded by NASA during the 
last decade, have not yet led to generally applicable capabili- 
ties. In this subsection, a high-level description of the most 
critical system autonomy technologies is given, portraying a 
functional point of view and identifying the state of these and 
related techniques in the context of technology developments, 
demonstrations, and space mission applications. The technology 
developments and demonstrations focus initially on the target 
capabilities of goal-oriented behaviour and self maintenance, 
where first knowledge-based systems for planning and diagnosis in 
various application contexts are considered. Later, sensory 
information extraction and interpretation will gradually be 
incorporated to arrive eventually at an autonomous capability for 
servicing, repair, and assembly. 

Accordingly, it is envisioned that space system autonomy 
will evolve from relatively simple to advanced capabilities in 
several technology development steps, and that the associated 
system architectures will be designed to accommodate a stepwise 
progression of ever more capable autonomous systems. The general 
architecture described in Chapter 2 and the technology challenges 
in Chapter 3 imply the development of a broad spectrum of 
required technical advances in artificial intelligence that are 
not within immediate reach. Considering existing limitations on 
related technology development resources, one must make choices 
regarding those technical areas with the highest priority to 
accomplish most significant overall progress toward space system 
autonomy. These requirements have implications not only at the 
system and subsystem level, but also at lower levels and at all 
interfaces . 

4.1.1. Task Planning and Reasoning 

The critical technologies in the task planning and rea- 
soning area are primarily related to four subsystems in Fig. 8, 
namely the planner, the simulator, the diagnoser and the system 
knowledge base. The technologies for the monitor and executor 
subsystems appear to be sufficiently well in-hand to satisfy 
space system requirements. The research and developments in plan- 
ning and reasoning concentrate primarily on issues of artificial 
intelligence. 

19 



4.1.1.1. Reasoning under Uncertainty 

Unreliable data or knowledge in the systems knowledge 
base has numerous origins. In building the knowledge base origi- 
nally, all of the data may not be available, some may be suspect, 
and some of the knowledge for interpreting the data may be unre- 
liable. Inputs from human operators during operation may contain 
errors, and sensory inputs and their interpretations about the 
environment and/or about the state of the system itself may be 
inaccurate, spotty, and fragmentary. The problem of reasoning 
with and drawing inferences from uncertain or incomplete data has 
led to a variety of technical approaches to its solution. For 
example, one of the simplest approaches has been used in MYCIN by 
using so-called certainty factors to indicate the strength of a 
heuristic rule. MYCIN, an expert system for selecting antibiotic 
therapy for bacteremia, is probably the most elaborate and most 
advanced of the existing knowledge-based systems. Other more 
elaborate approaches are based on Bayes' Rule, fuzzy logic, 
belief-revision systems, data correction rules, etc. Little 
agreement exists today on the utility of any of these approaches 
for intelligent autonomous systems in the space arena. Much of 
the future work will necessarily be exploratory research to 
determine which technique or combination of techniques proves 
most appropriate. 

4.1.1.2. Learning 

To develop computer systems that could learn has been a 
goal since the early beginnings of AI research. Perhaps the best 
definition of learning in the context of intelligent autonomous 
systems has been stated by Herbert Simon as "any process by which 
a system improves its performance." This definition includes such 
notions as the acquisition of explicit knowledge, the acquisition 
of skills, theory formation, hypothesis formation, and inductive 
inference. Today, a prevailing view about learning is that a 
system can only be expected to learn high-level concepts, and 
thus autonomously improve its performance, if it has at least 
some knowledge about the domain of discourse, i.e., a knowledge 
base forms the basis for discovering high-level concepts. Hence, 
for the system knowledge base, the initial content and the asso- 
ciated representational forms are particularly important design 
considerations which aim at expressiveness, ease of inference, 
modif iability , and extendability. The initial content of the 
knowledge base will be improved and extended in the learning 
process, when the system interacts with human operators and/or 
with the environment. The quality of information input has a 
major effect on the difficulty of the learning process. Simi- 
larly, the level, or the degree of generality, of the information 
provided by the environment and/or the human operators determines 
the kinds of hypotheses that the system must generate. Since all 
the related technical areas are still basic research topics at 
university laboratories, it is not expected that a practically 
applicable learning system will soon be available. 



50 



4.1.1.3. Causal Modeling 

The operation of a complex autonomous system in space, 
(for example a Mars rover, a free-flyer' robot , etc.) will occa- 
tionally be subject to major redirection of its planned activi- 
ties. Before making a commitment and sending the commands for 
such changes in plans, the control station should simulate the 
causal process and determine the effects of such redirection. 
This provides the possibility of experimenting with the causal 
model in order to assure the best and most reliable outcome. 

The causal model in the simulator processes key plan- 
ning elements in conjunction with the appropriate information in 
the knowledge base and displays the simulated results to the 
operator. The operator is then able to make high-level control 
corrections and do replanning before the plan is executed by the 
system. This process entails close interaction between the opera- 
tor and the operator interface. When the plan has been checked 
out and is sent to the executor for execution, the simulator will 
also receive it. Together with the required information in the 
knowledge base, the simulator comes up with a profile of the 
expected system behavior due to plan execution. This will then be 
used by the monitor subsystem for comparison with the actual 
system behavior. 

While, in principle, many causal modeling and simula- 
tion techniques are available, to date none have been researched 
and developed that would satisfy the performance requirements for 
such intelligent autonomous systems as envisioned here. In addi- 
tion to modeling and representing a complex dynamic process 
involving different operational data handling requirements, here 
the simulator must do this ultimately in real-time or, at least, 
in near real-time. Also, the simulation process puts an extraor- 
dinarily heavy burden on the architecture and information content 
of the knowledge base. For example, a realistic simulation of a 
dynamic process to be executed by the system in an uncertain 
environment requires a dynamically changing world model based on 
sensory information inputs. This type of technology is as yet not 
available, nor is it presently under development. In this con- 
text, the first steps in this research and development work will 
have to deal with utilizing structural and functional information 
about devices and processes together with the governing physical 
laws and establishing generally valid reasoning procedures. 

4.1.1.4. Knowledge Acquisition 

The development of the system knowledge base is the 
central, most critical technology development area, because it 
interacts with the most important subsystems and influences the 
operation of all aspects of intelligent autonomous systems. Know- 
ledge base development for dynamic large-scale systems, espe- 
cially for space systems such as the Space Station, still 
requires comprehensive definition and planning work. For applica- 
tion domains with existing operational human expertise, it is 
usually the most difficult development area to accomplish satis- 

51 



factorily. For the Space Station, presently without such exper- 
tise, it is the most important and urgent research and develop- 
ment area that requires careful planning far into the future. 
This process must start during the design phase, where the final 
design represents a first baseline set of factual information 
from which factual knowledge for the system knowledge base can be 
extracted. The knowledge base can be completed with heuristic 
knowledge obtained in the usual manner by a question and answer 
process from humans at a later time. Of immediate concern, there- 
fore, is the development of a mechanism for capturing and storing 
relevant design information in machine readable format and the 
development of techniques for extracting operational knowledge 
for the system knowledge base from this design information. 

Equally important for dynamic systems, such as the 
Space Station, is the development of a perceptor-driven dynamic 
world model that can change its information content based on 
sensory information. The knowledge base should also be designed 
to allow for dynamic changes of the CAD/CAM data, the system 
configuration and perhaps the heuristic information. In addition 
to maintaining current knowledge base content, this will provide 
the ability to preserve relevant past experience and knowledge of 
previous situations. As it becomes possible to develop and incor- 
porate learning algorithms, the system will be able to recognize 
task descriptions in the context of similar situations handled 
previously. Based on this past experience, the system will have 
learned and will be able to plan more effective task strategies. 
In time, it will become robust for handling uncertain data and 
unknown or unanticipated events with confidence. 

Since the system's knowledge base is the hub on which 
everything else depends, it and its development are the driving 
elements for technological developments. Given that the know- 
ledge base is appropriately designed, other subsystems, such as 
planners, simulators, diagnosers, etc., can also be developed in 
parallel with, or at almost any time after the knowledge base. 
Thus, by adding and properly interfacing progressively more ad- 
vanced subsystem modules, the system will evolve over time into 
an intelligent autonomous system. In addition, it will be pos- 
sible to develop and use dedicated expert systems as intelligent 
aides which are not elements of the intelligent autonomous sys- 
tem, but nevertheless may use part or all of the system's know- 
ledge base. 

At least a major portion of the information for the 
knowledge base will be created during the design process, long 
before the intelligent autonomous system starts operation. This 
implies that certain information should be captured at the latest 
during the final design stage and should be kept current with 
subsequent test, manufacturing, and operational data as required. 
Hence, an approach to design information capture and subsequent 
knowledge base design is required. In fact, one can express the 
strong belief that the success of intelligent autonomous systems 
in connection with space systems is critically dependent on how 
reliably the related design information can be captured and 

52 



updated. 

The final design information is the first baseline 
description of the system. It is important that attention be 
given to its organization as early as possible, so that it can be 
augmented by subsequent changes and can be modified to accommo- 
date new situations. For most space systems, this is complicated 
by the fact that the design efforts are distributed over many 
organizations, each with different design responsibilities, and 
each likely to use different design tools and techniques. These 
problems require not only technical , but also organizational, 
solutions in the areas of standardizations, networkings, etc., 
related to distributed databases. 

The distributed database must have capabilities which 
go beyond those of traditional, relational data models (Ref.6). 
These capabilities include representations of relationships, 
mappings, dependencies (time, spacial, attribute, etc.), con- 
straints, classes, inheritances, procedures, system operations, 
and the like. In addition, it is necessary to support data types 
that include matrices, graphics, pictorial images, text, CAD/CAM 
data, voice, etc. Such extended data models are currently not 
available, but are being researched, and should be incorporated 
into the distributed database as they become available. Also, a 
combined relational and hierarchic data model should be consid- 
ered for development, since in the future, such a model may move 
effectively satisfy the needs of future space systems. 

4.1.1.5. Advanced Planning Methods 

The planning system accepts task description inputs in 
terms of goals and scheduled events at the system level. Together 
with the information in the knowledge base, the planning system 
then develops a partially ordered network of actions and events 
similar to the critical path method (CPM) in project scheduling. 
At the simplest level, without considering resource constraints, 
CPM software requires explicit specification of the precedent 
relations to develop the corresponding partially ordered network 
plan. The Al-based methods, on the other hand, deduce the prece- 
dent information from the knowledge in the knowledge base. In 
general, not only precedent relations but also various resource 
and system constraints must be satisfied. Because these problems 
tend to explode exponentially with the number of variables or 
subgoals involved, their solution process usually entails the 
application of search procedures based on suitable context depen- 
dent heuristic criteria and, therefore, does not necessarily 
result in an optimum but a possible solution. The effectiveness 
of Al-based planning methods in generating acceptable plans is 
critically dependent on the design of the knowledge base. 

Within the context of space program applications, some 
work for Al-based planners has been performed by NASA. However, 
beyond the inherent problem of search control, this work still 
has severe limitations. It requires that complete, perfect, and 
deterministic information be given. This is typical and usually 

53 



satisfactory for deep space probe activity planning, but is 
probably inadequate for planning complex operations associated 
with the Space Station. Future planning systems should be able to 
cope with uncertain, incomplete and spacial information, and they 
should evolve to include also learning capabilities. Efforts in 
various directions for developing such technologies seem to en- 
counter no fundamental limitations and are in fact the subject of 
ongoing research at major AI laboratories. 

4.1.1.6. Cooperating Knowledge Base Systems 

Knowledge-based systems will initially be designed to 
serve a limited number of functions performed by a particular 
subsystem. The coordination between two or more knowledge-based 
systems will be done by human operators. In the course of evol- 
ving technological capabilities and as operational and system 
complexities increase, the coordination functions also will be 
subject to automation. The knowledge-based systems and the inter- 
faces will be designed and configured to facilitate both coordi- 
nation and cooperation in serving the functions of more than one 
subsystem. Communication with the human operator (s) will then 
occur at a correspondingly higher level. The system architecture 
issues include hierarchical structures, distributed structures, 
connectivity of system elements, and architectural alternatives. 
Operational issues include coordination of processes, real-time 
operations, cooperative processing, dynamic connectivity of pro- 
cesses, and communication protocols among processes. Character- 
istic problems in connection with cooperating knowledge-based 
systems are knowledge replication, segmentation, fusion, syn- 
thesis, and consistency. The subject of cooperating knowledge- 
based systems is a new area of research with little specific 
technical and development background. 

4.1.1.7. Validation Methodologies 

Unlike many conventional programs, knowledge-based 
systems usually do not deal with problems with a clearly right or 
wrong answer, such as sorting a list or inverting a matrix. It is 
therefore often difficult to demonstrate in a straightforward 
manner that the resultant answers are correct and then can be 
used to solve other dependent problems. The evaluation and vali- 
dation of new knowledge-based systems requires some kind of 
standard with which the results of the new methodology can be 
compared. In general, there are currently two views of how to 
define the standard for a knowledge-based systems' task domain. 
First, there is what eventually turns out to be the correct 
answer for a problem in some objective sense, and second, there 
is what a human expert, or group of them, presented with the same 
information available to the program, say is the correct answer. 
In the context of space systems the first view turns out to be 
not as important for the evaluation and validation process. The 
second view requires that domain experts themselves be subjected 
to rigorous evaluations of their decisions. Such assessments of 
human expertise provides a useful set of benchmarks against which 
to measure the expertise of a knowledge-based system. However, in 

54 



the space arena there are many situations for which human exper- 
tise is not available, e.g., the operation of the Space Station 
or a Mars rover. The development of validation methodologies for 
knowledge-based systems that are to be applied in space missions 
must take this circumstance into account when evaluating and 
validating the facts, heuristics, and models in the knowledge 
base as well as the operational processes of the system. 

4.1.2. Control Execution 

Actuators of some sort will perform the handling func- 
tions necessary for assembly, construction, repair, and the like. 
These devices will move on rails or will be attached to free 
flying robot vehicles. Common characteristics of all of them are 
probably that they are relatively light and flexible and will 
require control strategies and techniques which still must be 
developed. A number of broader issues also need to be resolved 
and the corresponding autonomy technologies developed, such as 
autonomous navigation, proximity operations, cooperating manipu- 
lator control, cooperating robots, etc. This requires that stra- 
tegic command issues related to symbolic controllers be investi- 
gated. Autonomous space vehicles require the ability to carry out 
tasks at a high conceptual level. Their manipulation activities 
will involve cooperation between multiple arms and multiple 
robots. This requires not only accurate force and position, 
control, but also the strategic guidance necessary to plan and 
carry out tasks involving more than one device. The communication 
of manipulative strategies, whether they originate from human or 
artificial intelligence, is not well understood. 

4.1.3. Operator Interface 

In line with an evolutionary system, the operator inter- 
face evolves from continuous supervisory control with goal and 
causal explanation displays to interrupted supervisory control by 
the addition of operator aids for unanticipated failures, task- 
oriented dialog capabilities and human error tolerance capabili- 
ties, to sparse supervision using a goal driven natural language 
interface. The critical technologies for the operator interface 
are primarily in the areas of human factor designed displays for 
complex data streams and the reliable recognition and interpreta- 
tion of natural language inputs. 

The displays present necessary information for high-level 
(and, if necessary, also low-level) decision-making to the oper- 
ator. This information includes alphanumeric data, geometrical 
representations, simulator-computed trend extrapolations of sys- 
tem behaviour, etc. The controls, on the other hand, will parse 
and package the operator's high-level inputs into task descrip- 
tions for the automatic planner. To provide operational flexi- 
bility, it is assumed that the operator will also be able to 
operate, with direct access, the planner, the simulator, and the 
diagnoser as tools in the form of expert systems. The knowledge 
for these expert system tools may be embedded in the system's 



55 



knowledge base or in other, compatible knowledge bases with 
similar content. 

4.1.4. Systems Architecture and Integration 

A primary requirement for systems architecture and inte- 
gration is to provide the posssibility for evolutionary, modular 
growth from current stand-alone knowledge-based systems to coor- 
dinated multiple systems followed by hierarchical and distributed 
systems. Systems under development today are not suitable for 
such large, real-time knowledge-based systems projected for the 
Space Station and subsequent space projects; and the unique NASA 
requirements in this area will not be addressed by research in 
industry and/or academia without related funding. Some indicative 
capabilities required by future systems are allocation and deal- 
location of large memory stacks, integration of numeric and 
sysmbolic processing in both cooperative and autonomous handling 
of data functions, management of multiprocessor architectures in 
a fault-tolerant environment, and management of large knowledge 
bases in excess of one gigabyte. 

The implementation of robust knowledge-based systems for 
spaceborne applications requires the development of new concep- 
tual approaches to integrated numeric/symbolic multiprocessor 
computers, network interfaces and data transmission protocols, 
and software protocol and management for large distributed data- 
bases. Advanced software compilers and translators need to be 
developed for both developmental and operational environments. 
Unprecedented verification and validation methodologies are 
required for fault-tolerant reconf igurable multiprocessor archi- 
tectures. 

4.2. Technology Breakdown Structure 

The development of the critical core technologies leading 
to their demonstrations and space mission applications is sche- 
matically illustrated in Fig. 5. 

4.2.1. Technology Demonstrations 

Key technologies and operational capabilities will be 
demonstrated and validated through a series of progressively more 
complex and demanding system demonstrations, before the techn- 
logies will be applied to actual missions, or before it will be 
integrated into flight experiment demonstrations. The System 
Autonomy Demonstrations concentrate on test and verification of 
software and hardware technologies leading to artificial intel- 
ligence based systems which will find application in ground-based 
mission operations, in ground-based information management sys- 
tems, in spacecraft system autonomy, in space station system 
autonomy, in space-based autonomous robots, in intelligent human- 
machine interface systems, and the like. There are two types of 
demonstration projects: (1) Space Station testbeds for a thermal 
control subsystem, a thermal/power control multiple subsystem, a 



56 



hierarchically structured system, and a system with distributed 
architecture; and (2) Specific domain demonstrations including 
STS flight control room operations at JSC, launch operations at 
KSC, and mission operations ground data systems at JPL. 

4.2.2. Core Technology Developments 

A broad spectrum of basic core technologies contributes 
to the successful implementation of autonomous space systems. 
Many of these technologies have been under development through 
NASA/OAST and other funding agencies in the country (e.g.DARPA), 
while others must be newly initiated. Some of these technologies 
have reached a level of maturity enabling their integration into 
a first-level demonstration project in 1988. However, all core 
technologies must be readied to be compatible with the demonstra- 
tion system integration requirements and must be further devel- 
oped for later, more demanding demonstrations. The primary areas 
of required core technology are reasoning under uncertainty, 
learning, causal modeling, knowledge acquisition, advanced plan- 
ning methods, cooperative knowledge-based systems, validation 
methodologies, control execution, operator interface, and system 
architecture and integration. 

4.2.3. SATP Technology Breakdown Structure 

The two major SATP activities, core technology develop- 
ments and technology demonstration projects, and their subdivi- 
sions are shown in Fig. 10. 



57 







SYSTEM AUTONOMY 
TECHNOLOGY DEVELOPMENT 







LOGY 
NATIONS 












!i 

Si 

V) U, 


IS 


Is 


is 

ii 













•0 r 


CO 


^l 


^s 


&) f 


i oE 


O f 


: T 


z E 


; Q 


o ? 


e 2 


^ f 


5 3 


Q ■ 


^ 






oS LU 




UJ . OC 








Q 3S f~ 




p2ty 










2 03 o 




^SS 





c 
E 

Q. 
O 

a> 
> 
a> 
Q 

>. 

O) 

o 

o 

c 

o 

0) 

H 

E 
o 

c 
o 

< 
(0 

E 

0) 

w 

>. 
w 



0) 

3 



-T^AL P/^-fj ^^s 



OF POOR 



^kiALs rv 



5. TECHNOLOGY DEVELOPMENT PLAN 

It is clear that autonomous systems technology will play an 
important role in the development and operation of future space 
systems. Hence, within the broad goal and objectives of the 
Systems Autonomy Technology Program (SATP) stated in Section 
1.2., programmatic and technology development efforts will be 
initiated and implemented to enable future difficult space mis- 
sions, to make future missions affordable and cost effective, to 
maintain a competent and vigorous R&D capability in related 
technical disciplines, and to ensure the transfer of technology 
to space mission applications. 

5.1. Programmatic Efforts 

To ensure that the stated general goal and objectives can 
be accomplished, the SATP will pursue and sustain the following 
programmatic efforts: 

(1) Fundamental research efforts will be sustained at the 
appropriate level to satisfy future demands and needs in 
system autonomy technologies, such as task planning and 
reasoning, control execution, operator interface, and 
systems architecture and integration. 

(2) Collaborative and contracted efforts in the above areas 
will be established and sustained with academic and indus- 
trial institutions to train and engage the best available 
talents of the country in this Program. 

(3) Efforts will be sustained to understand programmatic and 
technological needs in autonomous system technologies for 
NASA and to develop new approaches to capture, retain, and 
apply to future projects the expertise gained within the 
Agency. 

(4) Programmatic and technical initiatives will be undertaken 
to develop techniques at the component, subsystem and 
system levels for the effective utilization of system 
autonomy and to establish a systems autonomy technology 
base that will permit the implementation of new and more 
reliable and cost effective space missions. 

(5) Efforts will be made to ensure that the developed techno- 
logies for autonomous systems will be tested, validated 
and made available in a timely manner for space mission 
applications . 

5.2. Technical Goals and Objectives 

The development of technologies for space missions can be 
roughly subdivided into enabling and enhancing technologies. 
Without enabling technology, the corresponding mission, opera- 
tion, process, etc. would not be feasible. This type of techno- 
logy is therefore highly mission-dependent. Once identified, it 

59 



usually receives the highest priority, since it must be ready for 
integration about three to four years before mission start. 
Enhancing technology and/or cost reducing technology, on the 
other hand, has generally less stringent readiness dates. There 
is usually a way of doing a project differently, although it may 
not be affordable, or the attainable performance may not be 
totally satisfactory. Most technologies related to systems auton- 
omy fall into this latter category. 

For this SATP Plan, future NASA missions and their require- 
ments have been examined. Individual mission dates and their 
requirements often change radically, while the broad spectrum of 
technology requirements remains relatively constant. Thus, a 
phased research and development program is envisioned, that is 
derived from projected broad space system capabilities (not spe- 
cific enabling capabilities) to be achieved by the end of the 
1990's. Specific enabling capabilities will be identified and 
developed with the appropriate priority through periodic reexami- 
nation of changing space mission requirements. 

Hence, the broad, long-term technical goals of this plan 
are to develop, within the next decade, the required technology 
for intelligent, autonomous space systems which will have capabi- 
lities to validate instructions from system supervisors and re- 
ject those that would inadvertently endanger the system or its 
performance. Such autonomous systems will also be able to 
maintain acceptable operation through self diagnosis and repair 
and perform task planning to select satisfactory or optimal 
strategies for achieving high-level system goals, particularly in 
the presence of large environmental or system variations. 

The long-term technical goals will be accomplished by sev- 
eral thrusts of core technology developments which will be imple- 
mented at NASA Centers, universities and industrial institutions. 
These efforts will be at the laboratory breadboard integration 
level and will be carried to the point where they can be trans- 
ferred to technology demonstration projects. Hence, systemati- 
cally selected, representative demonstration projects will serve 
as foci and gauges for core development progress. The imple- 
mentation of the demonstration projects will ensure technology 
relevency and maturity for space mission applications. 

5.3. Demonstration Projects 

Based on technology assessments, a typical sequence of 
progressively more complex technology demonstration levels has 
been identified. These demonstration levels serve as indicators 
for the kind of technology capabilities that are necessary to 
perform integrated operations which exemplify intelligent, auto- 
nomous systems. The demonstration level indicators correspond 
roughly to the intelligent control and operation of single sub- 
systems in 1988, of multiple subsystems in 1990, of hierarchical 
multiple subsystems in 1993, and of distributed multiple subsys- 
tems in 1996. 



60 



The core technology capabilities identified in Fig. 11 are 
indicative of what can be demonstrated in realistic operational 
settings at the indicated date. Hence, these technology capabili- 
ties serve as guides to determine the objectives and as gauges to 
measure the accomplishments of core research and developments. 
They also serve as guides to establish expected results of speci- 
fic demonstration projects which will appropriately exercise and 
validate new technologies for system autonomy. The first demon- 
stration level, to be reached in 1988, is based on technologies 
which are now ready for integration. The technology capabilities 
for the second demonstration level, to be reached in 1990, need 
about one year of additional developments and then two years for 
integration. The technology capabilities for the demonstration 
levels to be accomplished in 1993 and 1996 still need, respec- 
tively, an estimated four and seven years of core technology 
research and development and about two additional years for 
integration. 

Specific technology demonstration projects have been selec- 
ted and will be implemented at various NASA Centers with contrac- 
ted support from industry and universities. These demonstrations 
are planned to show in realistic application settings that the 
respective technology capabilities, as identified in Fig. 11, 
have been advanced to levels of capabilities enabling integra- 
tion into space missions. 

Future technology demonstration projects will be screened 
and selected, from time to time, based on need, available resour- 
ces, and suitability of demonstration objectives. One measure of 
the suitability of a demonstration objective is the degree to 
which core technology capabilities with respect to the demonstra- 
tion levels in Fig. 11 will be exercized, demonstrated, and vali- 
dated. 

Currently, the following technical areas and their corre- 
sponding demonstration objectives are being pursued as prototype 
demonstration projects. 

5.3.1. Space Station Testbeds 

The Space Station is at the forefront of new projects 
under development, and its initial version is scheduled to become 
operational by the middle of the 1990s. System autonomy techno- 
logy for the Space Station therefore has a high priority to be 
tested for possible applications. 

5.3.1.1. Thermal Control System 

This joint effort between ARC and JSC will demonstrate 
technologies in 1988 for autonomous thermal control system opera- 
tions on the Space Station. This demonstration is significant in 
that it will be one of the first NASA knowledge-based system to 
control a large complex system in real-time and with real opera- 
tional hardware. Key technology capabilities to be demonstrated 
include advice on diagnosis and correction of anticipated faults, 

61 



incipient failure prevention through trend analysis, and explana- 
tion displays. Key technology thrusts include causal modeling of 
a complex electrical /mechanical system, and combined causal 
models and heuristic rules for intelligent reasoning, trend 
analysis, and validation methodologies- 

5.3.1.2. Thermal and Power Control System 

This joint effort between ARC, LeRC, MSFC, and JSC will 
demonstrate technologies in 1990 for autonomous control of the 
thermal and power system operation on Space Station. This demon- 
stration is significant in that it will show coordinated simulta- 
neous control of two large complex systems. The power system, 
because of its unique role among the onboard systems, has great 
potential for significant operational cost reductions through 
mature autonomous power systems. Specific technology capabili- 
ties to be demonstrated include fault detection/classification 
and isolation methodologies, system restoration strategies, 
replanning in the face of uncertainty, and operator training 
methodologies. Key technology thrusts include causal modeling of 
complex electrical /mechanical systems, cooperation of knowledge- 
based systems, and validation methodolgies . 

5.3.1.3. Hierarchical Knowledge-Based Systems 

This is a 1993 demonstration in which the key techno- 
logy thrust is to evaluate and validate methodologies for expert 
system controls of more than two Space Station subsytems through 
hierarchical architectural strategies. 

5.3.1.4. Distributed Knowledge-Based Systems 

This is a 1996 demonstration in which the key techno- 
logy thrust is to evaluate and validate methodologies for expert 
system controls of multiple Space Station subsystems through 
distributed architectural strategies. 

5.3.2. Specific Domain Demonstrations. 

A set of specific Domain Demonstrations has been planned 
to facilitate technology transfer to domains other than Space 
Station and to insure that generic technology demonstrated on 
Space Station testbeds is applicable in all NASA missions. 

5.3.2.1. STS Flight Control Room Operations 

A rule-based integrated communications officer (INCO) 
on-line expert system will be developed and demonstrated in 1988. 
Advanced powerful graphics capabilities will be incorporated in 
1989. This demonstration is significant in that it will be the 
first NASA knowledge-based system to be implemented into a real- 
time operational environment. The expert system will aid Flight 
Control operations at JSC with minimal backroom support during 
STS missions, thus reducing manpower requirements for flight con- 
trollers who support Space Shuttle system opertions. 

62 



5.3.2.2. Launch Operations 

The demonstrations at KSC will include system software 
and hardware for autonomous diagnostics and control of interac- 
tive complex electromechanical launch processing systems that 
will perform better than system engineers. Key technology capa- 
bilities demonstrated will include goal-directed control/re- 
configuration, fault recognition/warning/diagnosis, systems sche- 
duling/rescheduling, automated trend failure analysis, and intel- 
ligent user interfaces. Key technology thrusts include model- 
based simulation, CAD/CAM knowledge-base capture, explanation 
displays, limited uncertainty management, and validation tech- 
niques. 

5.3.2.3. Mission Operations Ground Data Systems. 

This demonstration project will develop and demonstrate 
technologies which will enable and enhance the multi-mission 
monitoring and diagnosis of unmanned spacecraft by emphasizing 
tools commonly applicable to the automated monitoring of space- 
craft telemetry and space flight operations ground data systems. 
The technology demonstrations at JPL include a multi-mission 
telemetry monitoring workstation for spacecraft engineering tele- 
metry in 1988, automated monitoring of Voyager/Neptune encounter 
in 1989/90, automatic command verification and monitoring for 
spacecraft in 1992/93, and dynamically configurable and teachable 
ground data system controllers in 1994/95. 

5.4. Core Technology Developments 

Taking into account the core technology capabilities in 
Fig. 11 and the outline in previous chapters, the following core 
technology goals and objectives are established. In each case, 
the work includes basic research and development of hardware and 
software technologies to the breadboard level of integration and 
testing in the laboratory. This work thus provides new techniques 
and components which can be integrated into systems at the proto- 
type level for the technology demonstration projects discussed 
above . 

5.4.1. Task Planning and Reasoning 

The general objectives of task planning and reasoning are 
to develop those technologies necessary to structure and build 
knowledge-based hardware/software systems which will enable 
intelligent autonomous systems to accept and retain uncertain 
and incomplete information from sensory and/or operator inputs. 
Furthermore, this information and previously retained information 
will be used to perform diagnostic searches, do simulations for 
performance assessments, and formulate reliable action strategies 
and plans which, when executed, will affect the space system 
itself and/or its environment in a desired manner. The know- 
ledge-based systems have learning capabilities which provide 
over time improving performance to the intelligent autonomous 
system. Specific objectives are described in the following. 

63 



5.4.1.1. Reasoning Under Uncertainty 

The objectives are to develop the ability to make 
sensible judgements and carry out reasonable actions when world 
knowledge is imprecise or incomplete, or heuristics and models 
have built-in uncertainty, or actions have uncertain effects. 

Ongoing internal research will focus on probabilistic 
methods for uncertainty management. External collaborations will 
include work on fuzzy logic and research on integration of deci- 
sion theoretic and heuristic methods. Work will also be sponsored 
in developing methodologies and tools for combining classical 
methods with AI methods. 

5.4.1.2. Learning 

The objectives are to develop the ability to alter and 
improve all functionalities as conditions change and knowledge 
is added over time. Learning may occur manually by being taught 
or automatically by experimentation, generalization, or dis- 
covery. 

Internal work will be in the areas of learning by 
discovery and explanation based generalization. External collab- 
orations with Carnegie-Mellon on learning by experimentation and 
with the University of Michigan on learning as search will con- 
tinue. Major milestones include an initial demonstration of 
learning by experimentation in a robotic environment during 1989 
and self-improving knowledge bases as part of the 1990 Systems 
Autonomy Demonstration Project. During 1991-1992 discovery-based 
learning by introspection will be demonstrated on a large data- 
base of sensor-based information on a type of data management 
system testbed for Space Station. 

5.4.1.3. Causal Modeling 

The objectives are to develop the ability to utilize 

structural and functional information about a device, along with 

the physical laws that govern the device, to simulate and reason 
about the device. 

Internally, the 1988 Thermal Control System testbed 
will be used as a test domain for the combination of heuristic 
and model-based methods in diagnosing flaws in complex systems. 
Externally the University of Arizona will be funded in integra- 
tion of knowledge-based and traditional simulation methods and 
Stanford University in logical representations of structure and 
function. A major milestone is the successful demonstration of 
these methods during the 1988 Thermal Control System demonstra- 
tion. More sophisticated methods will be employed in work on the 
Hubble Space Telescope and other projects that involve modeling 
complex devices. 



64 



5.4.1.4. Knowledge Acquisition 

The objectives are to develop the ability to preserve 
the "corporate memory", i.e. to ensure that all the facts, heuri- 
stics, and other information gained during the design, construc- 
tion, and testing of a device are available in a practically 
usable form during the operational life of the device. 

Internal work will be focused on studying the Hubble 
Space Telescope as a test domain for three research areas: (1) 
integration of knowledge acquisition into the design, construc- 
tion, and testing process, (2) acquisition of knowledge from 
large numbers of experts, and (3) large knowledge base techno- 
logy. Internal to NASA, MSFC will manage the knowledge engi- 
neering for this project in accordance with technical guidance 
supplied by ARC with regard to appropriate tools and methods. The 
large Hubble Space Telescope knowledge base developed by MSFC 
will serve as the "testbed" for this research as well as provide 
direct benefits to the Hubble Space Telescope. Externally, there 
will be collaboration with Stanford on the latter two topics and 
with Carnegie-Mellon on the first topic. It will be shown how 
the product of traditional engineering activities supporting 
design and testing in major projects can be utilized in knowledge 
acquisition during 1988 and 1989. A very large knowledge base 
system will be demonstrated during 1991. Methodologies for the 
combination of expertise from at least a dozen experts will be 
presented during 1990. 

5.4.1.5. Advanced Planning Methods 

The objectives are to develop the ability to take a set 
of goals, design a plan to utilize existing and potential re- 
sources to achieve those goals, monitor the execution of that 
plan, and dynamically alter the plan when initial assumptions 
prove incorrect. 

Behavioral net architectures will be investigated at 
LaRC for application to the problem of planning and scheduling 
and for the development of a prototype domain-independent plan- 
ning and scheduling tool. At ARC, internal work will proceed on 
testing the limits of current Al-based scheduling methodologies 
applied to NASA problems, particularly in space science. Work on 
dynamic replanning will continue and research will be initiated 
on the application of skeletal planning and plan refinement to 
NASA domains. Externally there will be collaboration with work 
at JPL in sensor-based planning, with industry in the development 
of a Truth Maintenance System-based planner, and at USC-ISI in 
the application of DARPA-sponsored methods to NASA problems. 
Current methodologies for heuristic scheduling will be demon- 
strated in Pioneer Venus experiments during 1987. The JPL work 
has milestones in a sensor-rich subsystem of the Space Station 
during 1988 and 1989. That work and other internal and external 
efforts will be demonstrated as part of scheduling the power 
subsystem of the Space Station during the 1990 Thermal and Power 
Control System tests. 

65 



5.4.1.6. Cooperating Knowledge-Based Systems 

The objectives are to develop the ability to provide 
for synergistic cooperation among several significant knowledge- 
based systems in a complex environment. 

Internal research focus will be on the 1990 Thermal and 
Power Control System demonstrations. The use of the Hubble Space 
Telescope will be considered as a second domain for cooperative 
systems. External work will be supported at the Stanford Know- 
ledge Systems Laboratory in blackboard architectures for distrib- 
uted control of knowledge-based systems, at the University of 
Maryland in potential hierarchical control methods, and at MIT in 
languages for commanding multiple systems. In addition, a major 
new effort, jointly sponsored with DARPA, will begin at Stanford, 
SRI, and Rockwell in methodologies for interacting intelligent 
agents in the domain of Space Station Construction. Blackboard 
architectures will be demonstrated in NASA domains during 1988. 
A plan for the development of the technology required for coordi- 
nated construction of the Space Station by human and robotic 
entities will be presented during 1989. This plan will utilize 
the results of small-scale demonstrations in a robotic test 
environment at SRI during 1988 and 1989. 

5.4.1.7. Validation Methodologies 

The objectives are to develop the ability to validate 
the correctness of the facts, heuristics, and models used by a 
knowledge-based system and to verify that the knowledge has been 
correctly represented within the system. 

During 1987 a NASA/ Industrial workshop was held to 
begin understanding the practical issues of knowledge-based sys- 
tem validation in NASA domains with a particular focus on Space 
Station. The result of that workshop will be a detailed report to 
appear in early fiscal 1988. The first major milestone will be 
the development of an accepted validation methodology for the 
1988 Thermal Control System demonstrations. Validation work will 
also occur as part of the work described above on multiple-expert 
knowledge acquisition and large knowledge base technology. This 
will produce results in parallel with those milestones in 1989 
and 1990. 

5.4.2. Control Execution 

The objectives are to explore the possibility of devel- 
oping a mathematical theory to enable the design of symbolic 
controllers for dynamic systems. The approach will use in-house 
research and university grants to build a predicate calculus with 
time and dynamics concepts within the syntax. Specific research 
products include: (1) ways for translating sentences of the 
command sequences into arithmetic functions of time, (2) ways for 
representing estimated states and time histories symbolically, 
and (3) means for expressing global system properties such as 
stability, robustness, and disturbance rejection. 

66 



5.4.3. Operator Interface 

The objectives are to develop human machine interfaces 
that enable communication with intelligent autonomous systems in 
space in a manner natural to the human operator. Emphasis will 
be placed on "intelligent" systems which satisfy human factors 
requirements, and where the distribution of the workload between 
human and machine is optimized. Specific research products 
include: (1) design decision aids and rapid prototyping tools, 
(2) more natural human-computer dialog systems, (3) advanced 
display and/or control concepts, and (4) computer aided interface 
design systems. 

5.4.4. Systems Architecture and Integration 

The objectives are to develop system concepts required 
for the implementation of robust knowledge-based systems in 
spaceborne applications. Specific tasks include: (1) design and 
development of the spaceborne integrated symbolic/numeric multi- 
processor computer; (2) definition and development of the network 
interfaces and data transmission protocols for a vendor-indepen- 
dent environment; (3) development of the software protocols and 
management for large, distributed knowledge-based data, systems; 
(4) development of software compilers and translators for use in 
development and operational environments; and (5) design and 
development of verification and validation methodologies for 
fault-tolerant reconfigurable multiprocessor architectures. Mile- 
stones for the spaceborne processor include conceptual design by 
mid FY-88, detailed design by mid FY-90, with development and 
qualification by FY-94. 

5.5. Traceability of Technology Developments and Demonstrations 

The technical goals and objectives set forth in Subsections 
5.2., 5.3., and 5.4. including Fig. 11, represent current NASA 
thinking with regard to the technologies necessary to satisfy 
NASA's system autonomy requirements for the next decade. The 
technology capabilities identified in Fig. 11 are aggregations of 
technology elements which will be the subject of more detailed 
planning documentation in subsequent sections of this plan. 

The technology development objectives address the whole 
spectrum of required technology capabilities indicated in Fig. 11. 
Since the technology capabilities serve as measures of accom- 
plishments for core technology developments, they are equally 
useful for measuring and judging the effectiveness of technology 
demonstration projects to advance, exercise, and validate system 
autonomy. These technology capabilities establish the tracing 
links between technology developments and technology demonstra- 
tions . 

There is some overlap among the demonstration projects in 
terms of technology capabilities to be demonstrated. Since the 
overlapping items are demonstrated in different application con- 
texts, they will be tested under different conditions and will, 

67 



en CO 


111 


_J 


K- 


111 


_l 


> 
liJ 


m -J 


< 


7' 


u. 
<• 


O 


o 


< 


> 


rr 


o 


h- 


O W 


_i 


z 


oo 


z 


? 


X 


HI 


o 


n 


liJ 


>• 


o 
o 


8 

-i 

o 

z 


u. 


I 


o 


o 


H 


HI 


Z 


h- 


lU 


co 


a 


z 


a. 

O 

_j 
u 


Si 

cc 
o 


a 


,£ 


> LL 


ceo 


< 


^- 


^ 


rr 


o 


O 


F Q. 


D Dl 


-1 3 


O W 


^ 


z 



ia 



8 



X 

H 
HI 
CC 

o 
o 



Q w 









3 
Z 
u. 
O 
z 
Q 

cc "J 



z 
z 
z 

3 

a. 
lij 
? 
o 

z 
z 



3 

a. 



§1^ 
m CO 

O is 



z 
I 
o 




O) 

LU 

s 

z 

55 



z , 
o i 



o 

s 

a: 



5 z 

3 lu 
5: z 



z 
Q 



in 



a: 



± 
Q 

m 

O Q 



11 



< 
?55 



z 
o 



> 



^§ 



CD U. 

Si 
ff Q 



z 

o 






3 
13 

a 






f' 



i i 

i£ f Q Z 

« 1 Z O 

?* s < « 
I- < ^ < 

a. EC 



og 






z S 



z s 

> ? 



2 I 

a I 



P I 



w a 

Q (^ 

< 5 

a: CL 

uJ < 



O Q 



O 

O LU 



DC lU 
O " 
P- < 

OC EC 
UJ LU 

o5 



^ 


D 


^£ 


!^ 


o 


UJ 2 




CD gC 




Q C 


^ 


2 o 


LL 


3 y 


CH 


o 5 








a ^ 



Ul O Q 5 

2 t «j: c) 

U^ X LU 

< - 



a 

a. 
n 
O 

>. 
D> 
O 

o 

c 

X 

o 



o 
u 



c 

41 

E 
a 

jO 
V 

> 



3 
LL 



68 



OF PC.tR 



accordingly, become the more robust elements of the technology. 
These elements will serve as the more reliable building blocks in 
subsequent demonstrations and will be the most suitable ones for 
transfer to space mission applications. Hence, such overlaps are 
not considered duplications, but a necessary and desirable bypro- 
duct in the evolutionary process. 



69 



6. PROGRAM MANAGEMENT 

This Section describes the overall program management struc- 
ture. It explains how special committees and advisory groups 
support the SATP, and how significant interfaces with other 
participating organizations function. It delineates the process 
of program reviews and outlines the interface and control strate- 
gies . 

Overall direction and evaluation of the SATP is the responsi- 
bility of the Associate Administrator of the Office of Aero- 
nautics and Space Technology. He assigned NASA Headquarters re- 
sponsibility for this Program to the Director of the Information 
Sciences and Human Factors Division, and NASA Center respon- 
sibility to the Director of the NASA Ames Research Center. 

The ARC has coordination and management responsibility for 
the implementation of the Systems Autonomy Technology Program. 
The Director of ARC assigned this responsibility to the Informa- 
tion Sciences Division at ARC. 

6.1. Organization 

The SATP is managed by the Manager of the Information 
Sciences Division at ARC. The Manager of the Information Sciences 
Division interfaces directly with the Director of the Information 
Sciences and Human Factors Division at NASA Headquarters, who 
receives NASA-wide management advice from the NASA Automation and 
Robotics Management Committee. The SATP Organization, together 
with the major organizational interfaces, is shown in Fig. 12. 

6.1.1. SATP Office at ARC 

The SATP Office at ARC is responsible for maintaining 
appropriate contacts and information exchanges with the respec- 
tive program offices at NASA/HQ for funding, reporting, and re- 
views. The SATP Manager is responsible for staffing the SATP 
within the Information Sciences Division at ARC and for overall 
program planning, direction, organization, performance, and eval- 
uation of all matters pertaining to the SATP. The SATP Office 
Manager is also responsible for coordinating, through the SAIWG, 
the timely development of the core technology and the implementa- 
tion of the demonstration projects at the various NASA Centers. 

6.1.2. Interfaces with Other NASA Centers 

Several NASA Centers contribute to the development of 
core technology and to the preparation and conduct of technology 
demonstrations. These activities are coordinated through a Sys- 
tems Autonomy Intercenter Working Group (SAIWG) . The SAIWG 
includes one Center Representative from each NASA Center (ARC, 
GSFC, JPL, JSC, KSC, LaRC, LeRC, MSFC) and is chaired by the SATP 
Manager. The SAIWG reviews program plans and advises on the defi- 
nition of, and broad guidelines for, the implementation of spe- 
cific core technologies and demonstration projects. 

70 



J J 



g 

< 
N 

Z 
< 

o 

O 

< 

(D 
O 
CC 
Q. 

> 



o 

< 

LU 

I- 
(f) 

> 



l^ 








— -i 




u 




















O 










n 




> 




^ 


s 

c 




Q 

M 


o 


t~ 


r^ 


^ 


O 
O 


u 




c 




li! 


a 


o 


td 
E 
o 

c 




CD 

E 

3 
I 




V 








y 





c 
o 



n 

D) 



E 
n 

o 



o 

3 

il 







c 


















LaRC 

Behav. Net. Arch. 
K-B Systems Validati 




!3 


II 

a CQ 

is 


to 

o E 

O) o 

-■ V) 

S CD 


&XJ<K>*<S<5I 




>< 
o 

11 

u a 


































o 

< 
o 

z 


s 

1 
o 

1 

OB 
'« 
O 

Q 










u 




ARC 

Task Planning and 

Reasoning (JPL) 

Control Execution 

Operator Interfaces 

Systems Architectures 














_ 






.,,, 















71 



6.1.3. Collaboration with Other Organizations 

Significant collaborative efforts have been established 
with DARPA in the area of cooperating intelligent systems, with 
the Air Force in the demonstration and evaluation of automated 
systems for ground mission control and operation of multiple 
satellites, and with DARPA and DOD in the development of space- 
borne processors. Collaborative efforts have also been estab- 
lished with industry to transfer the automation technologies for 
use in highly automated commercial spaceborne payloads such as 
the Industrial Space Facility and the Space Habitability Facility. 

6.2. Milestones and Schedule 

The successful completion of a demonstration project war- 
rants the possible transfer of the demonstrated technology to 
space missions. The space mission requirements and associated 
flight dates are, in general, the drivers of technology develop- 
ments, especially if the technology is mission enabling. The 
developed technologies must usually be demonstrated about three 
to four years before the launch date of the mission in which it 
is to be applied. The planned Space Station and its auxiliaries 
are currently the primary space systems that determine the con- 
tents and schedules of technology and demonstration developments 
for system autonomy. 

6.2.1. Technology Demonstration Milestones 

Technology demonstrations are planned and will be imple- 
mented covering a broad spectrum of potential application areas 
as shown in Fig. 13. The milestones of the major planned demon- 
strations are clustered in 1988 and 1990. In agreement with the 
statements above, the demonstrations in 1988 are based on exis- 
ting technology which still needs to be system integrated, while 
those after 1988 involve at least some technology that is still 
being developed. The success of each demonstration project 
depends not only on the availability of the technology at a 
particular point in time, but also on the compatibility of these 
technologies among themselves in terms of their levels of devel- 
opment. This requires a careful balance of the technology 
developments in different technical areas and at different geo- 
graphical locations. At the appropriate time, about one to two 
years before the demonstration date, the necessary technologies 
and techniques will be garnered and integrated into the demon- 
stration system for testing and validating. 



72 



HI 



<Q 
LUO 



a> 



CO 



O) 



o 



O) 
CD 



<i 

u. O 

o o 
d Q 

- Ui 

t- 

3 



UI 



S8 
d^ 

SE U 

111 7 

og 

K 

< 

u 



OT 

a 



CO 
CO 



00 



O ^ r* 
•J II O 

5 5 O 
poSF 



g 



^2 

a ui 
uj ^- 

I CO 

o a 
tc lU 

S^ 

O o 
u a. 

u. :i 

o < 

di 

S UI 
^ 3: 
Q h- 



S 111 

tc t- 

III v> 

X > 

H <0 

U. -I 

o o 

dfE 

E Z 

UI O 
a u 



in 

X 

K 111 
111 c 

S O 

t UI 

u. u 

O DC 
dg 
UJ UJ 
Q cc 



i 



Q 

s 

O 

DC 

5 



!§2 

ii I ■"» 



CO 



i 



o 

Z UJ 
-I w 

I o 

I- DL 

z z 

o o 
»- F 

< < 

H I- 
W CO 

UJ m 
o o 

< < 
a a 
w « 



o 
cc 



o 
u 

C3 

< 



UI 

»- 

(0 

>• 
(fl 



Si 
3 



o 

s 

UI 






111 < 

Z 5 

UI (A 

!i: -• 

O o 

UJ o 

Q U 



3 

3^ 

X IE 

O H 

OC Z 

< O 

X U 

^S 

Si 

d X 

56; 

a o 



i 
I 



C3 

<i 

Si 

UI UI 



X 

in 



V) 

<i 

U. 4 
O X 

Z (^ 

go 

< 
> 

Q 

< 



Q. 

z 
o 

ffi 



UI O 

ca E 

i 

o ° 

"i 

lg 
i" 

o ca 

u. < 

o 3c 

. o 

o < 

u "^ 
Q •« 



Z "= 

u. 
O 

d !i: 

Z c 

UI UJ 

Q > 



o 

§ 

O 
CD 

CO 



i 

i 



^^ 

z >■ 
o J2 
gS 

s _j 

UI UI 

a t- 



E o 
£ o 

UI s 

" z 

< cc 

5 UJ 
Si 

!!: o 
o o 

d UI 

z 

UJ 

a 



c 
o 

*^ 
(A 
O 



c 

(0 

k- 
*-• . 
(0 

c 
o 

E 

0) 

Q 

>% 

O) 

o 

o 

c 

o 

o 



CO 
CO 



0) 
O) 



i 

2 

o 

CO 



CO 

§ 

I 
o 

DC 
C5 



73 



CO 


CM 


LU 


a> 


2 




O 


._ 


h- 




0) 


^* 


LU 


O) 




(a 

(U 
B 
O 
■P 
(0 
V 

■H 

N 
t« 

<-i 
o 
a 
s: 
o 

V 

tt) 
)-. 
O 

o 






D 

ta 

•H 
Cri 



74 



6.2.2. Core Technology Schedule 

The core technology research and development schedules 
are based on first-cut estimates of the time necessary to accom- 
plish the identified tasks based on current funding guidelines. 
These schedules and milestones are most strongly guided by the 
requirement to accomplish the levels of core technology capabili- 
ties at the years indicated in Fig. 11, i.e., coordinated system 
control of multiple systems in 1990, hierarchical system control 
in 1993, and distributed system cooperative control in 1996, each 
with the respective subareas of identified technology capabili- 
^ties. The required technologies for the 1988 (and before) capa- 
bility levejs are essentially current state of the art. Hence, 
the schedules and milestones in Fig. 14 show detailed core 
research and development tasks, which must be implemented to 
ensure that the increasing technology capabilities and demon- 
stration levels will be achieved starting with 1990 as presented 
in Fig. 11. These schedules and milestones assume that relevant 
technologies of other government and industrial programs, notably 
those of DOD, can be transferred to NASA and do not need to be 
developed as part of this program. 

6.2.3 Reporting 

The accomplished work under the SATP will be documented 
as required for management, archival, and technology transfer 
purposes. There will be a formal and an informal reporting pro- 
cess. Formal reporting consists of annual submissions of detailed 
task proposals from the implementing NASA Centers to the SAIWG 
for endorsement within the framework of this SATP Plan. These 
proposals include information generally required for OAST RTOPs, 
such as task descriptions, required staffing, requested funding, 
milestone schedules, facility requirements, etc. In addition, 
meetings and associated oral presentations will be held as neces- 
sary. The informal reporting consists primarily of publications 
in the open literature including books, refereed journals, con- 
ference proceedings, lectures, and technical reports. 



75 



Fig. 14. SYSTEMS AUTONOMY PROGRAM SCHEDULE 



FY : 88 : 89 : 90 : 91 : 92 : Requirements/Goals 



Demonstrations 

1. Spa. Sta. Demos (SADP) 

2. Operations Demos. 



Core Technology 

3. Intentionally Blank 

4. Plan, and Reasoning 

4.1. Reas. under Uncert. 

4.2. Learning 

4.3. Causal Model. /Sim. 

4.4. Knowl . Acquisition 

4.5. Adv. Plan. Meth . 

4.6. Coop. K-B Systems 

4.7. Validation Meth. 



5. Control Execution 
5.1. Symbolic Control 



6. Operator Interface 
6.1. Human Int. Design 



7. Systems Arch./Integ. 

7.1. Symbolic Processor 

7.2. Dist. K-B Mgmt 



1 
4 5 



7 8 



: 5 
:15 


1 
3 

7 

12 


2: 

9 
: 13 
:16 


4: 
6 
8 
10 

: 17 


11 : 
! 14: 
: 18: 



1 : : 2 3: 
: 4: : 5 



Eval. & Valid, of 
coop. K-B Sys . 

Alternate domain 
benchmark sys. 



Decision robustness. 

Automated K-B 

expansion. 
High qual. decisions. 

Dynamic K-B Acq. 

Real-time contingency 

replanning . 
Interactive planning 

by intell. systems. 
Methodology based on 

fundamental theory. 



Symbolic-algorithmic 
control interface. 



Comp. aided inter, 
design tool. 



Real-time performance. 

Large K-B software 
to applic. engg. 



SYSTEMS AUTONOMY PROGRAM SCHEDULE 
MILESTONE NUMBERS AND TITLES 



Demonstrations 

1. Space Station Demos (SADP) 

1. Control of single subsystem (Thermal) 

2. Control of two subsystems. (Thermal/Power) 

3. Plans for hierarch. cntl. of mult, subsyst, 



(cont. next page) 



76 



2. Operations Demonstrations 

4. Shuttle flight control room automation (INCO) 

5. Shuttle launch ops diagnostic/control automation (ECS) 

6. Space Stat, ground multi-sys. diag/control autom. (PPCU) 

7. Space Stat, ground hierarchical/distr . diag/control autom. (GDMS) 

8. Planetary mission ops. automation (Gnd data systems) 

Core Technology 

3. Intentionally Blank 

4. Task Planning and Reasoning 

4.1. Reasoning under Uncertainty 

1. Major review document of current methdologies 

2. Demonstration of uncertainty management in 1990 SADP Demo 

4.2. Learning 

3. Demonstration of learning by experiment 

4. Demonstration of learning by discovery 

4.3. Causal Modeling/Simulation 

5. Demo of comb, causal models & heuristics in 1988 SADP Demo 

6. Demo of complex modeling of Hubble Space Telescope 

4.4. Knowledge Acquisition 

7. Demo of design and testing tools 

8. Demo of combined expertise from over ten experts 

4.5. Adv. Planning Methodologies 

9. Demo of scheduling in 1990 SADP Demo 

10. Demo of behavioral network architectures 

11. Integration of learning with planning methodologies 

4.6. Cooperating Knowledge-Based Systems 

12. Demo of blackboard architectures 

13. Demo of two cooperating subsystems in 1990 SADP Demo 

14. Hierarchical methodologies for control of mult, subsystems 

4.7. Validation Methodologies 

15. Report of . Validation Workshop 

16. Validation methodology for single subsystems 

17. Validation methodology for multiple subsystem 

18. Establishment of fundamental validation theory 

5. Control Execution 
5.1. Symbolic Control 

1. Algorithmic supervisors of arithmetric controllers 

2. Demo of global system properties of symb. -algorithmic interf. 

6. Operator Interface. 

6.1. Human Interface Design 

1. Design decision aids and rapid prototyping tools 

2. Natural human-computer dialog systems 

3. Advanced display/control concepts 

4. Computer aided interface design (CAID) system 

7. Systems Architecture and Integration 

7.1. Symbolic Processor 

1. Complete conceptual design 

2. Complete detailed design 

3. Initiate development, testing, and qualification 

7.2. Distributed K-B Management 

4. Large distributed Knowledge base models 

5. Large K-B management development tools 



77 



6.3. Resources 

The following Fig .15 shows the SATP resources required to meet 
the projected core technology developments and to implement the 
planned technology demonstration projects for system autonomy. 



Fig. 15a. SYSTEMS AUTONOMY PROGRAM FUNDING SUMMARY 
(Funding by Program Element) 



FY 



88 



89 



90 



91 



92 



Total 



Demonstrations 




4766 


4700 


4280 


4300 


3850 


21893 


1. 


Spa. Sta. Demos (SADP) 


3399 


3500 


3500 


3500 


3500 


17399 




o Thermal 




1905 


500 











2405 




o Thermal/Power 




1125 


2300 


2500 


700 





6625 




o Hierarchical 




369 


700 


1000 


2700 


3100 


7869 




o Distributed 













100 


400 


500 


2. 


Operations Demos. 




1364 


1200 


780 


800 


350 


4494 




o STS Fit Cont Room 


Ops 


620 


350 











970 




o Launch Operations 




397 


500 


430 


450 





1777 




o Ground Data Systems 


347 


350 


350 


350 


350 


1747 



Core Technology 
3. Intentionally Blank 



6366 



6948 



7643 



7900 



8533 



37390 



. Planning and Reasoning 3701 4050 4090 4250 4583 20674 

4.1. Uncertainty Mgmt. 140 200 240 300 400 1280 

4.2. Learning 500 500 500 500 600 2600 

4.3. Causal Modeling 250 300 300 300 300 1450 

4.4. Knowledge Acquisition 971 1000 1000 1000 1000 4971 

4.5. Adv. Planning Meth. 647 650 650 700 700 3347 

4.6. Coop. K-B Systems 753 800 800 750 783 3886 

4.7. Validation Meth. 440 600 600 700 800 3140 



5. Control Execution 
5.1. Symbolic Control 



96 
96 



150 
150 



200 
200 



200 
200 



200 
200 



846 
846 



6. Operator Interface 385 400 403 500 500 2188 
6.1. H-M Inter. Design 385 400 403 500 500 2188 

7. Systems Arch./Integ. 2184 2348 2950 2950 3250 13682 

7.1. Symbolic-Num. Arch. 1986 2000 2500 2500 2750 11736 

7.2. Dist. K-B Mgmt. 198 348 450 450 500 1946 



Systems Auton. Total (Net) 11129 11648 11923 12200 12383 59283 
Program Support 1195 973 994 1014 1028 5204 
Unique Requirements 179 183 186 189 737 



Systems Auton. Tot. (Gross) 12324 12800 13100 13400 13600 65224 



Fig. 15b. SYSTEMS . AUTONOMY PROGRAM FUNDING SUMMARY 
(Element Funding by Center) 



FY 



88 



89 



90 



91 



92 Total 



Demonstrations 






4766 


4700 


4280 


4300 


3850 


: = = = =! = = 

21893 


1. Spa. Sta. Demos. 


(SADP) 


3399 


3500 


3500 


3500 


3500 


17399 


o 


Thermal 






1905 


500 











2405 




ARC 






1305 


300 











1605 




JSC 






600 


200 











800 


o 


Thermal /Power 






1125 


2300 


2500 


700 





6625 




ARC 






625 


1250 


1400 


400 





3675 




JSC 









300 


300 


100 





700 




LeRC/MSFC 






550 


750 


800 


200 





2300 


o 


Hierarchical 




















ARC 






369 


700 


1000 


2700 


3100 


7869 


o 


Distributed 




















ARC 















100 


400 


500 


2. Operations Demos 






1364 


1200 


780 


800 


350 


4494 


o 


STS Fit Cntl Room 


(INCO) 














JSC 






620 


350 











970 


o 


Launch Operations 


















KSC 






397 


500 


430 


450 





1777 


o 


Mssn Cntl Gnd 


Data 


Sy; 


s 














JPL 






347 


350 


350 


350 


350 


1747 



Core Technology 

3. Intentionally Blank 



6366 



6948 



7593 



7900 



8533. 37390 



4. Planning and Reasoning 


3701 


4050 


4090 


4250 


4583 


20674 


ARC 


2883 


3000 


3050 


3150 


3483 


15556 


LaRC 


347 


550 


550 


600 


600 


2647 


MSFC 


471 


500 


500 


500 


500 


2471 


5. Control Execution 


96 


150 


200 


200 


200 


846 


ARC 


96 


150 


200 


200 


200 


846 


6. Operator Interface 


385 


400 


403 


500 


. 500 


2188 


ARC 


385 


400 


403 


500 


500 


2188 


7. Systems Arch/Integ 


2184 


2348 


2900 


2950 


3250 


13682 


ARC 


1986 


2000 


2500 


2500 


2750 


11736 


GSFC 


198 


348 


400 


450 


500 


1946 



Systems Auton. Total (Net) 11129 11648 11923 12200 12383 59283 



79 



Fig. 15c. SYSTEMS AUTONOMY PROGRAM MANPOWER SUMMARY 
(Element Manpower by Center) 



FY 



88 



89 



90 



91 



92 Total 



Demonstrations 






39 


41 


43 


38 


17 


. 178 


1. Spa. Sta. Demos 


. (SADP) 


24 


24 


25 


21 


14 


108 


o 


Thermal 






12 


9 


3 


1 





25 




ARC 






8 


7 


3 


1 





19 




JSC 






4 


2 











6 


o 


Thermal/Power 






11 


14 


21 


16 


1 


63 




ARC 






1 


4 


9 


9 





23 




JSC 












2 


1 


1 


4 




LeRC/MSFC 






10 


10 


10 


6 





36 


o 


Hierarchical 




















ARC 






1 


1 


1 


4 


9 


16 


o 


Distributed 




















ARC 


















4 


4 


2. Operations Demonstrations 


15 


17 


18 


17 


3 


70 


o 


STS Fit Cntl ] 


Room 


(INCO) 
















JSC 






2 


2 











4 


o 


Launch Operations 


















KSC 






10 


12 


15 


14 





51 


o 


Mssn Cntl Gnd 


Data 


Sys 
















JPL 






3 


3 


3 


3 


3 


15 



Core Technology 

3. Intentionally Blank 



26 



32 



38 



39 



40 



175 



4. 


Planning and Reasoning 


15 


20 


25 


27 


29 


116 




ARC 


8 


12 


16 


18 


20 


74 




LaRC 


3 


4 


5 


5 


5 


22 




MSFC 


4 


4 


4 


4 


4 


20 



5. Control Execution 
ARC 



10 



6. Operator Interface 
ARC 



13 



7. Systems Arch/Integ 
ARC 
GSFC 



7 
5 
2 



8 
5 
3 



36 
22 
14 



Systems Autonomy Total (MY) 



65 



73 



81 



77 



57 



353 



80 



6.4. Facilities 

The implementation of the SATP requires existing and new 
research and demonstration facilities at the contributing NASA 
Centers. A description of available and newly required facility 
capabilities in terms of hardware and software is give in the 
Appendix for each NASA Center Work Package. 



81 



7. RELATED NASA AND DOD ACTIVITIES 

Other ongoing activities in the area of system autonomy or 
closely related disciplines will be closely monitored, and appli- 
cable results will be incorporated in the SATP through technology 
transfer to NASA as appropriate. The Telerobotics Program, man- 
aged by JPL, is of particular interest in this respect. Coordina- 
tion and technology transfer activities among the SATP and the 
Telerobotics Program will be sustained on a continuous basis to 
ensure the possibility of a program merger in the future should 
this become required. The following programs are dealing with 
similar generic technologies as the SATP, although the applica- 
tion contexts are substantially different. The summaries of the 
three programs below are intended to indicate potential areas of 
commonality with the SATP. 

7.1. NASA Aircraft Automation Program 

This program will seize upon the current opportunity for 
major improvements for aircraft systems through use of AI techno- 
logy. AI offers the promise of higher-level automation. The 
program objective or strategic goal is to establish a national 
focus for research in automation of aeronautical flight and air 
traffic management systems. The technology will be developed for 
the design of intelligent flight path management systems which 
are goal driven and human error tolerant. 

The term "goal-driven" implies a higher level of interac- 
tion between the pilot and his aircraft system than is currently 
available. Communications will be by intent rather than by having 
to select specific autopilot modes or insert specific waypoints 
by latitude/ longitude coordinates. In helicopter automated NOE 
flight, the vision might be one of the horseman who controls the 
horse by simple commands and not high bandwidth/precise path 
control. 

The program potential payoff is in the form of improved 
mission effectiveness, elimination of pilot-induced accidents, 
and reduced crew complement and training costs. These opportuni- 
ties are available to high-performance aircraft, rotorcraft, and 
civil transports. Recognized mission requirements in these three 
vehicle classes provide the research focus. 

7.2. Army-NASA Aircrew/ Aircraft Integration Program 

This program is an Army-NASA exploratory development pro- 
gram with the purpose of developing a rational predictive method- 
ology for helicopter cockpit system design, including mission 
requirements and training system implications, that integrates 
human factors engineering with other vehicle/design disciplines 
at an early state in the development process. The program will 
produce a Human Factors/Computer Aided Engineering workstation 
suite for use by design professionals. This interactive environ- 
ment will include computational and expert systems for the analy- 
sis and estimation of the impact of cockpit design and mission 

82 



specification on system performance by considering the perfor- 
mance consequences from the human component of the system. The 
technical approach is motivated by the high cost of training 
systems, including simulators, and the loss of mission effective- 
ness and possible loss of lives due to ill-conceived man-machine 
design. The methodology developed to achieve goals of this pro- 
gram might be generalized as a paradigm for the development and 
planning of a variety of complex human operated systems. 

The program is jointly managed and executed by the Aero- 
f lightdynamics Directorate of th US Army Aviation Research and 
Technology Activity (ARTA) and the NASA Ames Research Center 
Aerospace Human Factors Research Division. 

7.3. DARPA Information Science Technology Office 

The Defense Advanced Research Projects Agency (DARPA) has 
recently combined its basic Al research and technology demonstra- 
tion projects within a single office called Information Science 
Technology Office (ISTO) . ISTO and its predecessor. Information 
Processing Techniques Office (IPTO), are the largest single 
sources of funding for basic and applied AI research in the 
world. ISTO supports AI research efforts at universities such as 
Stanford, Carnegie-Mellon, and MIT (typically at $lM/yr). Funded 
projects include the areas of knowledge representation, knowledge 
acquisition, and advanced inference methods such as the black- 
board system, and machine learning. 

In addition, a major effort analogous to Systems Autonomy, 
called Strategic Computing, was started approximately two years 
ago. The purpose of Strategic Computing is to both build and 
demonstrate an applied AI technology base necessary for military 
users in the next several decades. Seven applied research pro- 
grams are funded at places such as Intellicorp, Teknoledge, 
General Electric, Stanford University, and University of Massa- 
chusetts in areas of next-generation AI tool development and 
advanced hardware and software architectures for AI systems. 
Three major demonstrations. Pilot's Associate, Autonomous Land 
Vehicle, and Air-Land Battle Management are currently underway in 
multi-company teams. 

Through various efforts, both formal and informal, demonstrations 
presented as part of the Systems Autonomy program will utilize 
and leverage upon DARPA developed technology. The ARC Information 
Sciences Office is currently finalizing a working arrangement 
with the DARPA ISTO. 



83 



REFERENCES 

1. Sagan, C. "Machine Intelligence and Robotics: Report of the 
NASA Study Group," USGPO 1980-311-451/2659, 1980. 

2. Freitas, R. A. and Gilbreath, eds., "Advanced Automation for 
Space Missions," NASA Conference Publication 2255, 1982. 

3. Advanced Technology Advisory Committee, NASA, "Advancing 
Automation and Robotics Technology for the Space Station and 
for the U.S. Economy", NASA Technical Memorandum 87566, sub- 
mitted to the United States Congress, April 1, 1985. 

4. Heer , E., "Bringing AI Up to the Space Challenge," Astronau- 
tics and Aeronautics, July/August 1983. 

5. Gevarter, W. B. , "The Nature and Evaluation of Commercial 
Expert System Building Tools," NASA Technical Memorandum 
88331, June 1986. 

6. Hartzband, D. J., "Enhancing Knowledge Representation in 
Engineering Databases," Computer, September 1985, pp. 39-48. 



8M 



APPENDIX 
TECHNICAL WORK PACKAGES FOR NASA CENTERS 



85 



A. TECHNICAL WORK PACKAGES FOR NASA CENTERS 

The implementation of the SATP includes core technology 
developments and technology demonstrations. The core technology 
developments will be driven by requirements derived from the 
technology demonstration levels of Fig. 11 and, if applicable, 
from the requirements of the demonstration projects. These tech- 
nologies will be developed as parts of existing OAST RTOPs 
managed at the implementing NASA Centers. The core technology 
development tasks include basic research, fundamental develop- 
ments, and laboratory testing of system autonomy tools and 
techniques. Plans for these tasks, tools, and techniques will be 
prepared and proposed by the respective NASA Centers to the SAIWG 
for endorsement and then to NASA Headquarters for funding. 

The technology demonstration projects will be implemented 
under the OAST SATP RTOP which is managed by the SATP Office at 
ARC. The specific demonstration projects will be defined, plan- 
ned, and proposed by the respective NASA Centers to the SAIWG for 
endorsement and then to the SATP Office for inclusion in the SATP 
RTOP and funding by NASA Headquarters. The demonstration develop- 
ment tasks include work necessary to prepare the system autonomy 
tools and techniques, which were tested in core research labora- 
tories, for integration into the specific demonstration project 
scenario and testbed. These tasks will be defined and managed by 
the Prject Managers at the respective implementing NASA Centers. 

Within the framework of this SATP Plan, each implementing 
NASA Center is pursuing the work outlined in the following pages. 



86 



APPENDIX 
TABLE OP CONTENTS 

A. TECHNJCAI, WORK PACKAGES FOR NASA CENTERS. 

Al. AMES RESEARCH CENTER. 

Al.l. (lore Tech. - Task Planning and Reasoning. 

A;l.2. Core Tech. - Control Execution: Symbolic Controller. 

A1.3. Core Tech. - Operator Interface. 

A1.4. Core Tech. - SystemB Architecture: Symbolic/Numeric 

MultiprocesBor . 
A1.5. Demon. - Systems Autonomy Demonstration Project. 
A1.6. Eacilitles. 

A2. GODDARD SPACE FLIGHT CENTER. 

A2 . 1 . Core Tech. - Systems Architecture: Distributed 

Knowledge-Base Management. 
A2.2. Facilities. 

A3. JET PROPULSION LABORATORY. 

A3.1. Demon. - Automation for Mission Operations 

Ground Data Sys terns . 
A3. 2. Facilities. 

A4. JOHNSON SPACE CENTER. 

A4.1. Demon. - STS Flight Control Room Operations. 
A4.2. Demon. - Space Station Thermal Control System. 
A4.3. Facilities. 

A5. KENNEDY SPACE CENTER. 

A5 . 1 . Demon . - Diagnostics and Control for Launch 

ProceBsing. 
Ab.2. Facilities. 

A6. LANGLEY RESEARCH CENTER. 

A6.1. Core Tech. - Task Planning and Reasoning: Application 

of Behavioral Net Arch, to Planning/Sched. 
A6 . 2 . ('ore Teoh . - Task Planning and Reasoning: Validation 

Methodologies for Knowledge-Based Systems . 
A6.3. Facilitien. 

A7. LEWIS RESEARCH CENTER. 

A7 . 1 . Demon. - Space Station Power System Operation and 

Management. 
AT. 2. Facilities. 

A8. MARSHALL SPACE FLIGHT CENTER. 

A8.1. Core Tech. - Space Telescope Design/Engineering 

Knowledge-Base . 
A8 . 2 . Facilities. 



87 



Al. AMES RESEARCH CENTER. 

Al.l CORE RESEARCH AND TECHNOLOGY (Task Planning and ReaBoning). 

TITLE: Tank Planning and Reasoning. 

OBJECTIVES: 

The program described in this section represents the bulk of the 
science and engineering research thrusts of the Artificial 
Intelligence Branch of the Ames Research Center. It has the 
following major ob.jectiveB: 

o Conduct fundamental research on a limited, but significant 
number of topics in cognitive artificial intelligence that are 
of clear importance to the long-range technology development 
plans for NASA. 

o Sponsor external research collaborators in academia and 
industry to help us jointly meet ambitious goals in those 
research topics. 

o Develop significant in-house NASA expertise in the potential 
.application of the technology being developed to practical NASA 
problems . 

o Participate in the study and planning of major future NASA 

missions to determine AI technology needs and provide a pathway 
for their fjcceptance. 

The program will expand as senior in-house personnel are added 
and additional resouces are provided to it. Through fiscal 1988, 
the following seven topics form the foci of the program: 

o Reasoning under Uncertainty — the ability to make sensible 

judgments and carry out reasonable actions when world knowledge 
is imprecise or incomplete, heuristics or models have built-in 
uncertainty, or actions have uncertain effects. 

o Learning tlie ability to alter and Improve all functlonalltieB 
as conditions change and knowledge is added over time. 
Learning may occur manually by being taught or automatically by 
experimentation, generalization, or discovery. 

o Causal Modeling and Simulation — the ability to utilize 

structural and functional information about a device, along 
with the physical laws that govern the device, to simulate and 
reason about the device. 

o Knowledge from Design through Operations--the ability to 
preserve the "corporate memory," i.e. to ensure that all the 
facts, heuristics and other information gained during the 
design, construction, and testing of a device are available in 
a practically usable form during the operational life of the 
device . 

89 



PRECEDiNG PAGE BLANK NOT FILMED PAGf ?f 



.mTENTIONALLY SUNK 



AKC Planning and Reasoning (Continued) 

o Advanced IMcvnning Methods — the ability to take a set of goals, 
design a plan to ubiJize existing and potential resources to 
achieve thone goaLt=;, monitor the execution of that plan, and 
dynamically alter the plan when initial assumptions prove 
incorrect . 

o CqopercU,lt>n among Mull.iple Knowledge Based Systems-- the ability 
to provide for synergistic cooperation among several 
significant knowledge-based systems in a complex environment. 

o Validation Methodo Logies--the ability to validate the 

correctnenn of the facts, heuristics, and models used by a 
knowledge based system and to verify the knowledge has been 
correctly represented within the system. Much of this work 
will involve practicai considerations imposed by the potential 
end users of knowledge-based systems within NASA. 

RATIONALE: 

To achieve the ambitious goals for automation of major NASA 
projects like Space Station it is clear that a enormous amount of 
both short an<l long term research is necessary. Short-term work 
concentrates on generaiizing and scaling up existing 
methodologies to meet NASA needs; this is engineering research. 
Long-term work invoJves fundamental scientific research aimed at 
exploring nnd developing new methodologies. While it Ik 
certainly true tliat other governmental programs and agencies are 
interested in solving problems in artificial intelligence common 
to NASA's, it is also true that simply relying on those programs 
to meet NASA's AI Technology needs would be naive and 
unrealistic. The work described in this section represents an 
attempt to build a strong internal research resource and develop 
a long-term collaborative team of the best the external world has 
to offer. Significant sponsorship of external research is 
necessary both because of limited personnel and other resources 
within NASA and because it leads to a steady stream of interested 
and skilled researchers to potentialy devote to NASA problems 
(and who, in the current form of graduate students, may 
eventually j<Jin the Agency). 

APPROACH AN]) MILESTONES: 

As stated above the work will be accomplished by a collaborative 
research team consisting of scientists and engineers from Ames, 
industry, and academia. No external work will be conducted as 
"hands-off" activit,ies; there will always be a senior in-house 
researcher monitoring and sharing information with the activity. 
Limited budgetary resources will be leveraged by cooperation with 
other government-sponsored Al programs, particularly the DARPA 
Information Science Technologies Office (ISTO). Ames has 
developed a MOU with DARPA ISTO under which we agree to act as 
contracting agent and technical monitor for several contracts of 
mutual interest in exchange for significant influence on the 
conduct oi' the work (usually involving the substitution of NASA 
test domains for other military domains). In addition, we have 
the right to add funds to DARPA work sponsored through other 
agents and co-manage the technical directions of that work. In 
practical terms, tli is can mean up to a tenfold leveraging of our 
funds (see examples below) . 

90 

ORIGINAL PAGE FS 
OF POOR QUALITY 



Al?C PI .1 lining and Reasoning (Continued) 



We will now brlelly deKcribe, for each of the research areas 
described above, how the program will likely proceed in fiscal 
1988. In addition, best-guess milestones will be provided for 
each area. It should be noted that since much of the work is 
basic science, thfit milestones beyond a year or two out will most 
likely undergo significant alteration as the real world dictates 
the course of such work . 

o Reasoning under Uncertainty — We will continue our internal 
work, led by Peter Cheeseman, on probabilistic methods for 
uncertainty management. External collaborations will include 
Lotfi Zadeh's (UC-Berkeley) work on fussy logic and research by 
students in (lie Stanford Medical Computer Science Group on 
integration of decision theoretic and heuristic methods. We may 
also sponsor work by organizations like Advanced Decision 
Analysis and Advanced Decision Systems in developing 
methodologien and tools for combining classical methods with Al 
methods. A synthesis of current ideas will appear in the form of 
a major review or book during 1988. A practical demonstration of 
the ideas being developed will occur during the 1990 Systems 
Autonomy Demonstration Project. 

o Learning liy the beginning of fiscal 1988, we hope to have as 
part of our staff three respected researchers in this area (one 
is already onboard). Internal work is likely in the areas of 
learning by discovery and explanation based generalization. 
External collaborations with Tom Mitchell and Jaime Carbonell at 
Carnegie-Mellon on learning by experimentation and with John 
Laird at the Universi ty of Michigan on learning as search will 
continue. lliach of these projects has deroonBtration milestones in 
the 1988 to 1990 time frame; major milestones include an initial 
demonstration of i earning by experimentation in a robotic 
environment during 1989 and self-improving knowledge bases as 
part of the 1990 Systems Autonomy Demonstration Project. During 
1991-1992 we plan to demonstrate discovery- based learning by 
introspection on a Jcirge database of sensor-derived information, 
most likely either as part of a collaboration with SETI 
researchers or on a DMS-type testbed for Space Station. Truly 
robust metliods will probably not be available until at least 
1993-1994. 

o Causal Modeling and Simulation--lnternally we are using the 
1988 SADP Sp.ice Station Thermal System as a test domain for the 
combination of heuristic and model-based methods in diagnosing 
flaws in complex systems. In addition, we hope that at least one 
of two candidates currently being pursued in this area come 
onboard and initiate new internal research programs. Externally 
we will fund Bernard Ziegler at the University of Arizona in 
integration of knowledge based and traditional simulation methods 
and Michael Cenesereth at Stanford University in logical 
representations of structure and function. A major milestone is 
the successful demonstration of these methods during the 1988 
SADP Thermal System demonstration. More sophisticated methods 
will be empJoyed in work on the Hubble Space Telescope and other 
projects that involve modeling complex devices. 



91 



ORfGfWAL PAnp r 
OF POOR QUAUTY 



ARC Pli^nnins and Reasoning (Continued) 

o Knowledffo from DeKinn Through OperationB--Internally we will 
focus our work on Btudying the Hubble Space Telescope as a test 
domain for Uiroe research areas: integration of knowledge 
acquisition into tti<^ design, construction, and testing process, 
acquisition of knowledge from large numbers of experts, and large 
knowJedge hnso technology. Externally, the Knowledge Systems 
Laboratory at Stanford will collaborate with us on the latter two 
topics and Mark Fox at Carnegie-Mellon on the first topic. We 
will show how design and testing tools can be used for knowledge 
acquisition during 15H38 and 1989. A very large knowledge base 
system will be demonstrated during 1990. Methodologies for the 
combination of expertise from at least a dozen experts will be 
presented d\iring 1990. 

o Advanced Planning Methods--lnternal work will proceed on 
testing tlie limits of current Al-based scheduling methodologies 
applied to NASA problems, particularly in space science. Work on 
dyncimic r<;p ' ann iiig will c;ontinue and we will initiate research on 
the application of skeletal planning and plan refinement to NASA 
domains. Externa lly we will support and collaborate with work at 
JPL in sensor b,-u>ed planning, at IntelliCorp in the development 
of a 'J'ruth Maint^enance System-based planner, and at USC-lSl in 
the application of DAKPA-sponsored methods to NASA problems. 
Current methodologies Jor heuristic scheduling will be 
demonstrated in Pioneer Venus experiment scheduling during 1987. 
The JPli work has milestones in a sensor-rich subsystem of Space 
Station during 1908 and 1989. That work and other internal and 
external efforts will be demonstrated as part of scheduling the 
power subsystem of Space Station during the 1990 SADP 
demonstration. The THS-based planner will be delivered to NASA 
during 1989 and applied to at least one significant problem 
during that year. Finally, we will integrate learning methods 
into planning systems during 1989-1990. 

o Cooperation among Multiple Knowledge-Based Systems — Our 
internal research focus will be on the 1990 SADP demonstration; 
most likely a demonstration of coordinated control of thermal and 
power subsystems. We will use consider the use of the Hubble 
Space Telescope as a second domain for cooperative systems. 
Externally we will support work at the Stanford Knowledge Systems 
Laboratory in blackboard architectures for distributed control of 
knowledge- based systems, by Kon Larsen at the University of 
Maryland in potential hierarchical control methods, and by Tom 
Sheridan at MIT in languages for command of multiple systems. In 
addition, a major new effort, .jointly sponsored with DARPA, will 
begin at Stanford, SHI, and Rockwell in methodologies for 
interacting intelligent agents in the domain of Space Station 
Construction. Blackboard architectures will be demonstrated in 
NASA domains during 1988. A plan for coordinated construction of 
Space Station by human and robotic entities will be presented 
during 1989 with small scale demonstrations in a robotic test 
environment at SRI during 1988 and 1989. A practical 
demonstration of cooperative control (somewhere in the spectrum 
of distributed to hierarchical) will occur in the 1990 SADP 
demonstra ti on . 

92 

OF POZJi Qi:>,:XLitY 



AUC bVUinniiiK and ReaBoning (Continued) 

o Validation MethodolRieB--During 1987 we will conduct a 
NASA/Industrial workshop to begin to come to grips with the 
practical it?£>ueB of knowledge based Bystem validation in NASA 
domains with a particular focus on Space Station. This will 
involve participation from other NASA centers, Boeing, Rockwell, 
Honeywell, liockhoed, MACDAC, and several others. The result of 
that workshop will be a detailed report to appear in early fiscal 
1988. We are considering several externally-sponsored projects, 
particularly at Lockheed and Honeywell. The first major 
milestone will be the development of an accepted validation 
methodology for the 1988 SADP Thermal System demonstration. 
Validation work will also occur as part of the work described 
above on mu I tip le -expert knowledge acquisition and large 
knowledge base technology. This will produce results in parallel 
with those mileBtones in 1989 and 1990. 

PRODUCTS AND URNI^I'MTS: 

Since the focus is on research rather than development, the most 
important "products" of our work will be problem-solving 
methodologJGi5 as represented by "existence proofs" and 
publication jn major, respected journals and conferences (in the 
field of Artificial Intelligence, approximately eight journals 
and three conferences fit that description). However, because 
even our long term research will be conducted in the framework of 
a difficult NASA problem domain, it is certain that a stream of 
short-term applications to those domains will result. Our desire 
to use space science scheduling problems as a test domain for 
work in advnrtced planning methods will result in an automated 
scientific experiment scheduling product for Pioneer Venus during 
f isccjl 1987, and more sophisticated resource management systems 
for more complex spacecraft in 1988 and later. The Hubble Space 
Telescope work, in collaboration with MS£'"C will produce an 
Orbital Verification system in fiscal 1989 and a full Ground 
Support sysiem in 1990. A tool to link existing NASA databases 
to knowledge -based systems will be either built de novo or 
adapted from commericaJ products in 1989 or 1990. It has been 
our experience that the successful conduct of knowledge-based 
systems research involves long-term interactions with experts in 
the domains we use to test our ideas. Those experts will only 
retain their interest in our long-term goals if we provide such 
Bhort-term benefits to them. 

In addition, when existing commercial tools prove inadequate to 
conduct our- rcisearch work, we will develop initial forms of new 
tools to eneible our research progress. If those are promising, 
we will begin the generalization process and attempt to find a 
suitable, usually commercial raechanlBm for the "productization" 
of that work. F'art of this may automatically occur in work we 
sponsor in industry. The areas of Planning and Knowledge from 
Design through Operations described above are those most likely 
to result in such generalizable tool developments. 



93 



AIK' Planning and Reasoning (Continued) 



BUDGET AND lU-lSOUHCES: 

Budgel- in Fincai 1907 in $985K. Expected budget in 1988 Ib $3.bM 
with a projected incrrease of $lM/year for the next three years. 
Of that budf'ct, we expect roughly $lM/year will be spent 
internally on equipment and support service contractors (Sterling 
and RIACS mostJy) and the remainder spent in sponsoring academic 
and industrial collaborators. Effective budget in 1988 and 
beyond, bec<-)uf>e of the DARPA agreement, will be greater; in 1988 
we will bo. managing at least $i?M of DARPA funds on at least two 
contracts/gran1;s ( Btanford/SRl/Rockwell , and USC-lSl) and 
contributing to at least two DARPA SCI contracts managed by other 
agen ts . 

By the beginning of 1988, personnel will consist of approximately 
8 civil servants and 7 support service contractors (who will be 
considered full NAi'iA participants in the program). The number of 
civil servants devoted to research in this core technology area 
will increase by at J east four per year for at least three years 
with an emphasis on researchers with a PhD in artificial 
intelligence. Contractors will increase at a considerably slower 
rate (approximately two per year), as several current contractors 
will be converted to civil servants upon availability of job 
slots and naturalization of certain foreign nationals. 



TECHNOLOGY DELIVERABLES: 

Work conducted under this element of the Systems Autonomy Program 
spans a range of activities from long-term scientific research to 
medium-term tool development to short-term applications 
demonstrations and products. All activities are conducted in the 
context of challenging NASA problems, and all will have spinoffs 
into those problem domains. The history of applied Al indicates 
that particular spinoffs are nearly impossible to predict in 
advance, particularly this early in an expanding research program. 
However, for each of the seven major areas of research within this 
core technology element, we indicate short (0-2 year), medium (2-5 
year) and long (greal,er than 5 year) term goals as they now exist. 
Shorter term goals are more concrete than longer term ones and fall 
more i rrto the category of "deliverable" products. In addition, we 
expect considerable sharing of ideas, tools, and research results 
with all other elements in the Systems Autonomy Program; in 
particular, tliis element will be providing expertise in scheduling 
and cooperative knowledge-based systems to the SADP element and 
conducting joint research activiities with the MSEC HSTDER element. 

Machine Learning - A short-term goal is to make the AUTOCLASS system 
into a useful tool for a wide- Variety of data analysis tasks. 
Medium-term goals are to demonstrate utility of the learning by 
experimentation approach, and begin to integrate learning mechanisms 
into diagnosis and control systeffls useful for missions like Space 
Station. Longer term goals include successful model-based discovery 
systems and full integration of robust learning methods into flight 
systems . 

9V 



ORiGSMAL P.^GE tS 
OF POOR QUALITY 



AKC IManninfj and Reasoning (Continued) 

Planning and Scheduling - Short-term goals are to deliver heuristic 
scheduling tsystf^ms to several relevant Agency misBions and to 
demonstrale initial solutions to highly combinatoric science mission 
scheduling problems. For the medium term there are plans to provide 
a truth-ma jntenance-based planning tool for use in dynamic 
environments and to demonstrate reactive planning in such domains as 
Mars Rover science planning. A long-term goal is to provide full 
integration of planning, plan monitoring, and plan execution for 
complex tasks like Space Station resource scheduling. 

Cooperating Knowledge-Based Systems - In the short-term, blackboard 
systems will be demonstrated as a potential solution to 
loosely-coupJed control of multiple subsystems. Over the medium 
term, furtlier mechanisms for coordinated control at various points 
along the distributed to hierarchical spectrum will be developed and 
applied to NASA probJems, and detailed scenarios for interacting 
intelligent agents performing complex tasks (like construction 
tasks) will be published. A long-term goal is to demonstrate a 
system that ilJustrates full, robust communication of intents, 
beliefs, and goals among many disparate agents in a major problem 
domain. 

Validation of Knowledge-Based Systems - A short-term goal is to 
provide a practical solution to the problem of SADP thermal system 
validation. A medium- term goal is to tightly couple the process of 
system specification with system implementation for knowledge-based 
systems so (hat changes in specification are accurately and 
automatically reflected in tlie operational program. A long-term 
goal is to provide validation solutions for AI systems which can 
learn and therefore are self -modifying (solutions which are more 
satisfying than simply revalidating the total system each time a 
modification is made) . 

Managemeni; of Uncertainty - In the short term, systems which 
illustrate probabilistic, fuzzy logic, and evidential control of 
uncertainty w i J 1 be produced and demonstrated. A medium-term goal 
is to integrate two or more of these methods into a synergistic 
approach to the problem. A long-term goal is to combine machine 
learning with these static metliods to achieve robust system behavior 
under wide; varieties of changeable conditions. 

CauSiil ModtvlitJg Short term goals will be reflected in a 
demonstrable system which illustrates causal modeling for the SADP 
thermal management system. Over the medium term, the ability to 
modeJ interactions among related subsystems (i.e a total system 
view) will ho shown. A iong-term goal is to build a system that can 
model a complicated device at many different levels of detail 
(dependent on problem-solving needs). 

Rnowl(Ml;;e A<;<iui si tion and Large Knowledge Base Technology - A 
short term goal is l;o illustrate the integration of knowledge 
acquisition with traditional CAD/CAM design tools. In the 
medium-term, methodologies for completeness and consistency 
management o(; knowledge bases built from multiple sources of 
expertise wijl be demonstrated. Over the long term, there will be 
nearly automatic knowledge acquisition during design, construction, 
and testin/j oT a complex device, as well as usable, very large 
knowledge based systems representing both experiential and 
functionni knowledge about entities as complex as Space Station. 

95 

OF POOR QUAL!TY 




OmGltmi PAGE !S 
OF POOR QUALITY 



Al. AMES RESEARCH CENTER 

A1.2 CORE KESEAKCH AND TECHONOLOGY (Control Execution). 

TITLE: Symbolic Controller. 

OBJECTIVE: Develop and test a mathematical theory for the design 
of symbolic controllers which provide the required interface 
between the high-level AI planning/supervision levels and the 
realtime ar i thmetic levels where the commands are executed and 
system behavior measured. 

RATIONALE: There is a symbolic/arithmetic interface inherent in 
all intellJRent autonomous systems because strategies must first 
be generated by manipulating data at high levels symbolically by 
means of hiRh- level Janguages and then automatically converted 
into detailed symbolic command sequences. The symbolic commands 
must then be converted into arithmetic functions of time to be 
used as guidance signals for the effectors. Similarly, the 
information gathered by the various sensors measuring the system 
behavior is initially arithmetic and it is processed 
arithmetic;a I ly to obtain estimates of system state. The 
arithmetic functions of time expressing the system state 
estimates must then be converted into sentences in the high-level 
language used by the high levels of the system. Currently, there 
is a growing body of knowledge on how to design Al systems, and 
there is an effective methodology, strictly arithmetic, for the 
design of aut.omatic systems, but there is no methodology for the 
design of t)io symbolic/arithmetic interfaces. Such a methodology 
must bo developed. 

In addition, since Al is concerned with heuristic reasoning about 
quasti-s tatic processes, the AI methodology is not directly 
appJ icable to the design of dynamic systems. On the other hand, 
while dynamics is central to the conventional automatic control, 
design of reasoning algorithms is intractable with the arithmetic 
methodology in its current form. A method of expressing dynamics 
concepts symbolicalJy roust be found. 

APPROACH: The subject research program will explore the 
possibility of developing a mathematical theory for the design of 
symbolic con tollers for dynamic systems. Tlie approach will be to 
build up prodicate calculus to include time and dynamics concepts 
within the syntax; explore ways for representing estimated states 
and time hintories symbolically; and explore ways for translating 
sentences of tlie command sequences into arithmetic functions of 
time. In addition, means for expressing global system properties 
such as stability, robustness, and disturbance rejection will be 
explored . 

The researcti will be conducted both in-house, and through 
university grant£>, and NRC/IPA Research Associateships. The 
concepts and algorii^lims will be tested by means of realistic. 



97 



OF POOR QUALITY 



AlU; Symbolic Con broiler (Continued) 



PRODUCTS: Met.ho(lolo/»y I'or the desif^n of symboiic controilerB . 



BENEFITS: Symboiic controliers are essential components of 
intelligent- nutonomouG systems. 



SCHEDULING AND FUNDING: 



Modal loRic caicuJus for 
dynamic systems 

State translator 



Verifiable , alRorithm j c 
supervisors of arithmetric 
control lers 

Tests and evaluation ~ NASP 



Tests and evaluation - Robotics 



FY 88 89 90 91 92 



bO 


50 


75 


75 


75 


46 


50 


50 


50 


50 



25 50 50 50 



25 25 



25 25 



Totals ($R) 
Civil Service MY 
NRC/lPA 



96 150 200 200 200 
2 2 2 2 2 
2 2 2 2 



TECHNOLOGY DELIVERABLES: 

o Dynamic model of SADP/JSC Thermal Testbed Oct 1988 

o Symbolic Control model problem developed Oct 1989 

o Mathematical procedures for combining high level Oct 1990 
task planning with low level motion control 

o Simulation tests of NASP autopilot Oct 1990 



98 



L 



^ 



> 

o 

-J 

o 

z 

X 

q cc 

LU uj 

o 

oc 

I- 
z 
o 



< 
cc 

O 

a: 
a. 

> 



o 

D 
< 

LU 

h- 

> 



UJ 

> 
o 

lU 

03 
O 



LJJ 
CC 

o 



o 

m 

S 
>■ 

(O 

I 

z 
g 

O 
UJ 
X 

111 

o 

oc 

I- 
z 
o 
o 



oc 



5 

P: 

i 

i 

K 

Q. 
O 



X 



g] 



I 

«> 

i 
2 



o 

LU CO 

o 



UJ 



CD t- 



CO 



















UJ 






O 






Z 


o 


UJ 


< 

CD 


z § 

< 3 


O cc 

CO )- 




o 


S z 


Q 




> o 








t/) u 
















' 
























' 


' 




















v> 


















> 


















<2 


UJ 

O 

z 
111 




>a: 

K UJ 

W -1 

uj5 


CO 

UJ 

o 

Z 

UJ 


CC 

o 

< 

</J 




Z UJ 

OS 


o « 

UJ _| 

S O 

X CC 


S'uJ 

_ z 
< J 


Z 

UJ 




Z 

UJ 


< 




^S 


1- K 

Si 


(/> 




dO 


w 


CC 










cnO 




H 
























z 
o 




































. 


















ii 


1 




z 










z 




< 










< 




E ' 


■ 












S ' 





o 

z 

Q 

z 

U. 



lU 

_i 
3 
O 
UJ 

X 

o 

V) 







o 


O 

m 




0> 




o 
to 


o 
in 


S |mn 


s 




o 

lO 


o 


« gCM 


s 


g 


o 

IT) 


in 

CVJ 


in o «^ »^ 
CM tn 


s 


o 


(O (DM 



2 



C3> 




o 






o 




(5 






o 

E 


o 


(A 

C 






<d 


Ifl 


0. 


^« 


c 
>. 


c 


•o 

c 


z 


o 


_ 




n 




1 


F 


« 


E 
E 


U) 


<n 


^ 




(0 


U) 


o 




o 


« 


« 


u. 


<n 


O 


1- 


1- 



>- 
s 

3 — CC 
U. U Z 



V) 

UJ 

"3 

O 

< 

u. 

Q 

Z 
< 

z 
< 

CL 

o 

H 
QC 
< 
Q. 



{2 
2 



cc 

5 



> 

UJ 

cc 

UJ 

m 



Q 
QC 

2 



co 

CO 

UJ 

b 

CO 

cc 

UJ 

> 

z 

3 



CO 

UJ 



8 

CO 

o 

cc 

S5 

CO 

UJ 

cc 

< 

Ql 
Q 

z 
< 

o 

QC 

z 



CO 
QC 
P 



Z3 
1 
CO 

I 
O 



UJ 



«) CO CO 

Uj Ul UJ 

CSS 
3 < < 

G 

5 



99 



Al. AMES RESEARCH CENTER 

A1.3 CORE R&T (Operator Interface) 

TITLE: Human Interfaces to Automated Systems 

OBJECTIVES: The objective of this program is to provide NASA with a 
capability and focused fundamental research program in human-machine 
interaction with highly automated systems. Efforts will be directed at 
three domain areas of interest to NASA's space effort, and the Systems 
Autonomy Program in particular: 

(1) Systems Operation and Fault Diagnosis 

(2) Planning and Reasoning 

(3) Data Base Query and Access. 



RATIONALE: Significant levels of automation are anticipated for many 
future space-borne systems, including Space Station. Experience with 
highly automated systems in transport aircraft has shown the need for 
improvements in the communication of operator intent and machine 
behavior. Moreover, a substantial proportion of development time is 
devoted to the human-machine interface. Significant advances in our 
understanding of human cognition and man-machine interaction are 
necessary to improve human-machine communication and develop design 
aids that will shorten development time. 



APPROACH: The ob.jectives will be met by developing the fundamental 
understanding and tools to develop advanced interfaces, and by 
developing focused applications of prototype interface technology, 
including very advanced graphics systems and the Virtual Workstation 
being developed under RTOP 506-47. Improved design aids and interface 
technologies will be developed in a collaborative NASA - university 
research program. Prototype applications will be developed using civil 
servants, in-house support service contractors, and visiting university 
researchers. Cooperation with other NASA, industry, and academic groups 
will range from informal sharing of results, sponsoring of joint 
workshops and symposia, to formal, funded projects. Facilities within 
ARC/FL will be extended to support in-house research and make it 
possible to provide appropriate resources to visiting scholars. 
Augmentations in civil servant research staff will be made to insure 
the breadth necessary to meet program goals. 

PRODUCTS: The px-oducts include: 

(1) Design Decision Aids and Rapid Prototyping Tools 

(2) More Natural Human -Computer Dialog Systems 

(3) Advanced Display/Control Concepts 



100 



ORIGjr^AL PACE JS 
OF POOR QUAUTY 



ARC Operator Interface (Continued) 

Research and development efforts have been selected that will support 
the SADP and wliose products will be incorporated in post- 1988 
demonstrations. A major goal of the research program Is the development 
of a prototype Computer Assisted Interface Design (CAID) package that 
integrates the elements of the research into a single design tool. 
Specific products include: 



DESIGN DECISION AIDS AND RAPID PROTOTYPING TOOLS: The refinement, 
application, and evaluation of existing formal task analysis models 
will be undertaken with the goal of improving accuracy and decreasing 
overhead in use. An in-house action- level model developed for use with 
the Orbital Refueling System will be extended to cover the Thermal 
Management System and Implemented as a prototype software tool. 
Theoretical efforts directed at providing the necessary advances in our 
understanding of selected areas of human information processing will be 
documented. 

MORE NATURAL HUMAN-COMPUTER DIAGLOG SYSTEMS: In-house 
capabilities in speech and natural language interfaces will be extended 
and applied to the Human Interface to TEXSYS. Evaluations will be 
documented and continued experimentation will lead to guidelines for 
the use of speech and natural language as dialog media. These efforts 
will be merged with the virtual workstation to produce a prototype 
virtual interface. Support will be supplied to universities for 
continuing advancement of natural language interfaces. 

ADVANCED DISPLAY/CONTROL CONCEPTS: Research will focus on 
developing a set of rules, or guidelines, that would suggest how data 
graphs should be formatted, how schematics or other diagrams are best 
displayed, and how three-dimensional information should be presented on 
a two-dimensional screen. In addition to guidelines and reports, this 
effort will culminate in a prototype expert system for displaying 
graphic information. This work will be integrated with the virtual 
workstation. 

COMPUTER AIDED INTERB'ACE DESIGN (CAID) SYSTEM: Individual 
research and development efforts will be integrated into a prototype 
computational design tool for interface development. A major emphasis 
will b^ on the development of methodologies for interface evaluation. A 
facility will be developed for iterative testing and refinement of CAID 
on large scale applications. 

BENEFITS: The benefits from such a program would included software 
tools and guidelines that will facilitate the design and evaluation of 
human interfaces. The tools and guidelines will embody empirical and 
theoretical knowledge about human users that will guide the 
implementat^ion of aids for unanticipated failures and goal directed 
natural language interfaces . 



101 



ARC OoeratDr Interface (CDntinued) 

SCHEDULE AND FUNDING: 

FY SB B9 90 91 92 

Desian Decision Aids and Raoid ====: ==== ===== ==== ==== 

Prototvping Tools 200 200 150 150 150 



More Natural Human— Comouter ===== ==== ==== ==== ==== 

Dialog 1B5 150 150 150 150 



Advanced Di spl ay/Caritrol ==== ==== ==== ==== 

Graphics 50 50 100 100 



CAID DevElopment 



53 100 100 



Totals (*K) 385 400 403 500 500 

Civil Service MY 2 2 2 3 3 



TECHNOLOGY DELIVERABLES: As the Svstems Autonomv Program evolves an 
increasing caoabilitv in artificial intelliaence and automation 
systems of increasing complexity will be supervised by fewer human 
operators. Current systems with high levels of automation have 
already been associated with a pattern of human error chacterized bv 
a lack of situation awareness and a failure to generate appropriate 
system expectations. Human interface development and the integration 
of interfaces with automation and target "plants" is costly and 
time— consuming. An increased understanding of human cognition is 
required which focuses on the human operator's conceptual 
representation of situation, and addresses specific needs such as 
attention management, human error detection, information management, 
and communication of action and intent. Coupled with this is the need 
for tools that facilitate task analysis and the incorporation of task 
analytic and human performance data in the design of the human 
interface. 

Consistent with these needs the 19B8 Technology Deliverables from the 
Human Interface Core Research Program will center on the apglication, 
evaluation, and development of methods for task analvsis and operator 
modeling. These will include: <1) A task model of the thermal control 
system; (2) A computerized task analvsis tool derived, in part, from 
the application to the thermal control svstem: and, (3) An evaluation 
of three coanitive modeling methods. In addition, the 19SB 
deliverables will include efforts to improve the dialog between the 
human and an expert svstem bv developing (1) a task-oriented natural 
language interface and example discourse svstem for the thermal 
control Bvstem, and (2) an operator-compatible qualitative model of a 
space-borne process control application designed to facilitate causal 
explanations. Finally, an Operator Interface Workshop will be held to 
foster an exhanae of information of benefit to scientists, 
developers, and operators. 

102 ORIGINAL PAGE IS 

OF POOR QUALITY 



o 
o 



X 

o 

LU 
Ui 

o 
o 

< 

o 
o 

CC 
Q. 

>■ 



o 

D 
< 

LU 

> 
CO 



Hi 

> 

H 
O 
UJ 

"3 
ffi 

o 



o 

< 

u. 
QC 
LU 



cr 
o 

tc 

UJ 
CL 

O 



Q P o t 
•t S '^ ? 

?? g W OL 

f« f> t S 

uj lu b s 
-J 5uj - 



CO 



O 









w 






UJ z 



►- H 



SO 



tf) 



O O U) u. 








O 

z 

Q 

Z 

=> 

u. 

Q 

Z 
< 

u; 

_j 

Q 
UJ 

Z 

o 

(0 



SI 








g o 


a» 








89 
in n 


s 










0) 

CO 










s 







« 
5 
a 

E 
o 

'o ^ in 
§ ^ 6 



JO 

.8 



a 

c 

S) 
« 
Q 



•g 
'a. 

n 



2 2. 

I? 

so 

2 



c 
o 
O 

JS 
a 

CO 

O ffl 
n) o 

< 



>• 

s 

•D — 



c 
« 



5 
« 

Q 
9 

< 

o 



UJ 

u 

< 

u. 

IJ.?0 

^ OC EC 
-I O O- 

8^i 

S UJ c') 

a UJ 
< O Q 



UJ 



< 
u. 

Q 

Z 
< 

Z 
< 
Q. 

G 



QC 

< 
Q. 



CO _ 

UJ — 



CO 
DC 
UJ 
> 

z 

3 




oc 

2 



Uj 



2 



103 



AI. AMES RESEARCH CENTER 

A1.4 CORE R&T (Syntems Integration and Architecture) 

TITLE: Spaceborne VHSIC Multiprocessor System. 

OBJECTIVE: Develop systems concepts required for the implementation 
of robust knowledge-based systems in spaceborne applications. 

RATIONALE: Current systems under development today such as the 1750A 
architecture are not suitable for large real-time knowledge-based 
systems projected for the Space Station environment. Current 
limitationi; include the capability to allocate and deallocate large 
memory stacks vs. pages; the integration of numeric and symbolic 
processing lor both cooperative and autonomous processing of data 
functions; tlie management of multiprocessing archltecures in an 
automated, fault.- tolerant environment; the management of large 
knowledge data bases in excess of 1 gigabyte; and, software 
compilers cind translators to support both the development 
environment and the run -time operational environment. NASA has 
unique requirements in this area and cannot expect industry and/or 
academia to pursue this specialized area of research. As an 
example. Space Station will probably have the first large 
knolwedge based system test case for use in a operational test bed 
environment (Thermal Control System followed by the Power System) 
which is driven by real-time fault- tolerant constraints placed on 
space sys terns . 

APPROACH: Specific tasks include the design and development of the 
spaceborne integrated numeric/symbolic multiprocessor computer; 
definition and development of the network interfaces and data 
transmission protocols for an "open architecture" 
(vendor -independent environment) ; development of the software 
protocol and management for large, distributed knowledge-based data 
systems; development of software compilers and translators for use 
use in both a development and an operational environment; and, 
design and development of verification and validation methodologies 
for fault tolerant reconf igurable multiprocessor architectures. 

PLANNED ACCOMPLISHMENTS: Specific task elements to be accomplished 
under the System Architecture and Integration Task include the 
following: 

o Processor Architecture 

2nd Qtr. , FY-88: Complete the conceptual design of the 
spaceborne processor including identification of risks and design 
tradeoffs; delivery of computer models for simulation of the 
proposecl architectures; projected system design configuration for 
a 6 to 8 processor configuration including weight, form factor, 
performance, fault tolerance methodologies, both software and 
hardware approaches, and radiation tolerance. Processor 
architectures being considered include a 32-bit numeric processor 
with a VAX instruction set and a 40-bit symbolic processor with a 
Common LISP instruction set. Current work is being done under a 
contract awarded to the Symbolics/TRW Team. Completion of this 
work is scheduled for February 1987. 



10^4 



ARC Bpaceborne V'HSIC Multiprocessor System (Continued) 

3rd Qtr. , FY-80: Initiate Phase Two of the development effort 
with contracts awarded to two competing efforts. Phase Two will 
be for 24 months and will include the detailed design of the 
multiprocessor architecture including both hardware and software 
environment and interfaces . 

4th Qtr., FY-9(): Initiate Phase Three of the effort with the 
contract; awarded to the best of the two efforts from Phase Two 
above. Phase Three will be for 48 months and will include the 
development, test, and qualification of the spaceborne unit. 

It is expected that Phases Two and Three will be .iointed funded by 
Space Station and DARPA with possible participation by the Navy and Air 
Force. ARC will be the focal point for this activity. 

o Software Environment 

This effort focuses on the development of the software 
environment for the spaceborne multiprocessor. Activities 
include hhe development and validation of software compilers and 
translators for the software development environment and the 
operational run -time environment. Initially, Ada will be the 
target baseline language with compilers/translators being 
developed for compatibility with that language. Attention will 
be focused on Common LISP, Concurrent Common LISP, and Prolog. 
ARC will be the focal point for this activity. Other potential 
participants include QuinUus, LaRC, and DoD. During FY-88, 
funding will either be via IR&D or in-house funding. 

o Data Base Management 

Tliis effort focuses on the development of data base software 
methodologies for the control and management of large, 
distributed knowledge-based data systems including the 
maintenance and integrity of these large data bases under a 
dynamic, real-time operational environment. It is expected that 
these data bases will exceed 10 gigabytes. GSFC will be the 
focal point for this activity. 

o Fault-Tolerant Systems 

This effort focuses on the development of fault-tolerant 
methodologies, both hardware and software, for the management of 
real- time fault-tolerant reconf igurable multiprocessor 
architectures. Due to the complexity of these multiprocessor 
architectures, it is expected that a software approach to fault 
tolerance will be a significant factor in both processor fault 
tolerance and immunity to radiation including single event , 
upsets. LaRC will be the focal point for this activity. 

PRODUCTS: A Spaceliorne VHSIC Symbolic/Numeric Processor capable of 
handling a minimum of 22,000 rules with an execution rate of 8,000 
rules per second (equivalent to 8 mega-instructions per second). 
The processor will have an execution rate of 10-15 MIPS, 10 GBytes 
total memory, minimum of 100,000 rads radiation resistance, and a 
concurrent common LISP, Ada, Prolog, and C development environment. 

105 



ARC Spacreborne VHSIC Multiprocessor System (Continued) 

BENEFITS: Thip research effort will produce the advanced 
computational architecture technology for future complex NASA 
aerospace mJBnionc which will require robust intelligent autonomous 
systemB for increased capabilities, productivity, and safety while 
operating under adverse and hostile aerospace conditions. 

SCHEDULE/REEJOURCES : 

FY 87 88 89 90 91 92 93 94 

Concept Definition ==== 

User Inputs/Kvaluation ---= ==== ==== == 

Two BrasBboards ==== ==== 

Flight Qualified Unit ==== ==== ===== === 



Funding ($K.) 1185 1986 2000 2500 2500 2750 3000 3000 

Manpower (Civil Service) 55554322 

TECHNOLOGY DKLIVERABLKS: 

Several t'><!hnology "products" will be derived during the development 
of the Spaceborne VHSIC Multiprocessor System (SVMS). Since the 
SVMS is being developed as a heterogeneous parallel computer system, 
the interim technology deliverables will be primarily software 
products which are required for the integration and operation of 
several specialized processors with architectures optimized for 
specific functions such as numerical processing, symbolic 
processing, data base management, etc. The SVMS will be fully 
compatible with the DoU-developed VHSIC line of modules and the 
1750A processor. The projected hardware and software products are 
described below with the target delivery dates: 

a. 1988 

(1) Performance Metrics/Software "Traps" - A series of test cases 
representing large complex knowledge-based systems applications in 
both aeronautics and space domains will provide the reference 
baseline for the evaluation of the proposed SVMS architectures. The 
first of these test cases, the Thermal Control System (TCS) for 
Space Station application, will be available in mid-1988. Projected 
dates for the remaining test cases are as follows: 

Late 1908: "HUSK", an aeronautics test case developed by the 
Royal Aircraft Establishment (RAE) , for automated aircraft 
applications . 

Mid- 1990: TCS/Power Test Case, cooperating, intelligent systems 
for Space Station applications. 

TBI): "Autocons", cooperating, intelligent agents for robotic 
construction of large npace structures, a Joint NASA/ARC and DARPA 
effort. 

106 



ARC 



Bpaceborne VHSIC Multiprocessor System (Continued) 



TBD: "AuUoBis", intelligent robot Golentific explorer, a joint 
NASA/ARC and CMU effort. 

(2) Interface standardB/protocols - Draft set of 

guidelines/Rpecif ications will be developed to allow the evolution 
and Integration of advanced computer architectures including data 
networks into the information systems architectures baselined for 
the Space Station. The concept for implementing the "hooks and 
scars" for evolutionary hardware and software will be evaluated 
during this process. The guidelines/specifications will be 
evaluated using the 1988 TCS Demonstration at NASA/JSC as the 
baseline system. 

(3) Network protocols - The initial effort at defining and 
implementing the network protocols for multiprocessor systems 
including the dynamic management of large data bases in excess of 10 
GBytes will be developed with delivery of the prototype software 
network management system. Final version of the software system 
will be delivered in late 1990. 

b. 1989 

(1) Performance measurements for multiprocessor systems - Using the 
test cases developed during the 1988 time period, several 
multiprocessor system architectures will be evaluated and their 
strengths and weaknesses identified and investigated. These results 
will be used in optimizing the system performance of the SVMS design 
and integrated with the 1990 SADP demonstration involving the 
automation of two cooperating intelligent systems (TCS and Power) . 

(2) Data Hane Management System (DBMS) - The first version of the 
DBMS for mulliprocesBor systems associated with large data bases in 
excess of 10 GBytes will be delivered and tested. The results of 
the evaluation will be used in developing the final version of the 
DBMS targeted for delivery during late 1992. 

c. 1990 

(1) Automated load scheduler - An automated load scheduler for 
increasing the utilization of individual processors in a 
multiprocessor system will be delivered for evaluation. The load 
scheduler will be integrated into the operating system and will also 
include the software for fault diagnosis, identification, and 
correction. Final version is expected to be delivered in 1993. 

(2) "Brassboard" SVMS - The brassboard Spaceborne VHSIC 
Multiprocessor System will be delivered complete with the software 
required to operate the system and its software development 
environment. The System will contain flight qualificable components 
and modules but will not be packaged in a flight configuration. 
Software crnpablllty for fault tolerant management will not be fully 
develope<' ft (hJs time. 



107 



ARC Spaceborne VHSIC Multiprocessor System (Continued) 



d. 199:? 

(1) Reconfigurable, fault- tolerant software roethodologieB - Software 
for fault diagnosis, identification, and SVMS Bystem reconfiguration 
using on-chip components for system reconfiguration and hardware 
fault recovery. Tolerance to single event upsets will also be 
included as part of the software package. 

(2) Validaled Cross-compilers and data translators - The initial 
version of the validated crosB-compilers and data translators for 
the BVMS will be delivered in 1992. Emulations for the 1750A and 
VAX-780 instruction sets are expected to be included in this effort. 
The baseline run time environment is ADA with Common LISP, Prolog, 
C, and ADA as part of the programming environment. Final version is 
expected during early 1995. 

e. 1995 

(1) Flight-qualified Spaceborne VHSIC Multiprocessor System, early 
Cy-1995, 4 to 6 processors per system with supporting peripherals 
(networks, memory, etc.). 

(2) Compatible line of VLSl/VHSIC library of hardware modules for 
specialized functions such as image processing, FFTs, symbolic 
processing, etc. These modules will constitute the supporting 
computational eJeroents for the parallel heterogenous SVMS. 



108 



>- 

O 



O 
in 

H 
LU 
CC 
O 
O 

< 
GC 
(D 
O 
QC 
Q. 

>■ 



O 

H 

< 
CO 

LU 

H 

> 
(f) 




n 



eg 

O) 



o 

z 

Q 

z 
3 



< 

a 

z 
_i 

Q 
UJ 

X 

o 
w 



00 



co 



O CM 



O CM 



« CO 
C>1 



CM 



X 

< 



op 
o 



Q. 

O 
Q. 

m 



in "> 

CM 



o m 



1- lO 

cm' 



o <n 

CM 



i> w S = 



> 
111 



Q t= 



I CO tf) 



— O) « 
to ^ 

s 



■c -O m t^' ^ 



0) 



-c c •;= -:^ 



o 

Q. 

„ E 
♦? o 
c o 

5.0, E-S 



<o cnx> _ 



o>x> 
c c 
■^ re 



gg 



iO _ 
; g nj 



o : 



re 



> 15 



c >. 

=) oi 

-o > 

0) o 

•= "O 

™ u> 

O en 



if ^ 



>- 
s 

*» o 

D 

11 



m 



O 

< 
u. 

a 

z 
< 

CO 

I- 
z 
< 

Q. 
O 

H 
OC 
< 
Ol 



CC 

5 









UJ 








(> 








ir 




:^ 




o 




m 




u. 








nr 




:5 


CO 


<r 




OC 




< 






"^ 


a 




CO 




(i: 




o 


_1 


< 




_J 
O 

m 

:? 


u. 
O 

> 


CO 
UJ 




>- 








w 


z 


^ 


a: 

UJ 
Ml 




r) 


LU 


<) 


- 


CO 


Q 
O 


Q 
CC 

O 


< 


C) 


1- 




IJI 


X 


UJ 
Q 


g 


s 
z 
d: 
III 


(n 


> 


< 


^ 


UJ 


DC 


s 


(T 


ir 

CO 


Q 

Z 


UJ 
Q 


DC 

III 


UJ 


< 


T 


^ 


^ 


B 



Q 

Z 

o 



UJ 

< 

OC 



X 
CO 

_1 
m 

UJ 

_i 
< 
o 

H 

< 

Z 

o 

OC 
UJ 

< 

_j 
< 
>- 
o 

DC 



UJ 



5 



>- 

CC 

O 

DC 

o 

m 



CO 

>- 

CO 



UJ 
C3 



o 

DC 
< 



109 



ORIGINAL PAGE IS 
OF POOR QUALITY 



Al. AMES RESEARCH CENTER 

A1.5 Technology DemonstrationB . 

TITLE: Syntems Autonomy Demonstration Project (SADP) . 

OBJECTIVE: DemonBtrate technology feasibility of intelligent 
autonomous systems for Space Station through testbed demonstrationB . 

RATIONALE: The Systems Autonomy Demonstration Project provides a 
technical focus for automation R&D in support of the agency's 
space programs, provides the means for validation and 
demonstration of the automation techno J ogy prior to transfer to 
the agency programs, and establisheB credibility of automation 
technology and user confidence. 

APPROACH: The Systems Autonomy Demonstration Project will be a joint 
effort between renearach and operational centers, initially between 
ARC and JSC with the demonstration being conducted at JSC. It will 
be a phased knowledge engineering methodology consisting of 
identifying candidate systems/subsystemB for automation (beneficial 
to agency's programs, demo in operational environment, availability 
of domain experts); protoype knowledge base development; and 
implementation in a realistic environment. DemonBtrations will 
involve participation by both experts and novice personnel 
representing launch operations, mission operations and automated 
flight subsystems and automated sciences. 

The planned 1988 demonstration will focus on automation of the 
Space Station Thermal Control System (TCS) Testbed at JSC. The 
automation involves the modeling and simulation of components and 
configurations of a complex electro-mechanical subsystem, and 
includes f<-iuit diagnosis of a majority of common problems, 
real-time fault correction for several problems, design and 
reconfiguration advice, intelligent interface to both novice 
and expert users, and training assistance. 

PLANNED ACCOMPLISHMENTS : 

o Automated control of Space Station (SS) Thermal Control System - 1988 
o Automated control of Two SS subsystems (Thermal/Power) - 1990 
o Automated hierarchical control of multiple SS subsystems - 1993. 
o Automated distributed control of multiple SS subsystems - 1996. 

SCHEDULE: FY 87 88 89 90 91 92 

TCS Prototype Phase II ==== 

TCS Knowledge Base Expansion === 

TCS Integration into Thermal Testbed ==== 

TCS Demonstration ==* 

TCS/Power Prototype ==- 

TCS/Power Knowledge Base Expansion ==== 

TCS/Power Demonstration -=-* 

Demonstration Selection == 

1993 Prototype Development r=r= 

1993 Knowledge Base Expansion ==== 

110 



ARC SADP (Continued) 

BENEFITS: "Die SADP will provide technology for minimizing crew 
monitoring of Space Station subsystemn, increase crew safety through 
improved systems monitoring, provide design assistance, and training 
assistance. In addition, the SADP will promote strong working 
relationships between NASA Centers. 

PRODUCTS: Products include verification and validation 
methodologies, automated systems immune to human-induced errors which 
allow efficient crew interactions with complex mission-critical 
systems, automated systems capable of self-monitoring and 
self-maintaing for extended periods in real-time, and intelligent 
systems capable of learning and rendering reliable decisions in new 
and uncertain environments. 



FY 87 88 89 90 91 92 
FUNDING {$K) 3470 3399 3500 3500 3500 3500 

MANPOWER (civil service) 9 10 12 13 14 14 

TECHNOLOGY NKKDi',: 

The Systems Autonomy Demonstration Project has the following 
needs for new Al technology. 

1988 TCS Demonstration - A method is needed for the Validation 
and Verification of Expert (Rnowledge-based) Systems. If a 
method is not established for doing this, there will never be 
acceptance by the NASA user community of the Al technologies. 
The research will suffer as much as the demonstrations. It has 
been identified in the Core Technology research plan of ARC-RIA 
as a key research thrust. It is critical to have major emphasis 
on the solutLpn (;o tliis problem and develop not only the concepts 
and methodfi for the J 988 Demo, but stay very focused, and develop 
actual software for an acceptable long-range NASA solution to the 
problem. A second technology need for the 1988 Demo is causal 
modeling cind integration of such models with more traditional 
mathematical or algorithmic models. 

1. SADI' NEEDS: Validation and Verification Methodology 

COKi'; DELIVERAULES: Documentation describing acceptable 

concepts and methods for developing, 
testing, evaluating and approving 
expert systems for use on NASA 
missions . 

Software (as in usable products) to 
accomplish the above, i.e. computer 
assisted programming aids, etc. 

11 1 



ARC SADP (Continued) 

2. SAJ)l' NKEDS: Causal Modeling and Integration of 

Causal Models with Traditional 
Mathematical or Algorithmic Models. 

iiAVr DELIVKHABLES: The immediate need of SADP for these 

methodo]ogies necessitated SAUP 
direct funding of the research and 
development needed for the solution. 
SAUP has concepts, methodologies and 
actual software that can be 
contributed to other NASA centers to 
help with these problems . 

1990 TCS/Power Demonstration - There is a need for a planning and 
scheduling so lu I. ion for the Power System at Lewis Research 
Center. The domain experts for the Power System see a need for 
both reactive and prcidictive planning and scheduling for a 
dynamic, multiply constrained resource for Space Station. There 
is also a need for nignificant support in the area of cooperating 
expert systems and the mechanisms for communication, control, and 
interactive goal and task achievement. 

1. SAJ)1' NEKDS: Planning and Scheduling System 

CORE DEhJVERABLES: Design, Development and Testing of a 

software solution to be integrated 
into the Power Expert System for the 
1990 SADP Demo. 

2. SADP NEEDS: Cooperating Knowledge Based Systems 

CORE DEl.JVERABLES: Design, Development and Testing of a 

software solution to be used to 
couple the 1988 Thermal System with 
the 1990 Power System to Demonstrate 
Cooperating Expert Systems . 



1993 and IHHU Demonstrations - The technology needs are for 
methods to handle multiple subsystem hierarchical or distributed 
cooperative control, fault recovery from unanticipated failures, 
planning under uncertainty, fault prediction and goal driven 
natural language interfaces. The SADP Office will need as 
deliverables from the Core Technology consulting, development of 
concepts and methods, and actual software and hardware to solve 
all of these long-rcinge problems. 



Of POOR QUALITY 



112 



o 



m 
a 

< 
cc 

(D 
O 
CC 
Q. 

>■ 



o 

I- 

< 
C/) 

UJ 

H 

> 
CO 




13 






iTY 



ORIGINAL PAGE SS 
OF POOR QUAf.iTY 

A 1.6 ARC FACJLITIKS 

The implementation of the SATP at the ARC requires an 
augmentation of existing research facilities. Below is a brief 
statement about currently available equipment and a newly plan- 
ned Automation Sciences Research Facility (ASRF) . Additional 
information can be obtained from Refs. 7 and 8. 

Existing Equipment for System Autonomy Research 

Fig. Al shows the existing network of computers and some 
of the hardware development activities which are examples of the 
kind of development that would be pursued in the ASRF. The ISO 
currently has the use of six specialized AI work stations and two 
other workstations, each of which supports only one or two indi- 
viduals at a time. It also makes extensive use of time-shared DEC 
VAXes. These machines are located in laboratory space spread over 
three rooms and are used for software development, simulation, 
and testing of new algorithms, programs, and systems. The VAX 
also provides an electronic mail service that is heavily used for 
information transfer and as connections to other ARC computers, 
to external services such as the NASA Telemail service, and to 
the Milnet. Communication links exist from individual computers 
to terminals and some personal computers located at desks. Most 
of these terminal devices are directly connected to one of the 
major computer resources available to the ISO. A few are connec- 
ted to a data switching system that provides access to multiple 
computers. Approximately one third of the staff have personal 
computers at their desk for software development, research, and 
word processing. 

Automation Sciences Research Facility 

Since in the coming years the existing facilities cannot 
support the projected research and development work for autono- 
mous systems, a new ASRF is planned at the ARC. This facility 
will be in a 43,000 gross square feet building proposed for 
inclusion in the FY89 CofF budget. The ASRF will contain labora- 
tories, training facilities, and offices to house and support the 
activities of the ISO. It will provide the space needed to sup- 
port the organizational growth called for to meet programmatic 
needs. The facility will provide space and services for a focused 
program of research and development of automation technology, 
quick prototyping capabilities, integration validation, and dem- 
onstration of these technologies; and training and transfer of 
these technologies to NASA programs. 

Human Performance Research Laboratory 

Significant incorporation of AI technologies in Space 
Station and other future NASA aerospace missions will require 
fundamentally new rules for human-machine interaction. The Human 
Performance research Laboratory (HPRL) will provide necessary 
facilities for this critical integration of AI and Human Factors. 
The HPRL will provide laboratories and supporting areas required 



to develop crew interfaces with expert systems and techniques to 
verify and validate these new technologies. Construction of the 
HPRL will begin in FY88 and will be a 58,000 gross square foot 
building including offices and conference rooms. HPRL and ASRF 
will share a common high bay area containing mockups of portins 
of the Space Station. These will be used to support high fidelity 
simulations with the architecture and machinery of the Space 
Station. 



115 



OF POOR QU^iLsTY 



oj -a 

V 

u C 
u <>. 

no 

Ml M 
PS U 

c 

CO -u 




(0 

e 
< 

-p 

(0 

u 

<D 
•H 
■P 



o 
ro 

0) 

+j 

3 
ft 

a 
o 

o 

Pu 
< 

bo 

c 

•H 
■P 

•H 



<E 

0) 

hD 
■H 
to 



116 



A2. GODDARD SPACE FLIGHT CENTER 

A2.1. CORE R&T (Systems Integration and Architectures) 

TITLE: Knowledge Base Management for Distributed Automated Systems. 

OBJECTIVE: 

This task will develop knowledge base management technologies 
needed for automated control center operations realized through 
the use of distributed cooperating expert systems. A major goal 
of this work will be to develop a methodology and framework to 
support the interconnection of discrete knowledge base systems, 
for cooperative action. B'our ma.ior classes of technology issues 
will be studied and addressed under this task. These classes 
are: System Architecture, System Operations, Knowledge Base, and 
Human Factors. The system architecture issues include 
hierarchical structures, distributed structures, connectivity of 
system elements, architectural alternatives and models of system 
architectures . The system operations issues include coordination 
of processes, real-time operations, cooperative processing, 
dynamic connectivity of processes, and communication protocols 
among processes . The knowledge base issues include knowledge 
base development, knowledge representations, replication of 
knowledge at multiple sites, knowledge segmentation, 
fusion/synthesis of knowledge, incomplete knowledge, 
induction/reduction/abduction on knowledge bases, and consistency 
of distributed knowledge bases. The human factors issues will 
focus on interfaces/interactions between operators and knowledge 
base systems, and function allocation between humans and 
machines, A prime operational goal of this task will be to 
devise a distributed knowledge base architectural framework which 
will support high performance management of the knowledge bases. 
A supporting technology goal will be the prototyping and 
evaluation of Knowledge Base Management System engineering tools. 
Another significant goal is to develop in-house expertise in the 
theory and application of knowledge base management technologies. 

RATIONALE: 

Current spacecraft control ground/space systems depend on a 
highly synergistic mix of complex hardware/software systems and 
dedicated, highly trained operators functioning in a cooperative 
and collaboriitive manner to maintain effective and efficient 
operations. As these man/machine systems become more automated in 
response and reaction to increasing operational complexity more 
use will be made of knowledge-based system components. These 
will be configured cind execute in a framework specifically 
designed to facilitate both coordination and cooperation in 
supporting operations, and high level interfaces/interactions 
with the system's human operators. This task helps provide the 
core technology developments in knowledge base management 
required to realise this type of automation. 



117 



A^. .1 GSFC K-B Management (Continued) 



APPROACH: 



This research wilJ be a collaborative activity involving 
Goddard's Data Systems Technology Division and other Goddard and 
NASA researchers along with researchers from academia and private 
industry. To ensure ready application, the identification by 
appropriate NASA centers of demonstration scenarios involving 
distributed knowledge base systems will be a major factor in 
establishing the proper focus and direction for this core 
technology development. The Goddard scenarios that will be used 
for the same purposes will be based on Space Telescope (ST) 
ground operations. 

Various paradigms for realizing advanced knowledge base 
management systems operations including blackboard and 
object-oriented approaches will be formulated, analyzed, and 
evaluated within the contexts of automated ground systems and 
large space nys terns. 

The research will address various technology issues associated 
with knowledge base management systems. These issues include 
those associated with the following: 

o Experts systems implemented within the framework of a 
"generic" expert system in such knowledge-based contexts as 
fault rocognition/warning/diagnosis/recovery , planning and 
replanning, scheduling and rescheduling, fault prediction 
and trend analysis, and reasoning with uncertain and 
incomplete knowledge; 

o mechnn isms needed for coordination/control of multiple 
knowledge- based systems; 

o protocols and communication mechanisms needed to support 
distributed, hierarchical, and heterarchical knowledge-based 
systems ; 

o interactions between operators and knowledge-based systems 
including explanation aids, multiple levels of information 
presentation, task-oriented dialogs and error handling. 

As tlie research matures and specific knowledge base techniques 
are identified and detailed the tools needed to instantiate and 
maintain operational versions of the knowledge base management 
systems will be designed, prototyped, and evaluated. 

Facilities within the Data Systems Technology Lab along with 
resources provided by the Space Telescope Project will be used to 
support th(^ in-house research. 



118 



A2.1 GSBC K-B Management (Continued) 

PRODUCTS : 

This task will develop: 

o models for distributed knowledge-based systems 

o model of "generic" expert system 

o methodology for task decomposition 

o prototypes of frameworks for interconnection of 

knowledge-based systems - prototypes and evaluations 
o evaluation of alternative knowledge base management system 

architectures 
o knowledge base management system development tools - 

prototypes and evaluations 

BENEFITS: 

Successful execution of this task will provide: 

o proven approaches to knowledge base management applicable 

for use in demonstration and operational system 
o tools to support the design, development and evaluation of 

knowledge base systems 
o identification of knowledge base management 

techniques/technologies appropriate for Space Station 
o development of in-house expertise in the knowledge base 

management system technologies 



92 93 



SCHEDULE/RESOURCES : 










Item FY 


88 


89 


90 


91 


KBMS Model 


X 


X 


X 


X 


Generic ES Model 


X 


X 


X 


X 


Task Decomposition 


X 


X 


X 


X 



Methods 

Interconnection X X 
Frameworks 

Framework Prototypes XXX 
And Evaluations 

KBMS Tools Prototypes XXX 
And Evaluation 



Funding $K 198 348 400 450 500 500 

Manpower In-House 2.5 2.5 3.0 3.0 3.0 3.0 

Contractor 2.0 4.0 4.0 4.0 4.0 4.0 

119 



The GSFC Bystem Autonomy work will provide the following in 
support of demonstrations: 

o models of distributed knowledge-based systems 

o generic expert system model 

o task decomposition methods 

o prototypes and evaluations of frameworks for interconnection 
of distributed knowledge-based systems. ST and Cobe systems 
will be used to focus the prototypes and demonstrations. 

o evaluation of alternative KBMS architectures 

o KBMr> development tools. 



A2.2 GSl'X; FACILITIES 

The prime facility to be used to support the GSFC Systems 
Autonomy work will be the Code 520 Data Systems Technology Lab. 
This facility provides Symbolics, Vax 785, Vax 8600, IBM PCs, IBM 
PSATs, and a Vax Station. Software support includes such 
components as ART, REE, 0PS5 , LISP, MRS, C, NEXPERT, and CLIPS. 
It is planned that support for the demonstration of advanced 
technology In the Space Telescope environment will be provided by 
a network of ST MicroVAXs. 



120 




121 



A3. JET PROPULSION LABORATORY 

A3.1 TECHNOLOGY DEMONSTRATION 

WORK PACKAGE TITLEt 

Automation For Mission Operations Ground Data Systems 

OBJECTIVES: 

The primary objective o-f this task is to develop and demonstrate 
technologies which enable and enhance the MULT I -M I SS I ON monitoring 
and diagnosis capabilities of ground data systems for unmanned 
spacecraft. Effective detection, isolation, and recovery from anomalies 
requires consideration of both spacecraft and ground data systems. This 
task will develop tools commonly applicable to the automated monitoring 
of spacecraft telemetry and space flight operations ground data systems. 
Techniques will be developed for automated real-time monitoring of 
subsystem status, status trend analysis, trouble-shooting, and 
maintenance. In addition, technology for acquiring, modelling, and 
applying valuable human operator expertise in subsystem diagnosis and 
recovery will be developed. A phased series of demonstrations of 
increasing automated capability are planned. With the objective of a 
demonstration during the Voyager encounter of Neptune, initial work will 
focus on automated monitoring of spacecraft telemetry with subsequent 
extension to monitoring of ground data systems. The principle products 
of the task will be on-line software demonstrations of automated 
monitoring and diagnosis capability which are ready for installation in 
operational systems. The technology developed by this task will reduce 
human mission operator workload and improve ground operations 
productivity. 

APPROACH: 

1. Develop artificial intelligence techniques for monitoring, diagnosis, 
planning, error recovery, and human interface technology and integrate 
it into spaceflight operations. Moving this technology into operational 
environments will entail choosing and implementing the appropriate 
combinations of artificial intelligence and conventional computer 
science techniques. 

2. Perform R&D necessary for centralized automated real-time monitoring 
of spacecraft telemetry, and monitoring and control of ground data 
subsystems. Currently these functions are distributed throughout the 
system. 

3. Demonstrate the telemetry monitor and analysis capabilities for 
selected Voyager spacecraft subsystems during Neptune encounter. 

A series of demonstrations of increasing autonomous capability are 
planned which are well correlated with the thrust of other System 
Autonomy Demonstration Programs and draw upon the technology developed 
for those demonstrations. The approach will be to develop new 
technology and to validate other technology developed in the System 
Autonomy program. Each demonstration makes available items of 
significant new technology which may be incorporated into operational 
ground data systems. Most of the demonstrations take place in actual 
mission operations facilities, including the JPL Space Flight Operations 
Center (SFOC) prototype, the existing Real Time Data System in the Space 
Flight Operations Facility (MCCC RTDS) , and the (future) baseline SFOC 
facility. 

PRECEDING PAGE BLANK NOT FlUflED "' WfciE-WItNTlONAlU BWi' 



JPL Bnd Data Sys. (Continaed) 

BENEFITS: 

This task will develop systems which will reduce work-force and improve 
productivity associated with the monitoring of spacecraft telemetry and 
the monitoring and control of ground data systems. 

Currently the Flight Projects each have dedicated spacecraft teams 
consisting of real time and nonrealtime subsystem analysts. The real 
time subsystem analysts perform the functions of ensuring correct 
subsystem performance, identifying and characterizing subsystem 
anomalies, and identifying and initiating corrective actions. Real time 
analysts can be expected, depending on mission activity, to provide 24 
hours a day, 7 days a week online support. This requires 1 to 3 persons 
for each subsystem per mission. With automated spacecraft subsystem 
monitoring tools, mission controllers may be able to perform these real 
time analyst functions. This has the potential of reducing a typical 
single project staffing by up to 21 real time personel . 

The ground data system contains approximately 73 on-line CPUs which 
process spacecraft status and science data telemetry. Currently, 
approximately 23 displays are required to monitor ground data system 
status at 5 different locations. During spacecraft cruise flight 
stages, approximately 2 Qperators are needed at each of the five 
locations. This workforce is supplemented by additional personnel 
associated with individual flight projects coincident with encounter 
stages of flight. 

This task will achieve the following productivity benifits: 

1. Enable rapid detection and isolation of spacecraft and ground data 
subsystem faults, detection of failure trends, and recommendations 4ar 
fault recovery. This will reduce the necessity for human monitoring of 
the spacecraft telemetry data, reduce ground data system downtime due to 
failures, and enable improved capture of scientific data. The workforce 
associated with spacecraft and ground data system trouble-shooting and 
recovery could be reduced, especially during encounter phases of flight. 

2. Enable automated, on-line verification of uplink commands thru 
intelligent analysis of the downlink telemetry data to assist mission 
operators in the conduct of their mission. The workforce associated 
with spacecraft command verification could be reduced or freed to 
continue mission planning. 

3. Enable rapid, automatic software and hardware reconfiguration in the 
ground data system in response to both scheduled spacecraft needs and to 
anomalies. This will result in improved system response with fewer 
resource conflicts and reduce the associated operator workforce. 

4. Provide an automatic, uniform historical accounting of ground data 
system status and procedures in a representation suitable for 
computation. This would enable easy reference for training as well as 
real-time system control by operators or future automated systems. 



12i( 



JPL Bnd Data Sys. (Continued) 
PLANNED ACCOMPLISHMENTS: 



ORIGINAL PAGE ^ 
OF POOR QUAUTY 



1. MONITORING WORKSTATION 

Development of a multi -mission telemetry monitoring workstation which 
provides a centralized monitoring capability for spacecra-ft engineering 
telemetry. The initial system will focus on support of the Voyager 
spacecraft. Developments for this demonstration will make use of 
monitoring and diagnosis techniques being developed for the JSC Thermal 
Management System demonstration and for the JSC INCO demonstration. 
System capabilities/features include: 

On-line real-time monitoring of spacecraft subsystem engineering data. 

Monitoring of spacecraft and limited ground factors which influence 
the data quality of spacecraft telemetry. This is a precursor to full , 
monitoring of the ground data systems, and will include identification 
of additional sources of information necessary for a full monitoring 
capability. Examples of factors to be monitored include: 

Antenna pointing residual. 

Lock Status. 

Frame Status. 

S/N ratio. 

Heuristic diagnosis of spacecraft subsystem anomalies. This 
capability will capture existing valuable expert knowledge on detection 
and isolation of anomalies. Reasoned correlations between anomalies on 
multiple spacecraft subsystems will be automatically generated. Upon 
isolation of a fault, any information about known, appropriate recovery 
procedures will be automatically presented to human operators for 
consideration. 

Trend detection and monitoring of spacecraft subsystem status/health 
data. 

Human factors based display, including graphical icons, menus, and 
improved command language. 

Logging of data and significant events, including automatic report 
generation where standard formats are currently available. 

2. AUTOMATED MONITORING FOR VOYAGER AT NEPTUNE 

This effort will .apply the Telemetry Monitor Workstation described in #1 
above to the monitorins in support 

of the Neptune encounter as well as selected ground system factors. The 
workstation will be integrated with the MCCC Real-time Data System and 
be on-line for the encounter. 

3. GROUND DATA SYSTEM MONITORING WORKSTATION 

This effort will apply and extend the techniques developed in the 
automated Monitoring Workstation to the monitoring of additional ground 
data systems. This second, independent workstation will be integrated 
with the existing or developing SFOC Monitor and Control subsystem (SMC) 
and installed in the- SFOC Prototyps? for ovaluation. 

125 



JPL Gnd Data Sys. (Continued) 

4. INTEBRATED SPACECRAFT AND GROUND DATA SYSTEM MONITOR 
E-ffective real-time detection and isolation o-f faults in either the 
spacecraft or ground data system requires close consideration of both 
spacecraft engineering telemetry and ground data system health and 
status. This effort will fully integrate the two workstations developed 
previously for monitoring and diagnosis of spacecraft telemetry and 
ground data systems. Techniques developed as part of the 1990 Space 
Station demonstration of coordination between thermal and power systems 
would be utilized. The system would be installed in the baseline SFDC 
for evaluation in support of on-going multi-mission operations. 

5. EXTENDED GROUND DATA SYSTEM DIAGNOSIS AND MAINTENANCE 

The objective of this effort would be to develop the capability to 
command ground data subsystems to run diagnostic tests and provide 
additional status data. The system would be installed in the SFDC 
prototype. In addition to all the capabilities provided by the 
Telemetry and Ground Data System Monitoring workstations, software hooks 
and hardware scars for subsequent hardware and software configuration 
planning and control in the ground data system would be included along 
with the following new capabilities: 

Automatic running of preventive diagnostics on ground data subsystems, 
including peripherals such as tape drives and printers at remote 
locations. 

Diagnosis and verification of network health and configuration by 
automatic sending of test data blocks. Automatic commanding of ground 
data subsystems to provide additional status or diagnostic information 
on demand. These will require reasoning about real-time resource 
conflicts with other tasks, e.g., to avoid taking systems off-line for 
troubleshooting when they are actively supporting operations. 

Model-based diagnosis. This development will give the system the 
capability to reason about system failures using models and knowledge 
about the structure and function of subsystems in addition to the 
heuristic diagnosis capabilities developed in earlier tasks. This 
effort will provide additional automatic diagnostic capabilities to 
human troubleshooters which they do not now possess. 

Implementation of software and hardware modifications necessary to 
support automated software and hardware configuration control in the 
ground data system. Subsequent tasks, as described below, will build on 
this capability. 

Improved trend detection and evaluation of a greater number of 
subsystem health parameters. 

Automated logging of all operator invoked diagnostics. 

Real-time performance improvements, including multi-processing 
techniques for combining real-time monitoring, diagnosis, and 
commanding. 



126 



OF POOR QUALrrf, 



JPL Gnd. Data Sys. (Continued) 



6. SPACECRAFT COMMAND VERIFICATION 

The Telemetry Monitoring Workstation will be extended to utilize uplink 
spacecraft command sequences in the anticipation of spacecraft mode 
changes. This will enable automatic switching of format and alarm 
tables and thus reduce or eliminate this cause of data lossage. If 
appropriate spacecraft models are available, they will be used to 
generate predictions about engineering telemetry and thus further verify 
command completion. This development and installation will utilize the 
baseline SFOC. 

7. DYNAMIC GROUND DATA SYSTEM CONFIGURATION CONTROLLER 

The objective of this development is to extend the command and control 
ability of the ground data system monitoring workstation to dynamic 
hardware and software configuration control of ground data subsystems in 
the SFOC prototype. The task would extend SOE (Sequence of Events) 
planning to automatic generation of actual commands to accomplish the 
necessary changes. In addition to the capabilities provided by the 
earlier efforts, this development will include: 

Automated planning and scheduling of hardware and software 
configuration changes, taking into account scheduled spacecraft needs, 
on-going maintenance, and other constraints on acceptable plans. 

Automatic generation of extended configuration command sequences for 
the ground data system. 

Supervised execution of dynamically generated ground data system 
configuration change sequences and autonomous verification of change 
command completion. 

Full automation of simple recovery procedures e.g., those which 
respond to well known, or less critical anomalies. 

Logging and internal representation of reconfiguration and other 
commands which are issued by operators in response to anomalies. 

Automatic dynamic generation of alarm limits based on planned hardware 
and software configuration changes. 

Diagnostic test selection in response to novel failures. 

B. TEACHABLE GROUND DATA SYSTEM CONTROLLER 

The objective of this development is to extend the control ability of 
the ground data system monitoring workstation to areas not covered by 
the earlier efforts and to automate the application of more 
sophisticated error recovery procedures. Importantly, the ability to 
acquire diagnostic and error recovery techniques directly from operators 
while the system is on-line is a new feature. The system would be 
developed and installed in the SFOC prototype. Capabilities include: 

Fully automated configuration management. 

Error recovery planning in response to novel failures in addition to 
application of standard recovery procedures. 

Acquisition and ability to apply diagnosis and recovery procedures 
which are used by human system operators, including through a teaching 
mode as well as a "silent apprentice" mode where the system passively 

observes human procedureG. ^27 






JPL Gnd. Data Sys . (Continued) 



SCHEDULE: 



ITEM/GY 88 89 90 91 92 93 94 



1. Telemetry Monitoring 
workBtation X 

2. Automated monitoring 

for Neptune Voyager X 

3. Grnd Data Sys Monitor X 

4. Integrated Telem/GDS monitor X 

5. Extended GDS diagnoslB/maintenance X 

6. Spacecraft Command Verification X 

7. Dynamic GDS Config. Controller X 

8. Teachable GDS Controller 



Funding ($K) 347 350 350 350 350 350 350 

JPL WORKFORCE 3 5 5 5 5 5 5 



TECHNOLOGY NEEDS: 

The MisBion Operations Ground Data Systems demonstration task has 
needs for technology concepts and methodologies in several 
important areas. In the human interface area, the principle 
needs are for monitoring, diagnosis, planning, and control system 
display techniques. In the area of monitoring technology, 
methods for knowledge based signal to symbol transformation and 
situation assessment are needed. In the area of diagnosis 
technology, techniques are required for reasoning with uncertain 
or missing data, reasoning with deep knowledge, and hybrid 
technique diagnostic systems among others. Planning technology 
required for out-year demonstrations is required in the areas of 
maximizing resource utilization, dynamic replanning, and hybrid 
Al/Operations Research planning systems. Software validation and 
verification remain key methodological requirements, especially 
testing and verification procedures for knowledge based and 
hybrid systems. Finally, techniques are required which enable 
real-time processing in knowledge based systems. We expect most 
of this technology to be developed as part of the baseline core 
research program and the above mentioned requirements should not 
be considered hard levies on those tasks; instead, the 
requirements should be considered opportunities to utilize the 
advanced technology when it becomes available. 



128 



A3. 2 JPL FACILITIES. 



Artificial Intelligence Laboratory: 

The Artificial Intelligence Laboratory currently includes six 
Symbolics LISP Machines, one of which is a color system. The 
site has over 1660 MBytes of hard media storage availabe, soon to 
be expanded. Three Sun 3/280C mini-computers will soon be added 
and will provide the basic development system for the 
demonstration. In addition, approximately three additional LISP 
Machines will be added in the coming year. Network connections 
to the use campufs provide the site with ARPANET access. The site 
is also connected locally to other JPL sites via the JPL local 
area network . The AI lab also has a complement of four Mac+ and 
one Mac SE for office automation. There are two LaserWriter 
printers and several other dot matrix and impact printers also 
available for general use. 



Advanced Prototype Laboratory: 

The demonstration will also make extensive use of the Advanced 
Prototype Laboratory at JPL. This site includes a wide variety 
of mainframe, mini, and micro-computers which are being evaluated 
for incorportation into the Space Flight Operations Center. The 
prototype lab's primary objectives are to test the key SOFC data 
system concepts and to model the required SFOC throughput and 
response time using real and simulated spacecraft telemetry. The 
Voyager telemetry monitoring demonstration during the Neptune 
encounter will take place in this facility. The facility will 
soon be connected via an ethernet to the Artificial Intelligence 
Laboratory . 

Advanced Prototype Lab computers and support facilities include: 

Sun computers (two 3/280, eight 3/50, one 3/160c) 

VAX 11/750 running VMS 

Microvax 

Mascomp 

Several IBM PC- AT 

one Xerox 1108 

one Symbolics 3640 

one Apple Mac+ , Mac II, and one Atari 

Special hardware Includes LAN analysers, graphics cameras, and a 

fiberoptics backbone using standard ethernet interfaces. 

Additional shared facilities include a VAX 8600 running UNIX. 



129 



< 

H 
CO 



Lli 

a 

< 
a: 
o 
O 
oc 
a. 

>- 



z 
g 

I- 
< 

o 

Z> 
< 

UJ 

I- 

co 

>- 
w 

< 

I- 
< 

Q 
O 

z 
z> 
o 
cr 
o 

C/) 



< 

DC 
LU 
Q. 
O 

z 
g 

CO 



LU 

> 

I- 

o 

111 

-i 
CQ 

o 



o 

I 

o 
o 

i 

EC 

s 

i 
u. 
o 

a: 
o 

g 

e 

=5 



o 

o 

a: 
o 

5) 
5Q 

>. 
QC 

Q. 

a: 

o 
o 



cc 

LU 
Q 



m 
o 



(n 

^ ■< 

P: h- 

si ^ 

OQ a. 

^ O 

2 C5 



o< 



cr. 

LU 

d 
o 
cc 

I- 
z 
o 
o 

LU 

I- 
W 



I 



*^ 5:r r- 

LU O < 

!=FQ 

2 < Q 

< DC 2 

y u. DC 

CO o IB 



12 



i 



CO 

o 
I- 
w 
o 
z 
o 
< 

Q 

Q 
LU 
CO 

< 
m 
_j 

UJ 
Q 

O 



C3 
z 

_l 

Q 
LU 

X 

o 

CO 
Q 



a 



III 

u. : 

LU 2 UJ 

cc Q_ |_ 



UJ DC O 

pW LU 

2 5^2 



o 

z 

Q 

Z 

U. 

Q 

Z 
< 
UJ 

-I 

Q 
LU 

X 

o 

CO 



CM 




T- 

o> 


o 
in n 


o 






3 






o 

CO 


CO 




I 





o 
o 
o 



.£ CO 



O o 



T3 
C O) 

o "^ 

(5.2 

?l 



c 
o 



0) 

c 

Q. 
0) 






^ 2 

t to 

^ u. 

0) 



o 
> 






c 



c 
o 



c 
o 

12 

>,^ 
CO 0) 

CD o 

2 rt 






3 a 

U. -J 



O 



< 

LU 

CO 

>- 
CO 



(i 


._ 


O 




1 








Ifl 






,— 


>-CM 


10 


A 


a 


tf> 


M 


Ol 



CO '^ 

g I a 

I .2 C 

c ♦; c 

0| a 

CO O ai 

r» a. a 




CO 
LU 

I- 



O 

< 
u. 



CO 

h- 
Z 
< 



O 

H 

< 
Q. 



a: 

2 

o 

cc 

2 



Q. 

o 

cc 
o 

UJ 

o 

z 

UJ 

_i 
_j 

UJ 



< 
o 

U- 
h- 
DC 
< 



O 
LU 
CO 
CO 



LU 
Q. 
O 

H 

I 

^ 

_l 
u. 

UJ 

o 
< 

a. 
CO 



I- 

z 

LU 
Q. 

3 

UJ 



LU 

I- 

co 

> 

CO 

< 

Q 

CC 
UJ 

I- 
z 

UJ 

o 

_l 

o 

cc 



o 
o 



Q 

1- 
o 

LU 
CO 
CO 



LU 

a. 
O 
a 



CO 

LU 

I- 
O 
UJ 



cc 
a. 



> 
cc 
o 

I- 
< 
cc 
o 

DQ 



rS a. 



UJ 

I- 
co 

>- 

CO 

Q 

LU 



< 

Ul 
DC 
O 
O 

o 



8 

LL 
CO 

DC 

LU 
h- 

Z 
UJ 

o 

CO 

z 
o 



LU 
D. 

O 

H 
X 
C3 



LU 
O 
< 

CO 



5 



A4. JOHNSON SPACE CENTER 
A4.1. TECHNOLQQY DEMONSTRATION. 

Tit let STS Flight Control Room Operations - INCO Expert System 
Operational Readiness Demonstration Prototype. 

Objectives : 

Develop an expert system for monitoring Space Shuttle 
communications and instrumentation systems which can be used to 
evaluate if expert system technology is sufficiently mature for 
use in decision making where human lives and major NASA vehicles 
are in jeopardy. 

Connect this expert system to a real time Shuttletelemetry source 
and evaluate its performance during simulations. If simulation 
performance is acceptable, evaluate performance during actual 
Space Shuttle flight. 

Evaluate the problems of developing, verifying, certifying an 
expert system for use in the shuttle Mission Control Center. 
Evaluate training requirements for operators. 

Evaluate the use of laser disk technology and advanced graphics 
technology to replace paper products currently used by flight 
controllers. 



Approach : 

Taks Automation algorithms for fault detection of shuttle 
communications and instrumentation systems had previously been 
defined by Mission Operations Directorate personnel at JSC. 
Rules for an expert system to monitor Space Station 
communications systems had also been developed by these 
personnel. In this project the task automation algorithms will be 
coded on a UNIX workstation and combined with a rule based expert 
system built from a modified rule base from the earlier space 
station efforts. A standalone telemetry processor will be 
interfaced to the workstation and then integrated into the 
Shuttle Mission Control Center data system . 

Evaluations will initially be performed in a laboratory 
environment utilizing shuttle telemetry tapes. After confidence 
is gained in the combined automation/expert system, it will be 
moved to the Flight Control Room in the Mis9ipn. Control Center 
for use in integrated simulations. It will initially be used as a 

consultant to an experienced flight control team, then as a 
component of a "reduced" team with fewer operators to evaluate 
the use of the expert system to lower manpower requirements. 
After extensive testing , the system may be used as a consultant 
during actual shuttle flight if sufficient confidence can be 
gained in the system. 

Laser Disk and advanced graphics technology will be integrated 
into the system after initial use in the MCC. 

131 



J5C INCO <Continued) 



Planned Accomplishments: 

Demonstration of use of microprocessor based telemetry processor 
supplying real time telemetry information to a rule based expert 
system. 

Integration of task automation fault detection algorithm 
technology with a rule based expert system technology. 

Use/Evaluation of task automation/expert system technology in a 
real operational environment. 

Use/Evaluation of Laser Disk Technology and advanced graphics to 
replace paper products used in the MCC by flight controllers. 



Schedule: 
Item 



FY 



87 



88 



89 



90 



Real Time Data 
Interface 

Task Automation/ 
Expert System 
Developed 

Simulation 
Demonstrations 

Use Inflight 

Revision 2 
Expert System 

Integration 
of Laser 
Disk and 
Advanced 
Graphics 



May 
Sept 

Nov 



Feb 
Oct 

Nov 



Demonstration 
Of Revision 2 
Inflight 



Jun 



Funding 
Manpower 



250K 620K 
1 2 



350K 
2 



132 



z 

o 

z 
o 

LU 
O 

IS 

< 

o 

Q. 

>• 



(A 

Z 

o 

oc 
tu 
a 
o 

s 
o 
o 
oc 

-i 

o 

oc 







3 



0» 




Z 

o 
o 

z 5 
03 

< I 

^ (0 

CO 

LU 

C/) 

>■ 
if) 







< 

Q 

Z 
< 

w 

h- 
z 
< 

CL 

o 

I- 
q: 

< 

Q. 



{2 
o 

2 




v> 



CL 

2 

HI 

> 

UJ 

Q 

CO 



LU 
Q. 

o 






o 

5 



UJ 

o 

o 

z 

Q 
w 

t 

X 
OT 
O 
V> 

—> 



133 



A4. JOHNSON SPACE CENTER 

A4.2. SADP TECHNOLOGY DEMONSTRATION. 

TITLE: 

Space Station Thermal Control Expert System (TEXSYS) 

OBJECTIVE: 

The major objective of the 1988 Demonstration, TEXSYS, is the 
implementation of AI technology in a real-time dynamic environment of a 
complex electrical- mechanical Space Station system-the Thermal Control 
System. Specific objectives include: 

o Real-time control 

o FDIR-fault detection and identification for all major faults, 

reconfiguration or isolation for a limited subset of faults, 
o Trend analysis for incipient failure prevention 
o Intelligent human interface 
o Causal modelling 

o Reasoning based on standard procedures 
o Qualitative and quantitative simulation 
o Integration with a real-time system 
o Validation and verification demonstration 
o Training and design assistance for Thermal engineers 

RATIONALE: 

The Thermal Control Expert System (TEXSYS) will demonstrate significant 
use of state-of-the-art AI technology in a real-world domain and will 
serve to "push" the state-of-the-art in several specific areas. The slow 
dynamics of thermal systems reduce certain technical risks, which allows 
concentration on technical issues which are currently of greatest interest 
to the SADP. The Thermal Test Bed is a bona-fide Space Station test bed, 
and as such, will facilitate the transfer of the technology to be 
demonstrated to the Space Station (and other) programs. Plans call for 
interfacing the Thermal Test Bed with other Space Station test beds. This 
will allow interfacing of TEXSYS with other test bed expert systems, thus 
providing a natural framework for supporting future goals of the SADP; 
i.e, demonstrations of cooperating, hierarchical, and distributed expert 
systems . 

APPROACH : 

The 1988 Demonstration is a ground-based demonstration of an expert system 
used to monitor, control, and diagnose faults for test article hardware 
within the Thermal Test Bed (TTB) at JSC. The TTB is an evolutionary 
program designed to develop a ground based system representative of the 
Space Station thermal control system, to verify the readiness of two-phase 
thermal technology and to provide system level evaluation of advanced 
thermal control technology for Space Station use. The Thermal Control 
Expert System (TEXSYS) will be fully integrated with the TTB and its 
conventional system and subsystem controllers. 

TEXSYS will be developed jointly by Ames and JSC personnel with 
participation from industry contractors . 



JSC TCS Demo (Continued) 

PRODUCTS : 

An expert system which: 

o Monitors, controls, and performs FDIR on a complex 

electrical-mechanical system operating in a real-time dynamic 

environment 
o Provides assistance to test bed engineers during test operations 
o Provides a flexible, intelligent human interface 
o Demonstrates incipient fault detection via trend analysis 
o Provides a facility for training and design assistance for 

thermal engineers 

BENEFITS: 
See RATIONALE 
SCHEDULE: 

FY 87 88 89 90 91 

Development ==== 

Requirements Definition == 

Design Definition == 

Integration into Testbed === 

TCS Demonstration * 

Power System Interfaces ==== 

TCS/Power Demonstration ===* 

Analysis, Reporting === 

Funding ($K) 600 600 500 300 100 
Civil Service MY 3 4 2 2 1 



135 




ft* 
a> 



II 



o 

O T- 



Z 



u. 

a 

z 
< 

UJ 

-J 
a 

LU 

X 

o 



1 o 




in 




c 
<1> 

E 

Q. 
JO 

> 

a 



c 
o 



(D 



c 

E 
<u 

cr 

cr 









10 













(D 












U 


n) 










n) 












•c 


U) 










0) 


c 


o> 


c 


> 


g 


_c 




F 


c 
r 





oO 


I** 


E 
« 

CO 


0) 





'E 
Q 


> 

.0 


If) 

c 


E 


Q 

1 



CL 

to 
a: 


c 


n) 


Q 


k- 


Q. 


U) 


rn 


0) 




0) 




>. 


(/) 


w 


% 


CO 


nl 


0) 













c 







H 


Q. 


h- 


< 



>• 
s 

5-8 

^ = 



LU 



O 

< 
LL 

Q 

Z 
< 

w 

I- 
z 
< 

o 

< 



{2 
2 

o 

oc 

5 




> 


V 


a. 


rr 


p 


n 


^ 


!? 


u. 


rr 


m 




f] 


^ 


i 


^ 


LU 


LU 



5 



CO 

>- 

CO 

I- 
z 

Ol 



Ul 

I- 
z 



CO 

>- 

CO 

I- 
z 

LU 

C3 



LU 



Q 
LU 
CD 

&5 

Ul 

I- 



cc 

Ul 



o o 

CO CO 
-J -3 



136 



(ilf: it' 



A4.3 JSC FACILITIES. 



JSC SADP TEXSYS FACILITIES: 

The SADP TEXSYS facility will be located in Building 32 of 
the Johnson Space Center. This building is used by the Crew 
and Thermal Systems Division to perform vacuum and sea level 
testing of the prototype equipment for the Space Station 
thermal control system. The TEXSYS demonstration will use a 
prototype of the central thermal bus, supported by simulated 
heat sources and radiators, as its target system. The bus 
will have a MicroVAX II computer system as its data 
acquisition and control computer, using a commercial package 
called FLEXCON. In addition, a data archive system will be 
storing the real time data on a VAX 8650. The expert system 
will run on a Symbolics 3650 computer (using the KEE expert 
system shell) and a separate, undetermined computer will run 
the human interface software. All of these computers will be 
connected using DECNET protocols over an Ethernet. 



JSC INCO FACILITIES: 

INCO is an acronym for Instrumentation and Communications Officer. 
The INCO is the flight controller in the Space Shuttle Mission 
Control resposnible for monitoring and controlling the Space 
Shuttle instrumentation and communications systems. In the INCO 
Expert System Project, we are building a real time expert system 
to assist INCOs in monitoring Space Shuttle missions. 

The goal of the INCO Expert System Project is to evaluate the 
performance of a real time expert system monitoring the Space 
Shuttle in a real operational environment. Two facilities are 
being used. The Systems Operations Development Laboratory (SODL) 
is being used as a development facility. When development is 
complete, the system will be moved into the Space Shuttle Mission 
Control Center (MC'C) for use in simulated and real Space Shuttle 
missions . 

The Systems Operations Development Laboratory is a single room 
located in the Flight Operations Suppport Facility (Building 4) 
at JSC. The SODL is currently hosting two projects in addition 
to the OAST (Code R) funded INCO project. One is currently 
sponsored by Space Station (Code S) and utilizes a Symbolics 
computer to prototype expert system based systems management 
concepts. A second project is hosted by Space Shuttle (Code M) 
and utilizes Optical Disk Technology and an IBM PC to store and 
retrieve data from the Shuttle Inflight Maintenance Database. 
The laboratory is approximately 300 square feet in size and has 
separate dedicated air conditioning and power connections. The 
door is protected by a Cipher Lock. The facility however is not 
cleared for classified work. A Local Area Network (LAN) server 
connects the SODL to the JSC Space Station Data Management System 
Testbed for Space Station project work. 

137 



JSC Facilities (Continued) 

The INCO project has placed several new pieces of equipment 
in the SODL which have significantly increased its capabilities. 
The INCO project has purchased a Honeywell lOlE Portable 
Telemetry Tape Recorder. This recorder is used to playback tapes 
of unprocesssed Space Shuttle telemetry into the IHCO project 
telemetry processor. 

The INCO project telemetry processor is a Loral Instrumentation 
Advanced Decom System (ADS-100) which processes the Shuttle 
telemetry and makes it available to other computers in the 
laboratory for use in expert system based monitoring prototypes. 
This telemetry processor is capable processing a 4 Megabit per 
second input data stream and extracting and calibrating over 4000 
parameters a second. 

The INCO project has currently interfaced this telemetry 
processor to a M68020 based UNIX workstation. This workstation 
was purchased from the JSC Mission Support Directorate and was 
originally built by C3 Corporation {C3 is an OEM utilizing 
Masscomp computers. The C3 has been selected by Mission Support 
Directorate as the standard Mission Control Center Workstation). 
This workstation is currently being used for development of a 
rule based expert system for monitoring real time Space Shuttle 
telemetry. The C3 workstation is also located in the laboratory. 
JSC Mission Operations Directorate has also loaned the INCO 
project the use of a second smaller Masscomp workstation for 
development. This device is also located in the laboratory. 

When development is completed, the INCO project will start 
operations in the Space Shuttle Mission Control Center (MCC) . The 
Mission Control Center is located at Building 30 at JSC and is 
the primary control center for all Space Shuttle flights. The 
INCO project is currently scheduled to start operations in the 
MCC in February 1988. The INCO project will be used duringr 
simulations prior to the next shuttle flight (STS-26) and be 
evaluated during the actual flight. 

An ADS-100 Telemetry Processor and a C3 Workstation will be 
placed in Flight Control Room tt 1 (FCR-1) which is the prime 
control room for STS-26. JSC Mission Operations Directorate is 
funding the installation of a data line in the Mission Control 
Center to connect the JNCO telemetry processor with the real time 
telemetry from the mission. Data will be routed to the INCO project 
from all tracking stations and the Tracking and Data Relay 
Satellite, as soon as the data is received at the MCC. The INCO 
project will not be connected to any data systems processing 
classified data. The INCO project will not be connected to any 
life or mission critical MCC equipment. 

Display units from the C3 workstation are being installed at 
the INCO console and the Propulsion Officer console allow 
monitoring the performance of the INCO expert system in real 
time during the STS-26 mission. The INCO expert system will be 
evaluated during the STS-26 mission but will not be used to make 
any decisions affecting the conduct of the flight. The INCO 
project may be certified for operational use following the flight 
based on performance evaluation. 

138 



A5. KENNEDY SPACE CENTER 

A5.1. TECHNOLOGY DEMONSTRATION. 

TITLE: DiaKnoRtics and Control for Launch ProceBsing SyetemB 

OBJECTIVES: 

Develop and demonstrate the Bys terns autonomy "core technology" 
software and hardware necessary to accomplish autonomous 
diagnosticB and control of interactive complex electro/mechanical 
launch and cargo procesBing systems. The autonomous system will 
perform the duties of a systems engineer better than the best 
NASA systems engineer. 

RATIONALE!: 

Parallel development of "core technology" diagnostics and control 
software: i.e. the ARC development using KEE on the Space Station 
Thermal Control System and Power System at JSC and LeRC; and the 
parallel RSC development efforts on ECS/PPCU/GDMS/CCMS II 
demonBtrations against actual launch and cargo processing ground 
hardware, will provide assurance that the most robust software 
architecture is developed for use on Space Station, future ground 
processing systems, and mission control systems. 

APPRAGCH: 

During late 1987 and early 1908 existing RSC Knowledge-based 
Autonomous Test Engineer (KATE) diagnostics and control software 
and the Generic Model -Based Diagnostic System (GMODS) software, 
developed in previous years, will be merged into one autonomous 
diagnostics and control set of software and be demonstrated, 
showing single Bystem diagnostics and control, using the new 
Shuttle Operational Maintenance & Refurbishment Facility (OMRF) 
Environmental Control System (ECS) in 1988. The KATE/GMODS 
software shell will then be modified to accomplish diagnostics 
and controJ of multiple Bystems within a shared complex network 
of Unix based equipment; this software structure will be called 
the Generic Control System (GCS) . During 1989 the GCS software 
will be dem<:)nstrc»ted aRainst several real world 

electro/mechanical laboratory models. In 1990 the GCS shell will 
be modified to contain knowledge from the cargo Partial Payload 
Check-out Unit (PPCU) used to ground test Shuttle payloads; this 
PPCU BhelJ will be tested against several payload hardware 
syBtems, operating simultaneously. In 1991 the GCS will be 
modified to contain the Space Station Ground Data Management 
System know LodfTe (GDMS- used for ground testing of the Space 
Station modules) which will represent hierarchical multiple 
expert systems running on a large (300 computers with 250,000 I/O 
points) dlBtributed computer network. In the 1993-1995 time 
frame the GDMS shell will be modified to contain the knowledge of 
the Shuttle Launch Processing System which will constitute the 
advanced software structure for development of the new Launch 
Processing System ( CCMS II). 

139 



RSC Launch ProceBsing (Continued) 



PRODUCTS : 



FY '87: Prototype software shell for accomplishing diagnostics 
and control on a single electro-mechanical system. 

-fault, recognj l.ion/warning/diagnosis for all failures 

-symbol i(:;/numerio processing integration 

-oli.iects with state and feedback 

FY'88: Operational software shell (OMRF/ECS) for accomplishing 
diagnostics and (control on a single electro-mechanical system. 

-model based (causal modeling/first principles) 

-objects with state and feedback 

-muJti-user Unix type operating system 

-goal directed control/reconfiguration 

-fault recovery from all failures 

FY'89: Prototype software shell Generic Control System (GCS) for 
accomplishing simult,aneous diagnostics and control on complex 
electro-mechanical systems, 
-complex models 

-multiple objects with state and feedback 
-model based control 

-design knowledge capture from CAD/CAM data base 
-complex expert system validation/verification techniques 
-advanced user interface function; voice, active graphics, etc. 

FY '90: Operational software shell Partial Payload Check-out Unit 
(PPCU) accomplishing simultaneous diagnostics and control on 
complex electro-mechanical systems. 

-integrated LISP and Unix systems 

-parallel LJSP processing 

-modest learning 

FY '91: Operational software shell Ground Data Management System 
(GDMS) accomplishing simultaneous diagnostics and control within 
a very large network of control equipment (300 computers & 
250,000 1/0 points) . 

-simultaneous control of distributed systems 

-high level user interface 

-pJanning and scheduling of multiple system integration 

-scenario based reasoning 

BENEFITS: 

Current ECS manpower levels in the operational system require two 
console personnel operating on a three shift basis when operating 
in the local control mode. Additionally, two system level 
engineers support on a two shift basis. With the implementation 
of the Autonomous Iiaunch Processing System it is projected that 
the console operator Jevel can drop to one operator per shift, 
for the total ECS operational manpower reduction of 37.5%. The 
manpower require(i for the ECS operations is typical of the some 
seventeen Li'S systems and it is expected that this percentage 
reduction will be experienced throughout the operations when full 
systems autonomy is implemented within LPS. KSC currently has 7.9 
million lines of software code which require 420 people to 
maintain on an annual basis. It is expected that the 
implementation of the proposed GDMS/CCMS 11 knowledge based type 

IHO 



RBC Launch ProcesBing (Continued) 



of software system, including the capability to directly modify 
code through CAD/CAM and other design capture techniques, will 
reduce the code maintenance requirement by as much as 80%. 
Therefore, the implementation of these techniques will greatly 
reduce the operational costs of Shuttle and Payload ground 
processing. 

SCHEDULE: 



Item: 



KY : 



87 



88 



89 



90 



91 



Project Plan Development 

Integration of KATE/GMODS 

Develop OMHF/ECS Shell 

Demonstrate OMRF/ECS System 

HQ/ARC Project Review 

FY '88 Project Report 

Develop Generic Control System (GCS) Shell 

Demo GCS Against Multi-systems Lab Models 

HQ/ARC Project Review 

FY '89 Project Report 

Develop PPCU Shell 

Demonstrate PPCU System 

HQ/ARC Project Review 

FY '90 Project Report 

Develop GDMS Shell 

Demonstrate GDMS System 

HQ/ARC Project Review 

Final RSC SAJ)P Report 



D 
P 
R 



D 
P 
R 



D 
P 
R 



D 
P 
R 



Code R Funding (K$) 3B0 397 500 430 450 

Other Funding (SS/M)(R$) 684 1006 1196 1300 1245 

Contractor Manpower MY 4 8 14 12 11 

Civil Service Manpower MY 8 10 12 15 14 



Note 
D 
P 
R 



Demonstration 
Project Review 
Project Report 



ORIGINAL PAGE IS 
OF POOR QUALITY 



1141 



KSC Launch DiagnosticB (Continued) 

TECHNOLOGY NEEDS AND DELIVERABLES 

Core Technologies Needed 

The following core technologies are required to complete 
the RSC Diagnostics and Control Demonstration: 

1. A parsimonious, standard knowledge base representation. 

a. Based on a description of structure and function. 

b. Elecbrical, Fluid, and Mechanical circuits. 

c. Useable byb all NASA model based expert systems. 

d. Basis for deliverable documentation from vendors. 

2. Improved and generialized functional relationship inverter 

a. Would replace existing limited INVERT function in KATE 

b. Usable in other diagnosers and controllers 

c. Similar to TK-Solver or Mathematica 

d. Finds possible input sets from output value(B) 

3. A standard Flow Solver for expert systems 

a. Compressible and incompressible flow 

b. Assembles continuous flow models from description 

of structure and function 

c. Uses system commands to determine expected outputs 

d. Allows failure of components for diagnosis 

4. A high performance parallel Lisp processor 

a. Vastly improves speed of diagnosis 

b. Parallel evaluation of failure possibilities 

c. 5 processor PC, 80386, 100 mega bytes 

d. Multiple Lisp Chip machine 

Core Technologies Provided 

The fo 1 lowing Core Technologies will be provided by the 
RSC Diagnostics and Control Demonstration Project: 

1. A complete expert system shell for all aspects of control 
and monitor. 

a . Driven by a changeable knowledge base 

b. Autonomous real-time model-based anomaly detection 

c. Autonomous real-time information display with manual 
control provision 

d . Autonomous component level control 

e. Very high level requirements interface to operator 

f . A real-time model-based diagnoser with explanation 

g. Off-line and on-line Single Point Failure Analysis 
h. Autonomous failure history retrieval, and design 

information 
i. Autonomous real-time plot generation 
.j . Autonomous canera control 
k. Knowledge base validation tools 

2. An intelligent CAD knowledge extraction system 

a. Builds structure and function knowledge bases from 
CAD files 

b. Uses Intergraph ICAD data base to creat RATE KB's 

c. Could use IGES version 3.0 

1i)2 



A5.2 RSC FACILITIES. 

Over the past four years KSC has developed three Artificial 
Intelligence Development Laboratories at the Center to support 
many AI application projects, thirteen as of FY'87. These 
laboratories are under a continuous process of development; the 
folloHing capabilities list is the capability that will exist as 
of the completion of FY'87 procurements. 

Design Engineering Al Laboratory: 

This laboratory is used primarily for development of the KSC 
Systems Autonomy Demonstration Project. Another project being 
developed wi thin this laboratory is the Thunderstorm Weather 
Forecasting System. 

Symbolics 3601-1211 
8Mb RAM 
474 Mb Disk 
High resolution 19", 8 bit color system 

Symbolics 3640-140 
6Mb RAM 
140Mb Disk 
l90Mb Disk 

LGP 1 Laser Graphics Printer 

Apple Laser Writter 

2 ea IBM /AT 

Gold Hill Humming Boards 

Large Memory Gold Hill Common Lisp 

5 ea IBM /AT 

Large Memory Gold Hill Common Lisp 

Apple Mac II 
3 Mb RAM 
40Mb Disk 

2 ea copies of Automated Reasoning Tool by Inference Corp. 

Currently in procurement, specified as follows: 
Texas Instruments Explorer Il/LX 
8Mb RAM 
500Mb Disk 
Unix Co- processor 
High Resolution Color 
Ether Net 

These computer systems are currently being integrated across an 
Ethernet . 



11^3 



RSC Facilities (Continued) 

Pay load OperationB AI Laboratory: 

This AT laboratory is primarily involved in the development 
of the Smart Processing of Real Time Telemetry (SPORT) project 
which will provide real time intelligent analysis of Spacelab 
experiment data and will be a precursor for design of a ground 
checkout Bystem for Space Station Pay loads. The laboratory 
consists of the following equipment as procured through FY'87. 

Symbolics 3670-1211 
4Mb RAM 
474 Mb Disk 

High Resolution 8 bit Color 
9 track tape drive 
Floating point accelerator 
Frame grabber 

Symbolics 3640-190 
4Mb RAM 
2 ea 190 Mb Disks 

LPG 1 Laser Graphics Printer 

Apple LaserWriter 

14 ea IBM/XT/AT with various RAM/Disk configurations 

Entire Al lab computer networked over Ethernet LAN using TCP/IP 

Shuttle Operations Al Laboratory: 

This laboratory is being used to develop Al systems for 
diagnostics of the Shuttle Launch Processing System software and 
hardware. The laboratory has been under development during FY'87 
and the following description is what will be in place at the end 
of FY'87: 

2ea Texas Instruments Explorer II 
4Mb RAM 
368Mb Disk 

2ea copies of Knowledge Engineering Environment (KEE) by 
IntelliCorp 

Other AI Development Capabilities: 

During FY'87 KSC has been developing the capability of 
building small expert systems to support various Shuttle and 
Payload processing functions, four projects during FY'87 and an 
additional two for FY '88. To accomplish these tasks we are in the 
process of procuring Compaq 386 computers with 4 to 6 Mb RAM and 
130 Mb Disks. The development of these systems is being 
accomplished using the Texas Instruments Personal Consultant Plus 
software, we have seven copies of this software including the 
Images software. 



^HH 



ORlGirJAL PAGE fS 
OF POOR QUALITY 



o 
o 

-J 

o i 

Z m 



lU 

> 



CO 

o 

z 

LU to 

HI 

o 
o 

QC 
Q. 

X 

o 

z 

< 

GC 
O 
u. 

-I 
O 
cr 

H 

o 
o 

o 



O 
LU 



CC 

o 
o 

< 

DC 
O 

o 

CL 

>- 



LU 

o 



i 

*( 

i 

Q 

Q. 
O 

UJ 
Q 



I 

ii 



CL 
(A O 



< _i 



O 

H 

o 
o 
o 

LU 

cr _ 
< > 



< CO 

lU 
L}J O 

S < 
3 LI. 

d CE 

< UJ 

Q — 

Z (X 

LU UJ 

CC CO 

H ID 

Q H 

UJ Z 

I- UJ 

< C5 
2 _i 

H 

< 2 



{2^ 

^ Q 
liJ 
CO 

< 



LU 
CC 
ID 
t- 
Q. 
< 
O 
UJ 
CO 

< 

LLJ < 

CD _3 
Q a. 
UJ CO 

^5 



I 

O 

o 

i 



O 
z 
i^ 

< 

O _ 
Q Q. 
< X 

O UJ 



z 

i 

UJ 

o 

1^ iz 

go 
z t 

Z DC 

'5 ^ 

< z 

LU O 

LUS 
_l 
< 
> 



o 

H < 

3 CO 

^ z 

LU O 

h- - 

O) ° 

>- 
CO 




CM 



O 
Ol 



s — 

Q S 



° "2 ^ ■« 
,t w "^ 



SS wio 



S$:£ J^ 



LU 

-I 

Q 
LU 

X 

o 

CO 



i, 


CO 


2; 








lU 


1— 


^ 








> 


CO 


t; 








UJ 


z 


rr 




H- 




n 


< 

LU 
Q 


H 




Z 




1- 


Z 

o 
< 


CO 

UJ 
Q 

_J 
LU 


LU 

UJ 
> 


1 


o8 

o 


1 


2 

CO 
CO 


Q 


Q 
CO 


CO 


^ 
^ 


i 


^ 


Hj 






Q 


Q 


ZE 


2 


Q. 


a. 




LU 

S; 

Q 
CO 



Q 
(3 



CO 



LU 
Q 



Q 
O 



CO 

LU 



O 

< 
LJ. 

Q 

Z 
< 

CO 

H 
Z 
< 
Q. 

O 

DC ^ 
< I 

G 

OC 

2 



Ujtf 
UJ Q 

2 i 

O CO 
mg 

^^ 

QP 

^^ 
Z ^ 

m CC 



[ii 



■= I- UJ _ 
tu = h- = 



«2k 

LU — 

e LU 
CO CC 

^£ 






O w 



u: UJ 

, UJ 

< w 

tf CO 

E UJ 
^i 



o 

CO 



fr O ^-. CO m 



CCO 

t- CC 
CO K 

2 " 

Q LLI 

^3 



CO CO 

-1 CC CC 

z 2 > uj 

G 
5 



Q- LU 

^o 

ixi CC 

Q > 

<. LU 

O CO 

CO P 

^ CO 



— CO 

Z) > 2 

t- w iS 

3 1-1- 

O z CO 

b^ UJ > 

o 2 w 

UJ UJ C3 

X O Z 

o < 



-1 < 



CO 
CO 

LU 

o 
o 

DC 
Q. 

I 
o 



3 
o 

CC 

CO CO . 
CO CO CO 



13 

5 

CO 



1i)5 



A6. LAHGLEY RESEARCH CENTER 

A6.1. CORE R&T (Planning and Reseasoning) . 

TITLE: Application of Behavioral Net Architecture to 
Planning/Scheduling 

OBJECTIVE: 

To investigate the application of behavioral net architectures to 
the problem of planning and scheduling, and the development of a 
prototype domain- independent planning and scheduling tool. 

RATIONALE: 

Planning and scheduling problems are numerous throughout NASA, 
including telerobotic task planning, satellite fly-by scheduling, 
mission planning, crew activity planning ahd scheduling, job shop 
scheduling, and many more. Several tools have been developed in 
an attempt to automate these processes, but to date these tools 
have been extremely domain-specific. Furthermore, these tools are 
typically not capable of both static and dynamic planning and 
scheduling, are minimally interactive, and are non-real-time. The 
development of a "generic" , domain- independent 

planning/scheduling tool has been deemed beyond the current state 
of the art . 

Behavioral networks have recently shown promise in dynamic 
intelligent control execution for telerobotic systems. Behavioral 
nets are composed of multiple feedback control processes 
interconnected in a hierarchical lattice structure with weighted 
links. The structure of the network is determined by a hierarchy 
of resource requirements (including devices, space, and time), 
with the weights of the links determined by priorities and 
constraints within the system. 

This architectural approach offers the potential for the 
development of a domain-independent tool for planning, 
scheduling, and resource allocation. 

APPROACH : 

As previous stated, many planning and scheduling domains and 
algorithms exist , and many approaches have been tried for 
individual domains. The initial task of this research effort 
would be the analysis of various domains, problems, and tools, in 
order to index techniques against application criteria. These 
criteria would include such things as the dynamic vs. static 
nature of the application environment, the extent of the 
resources available, the availablity of alterate resources, the 
different classes of potential contraints, etc. This survey will 
concentra on NASA-developed tools and application domains, but 
will not be limited to these. 



li)7 



PRECEDING PAGE BLANK NOT FiLMED 



PACIi 



ilL 



.INTENTIONALU SUNK 



LaKC Behavioral Nets (Continued) 

Due to the inherent symmetry of the node and link structures in 
behavioral net architectures, a task specification language can 
be developed to allow a user to describe a planning/scheduling 
problem for initial plan resolution. This task specification 
language can also be used interactively to input modifications to 
the resource/constraint environment, which will cause a dynamic 
restructuring of the network to identify the optimum subsequent 
plan/schedule. Therefore, a second task in this research effort 
will be the specification of a behavioral net design language, 
and the implementation of a simple user interface for the use of 
this language in designing and manipulating a task-specific 
behavioral net. User displays will also be developed which show 
the current net state, i.e., the desired plan/schedule. 

A behavioral network "engine" for planning and scheduling will be 
developed on an available sequential computer architecture (VAX). 
(This prototype will only be able to simulate the parallel 
computation inherent in the behavioral net concept. Thus the 
speed of execution will be proportional to the size of the net. 
Subsequent implementations will be on parallel distributed 
hardware, as additional funding becomes available.) 

The prototype system will be used to develop plans and schedules 
for NASA-domain problems that have been encountered in 
operational situations. The choice of these problems will be 
based on interaction with personnel at other centers that have 
analyzed these problems and/or have developed tools for their 
solution, and who can provide specific resource/contraint 
information about the problems. This will require collaboration 
with other NASA personnel doing similar research. 

The number of problems used to test the system will depend on the 
availablity of this information and time constraints. The results 
of the use of the prototype against these problems will be 
analyzed and compared with current tool performance, and will 
include ease of problem net design, ease of use, acceptability of 
solution, and relative speed of execution. 

PRODUCTS : 

8/88 Document surveying current applications and techniques in 
planning and scheduling, indexing techniques against specific domain 
criteria. 

1/89 Document describing a task specification language for 
behavioral nets . 

6/90 Document describing the use of behavioral nets to solve 
specific available planning and scheduling problems pertinent to 
NASA. 

8/90 Prototype software implementation of a behavioral net 
"engine" for planning and scheduling, with a human interface 
using the task specification language, demonstrated and available 
for distril)ution. 

)k8 



LaRC Behavioral Nets (Continued) 



SIGNIFICANT MILESTONES AND FUNDING REQUIREMENTS: 



TASK 



87 



88 



89 



90 



Domain/technique analysis 
and taxonomy 

Task spec, language design 

Behavioral net "engine" 

for planning/scheduling 

User interface design and 
implementation 

Planning/sched . problem exp. 

Experiment results documented 

Prototype demon. & avail. 



FUNDING: 
MANPOWER : 
NASA in-house civil service 
NASA in-house contractor 

programming support 
University grant support 



(50) 



197 

2 

1.5 
7 



300 

2 

1.5 
2 



300 

3 

2.5 
2 



TOTAL: 



4.5 



10.5 



5.5 



7.5 



CORRELATION TO SADP CORE TECHNOLOGY NEEDS: 

1990 - Planning/replannlng 

1993 - Planning under uncertainty 

1996 - Real-time planning and replanning 
Can provide a link between the Systems Autonomy and the 
Telerobotic Programs . 

BENEFITS: 

Provide an in-depth survey and analysis of planning and scheduling 
applications and techniques, particularly those applicable to NASA. 

Extend the state-of-the-art to provide a domain-independent 
"shell" for planning and scheduling problems. 

Provide documantation of the application of this technique to 
several planning/scheduling problems pertinent to NASA's mission 
needs . 



Provide a common means of planning and scheduling between the 
System Autonomy Program and the Telerobotics Program, for eventual 
interaction between the two programs. 

1H9 



ItaRC Behavioral Nets (Continued) 

TECHNOLOGY DELIVEHABLKS: 

8/88 - Document surveying current planning/scheduling systems 

compared to specific NASA requirements. This is pertinent 
to any planning/scheduling problem within NASA, including 
demonstrations of the 1990-phase and beyond. 

1/89 - Document describing a task specification language for 
behavioral nets — possibly a formal generalized 
methodology for task decomposition. This is pertinent to 
researchers in any planning domain, including robotics, 
including both Systems Autonomy and Telerobotics 
demonstrations of the 1993-phase and beyond. 

8/90 - Software with documentation of behavioral nets solving a 
variety of planning and scheduling problems, demonstrated 
and available for distribution. Pertinent to any planning/ 
scheduling problem in NASA, including robotics, including 
both Systems Autonomy and Telerobotics demonstrations of 
the 1993-phase and beyond. 



150 



2 < 

X u. 
O w 

uj I 

UJ o 

O 5 
O ^ 

5 < 

ID 

z 



< 


O 

Q. 



O 

D 
< 

111 

(f) 

> 
CO 



< 

QC 

o 

> 
< 

X 
UJ 
CD 

O 

z 
o 

< 

LU 
OC 

O 

z 
< 

o 

z 

z 
z 
< 



UJ 

> 
o 

UJ 

-^ 
03 

o 








s 




'a ^ 


01 

r 








* r 






^ 


o 

CO 


o s 

z 










1 s 

-> 









a 



< 
Ul 

3 
O 
UJ 

z 
u 

(0 



E 
o 
c 
o 



(0 

c 
(« 

o 

3 

c 

u 
S 



c 



• 
n 

3 

c 
« 

c 
.9 

« 



c 
c 

IS 



f I 



IS 

E 
o 






c 
o 

5 

c 

9 

E 
• 
a 

E 



I c 

a » 

•a 8 

-1 I 

2-6 • 

s? z 

r I 



(0 

«-• 
c 
• 
E 
•c 

8. 

X 



I i 



o 



? 



3 

£ - 

8 c 



3 
M 
9 



C 
C 

« >r 

Q. Ul 



i 



* 

•o 
c 
« 

S 

c = 
0.2 

E 3 
9 J3 
•o C 
m M 

1^ 

O o 

p 



s 

IS 



o O 

2 ^ 
O UJ 

-1 UJ 

§: t 

< X 

a 
cr 

< 









Tw 




,,,„ 






s 






HI 


E 2 








u 










^=2 












^ c 








z 


1 s 

CO 0! 

> 








^ 




/ 















UJ 



< 

a 

z 
< 

H- 
Z 
< 
Q. 



I 
o 

z 



^ 



I 
o 

UJ 



2 ^ 

CC S: 
< ^ 

5 



r3 
< 
> 

C3 



« 

CC 
UJ 

> 

z 

Z 

2 

z 



CO 
CC 

Ul 

> 
z 

Ul 



CO 

I- 

•8 

< 
< 

z 
—I 

o 

CC 

< 

o 



oc 
o 

z 



>- 

CC 



o 

z 
< 



o 

UJ 

o 

Ul 

_l 
_J 

o 
o 



UJ 

o 

2 



Ul 



151 



A6. LAHGLEY RESEABCH CENTER 

A6.2 CORE RESEARCH AND TECHNOLOGY (Validation Methodology). 

TITLE: Validation of Knowledge-Based Systems with 
High-Reliability Requirements. 

OBJECTIVE: 

To define reliability and performance validation methods for 
life-critical knowledge-based systems. 

RATIONALE: 

On-board systems for space application must be reliable and 
validatable. Many NASA space operations are life-critical. Even 
when astronaut personnel are not involved, the loss of equipment 
and/or experiments can be prohibitively expensive. Crew 
availablity is limited for the performance of routine or 
excessively time-consuming functions, and intelligent autonomous 
systems which are designed to perform these functions must be 
thoroughly validated. 

Exhaustive testing of such complex systems as the knowledge-based 
systems proposed for space applications is insufficient to 
validate a man-rated system. 

APPROACH : 

The initial task will be to define quantitative parameters for 
characterizing the effects of an embedded knowledge-based system 
on the total system reliability. No such criteria currently 
exist. Performance and non-determinism are major reliability 
factors of a real-time knowledge-based system, in addition to the 
correctness of the rules. Therefore, the parameters will be 
measures of correctness and structure of the knowledge base , the 
performance and reliability of the hardware architecture, and the 
algorithm and implementation of the inference engine. Once the 
parameters to be measured are identified, analytical error models 
and/or simulative techniques will be developed for measuring the 
parameters. Proposed analysis techniques include graphical 
analysis of rule structures, graphical simulation of the dynamic 
behavior, and sensitivity analysis of critical rules. Once these 
techniques are in hand, it is possible to develop guidelines for 
designing validatable knowledge-based systems, and to develop a 
methodology and tools for quantifying the reliability of these 
systems . 

The proposed techniques and prototype tools will be applied to 
knowledge-based systems being developed at NASA Langley, 
including rule-based systems for fault prediction and trend 
analysis and the CSDL Electronic Flight Engineer, and model-based 
systems for fault diagnosis and recovery planning and for 
automated reliability modelling. 



152 



LaRG Validation Methodology (Continued) 



PRODUCTS : 



5/89 Document defining the unique characteriBtics of 

knowledge -based systems and the applicability of current 
validation techniques to these systems. 

8/91 Guidelines for building a validatable knowledge-based system. 

8/92 Development and documentation of methodologies for validating 
knowledge-based systems. 

SIGNIFICANT MILESTONES AND FUNDING REQUIREMENTS: 



TASK 



87 1 88 ! 89 1 90 ! 91 1 92 ! 



KNOWLEDGE BASED SYSTEM 
VALIDATION 

Define qualitative measures 

Develop evaluation methods 

ARCHITECTURES AND INFERENCE 
ENGINE DESIGNS 

Develop fault-tolerant model 
programming model 

Evaluation and analysis 






FUNDING: 1 

I 

KNOWLEDGE-BASED SYSTEM 1 
VALIDATION 1 

I 

ARCHITECTURES AND INFERENCE j 
ENGINE DESIGNS I 



100 



50 



150 



100 



150 



100 



200 



100 



200 



100 



TOTAL FUNDING: 



150 



250 



250 



300 



300 



MANPOWER : 



2.0 



2.0 



2.0 



CORRELATION TO SADP CORE TECHNOLOGY NEEDS: 

1993 - advanced validation techniques based on new theory 
1996 - expanded validation techniques 

BENEFITS: 

Provide design guidelines and a validation methodology for 
building and validating a knowledge-based system with 
high-reliability requirements. 



153 



LaRC Validation Methodology (Continued) 

TECHNOLOGY DELIVERABLES: 

5/89 - Document defining the unique characteristicB of 

knowledge-based systems and the applicability of current 
validation techniques to these systems. This is pertinent 
to any knowledge-based system development, including 
demonstrations of the 1990-phase and beyond. 

8/91 - Guidelines for building validatable knowledge-based systems. 
This is pertinent to any knowledge-based system 
development, including demonstrations of the 1993-phase 
and beyond . 

8/92 - Development and documentation of methodologies for validating 
knowledge-based systems. This is pertinent to any 
knowledge- based system assessment, including 
demonstrations of the 1993-phase and beyond. 



15M 



> 

O 



O 

IXJ 

H 

UJ 

oc 

o 
o 



o 

H 
D 
< 

CO 

:e 

LU 

CO 

> 
CO 



LU 

o 
o 

-I 

o 

a 
o 

X 

tn 



UJ 

> 
o 

m 

m 
o 



DC -i 



< 
> 



o 

CL Z 

o 



o 

< 

LU 
DC 



< 

o 

z 

z 
z 
< 





o 

z 

5 

z 

3 



LU 

a 

LU 

X 

o 

(0 











r 




(M 
0> 






o 

8" 


S> 






1" 


s 






s <^ 


8 






_n 




S 








1^ 



CI 

.g 

I 
I 

e 



^ 
r ® 



to 

Ig 

in 
n> 
■Q 

q> 

I 

o 



o 

t 

o 

« 

E 

c 
.2 g 

« r5 



c 

(0 

cr 

o 

c 

o 
o 



(0 

> 
(D 

a 
o 

5 

o 
Q 



a (A 
•—I * 

^^ 

CO -.. 
0) « 

5 



(O 

v> 

>. (0 

(IS 'in 

c >< 

(0 10 



M 



cd £7 
9£ .2 



^o 



9 

cr 



>• 
s 

G> • 

Ji > 

O) • 
C OT 

_ "O — 

SI -5 

o E 
X at 
S .£ 
J5 E 
„ E 

g-a 
« ? 

> g 

O Q. 
Q 



lU 



o 

< 
u. 

a 
z 
< 

(0 

h- 
Z 
< 
Q. 

O 

< 

0. 



^ OL 



{2 

2 



o 
5 



o 

CO 

to 

CO 
O 
_j 
O 
m 

>- 

CO 



CO 

oc 

g 

< 
o 

UJ 
Q 



155 



A6. LANGLEY RESEARCH CENTER 

A6.3 LaRC FACILITIES. 

NASA Langley is the home of reBearch activity in many aerospace 
disciplines. Research in Systems Automation and AI is conducted 
in the context of specific application areas. Therefore, Langley 
has chosen to provide Al research facilities in a manner that is 
cost/time efficient and consistent, yet gives maximum flexibility 
to the individual researcher. 

Flexibility is provided by promoting the acquisition of AI 
research facilities by the individual research branches. Many 
branches have general-purpose computers, such as VAXes and 
IBM-PCs, and use Al-oriented software on these to provide an 
introduction to AI techniques. Other branches with mature AI 
research efforts are purchasing symbolic processors of their own 
that can be tailored to suit specific research objectives. 

Efficiency and consistency result from a high degree of 
centralized support to AI researchers at Langley. A 
top-of- the line symbolic processor was purchased with central 
funds and Its centrally supported, both as a research tool for 
mature projects, and as an introductory machine for individual 
researchers considering the purchase of their own machine. An 
active and close-knit special interest group in AI disseminates 
Al-related information, hosts AI speakers, and forms a united 
voice for AI at Langley. Al-oriented software, such as CLIPS and 
GEST, is centrally disseminated, and the costs for expensive 
resources, such as KEE, are shared. Procurement of central 
support for distributed system maintenance and new-user tutoring 
has been initiated. Center support for individual branch 
ownership of symbolic processors is also being considered, 
especially in providing for continuing maintenance costs. This 
central support allows branches to acquire expensive AI research 
facilities even when AI activity is a small part of a branch's 
overall program. 

BEHAVIORAL NETWORK ARCHITECTURES FOR PLANNING AND SCHEDULING: 

This research activity is being conducted in the Automation 
Technology Branch (ATB) . This branch houses sophisticated 
computing equipment for telerobotics research, including 5 VAXes, 
7 PDP 11/73's, VSll and GTI POLY 2000 graphics capabilities. This 
activity will use a Symbolics 3675 that is DECNETed to an ATB 
microVAX, and a DEC VAX Al Color Workstation that has been 
ordered by the branch, with the necessary auxilliary support 
peripherals. 

VALIDATION OF K-B SYSTEMS WITH HIGH RELIABILITY REQUIREMENTS: 

This research activity is being conducted in the Systems 
Validation Methods Branch (SVMB). This branch houses the AIRLAB 
facility, a network of 11 VAXes and a number of special-purpose 
fault-tolerant research processors. This activity will use a 
Symbolics 3650 and a DEC VAX AI Workstation with LUCID software, 
that are also supported by SVMB. In addition, SVMB researchers 
will have access to knowledge-based systems developed at Langley, 
for validation measurements. 

156 



A7. LEWIS RESEARCH CENTER. 

A7 . 1 . Technology DemoiiBtrations . 

TITLE: Space Station Power System Autonomy Demons t rat ion. 

OBJECTIVE: 

To appy, evaluate, and demonstrate Autonomy Technologies for the 
operation of the Space Station Power System. Also, to 
participate in the 1990 demonstration of two systems - the Space 
Station Power System and the Thermal Control System - operating 
together in a coordinated mode with expert system controllers. 

RATIONALE : 

The space power system operating in a cooperative mode with other 
on-board systems has a special relationship with those other 
on-board syntems. It supplies the resource, power/energy, upon 
which all of the other systems/ experiments will rely for their 
propoer functioning. It will place special requirements and have 
a unique interface with the executive controller. The power 
system , because of its unique role among the the space station 
systems has great potential for increased reliability and 
significant o operational cost reductions from the application of 
the "Autonomy Technologies. Development, application, and 
demonstration of these technologies for space power systems will 
represent a major contribution to the goals of the OAST 
Automation and Robotics Program. 

APPROACH : 

The 1990 Power Systems Autonomy Demonstration Program is a joint 
effort between the Lewis Research Center and the Marshall Space 
Flight Center working in conjunction with the Ames Research 
Center and the Johnson Space Flight Center. At the Lewis Rsearch 
Center, the program will entail participation by the Power 
Technology DiviBion, (prime participant), and the Space Station 
Systems Directorate, (which is responsible for the development of 
the Space Station Power System. The program will entail: 

Use of the existing Space Station 25 KW PV/PMAD Test Bed. 

Develop and interface high speed data buss and microprocessor control 

with the test bed. 
Use the existing applicable power systems facilities and software 

developed by the Marshall Space Flight Center. 
Demonstrate autonomous control of selected subsystems: 

Fault detection/classif ication/isolation . 

Component operation/fault restoration. 

Component health/trend monitoring. 
Aquire and assemble reqisie knowledge base. 
Aquire/develop resource manager/scheduler. 
Develop training procedures for power system operators. 
Demonstrate stand alone power system operation. 
Participate in combined systems test with the Thermal Control System. 



157 



LeRC Power Demonstration (Continued) 

PLANNED ACCOMPLISHMENTS: 

SyBtem teGt bed operational, 2nd Q. FY 87 . 

Identify core technology requirements, FY 87-88. 

Finalize knowledge base, FY 89. 

Demonstrate autonomous component operation, FY 88. 

Identify /develop human interface requirements, FY 88-89. 

Demonstrate stand alone power system operation. 

Demonstrate combined system operation, (power/thermal) , FY 90. 

Develop training manuals/procedures for power sys . ope., FY 90-91. 

Determine best method of power system operation, FY 88-90. 

Verify best method of power system operation, FY 90. 

PRODUCTS : 

The Power System Autonomy Demonstration Task will result in an 
accumulation of autonomy technolgy expertise for the operation 
and management of space power systems and the resources they 
produce; on-board electrical power and energy. Much of this 
expertise will also be applicable to and can be used by space 
systems other than the power system. Also, technology transfer 
and fallout to the commercial terrestrial sector is a distinct 
possibility. Specific identifiable outputs are: 

Fault detection/classification/isolation methodologies. 
System restoration strategies, (after a fault). 
Planning/replanning in the face of uncertainty for the use of 

the power and energy resource aboard a space station. 
Operator training methodologies for power system operation 

and resource management . 
Extensive data base on the application of ES/AI technologies 

to the design and autonomous operation of space systems . 

BENEFITS: 

Operation of a mature autonomous space power system has the 
potential for significant reductions in operational support 
costs. In addition, the application of mature autonomy logics to 
space systems will result in improved reliability in the 
operation of such systems with the added benefit of enhanced 
resource management capability. 

SCHEDULE/RESOURCES : 

ITEM FY 87 88 89 90 91 

Operational Test Bed. X 

Core Technology Requirement X X 

Assemble Knowledge Base X X 

Autonomous Component Operation X 

Develop Human Interface Requirements X X 

Stand Alone Power Autonomy Demo. 

Power System Operations Methodology 

Combined System Demo. 

Verify Best Method of System Operation 

Training Manuals Procedures Formalized. 

FUNDING: $K 

CS Person Years 

158 







X 




X 


X 


X 
X 
X 








X 


X 


550 


750 


800 


200 


10 


10 


10 


10 



LeKC Power Demonstration (Continued) 

TECHNOLOGY NEEDS: 

The folloHJns "COHE TECHNOLOGY" elements are needed by LeRC to 
support the Power Systems Autonomy Program Development and the 
1990 Combined Systems Autonomy Demonstrations. 

1. AUTONOMY, (ES/AI), ENVIRONMENT, Definition - Requirements. 
Development Environment 
Ope^^lting Environment 

Stand alone systems operations 

Combined/multiple systems operations 

The following items are needed from the "Core Technology" 
program: 

(a). Software/hardware definitions and requirements, 

(b) . Structure and formant of the knowledge/rule base, 

(c) . Knowledge base capture methodology and requirements, 

(d). Distributed vs Centralized data base requirements. 

2. MACHINE/HUMAN INTERFACE DEFINITIONS AND REQUIREMENTS. 

Intelligent display requirements 

Domain specific interfaces and definitions. 

3. TASK PLANNING AND REASONING. Guidelines on: 

Prioritized vs random scheduling. 
Reactive vs dynamic scheduling. 
Scope of planning/scheduling program. 

Resource manager 

Task scheduling 

On- board experiments/tasks . 

Maintenaence/repair scheduling. 

Requirements imposed by the interactions of multiple systems. 

4. INTERFACES OF POWER SYSTEMS CONTROLLER/EXECUTOR WITH THE EXECUTIVE 
CONTROLLER/MONITOR . 

Requirements for the 1990 Demonstration. 

Requirements for the 1993-96 Demonstrations. 

Specific requirements for Space Station DMS interaction. 

5. MODELING REQUIREMENTS FOR ES/AI SYSTEMS. 

Causal and heuristic modeling requirements. 

Any special requirements to insure compatibity between the various 
systems for the combined/multiple systems demos. 

6. VALIDATION METHODOLOGIES FOR ES/AI SYSTEMS 

Definition of ES/AI system validation. 
System specifications. 



159 



LeKC Power DemonBtration (Continued) 



7. VERlFi CATION METHODOLOGIES FOR ES/AI SYSTEMS. 

Definition of ES/Al sysfcem verification. 
SyBtem operating requirementB . 



These core technology program elements are required by LeRC for the 
demonstration of: 

(a). Stand alone operation of Space Station Power Systems, 
(b). Combined operation of the Space Station Power Systems 

operating in a cooperative mode with the Thermal 

(Control System, 
(c). Operation of the Spacce Station Power System for the 

1993 and 1996 demonstrations. 



160 



A7. LEWIS RESEARCH CENTER. 

A7.2. LeRC FACILITIES. 

The following facilities at LERC are applicable to the POWER 
SYSTEMS AUTONOMY DEMONSTRATIONS/SYSTEMS AUTONOMY DEMONSTRATION 
PROJECT . 

POWER TECHNOLOGY DIVISION FACILITIES. 

o 1U0RW-20RHZ Component Test Laboratory. 

Testing of transformers, cables, RPS/RBl's load 

converters , etc . 
Full power thermal evaluation of Space Station and 

Power System Autonomy Demonstration hardware. 

o Fault Tolerant Controller Development Laboratory. 

Develop and demonstrate fault diagnosis/prediction and 

reconfiguration hardware and algoriths . 
Microprocessor controller applications development and 
test facility. 

o Power Semiconductor Test Laboratory. 

Characterization of developmental/commercial power 

Gemiconductors . 
Evaluations of degradations due to high 

temperature/radiation environments . 

SPACE STATION DIRECTORATE ELECTRICAL POWER SYSTEM TEST BEDS AND 
DEVELOPMENT FACILITIES. 

o Solar Dynamic/Power Management and Distribution Test Beds 
and Development Facilities. 
Primary candidate for advanced automation and 

enhancement for Systems Autonomy Demonstration 

Project. 
Cenerically closest to evolutionary Integrated PMAD 

Test Bed defined as near prototype IOC Space Station 

Electrical Power System with regard to end-to-end and 

top to bottom controls. 
Provide Ethernet port from Power Management Processor to 

advanced autonomy workstations and link processors. 

o Photovoltaic/Power Management and Distribution Test Beds: 
GDC 25 KW, 20 RHZ Test Bed. 

Test/Evaluation of Space Station components in PMAD System. 
Provide data base/operational base. 

o Software Development Facility. 

Provide controller software development on Test Beds. 
Host for Modeling/Simulations for Test Beds and Space 
Station Electrical Power System. 

Support AI/ES software development for Power System 
Autonomy Demonstration . 

161 



ORIGINAL PAGE IS 
OF POOR QUALITY 




162 



A8. MARSHALL SPACE FLIGHT CENTER 

A8.1 CORE RESEARCH AND TECHNOLOGY (Planning and Reasoning) 

TITLE: Hubble Space Telescope Design/Engineering Knowledgebase 
(HSTl)EK). 

OBJECTIVES: 

The short term objectives of this project are to capture as much of 
the design and engineering (construction/test) knowledge currently 
available within the HST development team as possible in an 
intensive knowledge acquisition effort. The resulting knowledgebase 
will be used to demonstrate the immediate utility of knowledge based 
systems by developing the HST Operational Readiness Expert (HSTORE) 
system which will support MSFC's Orbital Verification activity 
immediately following launch of the HST, now scheduled for November 1988. 

RATIONALE: 

The HSTORE knowledgebase will also be the focus of a long term 
effort to develop methods for capturing design/engineering knowledge 
on major NASA projects, involving multiple technical disciplines and 
a large number of experts, as well as for constructing large-scale 
knowledgebases. The extended HST Design/Engineering Knowledgebase 
(HSTDEK) will serve as the testbed for developing these methods, and 
will also support the development of a Ground-based Expert System 
for Space Telescope (GESST) intended to support the HST during its 
fifteen year operational lifetime. GESST will focus on the following 
four application areas: telemetry analysis for health maintenance 
(especially in the electrical power system), scheduling of HST 
activities, data analysis for science, and assistance to scientific 
investigators. In addition to defining and testing the methods 
required to support design/engineering knowledge capture on major 
projects at NASA's operational centers, this project will play a key 
role in developing a strong knowledge engineering capability at 
MSFC , oriented toward practical applications of the technology to 
achieve concrete enhancements of present engineering practices . 

APPROACH : 

This project is organized as a collaborative effort between MSFC and 
ARC. MSFC will manage the development of technology demonstrations 
in both the? short and long term; i. e., knowledge engineering of the 
HSTORE knowledgebase and expert system in the short term, and the 
HSTDER/GESST system in the long term. ARC will manage the research 
aspects of the HSTDEK project, and will use these knowledgebases as 
a testbed for their core technology efforts aimed at developing 
techniques for design/engineering data capture and constructing 
large-scale knowledgebases. HSTORE will be developed using currently 
available knowledge engineering technology, possibly augmented by 
interim results of the ARC research if it does not threaten the 
availability of HSTORE at HST launch. The HSTORE knowledgebase will 
be frozen at about six months prior to launch in order to support 
verification prior to its operational use, A copy of this 
knowledgebase will, in parallel, form the starting point of HSTDEK 
development utilizing the approach and methods produced by ARC 
research in this period. After serving as a testbed for ARC research 

163 



MSFC HST Design Knowledgebase (Continued) 

in large-scaJe knowledgebase construction for about two years, a 
version of HSTDEK wilJ be frozen to serve as the basis of GESST. 
GESST development will provide a check on the success of the 
large-scale knowledgebase design and construction effort. The 
methodology developed in this project will be documented and 
provided to other major projects at two points during the project. 
Methods for design/engineering data capture will be formalized, 
based on HST experience at about the midpoint of the project at the 
time of the HSTORE demonstration. A methodology for construction of 
large-scale knowledgebases will be formalized at the end of the 
project, in conjunction with the GESST demonstration. It is expected 
that the knowledge engineering capability developed at MSFC in the 
course of this project will be used for the first operational 
applications of these methods. The HSTDEK project itself will 
involve an extensive knowledge acquisition effort with the engineers 
responsible for the design, fabrication and test of the Hubble Space 
Telescope. The required expertise is presently spread across as many 
as two hundred engineers at six different sites, including Europe. 
Identifying a subset of these experts who can provide the required 
knowledge and which can be accommodated in a knowledge engineering 
project is a challenge in itself. New methods for accomplishing 
knowledge acquisition with multiple experts on this scale will have 
to be developed as part of the ABC Core Technology research. These 
challenges, coupled with the limited knowledge engineering 
capability presently available at MSFC and current lack of Fy87 
funding, may constrain the scope achievable in HSTORE at HST launch. 
It is expected that there will also be a few other collaborators on 
the HSTDEK project, in addition to MSFC and ARC. Lockheed Missiles 
and Space Company is the prime contractor for Space Telescope 
development, and most of the HST design knowledge resides at their 
Sunnyvale operation. They are also pursuing a related HST project as 
part of their Internal R&D program. We are planning to suggest some 
joint research with them as part of HSTDEK. The Knowledge Systems 
Laboratory at Stanford is very interested in participating in this 
project as a research vehicle for large scale knowledgebase 
development. The Computer Science Department at The University of 
Alabama in Huntsville is interested in supporting research on the 
integration of knowledge engineering techniques into the system 
development process at MSFC. 

PLANNED ACCOMPLISHMENTS: 

The HSTORE/HSTDEK project will demonstrate the value of knowledge 
based systems for both limited objectives such as the verification 
and checkout of the HST immediately after launch , and for broader 
types of support such as that provided by GESST/HSTDEK throughout 
the operational mission. Knowledgebase development in this project 
will also provide a real-world testbed , based on a significant and 
difficult domain, for research into design data capture and the 
construction of large-scale knowledgebases. The final products of 
this project will be two operational knowledge based systems 
supporting the JIST, well defined methods for design data capture and 
the construction of large-scale knowledgebases which have been 
developed and tested in a significant NASA domain, and a cadre of 
knowledge engineers at MSFC who are experienced with these methods 
and are in a position to apply them within other major NASA projects. 

]6^ 



OR!G?^iAL PAGE IS 
OF POOR QUALiTY 



M£)1''C IIST D'^nign Know ledgebase (Continued) 



SCHKDULK : 



Item 



FY 



HST DesJRn/KnRJneer inR KnowJedRebase Dev . 
HST Operational Readiness Expert Dev. 
HST Operational Readiness Expert Demon. 



Dev. of Den i fin Data 
Dev. of lian;e Scale 
GESST Development 
GESST Demonstration 
Technology Transfer 



Capture Techniques 
Knowledgebase Mthds 



in to Other Programs 



88 

X 
X 

X 
X 
X 



89 

X 
X 
X 
X 
X 
X 



90 
X 



X 
X 
X 
X 
X 



91 
X 



X 
X 



<>X 



Funding ($R) 

Civil Service (MY) 
Contrnctor (MY) 



471 

4 

2 



500 

4 
2 



bOO 

4 
2 



500 

4 
2 



500 

4 
2 



TECllN01,0(;v DKI.JVirRAHl.Fr.: 

Technology ConceptB/Methodologles 

o An assessment of the traditional engineering activities 
wliich comprise a major development project will be 
usod tt) construct a design data capture methodoJogy 
bac>ed on a prioritized list of the data products from 
these activities as sources of knowledge. 

o An attempt wilJ be made to develop a set of knowledge 
representations which are as general as posBible with 
respect to the design data to be captured, as it exists 
th'j Hr>T data products. 

o A method for interfacing a knowledge based system to 

a traditional system in an operational environment will 
be (Jeveloped and investigated. 



in 



o 



Met.h'xin Tor iitili?;ing a knowledge based system in 
support of design activities will be developed in the 
context of the Hubble Space Telescope (design of 
similar lacilitios such as AXAF, design of instruments 
to l)e n(Jded to the HST, construction of command 
messages , etc. ) . 

Software I'rograms 

o Hubble Space Telescrope Design/Engineering 
Knowledgebase (HSTDER): March 1992. 

o Hubble iifjace Telescope Operational Readiness Expert 
(HSTOHIC) : August 1909. 

o Groutid based Kxp<irt System for Space Telescope 
(GKSST): September 1992. 



165 



OF POOF QUA.iTr 



M:')!'''.; IliiT UoniRn Know le<lH<^l>n6e (Continued) 



TeBting nnd Kvn luai ions; 

o 'Die (iovelopmenl, of a comprehenRive knowledgebaBe of 
de[> if;n/«nRi "RorlnB expertiBe fr^r the Hubble Space 
Te)o!-rropo will be UGed aB a teBtbed for evaJuatin^ 
mol.hodi; d<ivolo|)(Ml in otlier c;oro t.echnoJogy elementB 
for: 

Onpturo of denign data from the data products of 
l.radi tjon.j 1 engineering activities involving 
multiple technical disciplineB. (January 1990) 

('apture of design expertise from multiple 
experts. (January 1990) 

nonRtruction of large scale knowledge bases. 
(March 1992) 

Documenta b i on 

o Technicai RepjortB will be developed documenting: 

(Juidelinos for effectively locating sources of 
design data in the data products of development 
proJeejtB. (Sepiiember 1988) 

(Guidelines for selecting a generalized knowledge 
reprenentat;ion appropriate to different types of 
(iesign data. (March 1989) 

A method for interfacing a knowledge based 
system with a traditional system in an 
operational environment. (November 1989) 

- Methods for capturing design expertise and 
utilizing it in similar design activities. 
(r)eptember 1992) 



166 






MSl'C lit"]' Design Knowledgebase (Continued) 



A8.2 MSJj'C lfACJl.lTlF.ii. 

Rnowiedge Kngineeririg KnvironmentB 

There Ib no centralized faciJity for Knowledge Engineering at 
MSFC'. Hardware and r.ofl.ware l;o Bupport the Knowledge Engineering 
activity in IISTDKK at. MSEC will have to be procured by the 
project, and a portion of the HSTDEK funding has been set aside 
for this purpoRc. J)iF.cuBBionB are ongoing with ARC as the NASA 
lead Al cerii.er to determine the moBt appropriate development 
environment for USTDER. At the present time, it is expected that 
two workRtatJonn and a central server will be procured in FY88 to 
support ktioH ledge bane construction at MSEC. This capability will 
be augmented as more people are aBsigned to the project and aB 
additional capacity is required. 

Stanford IJtiiversity will utilize the capabiiitieB of their 
Knowledge Systems Iiaboratory (KSL) to support their research 
under the IISTUEK (^rant, and also to support our MSEC 
representative at ARC. EacilitieB are also being made available 
at ARC in the Information Science Division Laboratory to support 
MSEC personnel detai led to the ARC area as part of the HSTDEK 
project. E.«:lJities at the Lockheed AT Center will also be 
available to MSF(; HSTDEK personnel who are assigned to the 
Knowledge JCngineer Training Program there. This includes the 
three month practicum which follows the ciaBBroom instruction, 
during which HSTDEK personnel will be actively involved in 
augmenting tiie HST knowledge base. 

Huntsville Operational Support Center (UOSC) 

The Uirst knowledge baBed system to be constructed as part of the 
validation of HSTDEK. called the HST Operational Readiness Expert 
(HSTORE), will be used to support the Orbital Verification (OV) 
activity for the HST. MSEC will conduct this activity in the 
HOSC. The HOBC villi Bupply telemetry reduction, data 
distribution, data display, and facility support to the misBion. 
HSTORE will have to be integrated in this operational 
environment. MSEC wi J 1 supply facility support to HSTORE in the 
HOSC, aB well as assistance in planning the HSTORE/HOSC 
interface;. Development of tiie Ground based Expert System for 
Space Telescope ((jESST) to Bupport HST nominal operations will 
also require some access to the HOSC, which will be provided by 
MSEC . 



167 



ORiGir^AL PASS m 
OF POOR QJJALilY 



UJ 

< 
ffi 

LU 

o 

Q 
LU 

-I 

o 
z 
^ 

u 

z 

E 

Oiu 
UJ 

LU z 
HO 

LU UJ 
CC z 

O UJ 
„_ Q 

UJ 
Q. 

O 
o 

UJ 



UI g 

s < 

U) O 

UI V) 



O 0) 
UI O 



(0 

UJ a: 

UJ 

-9 

OQ 
O 



u 

c 
< 

e S 

n 

a s 

gS 
=: o 

o" 

IE UI 

a. in 
pi 




c 
o 

3 



«1 
Q 
O 



UI 

a 

UI 
(0 
UI 



>• 

Q 
* 
Ui 

b: u. 
UI 5 



< D 

Q. « 

O (A 

ui b 

> UI 

UI -> 

D O 





-1 




u> 


S> 






o 

o ^ 


S 








o 


O 8 










§ S 











s 
o 



3 
U. 

a 



UJ 



Q 
UJ 

X 

o 



S 



ID 








7 








^ 


o 


UI 




< 
O 

UI 


z 


O 






s 

CD 


-J 
> 

UI 


Ul 


UJ 

_i 
< 


a 
m 

a 


F 

UJ 
Q. 


z 


Ul 


UJ 


X 


^ 


O 

DC 


S 


UJ 


g 


5 


1- 


z 



■o — 














ci 




ONS 

DRY 
NTER 


(fi 

UJ 

F 

-1 
o 




o 

u. 

CO 






u' 

CO (- 




WORKSTAT 
ORATORY 
/IS LABORAT( 
EARNING CE 


< 

u. 
a 

< 

tn 

\- 
z 
< 
a. 

o 

F 


12 


z 

1- 
I 
a 

_i 

u. 

IXI 
CO 

< 

CO 


o 

I 

CC 

\^ 

z 

Lit 

o 

I 

CO 

m 

CC 
CO 


1- 

Q 

UJ 
UI 

I 

£ 

1- 
CO 

Q 
2 

• 


DC Z 

Z rf- 
Q < 

OC m 
z < 

< LL 

= CO 
S DC 




C ARTIFICIAL INTELLIGENCE 
INTELLIGENT SYSTEMS LAB 

^JFORD KNOWLEDGE SYSTEN 
ARTIFICIAL INTELLIGENCE L 


< 

Q. 


5 

o 


oc 

• 


< 

• 


• 


3 


4; U < i 
CO CC H < 

5 < CO r) 

• • • • 




CC 

















"t 










"<t 






Cl. 










u. 





168 



IW>SA 

Natonal Aefonautcs and 
Scace AdTTunistfation 



Report Documentation Page 



1. Report No. 

NASATM-100999 



2. Government Accession No. 



4. Title and Subtitle 

Systems Autonomy Technology: Executive Summary and Program Plan 



7. Author(s) 



Ames Research Center with contributions from Goddard Space Flight Center, 
Jet Propulsion Laboratory, Johnson Space Center, Kennedy Space Center, 
Langley Research Center, Lewis Research Center, and Marshall Space 
Flight Center 



9. Performing Organization Name and Address 
Ames Research Center 
Moffett Field, CA 94035 



12. Sponsoring Agency Name and Address 

National Aeronautics and Space Administration 
Washington. DC 20546-0001 



3. Recipient's Catalog No. 



5. Report Date 
December 1987 



6. Performing Organization Code 



8. Performing Organization Report No. 
A-88174 



10. Work Unit No. 
549-03 



1 1 . Contract or Grant No. 



13. Type of Report and Period Covered 

Technical Memorandum 



14. Sponsoring Agency Code 



15. Supplementary Notes 



Point of Contact: John S. Bull, Ames Research Center, MS 244-7, Moffett Field. CA 94035 
(415) 694-5699 or FTS 464-5699 



^ "^tHe National Space Strategy approved by the President and Congress in 1984 sets for NASA a major goal of con- 
ducting effective and productive space applications and technology programs which contribute materially toward United 
States leadership and security. To contribute to this goal, OAST supports the Nation's civil and defense space programs 
and overall economic growth. OAST objectives are to ensure timely provision of new concepts and advanced technolo- 
gies, to support both the development of NASA missions in space and the space activities of industry and other 
organizations, to utilize the strengths of universities in conducting the NASA space research and technology program, and 
to maintain the NASA centers in positions of strength in critical space technology areas. 

In line with these objectives, NASA has established a new program in space automation and robotics that will result 
in the development and transfer of automation technology to increase the capabilities, productivity, and safety of NASA 
space programs including the Space Station, automated space platforms, lunar bases, Mars missions, and other deep space 
ventures. 

The NASA/OAST AutomaUon and Robotics program is divided into two parts. Ames Research Center has the lead 
role in developing and demonstrating System Autonomy capabilities for space systems that need to make their own deci- 
sions and do their own planning. The Jet Propulsion Laboratory has the lead role for Telerobotics (that portion of the 
program that has a strong human operator component in the control loop and some remote handling requirement in 
space). 

This Program Plan is intended to be a working document for NASA Headquarters, Program Offices, and implement- 
ing Project Management. It should be reviewed and updated at least once every year. The Program Plan includes contri- 
butions from all participating NASA Centers. ^ 



17. Key Words (Suggested by Author(s)) 

Automation, Artificial intelligence, Knowledge-based 
systems, Planning and reasoning. Expert systems. 
Machine learning. Knowledge acquisition, Causal 
modeling, Heuristic rules 



18. Distribution Statement 



Unclassified-Unlimited 



Subject Category - 59 



19. Security Classif. (of this report) 

Unclassified 



20. Security Classif. (of tfiis page) 
Unclassified 



21 . No. of pages 
170 



22. Price 



A08 



NASA FORM 1626 OCT 86 



For sale by tlie National Technical Inforination Service, Springfield, Virginia 22161 



