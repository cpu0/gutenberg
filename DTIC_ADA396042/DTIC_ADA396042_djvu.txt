WP FH 8807 


Working Paper 


MANPRINT FINDINGS FROM THE INVESTIGATIVE OPERATIONAL 
ASSESSMENT OF THE JOINT TACTICAL 
INFORMATION DISTRIBUTION SYSTEM 
(Contract MDA903-83-C-0033) 


Reproduced From 

Larry Avery Best Available Copy 

William J. Pieper 
Essex Corporation 


Fort Hood Field Unit 


DISTRIBUTION STATEMENT A 
Approved for Public Release 
Distribution Unlimited 


March 1988 


U.S. Army Research Institute 

for the Behavioral and Social Sciences 

5001 Eisenhower Avenue, Alexandria VA 22333 


' i in mu 1 1 i l l ii iir Yu i iH 

This working paper is an unofficial document intended for limited distribution to obtain comments. The 
views, opinions, and/or findings contained in this document are those of the author(s) and should not be 
construed as the official position of ARI or as an official Department of the Army position, policy, or 
decision, unless so designated by other official documentation. 




20011018 081 





CONTENTS 


page 


Section 1. Introduction . i 

Systera Description .. i 

Test Planning .. 2 


Section 2. Issues and Criteria . . . . 
Issue I: Personnel and Training 
Issue 2: Huiaan Factors Engineering 
Issue 3: Safety .... . 


U 

6 

9 


Section 3. Instruments and Procedures 
General . . » a , , , . , . , . , 
Data Collection Procedures . . . 
Training Assessment . . , . 
Multiservice Testing , . . . 
Side Tests ,., , . 


10 

10 

10 

12 


Section 4. Analysis and Results . . \ . . . 
Personnel and Training ........ 

Operators . . . . ....... , 

Maintainers . . » . . . . . . , . 

Net Managers ........... 

HFE for Operation and Maintenance . . . 

Terminal Deployment « . « . . . « 

Initialization .......... 

Operation ............ 

Hardware Design .... . 

Software Design « . « . . 

System Interface Design . . . . . 

Maintenance ... . 

Network Planning ......... 

Safety Design .. . . . . 


15 

IS 

20 

20 


21 

24 

27 

27 

27 

29 

30 


Section 5. Summary . . . . . . . . . « . . , . . . . . , , , . , » , . .30 

Introduction ....,32 

Conclusions ..... . . 32 

IDA Issue 1 ..32 

IGA Issue 2 .............. . ...... .33 

I0A Issue 3 ... .... « ...... 34 


AF'PuNuI X A Data Collection 'forms . « 
Demographic Questionnaire . . , . 
Oper at or/Maintsiner Questionnaire 
I CP Initialization Check List . . 
Task Performance Error Report . . 


Safety Incident Report 




■y 

■J* 7 


51 
59 
6 1 






L 











































Cable 


Figure i 


Li 5 1 of iablee 

1. JTIDS Operator Demographic Data 

2. JTIDS Operator Demographic Summary . 

3. Operator Training Outcomes . 

.4. JTIDS Maintainer Demographic Data 

5. JTIDS Maintainer Demographic Summary 

6. Maintainer Training Outcomes . , . . 

7. JTiDS Manual Initialisation Times 

JTIDS S250 Configuration . 














JTIDS INVESTIGATIVE OPERATIONAL ASSESSMENT 
MANPRINT REPORT 

Contract No. MDA 903-83-C-0033 


U.S. 


Prepared For 

Army Research Institute for the Behavioral 
Fort Hood Field Unit 


HQ, TCATA 
ATTN: PERI-SH 
Fort Hood, Texas 76544 


Sciences 


Prepared By 

William J. Pieper 
HF Consultant 

and 

Larry W. Avery 
Essex Corporation 
333 North Fairfax Street 
Alexandria, Va. 22314 


15 September 1987 


TABLE OF CONTENTS 


SECTION I INTRODCUTION . 

System Description . 

Test Planning . 

SECTION II ISSUES AND CRITERIA . . 
Issue 1: Personnel and Training 
Issue 2: Human Factors Engineering 
Issue 3: Safety . 


SECTION III INSTRUMENTS AND PROCEDURES 

General . 

Data Collection Procedures . . . . 

Training Assessment . 

Multiservice Testing . 

Side Tests . 


SECTION IV ANALYSIS AND RESULTS . 
Personnel and Training .... 

Operators . 

Maintainers . 

Net Managers . 

HFE for Operation and Maintenance 

Terminal Deployment . 

Initialization . 

Operation . 

Hardware Design . 

Software Design . 

System Interface Design . . . 

Maintenance . 

Network Planning . 

Safety Design . 


15 

15 

15 

18 

20 

20 

20 

21 

24 

25 
27 
27 
27 

29 

30 


SECTION V SUMMARY . 
Introduction 
Conclusions . . 

IOA Issue 1 
IOA Issue 2 
IOA Issue 3 


30 

32 

32 

32 

33 

34 


ii 






































APPENDICES 


APPENDIX A - DATA COLLECTION FORMS .35 

Demograph Questionaire . 36 

Operator/Maintainer Questionaire . 39 

ICP Initialization Check List.51 

Task Performance Error Report . 59 

Safety Incident Report . 61 

LIST OF FIGURES 

Figure 1. JTIDS S250 Configuration . 3 


iii 










SECTION I 
INTRODUCTION 

System Description 

The Joint Tactical Information Display System (JTIDS) is a 
multiservice acquisition program being led by the US Air Force. JTIDS 
is designed to provide secure transmission of position, target track, 
and voice data between host terminals in a manner that is transparent 
to the user. The user or host terminal is any system which orignates 
or receives digitized tactical information transmitted over the JTIDS 
secure radio links. The system was originially designed to provide 
communication between F—15 and Advance Warning and Control System 
(AWACS) aircraft and Combat Reporting Centers (CRC). The US Army 
recognized the potential for improved communication between Air Force 
and Army Air Defense Artillary (ADA) units, and within ADA units, and 
became part of the program well into the development process. The Army 
host terminals were to be TSQ-73s at the brigade and battalion levels 
for the HAWK fire units, the Platoon Command Post (PCP) at the 
batteries, and the PATRIOT missile system. 

There are a number of different configurations of JTIDS, designated 
classes. The Class 1 terminal is currently used in the Air Force CRCs 
and the AWACS; it is also being fielded to some of the ADA Brigade 
level units. The current system under test is the Class 2 Terminal, 
composed of several equipments housed in an S250 Shelter. This was to 
be fielded at all levels for certain of the ADA units. The current 
objective system for the Army is the Class 2M, which will be a single 
hardware component that will be integrated into the host terminal's 
(e.g., TSQ-73, PCP, and PATRIOT) shelter. 

The Army Class 2 Terminal equipment, housed in the S250 shelter, 
consists of the following major units: 

a. Indicator Control (IC) - The IC is the control and display 
panel for JTIDS. It is used for data input, data output, and fault 
isolation. 

b. Radio Receiver-Transmitter (RT) - The RT provides the 
transmission and reception of data between the various JTIDS 
terminals. 

c. Digital Data Group Processor (DDGP) - The DDGP is composed of 
the Digital Data Processor (DDP) and the Interface Unit (IU). The 
IU is used for encoding/decoding data messages, while the DDP is 
used for Built in Tests (BIT), signal conditioning, and interface 
between the host and the other JTIDS equipments. 

d. Host Interface Unit (HIU) - The HIU provides the interface 
between the host system (e.g., TSQ-73 etc.) and the JTIDS system. 


1 





This interface consists of translation of the host data 
communications protocol to the JTIDS data communications protocol, 
and vice versa. 

e. Keyer Control Panel (KCP) - The KCP provides the capability for 
entering crypto variables. 

The JTIDS S250 shelter is deployed near the host terminal. Figure 
1. JTIDS S250 Configuration, illustrates the layout of the equipment. 
The two systems are interconnected via cable connection panels on the 
exterior of each shelter. Connections are made for voice communication 
between the JTIDS and host system operators to facilitate normal 
operation and troubleshooting/maintenance activities. In addition, 
host system to JTIDS and JTIDS to host system data cable connections 
are made to provide host to host communication over the JTIDS radio 
links. 


Test Planning 

Originally, the JTIDS test and evaluation was to be a full scale 
Independent Operational Test and Evaluation (IOT&E), executed jointly 
with the Air Force. The test site was to be Eglin Air Force Base, 
Florida and was to include the 11th ADA Brigade, with the 165th 
Battalion and two HAWK fire platoons. This was to include two (2) 
TSQ-73S and two (2) HAWK PCPs. 


During Army developmental testing, a number of problems were 
discovered in the Class 2 Terminal. The nature and significance of 
these problems led the Army Program Manager's Office and the TRADOC 
System Manager to not certify the terminal for transition to 
operational test. Given that the Class 2 was not the objective system, 
the main reason for army operational testing became moot. 


Since the multiservice testing between the Air Force and the Army 
was particularly important for the Air Force, the Army decided to 
support the Air Force to the minimal extent possible. This included 
the use of only a single TSQ-73 and a single HAWK PCP, with four relays 
and minimal manning by the 11th ADA. The Army's portion of the test 
was downgraded to an Investigative Operational Assessment (IOA), 
lasting eight weeks. 


The intent of this IOA was to e 
terminals stayed operational during the 
every means at hand including maintenance 
collection was to be minimal, with 1 
trials and limited system operating time, 
used to provide insights into the adequacy 
Terminal from the Army's perspective, and 
design of the Class 2M Terminal. One 
during the IOA was MANPRINT. The IOA took 
and April 1987. This report documents 
MANPRINT. 


nsure that the Army Class 2 
multiservice trials, using 
personnel drawn from DT. Data 
ow reliability due to the few 
The data collected was to be 
of the design of the Class 2 
to provide input into the 
of the areas being explored 
place between February 1987 
the results of that IOA for 


2 







Tpst. Ohiectives The objectives of this IOA for MANPRINT were to 
provide, to the degree possible, insights on how well the JTIDS Class 2 
Terminal met the requirements of the MANPRINT program. The specific 
domains of MANPRINT that were assessed during the IOA included 
personnel, training, human factors engineering .^FE), and system 
safety. Manpower could not be assessed given the limited 11th ADA unit 
resources available for the IOA, and health hazards had been assessed 
by developmental testing. 


Test Limitations Given the downscaling of the original USAOTEA test 
plans to an IOA and the manner in which the test was conducted, data 
collection and analysis were limited as discussed below. 


The size of the player pool was 
for net managers, and n = 2 for 
validity, increasing the risk of a 
characteristics, and limiting the 
population as a whole. 

The small number of trials 
statistical reliabilty of the data, 


small (n = 8 for operator, n = 2 
maintainers), lowering statistical 
nonstratified sample of personnel 
generalizability of the data to the 

that were conducted lowered the 
leading to unknown validity. 


The maintenance objective of the IOA was to ensure that the 
terminals stayed operational during the multiservice trials. This was 
achieved using whatever means were at hand. This practice introduced 
uncontrollable confounds into the maintainability data and interfered 
with the collection of the human factors data. 


4 



SECTION II 
ISSUES AND CRITERIA 


There were only three basic issues for this IOA. Each is described 
below, along with the criteria and how they were measured. 

Issue 1 

The JTIDS Class 2 Terminal shall be designed to insure that 
personnel representing the full range of capabilities of the designated 
MOSs for operators and maintainers have the necessary skills and 
aptitudes to be trained to perform their required critical tasks to the 
expected level of proficiency in a field environment. 

This issue combined the MANPRINT domains of personnel and training 
due to their close interrelationship. The complexity of a system's 
operation or maintenance should not exceed the capabilities of the 
personnel in the designated operator and maintainer MOSs to perform the 
expected tasks or to be trained to perform these tasks. 

C r i teriQ n i 

Initialization, reinitialization, and other operational procedures 
shall be simple enough to ensure that personnel of the expected MOS 
levels and mental capabilities can learn, retain, and perform them 
given standard Army training methods. 

The measurement methods were as follows: 

a. Demographic data to include duty MOS, time in duty MOS, years 
in service, years of civilian education, and years of experience in 
communications, electronics, and computers. The demographic data 
was collected using a pre-training questionaire, presented in 
Appendix A. 

b. Observations by the human factors engineers and test 
directorate personnel. 

1) Personnel/training problems observed or identified 

2) Corrective actions recommended 

c. Comments from operators, maintainers, data collectors, and test 
directorate personnel elicited during interviews. 

1) Personnel/training problems observed or identified 

2) Corrective actions recommended 

d. MANPRINT training assessment 

1) Adequacy of training materials 


5 



2) Adequacy of manuals 

3) Posttraining proficiency scores and ratings 

e. Performance times and errors for initialization measured while 
the operators were wearing normal clothing, cold weather gloves, 
and MOPP IV gear. The measurement instrument was the 
initialization test presented in Appendix B. 


Issue _ Z 

Does JTIDS Class 2 terminal incorporate human factors design 
principles for ease in operation and maintenance? This issue reflects 
the HFE concerns of MANPRINT. The following critieria were used to 
determine satisfaction of the issue. 

c. riteriQn 1 

The properly trained operator or maintainer must be able to: 

a. Initialize the JTIDS Class 2 terminal and any associated host 
interface with its required long-term data within 2 hours without 
error. 


b. Place into operation or change initialization variables of a 
completely installed terminal and associated host interface, that has 
been previously loaded with its long-term data, in less than 3 minutes. 
This includes loading of required crypto variables. 

The measurement methods were as follows: 

a. Performance times and errors measured while the operators were 
wearing normal clothing. These measures were taken when the 
operators were performing regular operational procedures. 

1) HFE problems observed or identified 

2) Corrective actions recommended 

b. Observations and comments from the human factors engineer, data 
collector, player, and test directorate personnel. 

1) HFE problems observed or identified 

2) Corrective actions recommended 
Criterion 2 

The JTIDS Class 2 terminal hardware and software shall be designed 
to facilitate operator task performance'. 



The measurement methods were as follows: 

a. Observations from the human factors engineer, test directorate, 
and data collectors. 

1) Adequacy of controls and labeling (size, shape, location, 
appropriateness, etc.) 

2) Adequacy of displays (luminance contrast, location, 
brightness, character design, etc.) 

3) Adequacy of software (data display, interactive control, 
system response time, feedback, use of prompts, etc.) 

4) Adequacy of workspace (dimensions, lighting, noise, 
accessability, etc.) 

5) Adequacy of operational procedures (complexity, logicalness 
of steps, number of keystrokes, etc.) 

b. Comments from operators, maintainers, and data collectors 
obtained during interviews. 

1) Adequacy of controls and labeling (size, shape, location, 
appropriateness, etc.) 

2) Adequacy of displays (luminance contrast, location, 
brightness, character design, etc.) 

3) Adequacy of software (data display, interactive control, 
system response time, feedback, use of prompts, etc.) 

4) Adequacy of workspace (dimensions, lighting, noise, 
accessability, etc.) 

5) Adequacy of operational procedures (complexity, logicalness 
of steps, number of keystrokes, etc.) 


Criterion _3 

The net planner shall be able to perform the necessary planning and 
to develop the initialization sequences for those nets for which he is 
responsible without error and within four (4) hours ninety-eight per 
cent (98%) of the time. 

The measurement methods were as follows: 

a. Time and errors measured during the development of network 

plans. 


7 


1) Time and date 

2) Elapsed time 


3) Number of errors 

b. Observations from the human factors engineer and test 
directorate personnel. 

1) HFE problems observed or identified 

2) Corrective actions recommended 

c. Comments from net planning and test directorate personnel 
elicited during interviews. 

1) HFE problems observed or identified 

2) Corrective actions recommended 


Criterion 4 

The system shall be designed so that personnel of the expected MOS 
levels at Operational Support, Direct Support, and General Support 
maintenance activities can easily perform necessary maintenance tasks. 
The JTIDS class 2 terminals shall be repairable within 0.25 manhours 
seventy five percent (7556) of the time. 

The measurement methods were as follows: 

a. Observations by the human factors engineer regarding the 
maintainability of the JTIDS Class 2 terminal. 

1) HFE problems observed or identified 

2) Corrective actions recommended 

b. Comments and data from the RAM data base regarding the causes 
of system failure, the length of time the system was unavailable, 
and the causes for the length of time unavailable for those 
incidents attributable to human error. 

1) Maintainer name and SSN for each maintenace action. 

2) Terminal ID number 

3) Incident descriptions 

4) Manhours required to repair each incident 


I 

i 


8 





5) Total number of incidents requiring repair 

6) Percentage of incidents repaired within 0.25 
manhours 

c. Observations and comments from operators, maintainers, data 
collectors, and test directorate personnel elicited during 
interviews. 

1) HFE problems observed or identified 

2) Corrective actions recommended 


Issue 3 

Is the JTIDS Class 2 terminal designed to be operated and 
maintained without risk of personnel injury? This issue reflects the 
MANRPINT domain of safety. 

Criterion 1 

The soldier must be able to operate, maintain, and deploy the JTIDS 
Class 2 terminal without danger of personal injury. 

The measurement methods were as follows: 

a. Observations from the human factors engineers regarding safety. 

b. Comments from the operators, maintainers, test directorate, and 
data collectors elicited during interviews. 

1) Safety problems 

2) Corrective actions recommended 

c. Reported incidents of injury due to electric shock, sharp 
edges, or other physical trauma. 



SECTION III 

INSTRUMENTS AND PROCEDURES 


General 

Data for MANPRINT was collected using three basic techniques: 

a. Observation 

b. Interview/questionnaire 

c. Performance data collection 

Observation 

Observation consisted of experienced HFE personnel watching the 
operator/maintainer during the performance of typical tasks. If any 
difficulties in task performance were observed, the HFE personnel 
elicited information through the collection of comment data. Comment 
data was collected by immediate or delayed informal unstruc- tured 
interviews. 

Interview/questionnaire 

These consisted of formal structured interviews or questionnaires 
administered to player, data collector, and test directorate personnel 
in a controlled setting. The items dealt with the operability and 
maintainability of the system, and with MANPRINT issues such as 
training, manpower, and personnel. 

Performance Data 

Performance data collection consisted of collecting objective data 
on how well a task or tasks were performed. For this data the main 
types of performance measures were time to perform and errors during 
performance. 


Data Collection Procedures, 

Data collection for the JTIDS IOA was performed in three phases: 

a. Training assessment 

b. Multiservice testing 

c. Side tests 

The multiservice testing and side tests were concurrent. 

Training Assessment. 

The training for the IOA consisted of two distinct types. The 
first was operator and maintainer training and the second was net 
manager training. Operator and maintainer training was conducted from 
2 February 1987 to 20 February 1987. Net Manager training was 


10 




conducted from 26 January 1987 to 13 February 1987. Both were 
conducted at Fort Bliss, Texas. 

Operator and Maintainer Training Assessment. This assessment used 
four types of measurements: 


a. Pre-training questionnaire - All personnel selected for player 
training were given a pre-training questionnaire to collect 
demographic data on the operators and maintainers. In addition, 
AFQT and AREA Aptitude (AA) scores were collected for each of the 
player personnel. 


b. Post-training test - A post-training test was given at the 
conclusion of the formal JTIDS training. The post-test consisted 
of 45 multiple choice questions and took approximately 45 minutes 
to administer. This test assessed operations and maintenance 
tasks, and the trainees understanding of the concepts underlying 
the operation and maintenance of the JTIDS Class 2 Terminal. 

c. Performance observation - In addition to the formal tests, HFE 
personnel observed the player personnel during the multiservice 
testing. The emphasis of the observations was to identify any 
player performance difficulties that were attributable to training 
shortfalls. 


d. Technical manual evaluations - The technical manuals were 
reviewed to assess their readability and format for information 
transfer. The reading level of each of the technical manuals was 
also assessed to ensure that they did not exceed the capability of 
the users to comprehend the written material. This assessment was 
performed using a personal computer program called RIGHTWRITER. 
Several representative pages of each manual were typed into the 
program to determine the overall reading level. 


Net Manager Training Assessment. Training for NET Managers was 
multi-faceted. The management process involves identifying the 
participants and their information transmission requirements. From 
this, a set of information transmission blocks is allocated and each 
user is assigned a set of transmission time slots. The communications 
security needs are determined and parameters for the network are 
developed. Finally, various master parameters are determined along 
with the equipment initialization parameters. This whole process makes 
up the job of the Network Manager who developes a network plan. 

There is almost never a single/unique correct network plan for a 
set of network participants. Different personnel can develop plans 
that are different and yet each will satisfy the operational network 
communications requirements. To assess the adequacy of training for 
the net managers, a part-task approach was used. The segments of the 
assessment instrument were as follows: 


11 




a. 

b. 


c. 


d. 


e. 


Participants list 
Multi-Net Connectivity Worksheet 
Single & Multi-Net Time Slot Map 
COMSEC Parameter Checklist 
Network Parameter Checklist 


f. ASIT Master Parameters 

g. HIU Master Parameters 

h. Class 1 Initialization Worksheets 

i. Army Working Parameters 

j. Time Slot Initialization Parameters 

At the end of training, the graduates were tested on all tasks 
except the two tasks establishing the initialization input data (i.e., 
h and j above). They worked each segment in sequence and each was 
reviewed for completeness and use of the forms. Total performace time 
was recorded. 


Multiservice Testing 

The JTIDS Class 2 Terminal multiservice testing consisted of the 
Army ADA units of one Master Battalion (MBOC) and one HAWK Fire Platoon 
creating a missile engagement zone (MEZ) for supporting simulated Air 
Force air-air combat missions. In addition, the Army elements provided 
simulated base defense missions before and after the multiservice 
missions. The principal effort was to support the Air Force 
operational test while collecting as much Army specific data as 
possible in the process. The data collection procedures used during 
this test phase are described below: 

Observation Data. Observation data was collected throughout the 
multiservice testing. HFE personnel observed Army JTIDS player 
personnel during the trials to identify any human performance problems 
that existed. Observations focused on those trials with the most 
potential for human performance problems. Observations and comment 
data were compiled in notebooks continuously during the testing. These 
records described the nature of each problem, the trial in which it was 
observed, any comments from the player personnel regarding the problem, 
and observed effects on human and system performance. 

Performance Data. Performance data in the form of time and errors 
were collected during the following operations, to the extent possible: 


12 



a. Initialization of JTIDS and host terminals 

b. Place into operation or update initialization variables, 
on a completely installed terminal 

c. Fault diagnosis and repair 

d. JGRAM message handling (JGRAM messages were not routinely 
used, so no data was available) 

Manual initialization was also explored in a side test discussed below. 
RAM data forms were reviewed to determine the time required for the 
performance of maintenance tasks. 

Interview Data. Structured interviews were administered to players 
and unstructured interviews were administered to test directorate, data 
collector, and HAWK personnel at the end of multiservice testing. These 
interviews elicited opinions regarding the operability and 
maintainability of the JTIDS Class 2 Terminal. The items included in 
the interview addressed potential HFE and safety problems identified 
during the pilot and multiservice testing. 

Safety Data. Safety data consisted of HF engineer identified 
potential safety hazards. There were no safety incidents during the 
testing period. Other data consisted of informal interview opinions 
from player personnel. 


Sjd e ,-T. ests 

During the multiservice testing, two Army specific side-tests were 
accomplished, manual initialization and network planning. 

Manual Initialization. During periods when multiservice testing was 
not being conducted, data was collected on manual initial- ization of 
the terminals. Operators were given pre-prepared initial- ization 
sequences to enter into the terminal. The HFE personnel observed the 
operators, using the Manual Initialization checklist, and made notes of 
any errors committed. Performance times were collected. Data was 
collected on all operators wearing normal uniforms, cold weather 
gloves, and NBC gloves and mask. 

Net Management Planning. The objective of this side test was to 
assess network planning through generation of initialization sequences 
under field conditions in a multiservice environment using Army and Air 
Force net managers. During the multiservice testing, there were only 
two Army and two Air Force trained net managers. These net managers 
developed network plans and initialization sequences based on 
information provided to them by the test controllers. 

During the test, HFE personnel observed the net managers performing 
their tasks and made notes of any performance difficulties. The net 


13 


managers were interviewed at the conclusion of the exercise to elicit 
their comments and to explore the noted performance problems. 
Performance time data was collected and the network plans were 
submitted to MITRE Corporation for adequacy scoring. It was not 
possible to use the planned network initialization data during 
multiservice testing. 


14 



SECTION IV 

ANALYSIS AND RESULTS 
Personnel and Training (IOA Issue 1.) 


Operators 

Operator Demographics. There were eight JTIDS Operators involved 
in the IOA. The characteristics of each operator are presented in 
Table 1. JTIDS Operator Demographic Data. The operators ranged in age 

TABLE 1. JTIDS Operator Demographic Data 

OPERATORS 


CHARACTERISTIC 

1 

2 

3 

4 

5 

6 

7 

8 


Height(in) 

71 

69 

64 

75 

70 

76 

70 

68 


Weight(lbs) 

198 

155 

135 

240 

175 

195 

172 

140 


Age(yrs) 24.5 

20.3 

38.0 

25.5 

30.0 

21.2 

27.5 

20.5 


Grade/Rank 

E4 

E4 

E6 

E5 

E4 

E4 

E5 

E4 


Months Service 

27 

29 

120 

77 

52 

30 

114 

30 


MOS 

16E 

16E 

25L 

25L 

3 IK 

3 IK 

31K 

3 IK 


Months in MOS 

27 

29 

84 

5 

52 

30 

114 

30 


Weeks in JTIDS 

2 

2 

0 

0 

0 

1 

2 

0 


Civ Educ.(yrs) 

12 

12 

16 

12 

12 

12 

12 

12 


AFQT Score 

68 

64 

92 

43 

66 

30 

18 

39 


%ile of MOS(AFQT) 

72 

66 

94 

26 

61 

11 

4 

19 


GT Score 

120 

109 

125 

109 

109 

84 

96 

94 


%ile of MOS(GT) 

85 

62 

89 

51 

79 

18 

47 

41 


from 21 to 38 years, 

held 

the 

rank ' 

of E4 through 

E6 , 

and 

were 

from 

three different MOS 

groups. 

All 

but one 

had 

been in 

their MOS 

more 

than two years. A summary 

of 1 

these 

characteris- 

tics is 

presented 

in 

Table 2. JTIDS Operator Demographic 

Summary 

. Their average 

AFQT score 


TABLE 2. JTIDS Operator Demographic Summary 


CHARACTERISTIC 

MEAN 

sd 

Height(in) 

70.4 

3.57 

Weight(lbs) 

176.3 

32.36 

Age(yrs) 

25.9 

5.60 

Grade/Rank 

E4 

NA 

Service Time(mo) 

59.9 

36.60 

Time in MOS(mo) 

46.4 

33.44 

Time - JTIDS(wks) 

0.9 

0.93 

Civ Educ.(yrs) 

12.5 

1.32 

AFQT Score 

52.5 

22.59 

%ile of MOS(AFQT) 

44.1 

NA 

GT Score 

105.8 

12.80 

5Jile of MOS(GT) 

59.0 

NA 


15 



was 52.5, slightly below the 50 $ile for their respective MOS groups 
and their average GT score was 105.8, slightly above the 50 %ile for 
their MOS groups. This was probably as good a sample of expected JTIDS 
operators as could be obtained for test purposes without a great deal 
of added effort in their selection. 

Operator Training. Operator training consisted of 80 hours of 
training at Fort Bliss, TX. The training consisted of instruction and 
practice in the operation of the JTIDS equipment as installed in the 
S250 truck mounted shelters used during the IOA. The course was that 
prescribed by TRADOC and was taught by instructors from Fort Gordon, 
GA. All trainees passed all course tests and completed the prescribed 
hands-on exercises during the training. 

At the completion of training, all operators were given a written 
multiple choice test on the nature and operation of the JTIDS. In 
addition, the instructors as a group were asked to rank order the 
students as to their expected capabilities to perform the JTIDS 
operator tasks. The results of the instructor ratings and the written 
test are presented in Table 3. Operator Training Outcomes. The table 


Table 3. Operator Training Outcomes 


OPERATOR 

PRIMARY 

AFQT 

%ile of 

POSTTRNG 

TRAINER 


MOS 

SCORE 

MOS 

SCORE 
(* RIGHT) 

RATING 

1 

16E 

68 

72 

51 

4 

2 

16E 

64 

66 

64 

2 

3 

25L 

92 

94 

53 

7 

4 

25L 

43 

26 

51 

8 

5 

3 IK 

66 

61 

69 

6 

6 

31K 

30 

11 

51 

3 

7 

31K 

18 

4 

58 

5 

8 

3 IK 

39 

19 

51 

1 


suggests that the individuals used in the assessment were not atypical 
of soldiers since the range of AFQT scores was from 18 to 94 and 
included 30s, 40s, and 60s. No MOS group had any consistent advantage 
in terms of the Post Training Test or the Trainer Ratings. There was no 
clear advantage to one or the other of the represented MOSs during 
operator training. Therefore, based on the IOA training experience, 
the three MOS groups (16E, 25L, or 31K) seem to be adequate for the 
JTIDS Operator position. 

One problem with the training was course content omissions because 
of the limited time for administration. Since the maintenance concept 
required the operators to be the direct support maintenance personnel, 
omissions in course content covering the localization of faults that 
caused failures in communication between the Master Battalion(MBN) and 
the Assault Fire Platoon(AFP) were a problem. The faults were in the 


16 


interface between the JTIDS and the host computers and over the radio 
links between the JTIDS terminals. Each piece of JTIDS terminal 
equipment could be working properly and the communica- tion would still 
not be accomplished. The operator training did not include tasks for 
fault isolation beyound the JTIDS shelter. The fault isolation tasks 
involved in locating a problem in a network interfacing computers over 
radio links are not exhausted by checking the terminal equipment 
without getting any information about the interface. The operators 
were not trained in tasks for troubleshooting interface problems. 

The course content for interface troubleshooting would not be 
concerned with any single piece of JTIDS equipment; however, it would 
still involve some of the principal operator job skills. This area of 
problems points out a major oversight in the concept of New Equipment 
Training (NET), that is, NET is equipment oriented instead of job task 
oriented. It is possible to do a very good job of teaching the new 
equipment and have the trainee come away with almost no ability to do 
the job tasks, because they are not equipment specific. 

It seems apparent that two weeks training is insufficient for the 
JTIDS operator to reach competency without extended field experience. 
Training host operators to be JTIDS operators was not addressed in the 
IOA and may in fact provide some saving in training time due to 
experience with the host system, something the JTIDS IOA operators did 
not have; even though they were ADA personnel, they were not host 
operators. 

In general, the training materials were adequate in terms of 
usability and clarity, based on the trainees comments. The principal 
problem mentioned by the trainees was the availability of equipment for 
job task practice. 

Class size/Equipment availability. The class in which the eight 
operators and two GS maintainers were trained, consisted of 22 
students. The class had five JTIDS shelters available for use, with 
one shelter non-functional because of equipment problems. Since the 
students could only work in the shelters in pairs, some were working 
while others were waiting. In addition, when pressed for time only one 
of the students got to perform a specific task while the other observed 
or read the procedure from the manual. This approach familiarizes the 
students with the tasks but does not produce graduates with great 
competency in job skills. 

Recommended Solutio n. Class size should be reduced in order to 
provide adequate time on the equipment for each student to develop 
competency in the necessary job skills. If class size cannot be 
economically reduced, then staggered entry of one day could be used for 
half the class. This would require that two instructors be used for 
each class so that half the class could be in the classroom while the 
other half could be in the shelters. The class halves would rotate 
each day, providing one day in the shelters and the next in the 


17 



classroom. In either case, the number of students in a class section 
should be no more than two times the number of shelters available for 
task practice. 

Maintainers 

Maintainer Demographics. There were two maintainers used during 
the JTIDS IOA. The characteristics of each maintainer are presented in 
Table 4. JTIDS Maintainer Demographic Data. One of the maintainers was 


TABLE 4. JTIDS Maintainer Demographic Data 


MAINTAINERS 


a 35L and the 
completed high i 
presented in Table 5. JTIDS 
average AFQT score was 57.5 and 


CHARACTERISTIC 

1 

2 

Height(inches) 

71 

71 

Weight(lbs) 

155 

147 

Age(yrs) 

24.2 

19.8 

Grade/Rank 

E4 

E4 

Service Time(months) 

66 

18 

MOS 

35L 

33P 

Time in MOS(months) 

66 

5 

Time with JTIDS(wks) 

28 

60 

Civ Education(years) 

14 

12 

Stile of MOS (AFQT) 

16 

59 

GT Score 

86 

117 

Stile of MOS(GT) 

7 

46 

.her was a 33P; however, 

both 

tool. The summary 

of 

their 


characteristics is 
Maintainer Demographic Summary. Their 
their average GT score was 101.5. 


TABLE 5. JTIDS Maintainer Demographic Summary 


CHARACTERISTIC 

MEAN 

Height(inches) 

71.0 

Weight(lbs) 

151.0 

Age(yrs) 

22.0 

Grade/Rank 

0.0 

Service Time(months) 

42.0 

Time in MOS(months) 

35.5 

Time with JTIDS(wks) 

44.0 

Civ Education(years) 

13.0 

AFQT Score 

57.5 

GT Score 

101 .5 

Stile of MOS(GT) 

26.5 


18 




Although neither their AFQT or GT scores was high in the $ile ranking 
for their respective MOSs, both seemed competent during training and on 
the job. 


Maintainer Trainin g. The maintainers received 120 hours of 
instruction on the JTIDS. The first 80 hours was the same as the 
operator training, 40 hours additional training was given after the 
conclusion of the operator course. The additional instruction 
emphasized chassis and card removal and replacement, as well as, 
troubleshooting. At the conclusion of the maintainer training, the 
post-training test was given to the maintainers. The outcomes are 
presented in Table 6. Maintainer Training Outcomes. Although the 


Table 6. Maintainer Training Outcomes 


MAINTAINER 

PRIMARY 

AFQT 

?ile of 

P0STTRNG 


M0S 

SCORE 

M0S 

SCORE 





(% RIGHT) 

1 

35L 

34 

16 

71 

2 

33P 

81 

59 

67 

maintainers AFQT and 

GT score 

s were similar to 

the operators, their 

post-training test scores were 

somewhat 

higher. 

It seems that the 


maintainers were somewhat more knowledgable about the JTIDS at the 
conclusion of their training with the additional 40 hours of 
instruction and practice. 

Observation of the maintainers during the IOA suggests that the 
content of the training was relevant to their jobs and that it was 
placed at the right level. It was clear that the graduates were able 
to run the available diagnostic tests and use the technical orders 
adequately for the jobs assigned during the IOA. Since no military 
personnel performed the whole maintenance job, it is not possible to 
draw any conclusions about the adequacy of the training for the total 
set of JTIDS maintenance tasks. Problems observed during maintenance 
are detailed later in this section; however, the biggest problems 
overall were the job performance aids (i.e., the technical manuals and 
the diagnostic procedures). 


The reading 
is somewhat higher than desired. The 
text and tables in the manuals is 
grade being desired. Although the 


manuals is 
effectively 


high, learning the vocabulary 
reduce the apparent reading 


level for the technical manuals 
average reading level for free 
about 10th grade level, with 9th 
required reading level of the 


change to the reading level 
manuals are discussed under 


is recommended, 
the maintenance 


of the specialist will 
difficulty. Therefore no 
Other problems with the 
heading below. 


19 


Net Managers 


Net Manager Demographies. Demographic data was not collected for 
the two Net Managers assigned to the IOA. However they seemed adequate 
during training and during the IOA testing discussed below. 

Net Manager Training. Net Manager training was two weeks and two 
days in length and was presented just prior to the start of IOA. The 
course was taught by experienced Net Manager training personnel from 
Ft. Gordon, GA. The course focus was on net planning of Army 

resources and covered all planning forms up to and including terminal 
initialization parameters. Both IOA Net Managers completed the course 
satisfactorily, including the final exercise. 

At the completion of training, a problem was given to the Net 
Managers which involved the resources to be used at Eglin AFB, FL. The 
solution required the completion of a net plan through the working 
parameters but did not require the development of initialization 
parameters. All forms were completed and all required entries were 

made on each form. All participants were included and each was provided 
the needed time slots for the type of information to be handled. The 
training provided at least a minimum background for both the cognitive 
skills of organizing a network and the clerical skills of using the 
Army forms. Apparently the personnel assigned to the training were 

capable of learning the Net Manager skills, at the novice level, 
through the available course. 

HFE for Operation and Maintenance (IOA Issue 2.) 

Terminal Deployment 

Actual set-up immediately following a move occurred every day for 
the relays. In general, the required activities after arriving on site 
included the following: 

1. Spot and ground the JTIDS van 

2. Spot and ground the generators 

3. Connect JTIDS power and antenna 

4. Connect host interface cable (HAWK) 

(at MBN and AFP - not JTIDS relays) 

5. Turn on JTIDS system equipment 

These activities required 20-30 minutes to complete, given no equipment 
or cabling problems. This did not include attaching interconnecting 
cables between the JTIDS components. 

Antenna set-up was performed only occasionally, when it was 
necessary to relocate an antenna. When performed, this activity took 
45 - 60 minutes depending on the level of proficiency and practice of 
the individuals assigned to the activity and the nature of the antenna 
site. 


20 





Location of Connector Panel. The principal problem was the height 
above the ground of the antenna, host interface, and field phone 
connectors on the vehicle mounted shelter. Soldiers over 6 feet tall 
could reach the connectors with only minor difficulty, anyone shorter 
had to stand on the truck tail gate and reach around the side of the 
shelter to connect the cables. The average height of the operators was 
five feet ten inches, so almost all of them had problems with these 
connections. Making the connections was a one-hand job since the other 
hand had to be used to hold on, so as not to fall off the tail gate. On 
several occasions, antenna connection problems caused the equipment to 
function improperly. 


Recommended Solution. The connection panel for the antennas, field 
phone, and the 26 pair cables should be moved down to mid- shelter. 
This should facilitate cable connections for a truck mounted shelter 
and one placed on the ground. Moving the panel below mid- shelter 
would make cable connections difficult for a shelter placed on the 
ground. 


Initial iz 3 t .iQ.n 

The required activities after completing deployment included the 
following: 


1. Load crypto variables 

2. Initialize JTIDS equipment 

3. Coordinate net participants 

4. Enter net ready to pass traffic 


These activities required approximately 35 - 45 minutes when using the 
rapid load available with the IOA equipment configuration. When 
performed using the ICP manual initialization scenario, these actions 
took about 50 - 60 minutes. These times are representative given no 
equipment or operator problems. Problems frequently extended the time 
to two - three hours. Average times for manually initializing JTIDS 
equipment (2. above) are presented in Table 4.2.1.2.1. Specific 
problems associated with initialization are discussed below. 


n 

Table 4 - .2.1.2 ^ 1 JTIDS Manual Initialization Times (minutes) 



Aver. Time 

Time S. 

Field Live level 0 

30.6 

16.5 

MOPP Level 0 

18.8 

1.9* 

Cold Weather Gloves 

19.0 

3.2* 

NBC Gloves and Mask 

19.7 

2.1* 


* The procedure for these measurements required the initial¬ 
ization of 10 slot blocks - a relay. Procedures for the AFP 
and MBN were 50% - 150% longer. 


Loose Connector. The connector for loading the crypto variables on 
the Digital Data Group Processor was prone to coming loose if not used 


21 



carefully. If the crypto load device was put on the connector tightly 
(a likely occurrence with gloves which mask tactile sensations), the 
connector would loosen when removing the load device. Once loose, this 
connector would spin in its mounting hole and subsequent loading of 
variables was next to impossible because the load device could not be 
attached to the connector. 

Recommended Solution . This connector should use a D-shaped mounting 
hole. Even if the backing nut loosened the connector would not be able 
to spin in its mounting hole. 

Loss of Initialization Variables. Initializing the terminal was 
fairly routine except when variable values would be dropped or changed 
by the JTIDS equipment for no apparent reason. In some cases, there 
was no indication that the values had changed until a confirmation 
check of the values was performed by the operator. This was frequently 
not done unless the operator believed there was a problem. In most 
cases, reentering the variable values which had changed was all that 
was required to clear the problem. In other cases, there was an actual 
system failure and some form of troubleshooting was required (e.g., use 
of BIT). The variables most frequently involved were those in the HIU 
referring to host type and message packing. During the IOA This 
problem occurred approximately every other day. 

Recommended Solution. A Standard Operating Procedure (SOP) for 
verifying variable values after initialization would prevent attempts 
at operation when the variables had changed. A better solution would 
be to identify and correct the cause of the value changes. 

Design of TCP Keyboard. Entering alpha information on the keyboard 
was difficult for two reasons. First, the arrangement of the alpha 
keys is different than that of any other keyboard in use by operator 
personnel; this produces errors in both initialization value entries 
and in J-gram messages. Errors in key localization were observed daily 
even after eight weeks of equipment usage. This problem will not go 
away, because QWERTY keyboards are used daily by operators. Second, the 
size and actuating pressure of the "keys" makes entry difficult and 
error prone even without gloves, this problem gets worse with gloves. 
On at least one occasion two keypads were observed to come loose, 
causing the keys to operate erratically. 

Recommended Solut ion. The standard QWERTY keyboard layout should be 
used on the JTIDS keyboard so the operators will have common keyboards 
to use for text and data entry, regardless of which system they are 
operating. The alpha and numeric key pads should be larger and farther 
apart to accommodate the use of gloves by the operator. Since the loose 
keypads were observed on only one occasion, it is hard to determine if 
this was an isolated case or a general problem. 

Protocol fo r Net St ar tup. Coordination of NET participants was more 
of a chore than first anticipated. Coordination of all participants is 
accomplished by synchronizing the clocks of all other terminals in the 


22 



network to the clock of the terminal identified as the Net Time 
Reference (NTR). This is done automatically by the terminals. It 
turned out that the NTR had to be leading all other stations in terms 
of clock time. If the NTR was lagging a station attempting to enter 
the NET, that station took a long time to enter the NET and sometime 
never entered. This fact was learned only after the operators had 
several failed entry attempts. In addition, there can be only one NTR 
or more than one NET may be created. There were no procedures for 
determining whether there was more than one NTR for a given NET or for 
returning to one NTR if more than one existed. 

Multi-service note - 

This was a particularly knotty problem when there was an Air Force 
Net and an Army Net operating simultaneously prior to creation of 
the multiservice Net. It appears this problem could get worse if 
the multiservice participants are NTR in the non-multiservice 
portion of their initialization and are not NTR in the multiservice 
portion of their initialization. Someone needs to identify how the 
operators are to determine that there are NTR problems and what 
should be done when these problems are found. This is not a 
doctrine problem but a procedure development problem! Special 
attention must be given to the time when there is no communication 
among the participants because the NET is not established. 

Recommended Solution. First, develop a SOP for ensuring that there 
is only one station with the NTR designation in the NET. Second, 
either develop a SOP to ensure that the NTR clock is leading all other 
participant stations or make certain that the terminal hardware and 
software can synchronize forward as well as it does backward. 


Strength. pHJ jaflia ..§lgna.1Entering the net becomes a problem when 
the station attempting to enter has a marginal radio signal between 
itself and the station(s) with which it should be communicating. 
Principally, there is no way for the operator to tell whether the 
signal is there or not, the display simply says NO SYNC; it does not 
say why there is no sync. The operator can only check the terminal's 
initialization values and if they are correct no other information is 
available for further diagnosis. All that can be done is to keep 
sending the terminals signal over the air waves and hope another 
terminal receives it and provides the net entry assistance. 


An indicator of received signal strength 
should be provided; either as an alert message or an indicator on the 
front of the R/T. There is no point in attempting to enter a net if 
insufficient radio signals are being received. An analog indication is 
preferred because a judgment of likelihood of success can be learned 
for various levels of received signal. In addition to this indicator, 
a means of communication among the JTIDS stations, other than the JTIDS 
terminals, needs to be provided. Had a back-up means of communication 
not been available during the IOA, it is doubtful that the assessment 
would have been completed or that any successful nets would have been 
established. 


23 




Operation 


There are very few tasks for the operator to perforin when the 
terminal is operating properly after entering the net. If there had 
not been many malfunctions during the IOA the HAWK operators could 
easily have been the JTIDS operators. Periodically the operator checks 
on the message status of the terminal by looking at the IC alert 
message details, even when there are no alerts. Under the current 
configuration the most frequently watched alert/status was the HIU 
alert page. This is because the most frequent problems during 
operation occured between the HIU and the host equipment. 

Troubl e shooting of Integ rated S ys tems,, The HIU link to the host 
equipment provided the most difficult problems during the IOA. This 
also turned out to be the area of the integrated systems with the least 
information available for troubleshooting. Neither the host operators 
nor the JTIDS operators had sufficient documentation for 
troubleshooting the interface. In addition, neither had training in 
this area of system integration. Both operators (i.e., JTIDS and HAWK) 
had training in their system but neither had training in the interface 
area. When problems arose, dicussions between the operators were not 
only fruitless but the usage of terms for each system was different, 
thereby interfering with meaningful communication. For example, when 
the HAWK operators talked about a good link, they meant good data from 
the MBN to the AFP. Whereas, the JTIDS operators could have a good 
link when the terminals were communicating even though the data from 
the MBN to the AFP was not good (i.e., a needline fail existed). 

Recommended Solution. First, a set of procedures for trouble¬ 
shooting the JTIDS to host interface for each of the potential hosts 
needs to be developed and validated. The procedures need to cover the 
HIU to interconnecting cable, the interconnecting cable, the host 
modems, and the host interfacing computer ports. These procedures need 
to include the information requests to the host operator in terms of 
the displays and information available to that operator, as well as, 
the displays and information available to the JTIDS operator. Second, 
validated procedures need to be incorporated into the JTIDS operator 
course and practice needs to be given in using the procedures during 
operator training. 


Messages in Error . The HIU provided one interesting condition 
during operation, the IC would show an alert of INIT WAIT on the screen 
after the net was established and traffic was being passed. When this 
occured everything proceeded normally although the operator had an 
indication that the terminal was in a wait state. This alert was not 
covered in any of the manuals for the condition of non-initialization 
activities. 

Recommen ded Solution. Remove messages which are not appropiate to 
the terminal operating mode. It may be necessary to add a new message 
to the pool, one for ’’wait" states that occur during normal operation. 


24 


Operation under Electronic Counter Measures(ECM). The operators had 
very few choices of what to do during operation in an ECM environment, 
there were too few indications of the quality of signals or data. In 
addition, there were no operator adjustments available which might be 
used to combat ECM. The principal problem was that the operators could 
not tell what was causing a communication difficulty. They were not 
able to tell whether bad data was caused by a bad link or by ECM. 

Recommended Solution. Provide signature key words embedded in the 
transmissions to aid in the determination of the quality of the data 
independent of the quality of the received radio signal. This should 
include keywords for each of the transmissions. An alternative is to 
use something like CRC words in the transmissions to detect the 
occurrence of errors. 

Hardware Design 

Most of the hardware design problems are related to connector 
placement, indicator placement, and control accessibility. 

Design of TC P Keys, The ICP line select keys seem to be usable with 
and without gloves since few errors in line selection occured during 
the initialization or operating sequences. The keyboard keys were 
another matter. The keypads were too small and too close together, 
causing the wrong character to be entered even without gloves. In 
addition, the key actuating force was high enough to cause considerable 
finger discomfort when entering initialization sequences as short as 
those for the relay terminals. 

Recommended Solution. Both problems require ICP keyboard redesign 
for correction. 

Time f or Init ial ization. A separate but related problem is the time 
required to initialize a terminal from scratch after a maintenance 
action has been performed or whenever a terminal needs to change its 
initialization because of network reconfiguration. Terminals with even 
modest slot block requirements, 10 to 20 slot blocks, required at least 
one half hour to initialize using the manual procedures. It must be 
possible to initialize faster than this under battle field conditions. 

Recommended Solution. Battlefield time constraints suggest the need 
for some sort of long term off-line variable storage. The new 3 1/2" 
disc drives would seem to be a good choice based on storage capacity 
and media durability. Changing initialization parameters amounts to 
loading the previous parameters, changing those that need it, and 
saving the new parameters. It seems reasonable to retrofit a 3 1/2" 
drive and controller to the current ICP. With some modification to the 
software, the initialization variables could be saved directly to the 
ICP 3 1/2" disc drive. These variables could then be reloaded whenever 
required. All this could be done without the need for an auxiliary 
computer which is fairly sensitive to abuse (shock mounting developed 
for the auxiliary computer used in the shelters during the IOA). 


25 


Design o f Dig ital Data Processor Group(DDPG). The principal 
hardware design problem for this component is the placement of the 
cable connections. With the exception of the outside connectors (i.e., 
J2, J3, & J4) it is necessary to remove one or more cables in order to 
remove an inside cable. With an ungloved hand, this is a fairly 
difficult task, with a gloved hand this task is just barely manageable. 

Recommended Solution. Rotating the JTIDS mounting rack 45 degrees 
clockwise would help this problem immensely. The permanent cure is to 
rotate the rack and rearrange the connector layout on the front of the 
DDPG. 

Location of DDPG Indicators. A second problem is the location of 
the BIT indicators and Reset switch. To a lesser extent, the location 
of the Elapsed Time indicator is also a problem. The BIT lights cannot 
be seen or reset by the operator without leaning over the equipment 
mounting rails so that the eyes are directly in front of the component. 
This cannot be done easily enough to ensure continuous monitoring of 
BIT status. 

Recommended Solution. Again, rotating the mounting rack 45 degrees 
clockwise would correct this problem. Even rotating the rack will not 
make the Reset switch easy to reach and press because of the proximity 
of connector and cable J9. The only solution is to revise the layout 
of the front panel. 

Layout^j^f.JRjeceiv^x. .JjigGsm.iLter„ JRX). _ _E.aJie.lj_ The front of this 
component has a much cleaner layout because it has fewer cable 
connections. However, given the current mounting configuration, the 
Elapsed Time indicator, Fault lamp, and Reset switch are hidden from 
the operators view by cables. 

Recommended S olut ion. Rotate the mounting rack 45 degrees 
clockwise. 

Design of Power Control P anel (PCP). The Power Control Panel had at 
least one major problem and several minor problems in its design. 
During one maintenance problem the Terminal Power CB was found to be 
faulty. This switch could not be replaced by the DS maintainers except 
by replacing the whole PCP. For battlefield maintenance and logistics 
this seems like overkill in the maintenance philosophy. If a new PCP 
were not available a whole JTIDS terminal would be out of action 
because of a bad circuit breaker. 

,RecQm.roended_Jj.QlnfcjLsiu Re-plan the spares provisioning and level of 
maintenance activities for the battlefield environment in terms of the 
user units in which this equipment will be located. If the right 
switch was available, the HAWK unit could have replaced it and the PCP 
would not have had to go back to depot for repair. 

Mounting—oil_ELost_ Interf ac e. Uni t . .(HIU). This unit experienced the 

most problems during the IOA. However, the Fail lamps and reset switch 


26 



were the most easily seen and reached of all the JTIDS components. The 
connectors are somewhat better spaced for connecting cables than on 
most of the other JTIDS components. Only the J3 connector proved a 
problem for operators with gloved hands, because it was located between 
two other connectors. The power switches and circuit breakers were 
located between cables which made their operation difficult given the 
current mounting configuration. Again, the power indicator lamps were 
hidden from the operator's view by cables in the current mounting 
configuration. 


Recomme nded So lut jon f Turning the mounting rack 45 degrees 
clockwise would help the HIU problems with the exception of J3. Moving 
J3 would require redesign of the HIU front panel. 

Software Design 

The software design, using nested menus, seemed to work reasonably 
well and the current implementation seemed adequate. The operators had 
little trouble using the menus and did not seem to get lost since they 
could always get back to the first menu, Pgl, and then reenter if 
necessary. After some field practice all operators were competent in 
getting alert pages on the ICP to monitor message and HIU status, the 
two areas giving the most information about the current state of 
operation. 

System Interface Design 

The design of the host/JTIDS interface seemed adequate in terms of 
system interconnection to the host and the ease of connecting the 
necessary cables. The main interface problem areas were in 
troubleshooting and fault isolation. These areas were discussed above 
under operator tasks. 

Maintenance 

Manual Referen ci ng. The principal problem with the design of the 
technical manuals is that they require a large amount of skipping 
around from one procedure to another to get anything completed. This 
approach is highly error prone, since it is easy to loose track of 
where in the initial procedure one left off and where one should pick 
up when coming back. This is particularly bad when Table 1 references 
Table 2 which references Table 3. After Table 3 which table should be 
done next - Table 2 or Table 1. There is no return referencing in the 
tables, only outgoing referencing. Frequently one manual needs to be 
opened to two places at the same time. This is a MANPRINT nightmare. 

Recommen ded gplutj pp. Although it would require some work, a linear 
approach to procedure development would be desirable. Even an approach 
where all referencing to which table to go to next was in one manual, 
with the procedure tables in another, would be preferred to the present 
organization. It's easier to have two manuals open than to have one 
manual open to two places. 


27 


Manual_.OrggJuLzPt.i.QQj. The performance aids are not organized by the 
equipment or procedures being followed; its a mixture. In one case, 
the DDPG is split in the manual with the II) being covered in one place 
and the DDP being covered in another. In the case of initialization 
procedures there is so much duplication across manuals that it is hard 
to know which procedure to follow - the one in DEP 11-5820-903-12 Radio 
Set AN/URC-107(V)3 or the one in DEP 11-5820-929-12 Host Interface Unit 
J-4278/G. Some things are done in different orders in these two 
manuals, with no indication of whether or not this makes a difference. 

Recommended gol.u.ti&IL. Organize the manuals so that the procedures 
for each chassis are in a single manual. Reduce the duplication and 
change the procedures to agree or indicate why any differences exist. 

£&Pe tj tjon_ q£_JLH _Prece.dur.gSj_ Operator & DS Maintenance 

troubleshooting was performed by using BIT. GS Maintenance trouble¬ 
shooting was performed by contractor (Singer) personnel and was not 
observed during the JTIDS IOA. For most observed problems the BIT 
tests seemed to work satisfactorily, with one exception. 

If the outcome of the BIT was in doubt and it was repeated several 
times, the displayed values could not be trusted. If BIT was run more 
than twice, it was necessary to turn off the equipment so that the 
memory was cleared and then turn it back on and run BIT again. If the 
problem was suspected to be in the HIU there was no BIT which could 
test this part of the JTIDS equipment. 

Recomme _ nd gd__Selj,it_iQn_. Revise the BIT programs to permit the use of 
BIT as many times as necessary without memory contamination. 

Lay put of Cable„CQnhgc_t&r^j. Cable connections between the JTIDS 
equipment items were for the most part unacceptable. The cables on the 
PCP are large and too close together, frequently two connectors must be 
removed to get at the one of interest. The data cable connectors on 
the RT are much too close together for manipulation by a gloved hand. 
The same is true of the DDPG, the HIU, and the main power control 
panel. Even when the maintainer did not have gloves on, the cables 
could only be removed and reconnected in a certain order on each of the 
front panels. Cables on the rear of some items required the maintainer 
to get in very difficult working positions, this situation will 
undoubtedly lead to improper connections and/or damaged connectors. 

.Recpmrnended_ Solution . If the JTIDS is to be fielded in the tested 

configuration serious consideration must be given to redesigning 
connector layout on each of the chassis front panels. 

.Mounting-pf. .JTIDS_.Clig,Aglgj. Chassis removal for three of the four 
main components is difficult since the chassis are heavy and in awkward 
positions for removal and replacement, especially since they all 
require a two person lift. During the IOA, a single person lift was 
almost always observed. Several removal and replacement activities 
were performed during the IOA and most of these required 15 to 25 


28 



minutes to accomplish when the replacement chassis was available at the 
required location. The fact that these activities went quickly and 
without any safety incidents is a. credit to the effort put forth by the 
operators and DS maintainers, not the quality of the design of the 
cabling or mounting systems. 

Recomm ended. Solution. Turn the mounting rack 45 degrees clockwise 
so that two people can remove/install the JTIDS chassis. 

T_ Q°1 s .—and—Test— Equipment. Special JTIDS tool kits for the Army 
maintenance personnel were non-existant. It is assumed that the host 
organization maintenance operations will possess adequate tools to 
support maintenance activities on the JTIDS. The only piece of test 
equipment which seems to be required is a multimeter to use in checking 
cable continuity and voltages. Again, it is assumed that the user 
organizations will have at least one of these meters. 

Network Planning 

The two Army Net Managers were tested during the IOA in a planned 
side test. In this test, the two Army Net Managers worked with two Air 
Force Net Managers. The test consisted of having the Net Managers plan 
a JTIDS communication network using a limited set of resources which 
were available at Eglin AFB. The anticipated scoring technique was to 
use the planned network as the initialization basis for the resources 
at Eglin AFB and see if the planned network was able to communicate. 
This evaluation was never accomplished. However, the network plan was 
submitted to MITRE Corporation for scoring in order to determine the 
types of errors committed. 

The net planning tasks during the IOA test seemed to be completed 
with greater expressed confidence in the outcomes than when the Army 
Net Managers worked alone. The resulting network initialization 
documents were more complete as each of the pairs of managers worked on 
the part of the problem each understood best (i.e., the Army Net 
Managers planned for the Army resources and the Air Force Net Managers 
for the Air Force resources). This approach seemed preferable to both 
pairs of managers and each learned some techniques from the other. The 
task was completed in four hours; however, more skills and techniques 
were brought to bear on the network plan. 

MITRE scoring of the outcomes showed errors to be present which 
would have prevented the planned network from working. Even with the 
errors, it is difficult to say whether so complete a job could have 
been done by the Army or Air Force Net Managers separately, but it is 
doubtful. However, it seems from observation of the network planning 
task that the errors and lack of completion were not related to 
personnel concerns but to training emphasis, task complexity, and three 
weeks of non-related intervening activities. 


29 


Safety.. .Dpsign _XXQA .Is sue 3.♦) 

Deployment , O peration., and Maintenance 

There were no JTIDS injury incidents during any of the pilot or 
multi-service test trials. 

3250 Sh e!tex-.FIoor^. Although not specifically a part of the JTIDS 
system, the S250 Shelter has one safety related problem. When wet, the 
floor of the shelter is very slippery. During the JTIDS IOA, all 
shelters were equipped with rubber mats to prevent the operators and 
maintainers from slipping and falling on wet floors during or after a 
rain. 


Recommended_ Soluti on. Either coat the shelter floors with a slip 

resistant finish or equip each shelter with non-skid floor mats. 


30 



SECTION V SUMMARY 


Introduction 

Originally, the JTIDS test and evaluation was planned as a full 
scale Independent Operational Test and Evaluation (IOT&E), to be 
executed jointly with the Air Force. During the Army developmental 
testing, a number of problems were discovered in the Class 2 Terminal 
and it was not certified for transition to operational test. Since the 
multiservice testing between the Air Force and the Army was 
particularly important for the Air Force, the Army decided to support 
the Air Force to the minimal extent possible. This included the use of 
a single TSQ-73 and a single HAWK PCP, with four relays and minimal 
manning by the 11th ADA. The Army's portion of the test was downgraded 
to an Investigative Operational Assessment (IOA), lasting eight weeks. 

The intent of this IOA was to ensure that the Army Class 2 
terminals stayed operational during the multiservice trials, using 
every means at hand including maintenance personnel drawn from DT. Data 
collection was to be minimal, with low reliability due to the few 
trials and limited system operational time. The data collected was to 
be used to provide insights into the adequacy of the design of the 
Class 2 Terminal from the Army's perspective, and to provide input into 
the design of the Class 2M Terminal. 

The objectives of this IOA for MANPRINT were to provide, to the 
degree possible, insights on how well the JTIDS Class 2 Terminal met 
the requirements of the MANPRINT program. The specific domains of 
MANPRINT that were assessed during the IOA included personnel, 
training, human factors engineering (HFE), and system safety. Manpower 
could not be assessed given the limited 11th ADA unit resources 
available for the IOA, and health hazards were assessed by 
developmental testing. 

The maintenance objective of the IOA was to ensure that the 
terminals stayed operational during the multiservice trials. This was 
achieved using whatever means were at hand. This practice introduced 
some confounds into the maintainability data and made it all but 
impossible to assess the effect of some of the variables. 

The size of the IOA player pool was small (n = 8 for operators, n = 
2 for net managers, and n = 2 for maintainers), lowering statistical 
validity, increasing the risk of a nonstratified sample of personnel 
characteristics, and limiting the generalizability of the data to the 
population as a whole. However, every effort was made to derive 
information which was as reliable as possible in reaching the 
conclusions presented in this report. 


31 


Conclusions 


IOA Issue 1 

JTIDS Class 2 Terminal shall be designed so that representative 
personnel have the necessary skills and aptitudes to be trained to 
perform the critical tasks to the required field proficiency. In 
general, this issue was satisfied by the JTIDS Class 2 Terminal in the 
IOA with one exception, the JTIDS - host interface. 

Criteri on. Initialization, reinitialization, and operational 
procedures shall be simple enough to be learned, retained, and 
performed by representative MOS personnel. 

The demographic data showed the operators and maintainers to be 
representative of personnel in the respective MOS groups. The range 
and average scores for the eight operators and the two maintainers were 
appropriate for their MOSs and the anticipated operator/maintainer MOSs 
for the deployment units (e.g., HAWK units). If anything, the samples 
for the IOA were slightly below average for the host system MOS 
averages. 

Results of the training showed the operators and maintainers had 
the necessary skills and aptitudes to learn the material presented in 
the standard training setting. No MOS group had any consistent 
advantage in terms of training performance, instructor ratings, or 
field task performance. 

All operators performed the initialization, reinitialization, and 
operational tasks equally well. The tasks were simple enough so that 
they could be learned, retained, and performed given the standard 
training and the on-the-job performance aids used in the IOA. 

The only training problems were procedures not covered during the 
training; either because they were not developed or because the short 
training time did not allow their inclusion. The operators were able 
to learn procedures in the field as their experience accumulated and as 
new procedures evolved. 

The design of the system produced difficult procedures in one area. 
The interface between the host system and the JTIDS terminals did not 
meet the criteria of providing simple operational procedures when host 
interface problems arose. There was no simple way of isolating an 
interface problem to the host data multiplexer, the interconnecting 
wiring, or the JTIDS Host Interface Unit (HIU). A problem occurred in 
this area almost daily and no simple procedure was ever developed to 
isolate the causes of the problems. 


32 


IOA Issu e 2 


Human Factors design for ease of operation and maintenance. 

Criterion_ la. Initialize terminal within two hours. The design of 

the system, even with its problems was able to meet this criterion. 
During the tests involving initialization of the terminal, no operator 
took more than 45 minutes to initialize the terminal with 10 slot block 
assignments even when wearing NBC protective gloves and mask. During 
field operation; the Master Battalion JTIDS terminal, requiring 35 slot 
block assignments, was manually initialized in 1 hour and 15 minutes. 

Criterion_Ub*. Place into operation or change initialization 

variables within three minutes. Once initialized any single 
intialjzation variable or a slot block's variables were easily changed 
within the required three minutes. The terminal was also easily placed 
into operation within three minutes; however, entering the network as a 
communicating terminal almost never occurred within three minutes. From 
the standpoint of operator tasks, this criterion is met; however, this 
does not include entering the net as a participant. 

C riterion — 2 L*. JTIDS Class 2 hardware and software design shall 
facilitate operator task performance. This criterion is met for most 
operator tasks, with three major exceptions. First, the hardware 
design is deficient in facilitating operator performance when entering 
the net under conditions of marginal received radio signals and 
operating in an ECM environment. Second, the hardware and software do 
not facilitate operator performance under conditions of JTIDS - host 
interface problems. Fianlly, the hardware and software do not 
facilitiate operator performance when BIT is run under conditions of 
uncertainty and must be run more than twice to verify a failure 
condition. Before the JTIDS Class 2 terminal can be said to meet this 
criterion these three major shortcomings must be remedied. 

. CLitor JL Qn l3 .1. Net planner shall perform necessary planning and 
develop initialization sequences without error and within four hours 
98% of the time. This criterion was not met during the IOA. The 
problem does not appear to be a personnel problem in the sense of 
aptitude or intelligence. The tasks facing a net planner are complex 
and are not easily learned in a two week period. The more the net 
planners performed their tasks the better they got; however, they were 
never able to plan an entire IOA network without errors. The training 
is, if anything, rushed. Many complex details are covered quickly 
because of the time constraints, this leads to incomplete learning and 
forgetting in the absence of practice. In order for this criterion to 
be met in the future, changes should be made to training time and the 
job performance aids (e.g., the forms and a handbook). 

Crrtep . ion 4 i t The system shall be designed so that maintenance tasks 
can be easily performed and the system repaired within 0.25 manhours 
75% of the time. It is difficult to assess whether or not this 
criterion could be met because of the maintenance philosophy employed 


33 


during the IOA. However, observation of the maintenance activities 
performed by soldiers indicates that it cannot be met. Many of the BIT 
took more than 15 minutes to run* not including the time to disconnect 
cables, remove units, replace boards or units, reconnect cables, rerun 
BIT, reinitialize the terminal, and return the terminal to operation. 
This is espically true when considering the difficulties in removing 
and connecting cables given all the cable clearence problems noted. In 
addition, limited accessability caused by the current rack mounting 
configuration of the units further impeded the maintenance process. 
In order for this criterion to be met in the future, significant 
changes to the equipment front panel designs and the equipment mounting 
configuration will be required. 

IOA Issu e 3 

JTIDS Class 2 terminals shall be designed to be operated and 
maintained without risk of personal injury. There were no injury 
problems during the IOA. 

C enter i on— JL». Soldiers must be able to operate, maintain, and 
deploy the JTIDS Class 2 terminal without danger of personal injury. 
The current equipment mounting configuration limits two person access 
for heavy lifts and poses the real possibility of personal injury even 
though none occurred. In addition, the slippery-when-wet shelter floor 
also represents the possibility for injury. Both these problems should 
be fixed if the JTIDS Class 2 terminal is to be fielded in the S-25C 
shelter. 


34 



APPENDIX A 


- DATA COLLECTION FORMS 


35 



JTIDS IOA 


DEMOGRAPHIC QUESTIONNAIRE 


1. Date:_ 2. Time:_ 

yyddd hhmm 

3. Player No:_ 4. Player Name:,___ 

5. Position: (_)Net Manager (_Operator (_)Org. Maint. (_)DS Maint. 

(_)Data Collector (_)Test Directorate 


6 . Height: 


7. Weight: 

8 . Age:. 



Feet 

Inches 

Lbs. 


Years 

Months 

9. SSN: 






lO.Grde/Rank: 


11 . Time 

in Service:. 







Years 

Months 


12. Assigned Unit:_ . _ 

13. Primary MOS:_ 14. Time in Pri MOS: 

15. Secondary MOS:_ 16. Time in Sec MOS: 

17. Duty MOS:_ 18. Time in Dut MOS: 

19. ETS Date: _ 

Y Y M M D D 


20. How many months have you been working with the JTIDS:_(months) 


21. Please indicate the JTIDS training you had: Net Mgr Class _ 

Opr - Org Class _ 

DS Maint. Class _ 

22. Date Training started _ / _ Class plus OJT _ 

Mo Day FTX in Florida _ 

23. Civilian Education: (Please circle letter of highest achievement) 

a. No High School Diploma e. 1-2 years of college 

b. GED f. 3-4 years of College 

c. High School Graduate g. College Graduate 

d. Trade School Graduate h. Advanced Degree 


24. 


Degree or Trade: 


36 






25. Other personal skills (e.g., computer programming, electronics, etc.): 


T 


26. Do you wear prescribed glasses or contacts _: if yes, why? 

__ Seeing close (reading) _ Seeing far (driving) 


Other: 


27. If you have ever had an eye injury, please explain: 


28. Have you ever had any hearing problems _: if yes, explain: 


29. Have you ever had any problems with your arms, legs, hands, neck, and/or 
torso which make it difficult for you to drive, lift/carry, walk/run, 
and/or perform other motor activities _: if yes, explain: 


30. Have you been sick in the past two weeks _: if yes, explain 


37 





31. If you are taking any prescribed medication, please name it and 
why you are taking it:__ 



Rev. 3, 26 Feb 87 


JTXDS IOA 

OPERATOR/MAINTAINER QUESTIONNAIRE 

1. Name_2. Rank_ 

3. SSN_4. MOS_ 

5. Are you a JTIDS Operator_ DS Maintainer_ 

6 . Are you assigned to a Relay_ HAWK Fire Unit_ Battalion_ 

7. Have you experienced any difficulties in erecting either of the 
JTIDS Class 2 Terminal antennas? 

Yes No 

a. Shelter Mounted _ _ 

b. External Antenna _ _ 

If yes, please describe these difficulties: 


8 . Have you experienced any difficulties in attaching or removing the 

cables used to connect the JTIDS van with the generator or the HOST 
terminal? 

Yes_ No_ 

If yes, please describe these difficulties: 


39 



9. Have you experienced any difficulties in attaching or removing the 
cables that connect the various JTIDS components? 

Yes_ No_ 

If yes, please describe these difficulties: 


10. Have you experienced any difficulties in installing or removing 
any of the following components: 

Yes No 

a. Battery: _ _ 

b. Secure Data Unit (SDU): _ _ 

c. Blower-Power Supply Unit: _ _ 

d. Keyer Control Panel: _ _ 

e. Other_: _ _ 

If yes to any, please describe these difficulties: 


11. Have you experienced any difficulties in understanding and 
performing the procedures for starting up the JTIDS terminal? 

Yes_ No_ 

If yes, please describe these difficulties: 


40 


12. Have you experienced any difficulties in performing the 
initialization procedures for the JTIDS terminal? 

Yes_ No_ 

If yes, please describe these difficulties: 


13. If you have been interrupted during initialization, have you ever 

experienced any difficulty in determining where you left off and then 
completing the initialization? 

Yes_ No_ 

If yes, please describe the difficulties and how they effected your 
ability to perform your mission: 


14. Have you experienced any difficulties in using, when wearing 

standard uniforms, the controls on the JTIDS terminal equipment due to 
size, shape, distance between controls, force required to activate, or 
other reason? 


Yes_ No. 

If yes, please describe these difficulties: 


41 


15. Have you experienced any difficulties in using, while wearing 

MOPP IV or cold weather gear, the controls on the JTIDS terminal 
equipment due to size, shape, distance between controls, force 
required to activate, or other reason? 

Yes_ No_ 

If yes, please describe these difficulties: 


16. Have you experienced any difficulties in reading and 

understanding, while wearing standard uniforms, the labeling on the 
JTIDS terminal equipment due to size, contrast, terminology, 
abbreviations, or other reason? 

Yes_ No_ 

If yes, please describe these difficulties: 


17. Have you experienced any difficulties in reading and 

understanding, while wearing MOPP IV masks, the labeling on the JTIDS 
terminal equipment due to size, contrast, terminology, abbreviations, 
or other reason? 


Yes_ No 

If yes, please describe these difficulties: 


42 



18. While wearing standard uniforms, have you experienced any 

difficulties in viewing, reading, or understanding the displays (LEDs, 
indicator lights, fault balls, etc.), especially on the interface 
control panel, due to size, color, contrast, letter shape, location, 
or other reason? 


Yes_ No. 

If yes, please describe these difficulties: 


19. While wearing MOPP IV masks, have you experienced any difficulties 

in viewing, reading, or understanding the displays (LEDs, indicator 
lights, fault balls, etc.), especially on the interface control panel 
due to size, color, contrast, letter shape, location, or other reason 

Yes_ No_ 

If yes, please describe these difficulties: 


20. Does the JTIDS system always display understandable prompts when 
you have to input data or a command? 

Yes_ No_ 

If no, please describe when the prompts are not adequate: 


43 


••O w 


21. Are the menus used by the JTIDS Interface Control Panel displayed 
in a logical arrangement or order? 

Yes_ No_ 

If no, please describe how it is not logical: 


22. Are the terms, abbreviations, and codes used by the JTIDS system 
logical and consistent with what you expect? 

Yes_ No_ 

If no, please describe how they are not logical: 


23. Have you experienced any difficulty using the JTIDS terminal 
because of too much information being displayed at one time? 

Yes_ No_ 

If yes, please describe: 


44 



24. Are the different menus and display pages on the ICP consistent 
in format with one another? 

Yes_ No_ 

If no, please describe how they differ: 


25. Do you get adequate and timely feedback from the JTIDS terminal 
that it has accepted a command or data? 

Yes_ No_ 

If no, please describe how it is inadequate: 


26. Do you have any difficulty understanding error messages and 
correcting the cause of the error? 

Yes_ No_ 

If yes, please describe why: 


45 



27. When stepping through a series of menus, do you easily know where 
you are in the sequence? 

Yes_ No_ 

If no, please describe: 


28. When stepping through a series of menus, can you easily terminate 
an operation and get back to the beginning menu in the series? 

Yes_ No_ 

If no, please explain: 


29. Are the procedures for using the JTIDS terminal easy to 
understand and in logical order? 

Yes_ No_ 

If no, please explain: 


46 




30. Are there steps in the data entry procedures that you consider 


unnecessary t 


Yes 


No 


If yes, please describe them: 


31. Have you experienced any difficulties in performing your tasks on 
the JTIDS terminal due to the workspace in the shelter? 

Yes_ No_ 

If yes, please describe these difficulties: 


32. Is the lighting in the JTIDS shelter adequate for reading the 
displays and manuals? 


Yes 


If no, please explain: 


No 


47 




33. Did the training adequately prepare you to perform your assigned 
tasks with the JTIDS terminal, especially in a field operation? 

Yes_ No_ 

If no, please describe weaknesses in the training and how it could be 
improved: 


34. Do the technical manuals (TMs) provide clear, concise, 

understandable details on how to operate and maintain the JTIDS 
terminal? 


Yes_ No_ 

If no, please explain why and how the TMs could be improved: 


35. Given your observations during the OT of the JTIDS terminal, do 

you feel that your fellow operators and maintainers have the required 
skills for operation and maintenance of the system? 

Yes_ No_ 

If no, please describe why: 


48 




36. Have you experienced any incidents of incorrect fault isolation 
of LRUS/SRUs using the JTIDS built-in-test (BIT)? 

Yes__ No_ 


If yes, please describe: 


37. Have you experienced any instances of the BIT indicating falsely 
that a SRU was acceptable? 

Yes_ No_ 

If yes, please describe: 


38. Have you experienced any difficulties in accessing and removing 
any SRUs for maintenance? 

Yes_ No_ 


If yes, please describe: 


49 


39. Have you experienced any difficulty in using the troubleshooting 

procedures in the technical manuals to perform the BIT for fault 
isolation? 

Yes_ No_ 

If yes, please describe these difficulties: 


40. Have you experienced or observed any incidents where personnel 

were injured by sharp edges, electric shock, smashed fingers, etc. 
while operating or maintaining the JTIDS terminal? 

Yes_ No_ 


If yes, please describe: 


41. Please make any other comments or suggestions about the JTIDS 
terminal that you have not already covered: 


JTIDS IOA 

ICP INITIALIZATION CHECKLIST 


Name 


Date 

Time 

SSN 


SJS 

Time 

MOPP Level 

_ (0-4) 



MEND SELECTION 

VALUE 

| CORR | 

REMARKS 


DISPLAY CONT 

CONT RESET 

RESET IRC 

CONT FUNC 

FUNC SNE N 

RCDRON 
POOLAB 
TRANS 

PERFORM STAND BY / ON 

CONT PG1 

DISPL MODES 

MODES NORM 

NORM REF 

PRI 

DISPL INIT 

INIT MAN 

MAN IPF 

IPF EXER 


SDU VAR #LOC 0 2/0 

#LOC 1 2/1 

#LOC 2 13/0 

#LOC 3 13/1 

#LOC 4 14/0 

#LOC 5 14/1 

#LOC 6 1/0 

#LOC 7 1/1 




< 

TRANS 
COM-MODE MODE 1 
MAN DFLT 


DFLT #NET 0 

#MSEC 1 

#TSEC 1 

TRANS 

MAN SLOTS 

SLOTS #BLK 1 

#SLOT 29C 

> 

SLOTS #TSEC 2 

#MSEC 2 

#R-RATE 10 

> 

SLOTS #NPG 3 

#NET 0 

COMN 
TIME 

TSLOT XMIT 

#ACES 4 

< 

SLOTS TRANS 

SLOTS #BLK 2 

#SLOT 787A 

> 

SLOTS #TSEC 13 

#MSEC 13 

#R-RATE 4 

> 

SLOTS #NPG 28 

#NET 3 

COMN 
TIME 

TSLOT XMIT 

#ACES 16 

< 

SLOTS TRANS 


52 





SLOTS 


#BLK 3 

#SLOT 15A 

> 

SLOTS #TSEC 13 

#MSEC 13 

#R-RATE 10 

> 

SLOTS #NPG 29 

#NET 3 

COMN 
TIME 

TSLOT XMIT 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 4 

#SLOT 5A 

> 

SLOTS #TSEC 14 

#MSEC 14 

#R-RATE 10 

> 

SLOTS #NPG 33 

#NET 4 

COMN 
TIME 

TSLOT XMIT 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 5 

#SL0T 7B 

> 

SLOTS #TSEC 2 

#MSEC 2 

#R-RATE 12 

> 

SLOTS #NPG 6 

#NET 1 

COMN 
TIME 





TSLOT RCV 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 6 

#SLOT 11B 

> 

SLOTS #TSEC 2 

#MSEC 2 

#R-RATE 11 

> 

SLOTS #NPG 6 

#NET 1 

COMN 
TIME 

TSLOT RCV 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 7 

#SLOT 27 A 

> 

SLOTS #TSEC 13 

#MSEC 13 

#R-RATE 10 

> 

SLOTS #NPG 6 

#NET 3 

COMN 
TIME 

TSLOT RCV 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 8 

#SLOT 19A 

> 





SLOTS #TSEC 13 

#MSEC 13 

#R-RATE 10 

> 

SLOTS #NPG 28 

#NET 3 

COMN 
TIME 

TSLOT RCV 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 9 

#SLOT 8A 

> 

SLOTS #TSEC 14 

#MSEC 14 

#R-RATE 11 

> 

SLOTS #NPG 32 

#NET 4 

COMN 
TIME 

TSLOT RCV 

#ACES 16 

< 

SLOTS TRANS 

SLOTS #BLK 10 

#SLOT 25A 

> 

SLOTS #TSEC 13 

#MSEC 13 

#R-RATE 10 

> 

SLOTS #NPG 6 

#NET 2 

COMN 
TIME 

TSLOT RCV 

#ACES 16 

< 

TRANS 


SLOTS 





SLOTS 

< 

MAN 

POS 

POS 

POS 

POS 

LAT 

LAT 

#LAT 

#LONG 

#HGT 

> 

LAT 

#PUNCR 

#HUNCR 

TRANS 

POS 

< 

MAN 

TN 

TN 

#PRI 

TRANS 

MAN 

STA 

STATION 

NETE 

NETE 

NO 

STATION 

CONFIG 

CONFIG 

ANT A 

RCVRS 

4 

STATION 

CONN 

CONN 

YES 

STATION 

REPROM 

REPROM 

OFF 

STATION 

< 

MAN 

TIME 

TIME 

#IGMT 


ER/SEQ 


N30/34/13.7 

W86/07/45.1 

145 


20 

20 


102 


HR/MN/SC 



56 





ER/SEQ 

#ERROR 

TRANS 

MAN 

PG1 

DISPL 

BLT 

BLT-INIT RCRDR 

RCRDR 

#C0NT1 

#CONT2 

TRANS 

RCRDR 

#C0NT4 

TRANS 

BLT-IN 

PG1 

DISPL 

CONT 

CONT 

FUNC 

FUNC 

ANT 

ANT 

A 

CONT 

FUNC 

FUNC 

SNE Y 
TRANS 
PG1 

DISPL 

INIT 

INIT 

EOL 

CONFIG 

ICP 

DISPL 

HIU 


HIU MODE INIT 
HIU INIT RESET 

RESET YES 

TRANS 

HIU INIT NI 


2/0 


F11C 

FFOB 


FFEC 


HIU INITIALIZATION 


57 








NETMG/ HAWK 

NCS N 

TRANS 

ATDL-1 #HSTADR AH 

TRANS 

DLRP #LAT N31/15/00.0 

#LONG W85/25/00.0 

TRANS 

CHAN -CHNUM 1 

TYP ATOP 


ATDL-1 -CHNUM 1 

1/2 #DEST A 

#NPG 33 

#RR 10 

#CNTRLR N 

ATDL-1 -CHNUM 1 


|2/2 VNR NA 

I 

CH TYP END 


MSG CNTR P2DP 

#SIMF N 

#HCNT 7 

TRANS 


GEO FLT NO 

TRANS 

TSRD #DATCAT 0000 

TRANS 


HIU IN EOL 
PGl 





JTIDS IOA 

TASK PERFORMANCE ERROR REPORT 


°ate:_ Time 

Oper/Maint:_-_ SSN 

Senario Number:__ Terminal ID 

Environment: 

Uniform: Normal _ NBC _ COLD 


Jamming: No _ Yes 


Start Time 


Stop Time 


Total Time 


Type of Action: 

Normal Operation _ JTIDS Initialization _ Fault Iso/Repair _ 

Install/move/pwr _ Place into Operation _ J Gram message _ 

!! TASK TYPE (circle) !! 

INSTALL/MOVEMENT : JTIDS INITIALIZATION : FAULT ISO/REPAIR : J GRAM MESSAGES 


NORMAL OPERATION: 

When Host operator problem - 

Description of Incident: 


Friendly Tracks Enemy Tracks 


Tracks on Host Monitor 
Track filtering in use (if any): 


59 




OTHER ACTION TYPES: 


Describe Each Observed Error (Use back of page, if necessary) 


Total Number of Errors: 
Additional Comments: 


Data Collector: 


SSN: 


60 


JTIDS IOA 

SAFETY INCIDENT REPORT 

Date of the incident:_ Time of the incident: 

Equipment Involved in the Incident: 

_ Shelter 

_ Antenna Assembly 

_ Interface Control Unit 

_ Host Interface Unit 

_ Radio Receiver/Transmitter 

_. Battery 

_ Digital Data Group Processor 

_ Keyer Control Panel 

_Other, __ 


Personnel involved in the incident: 

Oper: _ SSN: _ Maint: _ SSN: 

Other: _ SSN: _ 


Location of the incident (site, location at the site, etc.): 


Describe the nature of the injury: 


What was the Cause of the injury: 


61 


Please describe the incident in detail 


How could the incident be prevented? 


Name of person completing this form: 
Signature: 


62 


