UNCLASSIFIED 


25 

Copy of 33 copies 


IDA PAPER P-3054 



DTIC 

ELECTE 
MAYl 0 1995 

c 



A SURVEY OF COMPUTER PROGRAMMING LANGUAGES 
CURRENTLY USED IN THE DEPARTMENT OF DEFENSE 


Audrey A. Hook, Task Leader 

Bill Brykczynski 
Catherine W. McDonald 
Sarah H. Nash 
Christine Youngblut 


January 1995 


Prepared for 

Defense Information Systems Agency 


Approved for public release, unlimited distribution: March 10,1995. 


DTJ.G QT} 




INSTITUTE FOR DEFENSE ANALYSES 

1801 N. Beauregard Street, Alexandria, Virginia 22311-1772 


19950508 098 


UNCLASSIFIED 


IDA Log No. HO 95-046314 
















UNCLASSIFIED 


IDA PAPER P-3054 


A SURVEY OF COMPUTER PROGRAMMING LANGUAGES 
CURRENTLY USED IN THE DEPARTMENT OF DEFENSE 


Audrey A. Hook, Task Leader 


Bill Brykczynski 
Catherine W. McDonald 
Sarah H. Nash 
Christine Youngblut 


January 1995 


Approved for public release, unlimited distribution; March 10,1995. 



INSTITUTE FOR DEFENSE ANALYSES 

Contract DASWOl 94 C 0054 
TaskT-S5-306 


UNCLASSIFIED 


Accesion For 

NTIS CRA&I 
OTIC TAB 

Unannounced 

JnstificatiOTi 


□ 

Q 


Distribution / 


Availability Codes 


DIst 


Avail and/or 
Special 







PREFACE 


This paper was prepared by the Institute for Defense Analyses (IDA) for the 
Defense Information Systems Agency under the task order, Ada Technology Insertion, and 
fulfills an objective, to perform a survey of high order languages currently used in the 
Department of Defense. 

This paper was reviewed by the following IDA research staff members: Dr. Alfred 
E. Brenner, Dr. Dennis W. Fife, Dr. Richard J. Ivanetich, Dr. John F. Kramer, and Dr. Dale 
E. Lichtblau. 

The authors would like to acknowledge Ms. Jean Sammet for providing many 
suggestions on improving the data collection form. Ms. Sammet’s knowledge of 
programming languages and their versions was most helpful. Ms. Linda Brown, Ms. Joan 
McGarity, and Mr. Don Reifer also provided guidance for conducting the survey. The 
survey respondents should also be thanked for taking time to complete and return the data 
collection form. 



Table of Contents 


EXECUTIVE SUMMARY .ES-1 

1. INTRODUCTION . 1 

1.1 Purpose. 1 

1.2 Background . 1 

1.3 Approach . 3 

1.4 Language Counting Issues . 3 

1.5 Scope. 4 

1.6 Organization. 4 

2. SURVEY METHOD .5 

2.1 Population Identification. 5 

2.1.1 Weapon Systems Population. 6 

2.1.2 Automated Information Systems Population . 6 

2.2 Sample Selection. 7 

2.2.1 Weapon Systems Sample. 7 

2.2.2 Automated Information Systems Sample . 8 

2.3 Data Collection Form. 8 

2.4 Contact Process . 11 

2.5 Respondent Errors. 12 

2.6 Analysis Process. 12 

3. RESPONDENT AND PROGRAMMATIC PROFILE.15 

3.1 Weapon System Responses.15 

3.1.1 Services. 15 

3.1.2 Acquisition Category . 15 

3.1.3 Acquisition Phase. 17 

3.2 AIS Responses . 17 

3.2.1 Services. 17 

3.2.2 Acquisition (Life-Cycle) Phase.18 

4. LANGUAGE USAGE FINDINGS .19 

4.1 Weapon System Findings. 19 

4.2 AIS Findings .27 

5. CONCLUSIONS AND DISCUSSION . 35 

6 . RECOMMENDATION . 39 

A-1 


APPENDIX A. SURVEY INSTRUMENT 




































APPENDIX B. SURVEY DATA .B-1 

LIST OF REFERENCES .References-1 

LIST OF ACRONYMS .Acronyms-1 







List of Figures 


Figure 1. Distribution by Service for Weapon System Responses. 

Figure 2. Distribution by Acquisition Category for Weapon System Responses 

Figure 3. Distribution by Acquisition Phase for Weapon System Responses. 

Figure 4. Distribution by Service for AIS Responses. 

Figure 5. Distribution by Acquisition Phase for AIS Responses. 

Figure 6. Total SLOC by Language Generation for Weapon System Responses 

Figure 7. Top Five 3GLs by Total SLOC for Weapon System Responses. 

Figure 8. Top Five 3GLs by Reported Usage for Weapon System Responses.... 

Figure 9. Distribution of Total SLOC Size for Weapon System Responses. 

Figure 10. Distribution of Number of Languages Reported by Weapon System 
Responses. 

Figure 11. Comparison of 3GLs w'ith Multiple Versions for Weapon System 
Responses. 

Figure 12. Total SLOC by Language Generation for AIS Responses. 

Figure 13. Top Five 3GLs by Total SLOC for AIS Responses. 

Figure 14. Top Five 3GLs Reported by AIS Responses. 

Figure 15. Distribution of Total SLOC Size for AIS Responses. 

Figure 16. Distribution of Number of 3GLs Reported by AIS Responses. 

Figure 17. Comparison of 3GLs with Multiple Versions for AIS Responses. 


.. 16 
.. 16 
.. 17 
18 
. 18 
. 19 
.22 
.23 
.24 

,25 

26 

27 

29 

30 

31 

32 

33 


Vll 



















List of Tables 


Table ES-1. Total SLOG by Language Generation for Weapon System Responses... ES-2 

Table ES-2. Total SLOG by Language Generation for AISs Responses.ES-2 

Table ES-3. Total SLOG by General Purpose 3GL for Weapon Systems.ES-3 

Table ES-4. Total SLOG by 3GL for AISs.ES-4 

Table 1. Values Assigned to SLOG Range Estimates.12 

Table 2. Values Assigned to Language Percentage Estimates.13 

Table 3. Total SLOG by Language Generation for Weapon System Responses.20 

Table 4. Total SLOG by General Purpose 3GL for Weapon System Responses.20 

Table 5. Third Generation Special Purpose Languages.2 1 

Table 6 . Third Generation “Other” Languages.21 

Table 7. Total SLOG by Language Generation for AISs.28 

Table 8 . Total SLOG by 3GL for AISs.28 

Table B-1. Weapon Program/System Names.B-3 

Table B-2. AIS Program/System Names.B-13 

Table B-3. Weapon System Survey Data.B-16 

Table B-4. AIS Survey Data.B-35 


















EXECUTIVE SUMMARY 


Background and Purpose 

In June 1994 the Assistant Secretary of Defense for Command, Control, 
Communications and Intelligence commissioned a programming language survey of the 
Department of Defense (DoD). The purpose was to identify the number of programming 
languages being used today in the DoD as compared to 20 years ago when the DoD first 
began developing the Ada programming language. 

A 1977 study, A Common Programming Language for the Department of 
Defense—Background, History and Technical Requirements, identified “450” as the 
minimum, probable number of general purpose languages and dialects used in the DoD, but 
went on to say that the actual number was not known. How this estimate, and the method 
used to count root languages, versions, and dialects, came to be is still questioned. For this 
survey, as part of establishing a strong methodology, counting the number of languages 
used today required input from the organizations developing or maintaining automated 
information systems (AISs) and weapon systems. A census sample would include new 
systems, those being modernized, and those being maintained. For this study, a judgement 
sample of weapon systems was identified from the 1994 Presidential Budget requests for 
Research, Development, Test and Evaluation (RDT&E) programs exceeding $15 million 
and Procurement programs exceeding $25 million. Of the 1,300 programs identified, 423 
programs were selected because they included software applications. The current DoD list 
of 53 major AISs was used as a sample population for non-weapon systems. 

Experts in the field of programming languages have differed dramatically in 
classifying programming languages for counting purposes, particularly in defining the 
terms “dialect” and “version.” For this paper, we use the term “dialect” to indicate a 
relatively minor change in a language whereas “version” indicates a larger change and 
usually has a different “name” although the new “name” may only be the concatenation of 
a different year or number to the baseline name (e.g.. Jovial, Jovial 73). We counted a 
“version” of a root language as a distinct language. The methodology and data collection 



approach is explained in detail in this report to allow further expansion of the sample 
population. 

Findings and Conclusions 

• The estimated 237.6 million source lines of code in this survey are distributed 
among five generations (Tables ES-1 and ES-2). 

Table ES-1. Total SLOC by Language Generation for Weapon System Responses 


Language Generation 

Total SLOC Reported 
(in millions) 

First 

3.90 

Second 

26.30 

Third 

General Purpose 

148.38 

Third 

Special Purpose 

3.70 

Fourth 

5.00 

Fifth 

0.29 


Table ES-2. Total SLOC by Language Generation for AISs Responses 


Language Generation 

Total SLOC Reported 
(in millions) 

First 

0.30 

Second 

0.63 

Third 

General Purpose 

38.24 

Special Purpose 

0.00 

Fourth 

10.81 

Fifth 

0.05 


























There are 37 third generation general and special purpose languages, the latter 
being used only in weapon systems. (Tables ES-3 and ES-4). 


Table ES-3. Total SLOC by General Purpose 3GL for Weapon Systems 


Third Generation Language 
and Version 

Total SLOC Reported 
(in millions) 

Ada 83 

49.70 

C89 

32.50 

Fortran pre-91/92 

18.55 

CMS-2 Y 

14.32 

Jovial 73 

12.68 

C++ 

5.15 

CMS-2 M 

4.23 

Other 3GLs 

3.38 

Pascal pre-90 

3.62 

Jovial pre-J73 

1.12 

Fortran 91/92 

1.00 

PL/I 87/93 subset 

0.64 

Basic 87/93 (full) 

0.48 

PL/i 76/87/93 

0.36 

Pascal 90 (extended) 

0.29 

Basic 78 (minimal) 

0.17 

LISP 

0.10 

Cobol pre-85 

0.09 

Cobol 85 

0.00 

Totai 

148.38 









































Table ES-4. Total SLOC by 3GL for AISs 


Third Generation 
Language and Version 

Totai SLOC Reported 
(in miiiions) 

Cobol 85 

14.06 

Cobol pre-85 

8.59 

Ada 83 

8.47 

Basic 87/93 

2.18 

C++ 

2.05 

C89 

1.55 

Fortran 91/92 

0.87 

Fortran pre-91/92 

0.47 

Totai 

38.24 


• For both weapon systems and AISs, over 80% of the applications are written in 
third generation languages. 

• There is a greater use of fourth generation languages in AIS applications due to 
commercial off-the-shelf products for such applications as data management, 
interactive graphical displays, and editors. 

• There is greater use of first and second generation languages (machine and 
assembly, respectively) in weapon systems than in AIS applications. This 
difference is due to the use of special purpose embedded computers in weapon 
systems. 

• Most respondents indicated that more than one language is being used in 
application software. This multi-language use includes languages from all five 
generations. With modem programming languages and compilers, increased 
use of COTS products, and re-use of software components, it will become a 
common practice to produce applications with components written in different 
languages. 

Recommendation 

Accepting the number of 450 or more general purpose programming languages in 
use in the 1970s, we can see considerable progress has been made by the Military 


ES-4 


























Departments and Agencies in reducing the number to 37 in major systems that are new or 
being modernized. Yet the survey indicates that a substantial legacy of applications remain 
that use older versions of programming languages, vendor-unique languages, and military- 
defined languages. The maintenance costs for these applications could be reduced and their 
reliability increased by converting these applications to a current version of a Federal 
Information Processing Standard language. Automated conversion methods should offer a 
cost-effective technology to facilitate this conversion. Re-engineering these applications in 
another language is also a cost reduction opportunity. Redundant code can be eliminated, 
software components can be re-used, and modern off-the-shelf programming tools can be 
used to improve maintainability and reliability. 

Consequently, we recommend that Service and Defense Agency Program Managers 
regularly review their software applications to identify a migration strategy and plan for 
upgrading them to current versions of standards-based versions of languages and modern 
labor-saving tools. The progress in reducing the number of languages used, as shown in this 
survey, indicates that further reduction should be possible. Indeed, we recognize that 
several migration efforts are already ongoing now. 



1. INTRODUCTION 


1.1 Purpose 

This paper reports the results of a programming language survey commissioned in 
June 1994 by the Honorable Emmett Paige, Jr., Assistant Secretary of Defense for 
Command, Control, Communications and Intelligence, and funded by the Defense 
Information Systems Agency, Center for Software, DoD Software Initiatives Department. 
The motivation for the survey was a desire to know how many programming languages are 
being used in the Department of Defense (DoD) today as compared to 20 years ago when 
the DoD began development of the Ada language. 

1.2 Background 

We reviewed studies that preceded and succeeded formation of the DoD High Order 
Language Working Group (HOLWG) in the mid-1970s to locate a primary source for a list 
of languages then in use within DoD. Two major software problems were under study at 
that time. The first was the trend toward unaffordable costs for DoD embedded systems 
software and the second was the potential proliferation of Service-unique programming 
languages. Software cost studies of this period did not reference specific programming 
languages, presumably because software development costs did not appear to vary as a 
function of the specific programming language being used [AF-CCIP 1973, Fisher 1974], 
These studies extrapolated total and projected costs based upon other factors (e.g., labor 
rates, purchase price, and maintenance costs for hardware and system software used to 
develop embedded systems). 

In 1974, each Military Department independently proposed the adoption of a 
common programming language for use in the development of its own major weapon 
systems. The then-Director of Defense Research and Engineering (DDR&E), Malcolm R. 
Currie, called upon the Military Departments to “... immediately formulate a program to 
assure maximum useful software commonality in the DoD” [Fisher 1977, p. 7 ]. The 
establishment of the HOLWG was the Services’ response to DDR&E. The Technical 
Advisor to the HOLWG, Dr. David Fisher, and the Defense Advanced Research Projects 



Agency sponsor, Colonel William A. Whitaker, have written historical accounts of 
HOLWG activities but these published papers do not document a list of programming 
languages in use while the HOLWG effort proceeded [Fisher 1977, Whitaker 1993]. 
However, Fisher’s paper, which summarizes the technical requirements for a common 
programming language, contains the following reference to languages in use: 

There are at least 450 general-purpose languages and dialects currently used 
in the DoD, but it is not known whether the actual number is 500 or 1500. 

With few exceptions, the only languages used in data processing and 
scientific applications are, respectively, Cobol and Fortran. A larger number 
of programming languages are used in embedded computer systems 
applications. [Fisher 1976, p. 6] 

As part of the present study. Dr. Fisher was contacted concerning the origin of the 
oft-quoted number of 450 languages being used. He did not recall that a systematic count 
of languages and versions had been done by the HOLWG. Although there may be papers 
or reports containing a list of programming languages used by DoD, we were unable to 
locate them through the open literature resources for use in this study. The analytical 
method used in the study of DoD software costs approximated the number of compilers 
installed on general purpose computers. Software cost estimates were derived from 
analysis of data that the Services were required to report to the General Services 
Administration under the requirements of the Brooks Act (1965). This data included the 
numbers, configurations, models, locations, initial cost, and utilization of computer 
systems. Questions remain about the 450 estimate, including the following: 

• How was the estimate of programming languages being used in weapon sys¬ 
tems derived? These systems were not subject to reporting under the Brooks 
Act. 

• How many of the 450 programming languages were special purpose languages? 

• How many of the 450 programming languages were minor dialects of major 
versions? 

The DoD does not maintain “corporate level” information on programming 
languages used in contemporary software projects. Therefore, gaining a reasonably 
accurate understanding of programming languages being used in the DoD required input 
from the organizations responsible for developing or maintaining individual systems. 
Accordingly, these organizations are the primary source for this survey data. 




1.3 Approach 

This study began with the identification of data elements needed for an analysis of 
programming language usage in the development or maintenance of DoD weapon systems 
and Automated Information Systems (AISs). The 1994 Presidential Budget was used to 
select a sample of weapon systems to survey. The current DoD list of major AISs was used 
to select a sample to survey. 

Service and DoD program offices provided the data on the programming languages 
being used to develop or maintain their operational and support software. The primary data 
reported included the generations and names of the programming languages being used and 
the amount (source lines) of software written in each programming language expressed as 
a percentage of the total system. Additional data reported includes the acquisition category 
and life-cycle phase of the program. 

A data collection form was designed to record the data elements identified by the 
survey respondents. Potential respondents were contacted by telephone to get their 
agreement to participate in the survey. The data collection form was then faxed to each 
participant and responses were analyzed to extract the information reported in this study. 

1.4 Language Counting Issues 

The classification of programming languages for counting purposes has always 
been, and continues to be, a highly debated subject on which experts differ in definitions 
and philosophy. Even when definitions are generally agreed upon, the application of the 
definition in a particular case is often difficult, with results depending on the judgement of 
a person. 

For the purposes of this report, the key issue is the difference between “version” and 
“dialect.” We use the term “dialect” to indicate a relatively minor change in a language 
whereas “version” indicates a larger change and usually has a different “name” although 
the new “name” may only be the concatenation of a different year or number to the baseline 
name (e.g.. Jovial, Jovial 73). While these definitions may appear to be abstract issues of 
interest only to language specialists, they actually have a profound effect on portability, 
interoperability, and counting. If a dialect (involving small changes) is involved, training 
and portability may be easier than with a new “version.” A dialect would normally not be 
considered a separate language. A version may or may not be considered a separate 
language, depending on the purposes of the counting. In this report we counted historical 
versions that divide conveniently between pre- and current version years. 






Because the practical usage of programming languages is generally at the third 
generation level, this survey concentrates on this level while still collecting some minimal 
data for other generations of languages. Consequently, the results from this survey can be 
compared only in a general way with the historical assertion about “450” general purpose 
languages as a practical illustration of what is happening in the DoD environment. 

1.5 Scope 

The results of this survey are drawn from a limited sample of DoD weapon systems 
and AISs; therefore, the survey does not provide an exact and detailed record of computer 
programming language usage in the DoD. Several constraints affected the precision of the 
results: 

• The study’s sponsors were primarily interested in knowing the primary languag¬ 
es being used in DoD. A detailed, comprehensive inventory of computer pro¬ 
gramming language usage in the DoD was not called for. Therefore, the 
following types of software were partially or wholly excluded from the survey: 

- Software being developed at Service and DoD research laboratories 

- Software being developed for highly classified systems 

- Commercially purchased software 
Firmware 

- Software funded by Operations and Maintenance (O&M) 

- Software below the funding level for Presidential budget-line identification 

• The effort required by respondents to complete the survey form was to be min¬ 
imized. Therefore, trade-offs were made in the amount and detail of information 
requested. 

• The resources available for the conduct of the survey were limited. 

1.6 Organization 

A description of the methods used to identify the survey population and sample is 
found in Section 2. A profile of the survey respondents is presented in Section 3. Analysis 
of the programming language data obtained by the survey is provided as findings in Section 
4. Section 5 summarizes the conclusions drawn from survey results. Section 6 contains the 
recommendation. Appendix A contains the survey instrument and Appendix B provides the 
data obtained during the survey. We have provided as much detail as possible about the 
method and response data with the intent of providing a documented baseline for future 
language studies. 




2. SURVEY METHOD 


Several approaches to conducting the survey were initially considered. These 
approaches are briefly discussed below before describing in detail the selected approach. 

A comprehensive DoD data call was considered, involving a formal request for 
specific data elements throughout the DoD. This approach was rejected because it would 
have encompassed a great deal of effort on the part of operational organizations whose 
primary mission is readiness. Historically, the response rate has been low to data calls for 
information that is not directly related to assigned missions. 

Another approach involved reviewing several automated databases that contain 
programming language information on DoD systems. Several of these databases were 
examined as part of this study, but none were able to provide the information required. It 
was also difficult to determine the lineage and accuracy of the data. Therefore, these 
databases were not used as part of the present study. 

The approach that was chosen involved direct contact with the organizations 
responsible for developing or maintaining systems that contain software. This section 
provides a detailed description of this approach, including the survey populations and 
samples, trade-offs made in designing the data collection form, the method used in 
contacting potential respondents, the methods for handling erroneous response data values, 
and the methods for analyzing the survey results. 

2.1 Population Identification 

We recognize that a census population of software would include systems that are 
new or undergoing major modernization and software in a steady state of maintenance. 
Software being maintained is a collection of applications that are difficult to identify 
because they are aggregated under operational costs. After a trial effort, we could see 
clearly that the estimated time and effort to approximate a census population would exceed 
the targets agreed for this survey effort. Consequently, we identified a judgement 
population as described in the next sections. 



2.1.1 Weapon Systems Population 

Weapon systems include aircraft, ships, tanks, tactical and strategic missiles, smart 
munitions, space launch and space-based systems, command and control (C2), and 
command, control, communications (C3), and intelligence (C31) systems. For the purposes 
of this survey, weapon system software is considered to comprise embedded, C3, and C31 
systems, as well as any other software that directly supports or is critical to a weapon 
system’s mission [STSC 1994]. 

Four acquisition categories (ACAT) are defined for weapon systems by DoD 
Instruction 5000.2 [DoDl 1991, pp. 2-2-2-4]: 

• Acquisition Category I is for major defense acquisition programs with eventual 
Research, Development, Test and Evaluation (RDT&E) expenditures of more 
than $300 million and eventual procurement costs of more than $1 billion (in 
FY90 constant dollars). 

• Acquisition Category II is for major systems with eventual RDT&E 
expenditures of more than $115 million and eventual procurement costs of more 
than $540 million (in FY90 constant dollars). 

• Acquisition Categories III and IV are for programs not meeting the criteria for 
ACAT I and II. These programs do not have specific expenditure profiles and 
exist to allow different levels of reporting. 

2.1.2 Automated Information Systems Population 

An Automated Information System (AIS) can be functionally described as follows: 

A combination of computer hardware and computer software, data and/or 
telecommunications, that performs functions such as collecting, processing, 
transmitting, and displaying information. Excluded are computer resources, 
both hardware and software, that are: physically part of, dedicated to, or 
essential in real time to the mission performance of weapon systems; used 
for weapon system specialized training, simulation, diagnostic test and 
maintenance, or calibration; or used for research and development of 
weapon systems. [DoDI 1993] 

These systems are often categorized as automatic data processing systems that are 
designed to meet specific user requirements for business functions (e.g., transaction 
processing, accounting, statistical analysis, or record keeping) and they are implemented 
on general purpose computers, including personal computers. 


6 




An authoritative source for a complete inventory of existing AISs could not be 
identified. Given the time and effort constraints placed on this study, the list of 53 
designated major AISs was used as the AIS survey population [OASD 1994], A major AIS 
is defined as one that is not a highly sensitive, classified program (as determined by the 
Secretary of Defense), and that according to DoDI 8120.1, the instruction on life cycle 
management of AISs [DoDI 1993], is characterized by the following: 

• Has anticipated program costs, computed in FY 1990 dollars, in excess of $ 100 
million; or 

• Has estimated program costs, computed in FY 1990 dollars, in excess of $25 
million in any single year; or 

• Has estimated life-cycle costs, computed in FY 1990 dollars, in excess of $300 
million; or 

• Is so designated by the milestone decision authority. 

2.2 Sample Selection 

The approach used in selecting the sample from the population of weapon systems 
and AISs is described in the next section. 

2.2.1 Weapon Systems Sample 

A close approximation of the population of existing weapon systems was found in 
a commercially available publication [Carroll 1994]. This publication provided a list of 
over 1,300 RDT&E and procurement programs for all Services and DoD Agencies. The 
list, called the Program Management Index (PMI), was based on the President’s 1994 
budget request and identifies all RDT&E programs with current or future fiscal budgets 
exceeding $15 million and procurement programs with total budgets of more than $25 
million. 

The PMI contains a number of programs that do not develop or maintain software 
for a weapon system (e.g., ammunition programs, medical research, biodegradable 
packaging technology) and lacks some programs that would have been of interest such as 
intelligence systems, highly classified programs, and programs below the budgetary 
thresholds cited. The PMI was then reviewed to eliminate programs that were obviously 
outside of the population of interest. For example, programs such as 25MM Ammunition 
Development, Health Hazards of Military Material, and Petroleum Distributions were 
eliminated from the population. Also eliminated were basic and applied research programs 





that involve technology years away from being fielded. While these programs often involve 
small amounts of prototype software development, the scope of the survey constrained the 
size of the survey sample. 

Each of the programs remaining in the PMI list was briefly examined to characterize 
the likelihood of being a weapon system. Weapon systems such as aircraft, ships, and tanks 
were (usually) easily identifiable. However, many of the programs required additional 
effort to determine their relevance to the population. For example, the AN/BSY-2 is an 
RDT&E project. Unless one is familiar with the AN/BSY-2 project, it is not immediately 
clear that it is the combat system for the Seawolf submarine and contains an aggregate of 
several million lines of software. 

Of the 423 programs selected from the PMI list to form the survey sample, 142 were 
eliminated from the sample after we found that they had been cancelled or were combined 
with another program, or contained no software. The remaining 281 programs included 
most of the typical weapon platforms (e.g., aircraft, ships, submarines, tanks) and many of 
the sensors, communication systems, and weapon subsystems. 

2.2.2 Automated Information Systems Sample 

Of the 53 AISs on the original list, 2 have been cancelled, 4 were primarily 
acquisitions for hardware and commercial off-the-shelf (COTS) software, 5 have not begun 
to develop software, and 4 programs had no current program manager name and telephone 
number. The survey sample of AISs for this study, therefore, consists of the remaining 38 
major AISs. 

2.3 Data Collection Form 

A data collection form was designed for this survey to reduce respondent error and 
to present technically accurate language choices. Because data was to be collected on five 
different programming language generations, definitions of these language generations 
were adapted from the ANSI/IEEE Standard Glossary of Software Engineering 
Terminology [ANSI/IEEE 1990] with advice from Ms. Jean Sammet, language historian. 
These definitions were provided on the form as follows: 

• A first generation language is the same as a machine language, usually 
consisting of patterns of 1 ’s and O’s with no symbolic naming of operations or 
addresses. 

• A second generation language is the same as assembly language. 




• A third generation language is a high order language that requires relatively 
little knowledge of the computer on which a program will run, can be translated 
into several different machine languages, allows symbolic naming of operations 
and addresses, provides features designed to facilitate expression of data 
structures and program logic, and usually results in several machine instructions 
for each program statement 

A special purpose language is used for special-purpose application areas 
such as robotics, machine tool control, equipment testing, civil engineer¬ 
ing, and simulation. Special purpose languages are a subset of third genera¬ 
tion languages. 

• A fourth generation language is designed to improve the productivity achieved 
by high order (third generation) languages and, often, to make computing power 
available to non-programmers. Features typically include an integrated 
database management system, query language facility, report generator, screen 
definition facilities, graphics generators, decision support capabilities, and 
statistical analysis functions. Fourth generation languages are usually available 
as components of a COTS software package. 

• A fifth generation language incorporates the concepts of knowledge-based 
systems, expert systems, inference engines, and natural language processing. 

Languages were grouped on the data collection form by these generations and listed 
by name and version within the third generation languages category. We decided not to ask 
for name and version of first, second, fourth, and fifth generations because supplying that 
type of data would require an inordinate amount of research effort for respondents to 
provide and for us to validate. 

An overriding concern for the data collection form was to keep it as simple as 
possible. Data collection forms that are lengthy or require a great deal of effort to complete 
are less likely to be completed and returned. Thus, the following design decisions were 
made with respect to the data collection form: 

• Survey respondents were allowed to choose the level of abstraction addressed 
by their response(s). Ideally, we would have liked to obtain a single response 
covering a single weapon system or AIS. However, many weapon systems are 
composed of subsystems that are separate procurement programs being 
developed or maintained concurrently by different contractors. These 



contractors and their sub-contractors may differ from one another in their choice 
of programming languages and dialects, depending upon the component(s) 
being developed or maintained. Because of the likely difficulty in requiring 
single-system reporting, survey respondents were asked to complete the data 
collection form at the level of abstraction that was the most convenient for them. 
Respondents were asked to photocopy the data collection form and return 
multiple copies if they provided data for more than one system or subsystem. 

• Where possible, a list of allowable values was provided so that the respondent 
could simply place a check mark by the appropriate value. For example, rather 
than asking the respondent to write the name of the system life-cycle phase, the 
allowable values were provided on the data collection form. Such lists also 
reduced the likelihood of obtaining invalid data responses. 

• Where practical, ranges were used instead of requesting exact values. Ranges 
were used for the estimation of total source lines of code (SLOC) and for the 
amount of software developed or maintained per programming language. The 
use of ranges reduces the precision of the survey results (e.g., the SLOC totals 
will be partially based on an estimation procedure). However, the reduction in 
precision was considered justified in terms of the corresponding decrease in 
effort for filling out the survey form. 

• The temptation to ask for more information than absolutely needed was resisted. 
A number of interesting data elements were considered for inclusion in the data 
collection form but rejected because they were not essential and would increase 
the effort and time needed to complete the form. This concern also led to the 
decision to ask for the versions of third generation languages only. 

The key information desired from each survey respondent included the following 

• A list of all third generation languages (by version) being used in the 
development or maintenance of operational and support software for the system 
of interest. 

• For each programming language listed, an estimate of the percentage that 
language represents in terms of the total amount of software being developed or 
maintained. We suggested that the percentage be derived from SLOC since 
most DoD programs track the amount of software using this measure. However, 




alternative methods of determining the percentage (e.g., function points) were 
allowed, as indicated on the questionnaire itself. 

• An estimate of the total amount of software being developed or maintained for 
the program/system. Again, we suggested using SLOC for this estimate. 

Secondary information desired from each survey respondent included the following 

items: 

• The amount of first, second, fourth, and fifth generation software being 
developed or maintained. 

• The number of distinct assembly languages being used in system development 
or maintenance. 

• A list of any third generation special purpose languages being used to develop 
or maintain software (e.g., equipment checkout languages such as ATLAS). 

• The acquisition category assigned to the program/system. 

• The system life-cycle phase of the program/system. 

A pilot survey was conducted using a preliminary version of the data collection 
form. Improvements were made according to suggestions made by several respondents as 
well as by analysis of their responses. Appendix A provides a copy of the final data 
collection form. 

2.4 Contact Process 

The process for contacting potential survey respondents for weapon systems and 
AISs differed only in the means by which telephone numbers were obtained. For weapon 
systems, the PMI list provided the name and telephone number of each weapon system 
program manager. For AISs, the Office of the Secretary of Defense official responsible for 
oversight of that AIS was contacted to provide the name and telephone number of the AIS 
program manager. 

The purpose of the survey was described upon contacting each potential 
respondent. Suggestions for filling out the form were provided and the form was then faxed 
to the potential respondent. If a response was not received after three weeks, a follow-up 
call was placed. 



2.5 Respondent Errors 

Some data collection forms were not completely or accurately filled out by survey 
respondents. For example, respondents may have omitted the Acquisition Category 
because it was not known to the respondent or was overlooked. The most common instance 
of inaccurate responses was that two different programming languages were listed as being 
used for over 75% of the system. If the correct data was not immediately obvious, the 
respondent was either contacted for the correct data or the values reported for the data 
element were excluded from our analysis and logged as a non-response. Graphic displays 
of survey results in the next section show these errors as “data not available.” 

2.6 Analysis Process 

The process for estimating the total number of SLOC addressed by this survey is 
now described. As discussed in Section 2.3, respondents were not requested to provide an 
exact SLOC count for their response. Rather, they were asked to select from a range of 
“Total Source Lines of Code.” A uniform procedure for estimating the SLOC represented 
by each survey response form was developed. Table 1 provides the Total SLOC ranges on 
the response form and the corresponding SLOC count assigned to each range. For example, 
if the ‘T00-500K” range was checked on the response form, 300K was used as the total 
SLOC covered by the response form. The SLOC sizes in the “Value Assigned” column in 
Table 1 were subjectively assigned. However, if an exact SLOC count was provided on the 
response form, that count was used in place of an estimate. The total SLOC addressed by 
this survey was therefore derived by summing the estimated SLOC (or in some cases the 
exact SLOC) from each response form. Values assigned in Table 1 were subjectively 
assigned for the top and bottom ranges; the midpoint was used for other ranges. 


Table 1. Values Assigned to SLOC Range Estimates 


“Total SLOC” Range 
Marked on Response Form 

Value Assigned 

1-1OOK 

75K 

100-500K 

300K 

500-1,000K 

750K 

1,000-5,OOOK 

3,OOOK 

5,000h-K 

6,OOOK 


Respondents were also requested to provide the percentage of the total system 
written in each applicable language. Ranges were available to identify this percentage. 
















Table 2 provides the “% of Total” ranges on the response form and the corresponding 
percentages assigned to each range. For example, if “5-25%” was checked for Jovial 73, 
15% was used as the percentage of the total system written in Jovial 73. If an exact 
percentage was provided on the response form, that percentage was used in place of an 
estimate. For each response, the SLOC for each language was derived by multiplying the 
total SLOC count (see Table 1 on page 12) by the estimated percent of total system written 
in that language. 


Table 2. Values Assigned to Language Percentage Estimates 


“% of Total” System Marked 
on Response Form 

Value Assigned 

<5% 

2.5% 

5-25% 

15.0% 

25-50% 

37.5% 

50-75% 

62.5% 

>75% 

87.5% 


The problems in using SLOC as a means of measuring the amount of software are 
well publicized [Jones 1991]. It is unlikely that respondents would have provided much 
data had specific methods for counting SLOC been required. Therefore, survey respondents 
were allowed to provide SLOC range estimates using their method for counting SLOC. 
Clearly, non-uniform methods for counting SLOC reduces the precision of the SLOC- 
related portions of the survey. However, this trade-off does not detract from the primary 
purpose of the survey (i.e., to produce a count of programming languages being used in the 
DoD today). 




3. RESPONDENT AND PROGRAMMATIC PROFILE 


Before presenting the survey results, it is important to realize that the level of 
abstraction of survey responses varies (see Section 2.6 to understand the rationale for this 
decision). For example, some responses describe an entire weapon system (e.g., the V-22 
Osprey), other responses describe different versions of a weapon system (e.g., the Standoff 
Land Attack Missile (SLAM) Baseline and the SLAM Upgrade), while other responses 
describe major subsystems resident within a weapon system (e.g., seven subsystems on the 
C/KC-135). Consequently, there is not a one-to-one mapping between a survey response 
and a single weapon system. Therefore, survey results are presented in terms of responses, 
not “programs” or “systems”. 

The survey data collection form was structured to provide the Service and Agency 
distribution of respondents as the demographic data of interest to DoD. Attributes being 
surveyed included the acquisition cost category and the life-cycle phase. This section 
presents observations from the weapon system and AIS responses. 

3.1 Weapon System Responses 

The distribution of the weapon system responses in terms of Service participation, 
acquisition category, and acquisition phase are presented for information purposes only. 

3.1.1 Services 

Figure 1 presents the distribution of responses by Services. TTie sample of programs 
selected was not evenly distributed among Army (19%), Navy (50%), and Air Force (26%); 
consequently, nearly half of the responses were from the Navy. The “Other” category 
represents responses from the Ballistic Missile Defense Organization, Defense Logistics 
Agency, and Defense Information Systems Agency. 

3.1.2 Acquisition Category 

Figure 2 presents the distribution of acquisition categories for the weapon system 
responses. The largest percentage of responses were from ACAT I programs, with ACAT 
III close behind. 



4% 


2 % 



^ Army 

• 

n Air Force 


1 Navy 


ID Marines 

• 

S Other 



Figure 1. Distribution by Service for Weapon System Responses 


26% 


17% 



14% 


■ Acquisition Category I 
Dl Acquisition Category II 
^ Acquisition Category III 
S Acquisition Category IV 
D Data not Available 


22 % 


Figure 2. Distribution by Acquisition Category for Weapon System Responses 


16 





3.1.3 Acquisition Phase 

Figure 3 presents the distribution of acquisition phases for the weapon system 
responses. The Engineering & Manufacturing Development and Production & Deployment 
phases combine to represent 79% of the total number of responses. 


3% 3% 


49% 



30%. 


in Concept Exploration 

^ Demonstration/Validation 

H Engineering and 

Manufacturing Development 

I Production and Deployment 

B Major Modification 

Q Data not available 


Figure 3. Distribution by Acquisition Phase for Weapon System Responses 


3.2 AIS Responses 

The distribution of the AIS responses in terms of Service participation and 
acquisition phase are presented for information purposes only. Acquisition category is not 
defined by the same rules as for weapon systems. The data collected from the survey forms 
has been omitted here because it was considered unreliable (e.g., over half of the 
respondents did not report acquisition cost category). 

3.2.1 Services 

Figure 4 presents the distribution of Services contributing to the major AIS survey. 
The “Other” category includes the Defense Information Systems Agency and Defense 
Logistics Agency. There were no Marine Corps AISs in the survey samples. 


































15% 



39% 


M Army 
n Air Force 
I Navy 
§ Other 


31% 


Figure 4. Distribution by Service for AIS Responses 
3.2.2 Acquisition (Life-Cycle) Phase 

Life-cycle phases for AISs are defined by DoDl Instruction 8120.1 [DoDI 1993]. 
Figure 5 presents the distribution of life-cycle phases reported by the major AISs surveyed. 


3%3% 



58% 


m Concept Exploration 
Q Development 
I Production and Deployment 
S Operational Support 
ni Data not available 


Figure 5. Distribution by Acquisition Phase for AIS Responses 


18 










































4. LANGUAGE USAGE FINDINGS 


4.1 Weapon System Findings 

Finding 1: Most weapon system software is being written and maintained in 
(general and special purpose) third generation languages. 



Figure 6. Total SLOC by Language Generation for Weapon System Responses 

More than 150 million SLOC (i.e., 81%) of the weapon system software surveyed 
is written in third generation languages. Without historical data similar to Figure 6, trends 
such as the changing emphasis on particular language generations cannot be adequately 
identified. However, it is very likely that over the past 20 years there has been a gradual 
decline in the use of machine and assembly languages and a corresponding increase in third 
generation languages. 

Table 3 on page 20 provides a numerical presentation of the same data as Figure 6. 
Table 4 lists the estimated total surveyed SLOC for each third generation language. The 



Total SLOC Reported column in Table 3 and Table 4 has been rounded to the nearest 
million. 


Table 3. Total SLOC by Language Generation for Weapon System Responses 


Language Generation 

Total SLOC Reported 
(in millions) 

First 

3.90 

Second 

26.30 

Third 

General Purpose 

148.38 

Third 

Special Purpose 

3.70 

Fourth 

5.00 

Fifth 

0.29 


Table 4. Total SLOC by General Purpose 3GL for Weapon System Responses 


Third Generation Language 
and Version 

Total SLOC Reported 
(in millions) 

Ada 83 

49.70 

C89 

32.50 

Fortran pre-91/92 

18.55 

CMS-2 Y 

14.32 

Jovial 73 

12.68 

C++ 

5.15 

CMS-2 M 

4.23 

Other 3GLs 

3.38 

Pascal pre-90 

3.62 

Jovial pre-J73 

1.12 

Fortran 91/92 

1.00 

PL/I 87/93 subset 

0.64 

Basic 87/93 (full) 

0.48 

PL/I 76/87/93 

0.36 

Pascal 90 (extended) 

0.29 

Basic 78 (minimal) 

0.17 

LISP 

0.10 

Cobol pre-85 

0.09 

Cobol 85 

0.00 

Total 

148.38 


20 






























































The following special purpose third generation languages were also reported 
(Table 5). 

Table 5. Third Generation Special Purpose Languages 


Language 

Purpose 

SLOC 

ATLAS 

Equipment Checkout 

1.38 

VHDL 

Hardware Description 

0.18 

CDL 

Hardware Description 

0.22 

GPSS 

Simulation 

0.04 

Simulink 

Simulation 

0.06 

CSSL 

Simulation 

0.01 

ADSIM 

Simulation 

0.02 

SPL/1 

Signal Processing 

1.62 

SPL 

Space Programming 

0.01 


Respondents were provided space on the data collection form to identify any 
programming languages being used that were not already listed. These languages formed 
the “Other 3GLs’’ noted in Table 4 on page 20, and included the languages listed in Table 5 
and Table 6. 


Table 6 . Third Generation “Other” Languages 


Language 

Purpose Unverified 

DTC 


LISA 

Language for Systolic Array Processor 

PIL 

HARM Program Implementation Language 

PLM 


PLM-51 


PLM-86 


Pspice 


REXX HOL 


TACL TSC 


VTL 



21 





Finding 2: Ada is the leading third generation language in terms of existing 
weapon system source lines of code. 


50 
45 
40 
35 
30 

Total SLOC 
(in miUions) 2 q 

15 
10 
5 
0 

pre-91/92 J73 

Third Generation Languages 

Figure 7. Top Five 3GLs by Total SLOC for Weapon System Responses 

Figure 7 presents the top five third generation languages in terms of estimated total 
SLOC surveyed. Survey responses reported an estimated 49+ million SLOC in Ada and 
32+ million SLOC in C. These five languages represent about 84% of the total estimated 
third generation SLOC reported. 



22 




Finding 3: Ada is the leading third generation language in terms of number 
of weapon system responses indicating usage. 



General Purpose Third Generation Languages 


Figure 8. Top Five 3GLs by Reported Usage for Weapon System Responses 

Figure 8 presents the top five third generation languages in terms of the number of 
responses reporting specific language use. As can be seen, 143 responses indicated the use 
of Ada and 122 responses indicated the use of C. In comparing Figure 7 and Figure 8, the 
key difference is the more frequent reported use of C++, albeit with fewer total estimated 
surveyed SLOC. Note that the data presented in Figure 7 do not represent a uniform 
population (i.e., survey responses address varying levels of abstraction). See Section 2.6 for 
details. 



Finding 4: Two-thirds of the weapon system responses reported on 
application systems of500,000 or less SLOC. 

140 
120 
100 
80 

No. of Weapon 
Responses 

40 
20 
0 

499+K 999+K 4,999+K available 

Total SLOC 

Figure 9. Distribution of Total SLOC Size for Weapon System Responses 

Figure 9 presents the distribution of responses in terms of the Total SLOC range 
selected on the response form. The large number of 1 -499+K responses is due, in part, to 
responses at the subsystem level. 




Finding 5: Over 70% of the weapon system responses indicated the use of 
more than one programming language from all five generations. 



Figure 10. Distribution of Number of Languages Reported by 
Weapon System Responses 

Figure 10 presents the distribution of responses in terms of the number of languages 
reported on a response form (single subsystem or system). 


25 





Finding 6: Multiple versions of third generation languages are being used 
in weapon systems. 



Figure 11. Comparison of 3GLs with Multiple Versions for 
Weapon System Responses 

The goal of the 1970s, language commonality within the weapon system 
community, has not been reached yet even for military standards such as Jovial and CMS- 
2 (Figure 11). In addition, at least two versions are being used for most Federal Information 
Processing Standards (FIPS). Different versions of a language are almost always 
incompatible. Dialects of a version present subtle but not inconsequential porting 
problems, particularly when they are dialects based upon older versions of the language. 
For example, there are 10 or more different dialects of pre-J73 Jovial still in use. 




4.2 AIS Findings 

Finding 7: Most AIS software is being written and maintained in third generation 
languages. 



Language Generation 

Figure 12. Total SLOC by Language Generation for AIS Responses 

Figure 12 is the SLOC distribution of all generations of languages used in AIS 
application. Table 7 is the numeric presentation of Figure 12. The use of first generation 
language (machine language) is limited to only one of the AISs. The use of assembly 
(including proprietary macro languages) is inconsequential when compared to weapon 
system applications. 


27 



Table 7. Total SLOC by Language Generation for AISs 



Language Generation 

Total SLOC Reported 
(in millions) 

First 

0.30 

Second 

0.63 

Third 

General Purpose 

38.24 


Special Purpose 

0.00 

Fourth 

10.81 

Fifth 

0.05 



Table 8 is the SLOC estimates in millions for third generation languages. 


Table 8. Total SLOC by 3GL for AISs 



Third Generation 
Language / Version 

Total SLOC Reported 
(in millions) 

Cobol 85 

14.06 

Cobol pre-85 

8.59 

Ada 83 

8.47 

Basic 87/93 

2.18 

C++ 

2.05 

C89 

1.55 

Fortran 91/92 

0.87 

Fortran pre-91/92 

0.47 

Total 

38.24 




28 









































Finding 8: Cobol is the leading third generation language in terms of 
existing AIS source lines of code. 



pre-85 87/93 

Total SLOC 

Figure 13. Top Five 3GLs by Total SLOC for AIS Responses 

Figure 13 presents the top five third generation languages in terms of estimated total 
SLOC reported. Survey responses reported an estimated 22 million SLOC in two versions 
of Cobol and about 8 million SLOC in Ada. These five languages represent about 89% of 
the total estimated third generation SLOC reported. 


29 





Finding 9: Ada is the leading third generation language in terms of number 
ofAlS responses indicating usage. 


No. of Major 
AIS Responses 



pre-85 85 

Third Generation Languages 


Figure 14. Top Five 3GLs Reported by AIS Responses 


Figure 14 shows that the use of Ada was reported by more respondents, although 
the number of lines of source code written in Ada is less than for Cobol. 


30 





Finding 10: Most of the AIS responses reported on application systems are 
in the range of 1OOK-5,000K SLOC. 

12 
10 
8 

No. of Major 
AIS Responses ^ 

4 
2 
0 

Total SLOC 

Figure 15. Distribution of Total SLOC Size for AIS Responses 

Figure 15 depicts that 85% of the responses are evenly distributed in the mid-size 
range of applications. 





31 




Finding 11: Ninety percent of the AISs surveyed indicated the use of one or 
more third generation programming languages. 



Figure 16. Distribution of Number of 3GLs Reported by AIS Responses 


The first column in Figure 16 showing no use of third generation languages 
indicates that some applications are developed only with fourth generation languages. 
Fourth generation languages for such applications as database query, report writing, and 
screens are not applicable to weapon system applications except in the support activities 
required to construct or maintain applications. 


32 




Finding 12: Multiple versions of third generation languages are being used 
in AISs. 


No. of Major 
AISs 



3GLs with Multiple Versions 


Figure 17. Comparison of 3GLs with Multiple Versions for AIS Responses 

Figure 17 indicates that Cobol 85, the current FIPS version, has not had a significant 
effect on AIS applications, and that older versions of Fortran exceed the number of 
applications written in the current version. 



5. CONCLUSIONS AND DISCUSSION 


This survey is not a universal census of weapon systems and AISs but the results 
reported do represent a substantial and visible portion of the population. Even though the 
sample size was constrained by available time and resources, a systematic method was used 
and documented so that others who care to extend the sample size at a later date will be able 
to obtain results that are consistent with the language counting method used in this survey. 
The responses received represent over 60% of the programs contacted. We have drawn the 
following conclusions about programming languages currently used in the DoD, based 
upon findings from the survey: 

Conclusion 1: The estimated 237.6 million SLOC in this survey are distributed among the 
five generations of programming languages currently used. The largest 
and most significant group of programming languages in SLOC is third 
generation languages which consist of 37 languages. In this group, there 
are 18 general purpose languages (including separate counts for differing 
versions of major languages as shown on the survey form), 9 special 
purpose languages (a subset of third generation languages), and 10 
unclassified languages. 

The issue of how to count languages makes this conclusion open to some level of 
debate. There are many dialects of a language version that some may choose to count as 
unique languages. If we accept the historical assertion that at least 450 third generation 
languages were used in the late 1970s, we can see that considerable progress has been made 
toward reducing the number of programming languages used in DoD. 


Conclusion 2: Ada 83 is being used in weapon system software and AISs that are being 
modernized. Using SLOC as a measure of usage, Ada ranks first (ref. 



Table 4 on page 20) in weapon systems. In AISs, Ada 83 has not replaced 
Cobol (ref. Table 8 on page 28). 

The fact that Ada usage is not greater in DoD could be due to several factors. First, 
production quality Ada compilers and development tools were not available immediately 
after the language was adopted as a standard. There was a lag-time of four to five years 
before compiler vendors could offer choices of Ada environments for high performance 
host/target machines. Second, there is always inertia to overcome before change can occur 
and the resistance of the DoD software development community to DoD policy toward the 
use of Ada perpetuated that inertia. And third, it takes time to educate and train software 
engineers and managers to understand the language and to use it effectively. 

There is an unknown quantity of legacy software being maintained by software 
support activities that modify code and/or provide data processing service. Many of these 
software applications were developed by contractors and are being maintained by the 
government using the language versions and dialects chosen by the development 
contractor. The constraints on this survey precluded our being able to systematically collect 
a sample from the software maintained by O&M budgets. However, we speculate that 
languages used in the maintenance community include more use of second generation 
languages (assembly) and older versions of third generation languages. 

Conclusion 3: The usage of first generation language (machine) in both weapon systems 
and AIS applications is insignificant (ref. Table 3 on page 20). 

The existence of first generation language (machine) is almost certainly due to the 
continued maintenance of fairly old legacy hardware and software. It is highly unlikely that 
future new software will be written in first generation languages, considering the target 
computer systems which will be candidates for modernization. 

Conclusion 4: Second generation language (assembly) is being used in both weapon 
systems and AIS applications and will likely continue in minimal use. 

To some extent, the use of second generation languages (assembly) is also due to 
the continued maintenance of legacy software. However, there are specific reasons, other 
than historical ones, that have necessitated the use of second generation languages. One of 
these reasons is special purpose hardware and, in this case, the need for second generation 
languages wiU almost certainly continue. Another reason is performance. Ten or more 
years ago, many systems used second instead of third generation languages for those parts 




36 




of the system that were time critical. Although the performance of modern third generation 
languages, such as Ada or C, can meet many such performance issues now, it is likely that 
minimal use of assembly language will continue for some time for its real or perceived 
performance properties. However, this wiU become less of a problem as better software 
engineering techniques are used in code generation. 

Conclusion 5: The use of fourth generation languages is greater in AIS applications than 
in weapon system applications. 

AIS applications have used fourth generation languages as database management 
products, graphical user interfaces, and shrink-wrapped tools have been acquired to 
improve user services. The SQL standard has not only promoted relational database 
products but has provided an alternative to the continued use of proprietary languages for 
data access. The modest use of fourth generation languages by the weapon system 
community could indicate that COTS products are seldom used to develop software or that 
the respondents did not consider the development environment as appropriate for this 
survey. 

Conclusion 6: Fifth generation (artificial intelligence) languages are hardly used in 
weapon system and AIS applications. 

There are several reasons for the very low usage of fifth generation languages. One 
reason is that the immaturity of fifth generation AI languages does not recommend their use 
in operational weapon systems. Other reasons could be the lack of exploratory R&D 
programs in the sample or that many AI problems are being solved with third generation 
languages. 

Conclusion 7: In both weapons system and AIS applications, the data shows that older 
versions of programming languages are being used. The perpetuation of 
applications written in these older versions can create portability and re¬ 
use problems. 

For example, the continued use of several versions of CMS2, Jovial, Fortran, 
Cobol, and platform/vendor unique languages may be motivated by short-term economic 
views. There are tools to aid in re-engineering and conversion tools that makes 
reimplementing existing software more feasible and practical than to continue maintenance 
of this multi-version software. 



Conclusion 8: Both weapon system and AIS applications use several languages. 

Even if only one language were used, software commonality, portability, and 
interoperability would be imperfect. With modern programming languages and compilers, 
increased use of COTS products and re-use of software components, it is possible to 
produce applications with components written in different languages. Ada, with its 
specified pragma interfaces, is a language that is well suited to being used with other 
languages in multi-language applications. 




6. RECOMMENDATION 


Accepting the number of 450 or more general purpose programming languages in 
use in the 1970s, we can see considerable progress has been made by the Military 
Departments and Agencies in reducing the number to 37 in major systems that are new or 
being modernized. Yet the survey indicates that a substantial legacy of applications remain 
that use older versions of programming languages, vendor-unique languages, and military- 
defined languages. The maintenance costs for these applications could be reduced and their 
reliability increased by converting these applications to a current version of a Federal 
Information Processing Standard language. Automated conversion methods should offer a 
cost-effective technology to facilitate this conversion. Re-engineering these applications in 
another language is also a cost reduction opportunity. Redundant code can be eliminated, 
software components can be re-used, and modem off-the-shelf programming tools can be 
used to improve maintainability and reliability. 

Consequently, we recommend that Service and Defense Agency Program Managers 
regularly review their software applications to identify a migration strategy and plan for 
upgrading them to current versions of standards-based versions of languages and modem 
labor-saving tools. The progress in reducing the number of languages used, as shown in this 
survey, indicates that further reduction should be possible. Indeed, we recognize that 
several migration efforts are already ongoing now. 



APPENDIX A. SURVEY INSTRUMENT 


The data collection form used in the survey is provided in the pages that follow. Two 
minor changes to the “System Life-Cycle” portion of the data collection form were made 
to tailor it for the AIS survey; 1) Engineering and Manufacturing Development was 
replaced by Development, and 2) Major Modification was replaced by Operations and 
Support. 


Language Survey 


1. Name of Program:_ 

2. System Name (if different than above):_ 

3. Acquisition Category: I:_, II:_, IE:_, IV: 


4. System Life-Cycie Phase: 

Concept Exploration: 

DemonstrationA^alidation: 

Engineering and Manufacturing 
Development: 

Production and Deployment: 

Major Modification: 


5. Total Current Source Lines of Code: 

1,000-99,999: _ 

100,000-499,999: _ 

500,000-999,999: _ 

1,000,000-4,999,999: _ 

5,000,000+: 


Please complete the remaining portion of the form by indicating the programming 
languages currently being used in developing or maintaining all the software (e.g., 
operational, support) for this program/project. 

• For each language being used, estimate the amount of usage in the appropriate “% 
of Total” column. Most programs should use percentage of source lines of code 
compared to the total number of source lines of code. However, if your program 
uses a different method for this calculation (e.g., function points), use this 
percentage and make a note on page 4. 

• Most languages identified on page 2 have a year designation that refers to a specific 
language version. If you are unable to identify the specific version, please provide 
supportive information on page 4. 

• For second generation (assembly) languages, we are asking for a count of distinct 
versions being used. The “% of Total” column should be filled out for the aggregate 
of all assembly languages being used on your program. 

• Definitions for language generations are found on page 3. 

• If your language version is not listed, identify the version in the space provided on 
page 4. Provide any comments or additional information on page 4. 




Language Type 


Language Name and Version 


First Generation 


Machine 


% ofTotal 

<5% 

■5- : 
25 % 

50% 

50- 

75% 

>75% 


Second Generation ^sembly (Provide Count of Distinct 
Versions Being Used):_ 


Ada 83 


ALGOL 


APL89 


BASIC 


C89 


ALGOL 60 


ALGOL 68 


BASIC 78 (minimal) 


BASIC 87/93 (full) 


Third Generation 


C++ (identify version on page 4) 


CHILL 89 


COBOL pre-85 


COBOL 85 


CMS-2 Y 


CMS-2 M 


FORTRAN pre-91/92 


FORTRAN 91/92 


JOVIAL pre-J73 


JOVIAL J73 


LISP (identify version on page 4) 


MUMPS pre-90 


MUMPS 90 


Pascal pre-90 


Pascal 90 (extended) 


PL/I 76/87/93 


PL/I 87/93 subset 


PROLOG (identify version on page 4) 


SIMULA pre-67 


SIMULA 67 


Smalltalk (identify version on page 4) 


TACPOL 


Others: list and identify on page 4 


Fourth Generation e.g., SQL, RPG, Clipper, Visual BASIC 


e.g.. Knowledge/rule base shells 


COBOL 


CMS-2 


FORTRAN 


JOVIAL 


MUMPS 


Pascal 


SIMULA 


Fifth Generation 




























































Special Purpose Languages 


Application 

Area 

Generic Language 
Name 

Version Name and/or Number 

% of Total 

<5% 

25% 

: .25 - : 
50% 

50- 

^■75% : : 

>75% 

Equipment 

Checkout 

ATLAS 







Hardware 

Description 

VHDL 







CDL 







Simulation 

GPSS 







SMSCRIPT 







CSSL 







Signal 

Processing 

SPL/1 







Space 

Programming 

SPL 







Statistics 

SPSS 







SAS 







Robotics 

Languages 

AL 







AML 







KAREL 







Expert 

System 

Languages 

KRL 







OPS5 








The following definitions are provided for language generation; 

• k first generation language is the same as a machine language, usually consisting of patterns of I’s and O’s 
with no symbolic naming of operations or addresses. 

• A second generation language is the same as assembly language. 

• A third generation language is a high order language that requires relatively little knowledge of the 
computer on which a program will run, can be translated into several different machine languages, allows 
symbolic naming of operations and addresses, provides features designed to facilitate expression of data 
structures and program logic, and usually results in several machine instructions for each program 
statement. 

• A special purpose language is used for special-purpose application areas such as robotics, machine tool 
control, equipment testing, civil engineering, and simulation. Problem-oriented languages are a subset of 
third generation languages. 

• A fourth generation language is designed to improve the productivity achieved by high order (third 
generation) languages and, often, to make computing power available to non-programmers. Features 
typically include an integrated database management system, query language facility, report generator, 
screen definition facilities, graphics generators, decision support capabilities, and statistical analysis 
functions. Usually available as components of a commercial off-the-shelf software package. 

• A fifth generation language incorporates the concepts of knowledge-based systems, expert systems, 
inference engines, and natural language processing. 






































Please provide the language name, version, generation, application area (for special 
purpose languages) and a reference to the manual (i.e., title, date and publisher) for each 
programming language or version not listed on page 2 or 3. Provide any additional 
information that would prove useful in uniquely identifying the language. 


Language Name, 
Version, etc. 


Manual IPitie, Date, and Fubiisber 



Additional Comments 





APPENDIX B. SURVEY DATA 


This appendix provides the raw data collected during the survey. In order to provide 
respondent anonymity, the program/system names (Section B.l) have been separated from 
the remaining portion (Section B.2) of the survey data. A single dash (-) in a table cell is 
used to denote data elements that were not provided on the response form. Each row has 
been sequentially numbered in order to facilitate identification of specific rows. 




B.l List of Surveyed Program/System Names 

This section lists the “Program Name” and “System Name” taken verbatim from 
each survey response form. Section B.1.1 is the list of program/system names for the 
weapon system responses. Section B.1.2 is the list of program/system names for the AIS 
responses. 

B.1.1 List of Weapon Program/System Names 


Table B-1. Weapon Program/System Names 


No. 

Program Name 

System Name 

1 

A-10 Thunderbolt II Modification 

AFMSS 

2 

A-10 Thunderbolt II Modification 

CDU 

3 

A-10 Thunderbolt II Modification 

LASTE 

4 

A-10 Thunderbolt II Modification 

OTS 

5 

A/A47U-4A Reeling Machine Launcher 

Navy Standard Tow Target System 

6 

AC-130U Gunship 

- 

7 

AEGIS Simulation Program (ACSIS) 

Current 

8 

AEGIS Weapon System 

BL 1 (1983) 

9 

AEGIS Weapon System 

BNI60III 

10 

AGM-130 Powered GBU-15 

AFMSS Weapons Planning Module (WPM) 

11 

AGM-130 Powered GBU-15 

Automatic Pilot Computer Program 

12 

AGM-130 Powered GBU-15 

Horizontal Attack and Envelope Expansion 

13 

AGM-130 Powered GBU-15 

Improved Modular Infrared Seeker 

Producibility Program 

14 

AGM-130 Powered GBU-15 

MSS ll/A Mission Planning Module (MPM) 

15 

AGM-130 Powered GBU-15 

WPM Weapons Simulation Module 

16 

AGM-65H 

TV Maverick R&M 2000 Program 

17 

AGM-88A High Speed Anti-Radiation Missile 
(HARM) 

- 

18 

AH-1W Cobra Helicopter 

- 

19 

AH-64 Apache Attack Helicopter 

- 

20 

AH-64A Apache 

- 

21 

AN/ALE-47 Countermeasures Dispenser System 

- 

22 

AN/BSY-2 Submarine Combat System 

- 

23 

AN/SLQ-32(V) Electronic Warfare System 

- 

24 

AN/SSQ-53E Sonobuoy 

- 

25 

AN/TPS-59 TMD MOD KIT Upgrade 

- 

26 

AN/UDR13 Pocket Radiac 

- 









































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

27 

AOE6 

28 

AOE6 

29 

AQM-37C Aerial Target 

30 

ATCCS Common Hardware/Software (CHS) 

31 

AV-8B 

32 

AV-8B 

33 

AV-8B 

34 

AV-8B 

35 

AWIS Project Management Office 

36 

Advanced Airborne Radiac System 

37 

Advanced Amphibious Assault Vehicle (AAV) 

38 

Advanced Cruise Missile (ACM) 

39 

Advanced Deployable System (ADS) 

40 

Advanced Field Artillery System (AFAS) 

41 

Advanced Field Artillery Tactical Data System 
(AFATDS) 

42 

Advanced Spacecraft Technology Integration 

43 

Advanced Spacecraft Technology Integration 

44 

Advanced Spacecraft Technology Integration 

45 

Advanced Tactical Air Command/Control Center 
(ATACC) 

46 

Advanced Tank Armament System (ATAS) 

47 

Advanced Training System (ATS) 

48 

Air Defense Missile Systems 

49 

Air Defense Missile Systems 

50 

Air Traffic Control (ATC) Improvements 

51 

Airborne Low Frequency Sonar (ALFS) 

52 

Airborne Surveillance Testbed (AST) 

53 

All Source Analysis System (ASAS) 

54 

Armored Gun System 

55 

Armored Systems Modernization 

56 

Armored Systems Modernization 

57 

Armored Systems Modernization 


System Name 


Machinery Centralized Control System 
(MCCS) 


SIM/STIM System 



AV-8B Muxbus Data System (AMDS) 


Day Attack Mission Computer 


Night Attack Mission Computer 


Radar Mission Computer 



High Altitude Balloon Experiment (HABE) 


Liquid Metal Thermal Experiment (LMTE) 


Technology for Autonomous Operational 
Survivability (TAOS) 



Air Defense Communications Platform 


DoD Common Console (DDC) 



Abrams MIA2 


Advanced Tank Armament System (ATAS) 


Wide Area Munition (WAM) 


B-4 


























































































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

58 

Armored Systems Modernization 

Airborne Standoff Minefield Detection System 
(ASTAMIDS) 

59 

Army Tactical Missile System (ATACMS) 

BAT 

60 

Army Tactical Missile System (ATACMS) 

Block 1 

61 

Army Tactical Missile System (ATACMS) 

Block lA 

62 

Army Tactical Missile System (ATACMS) 

Block II with BAT 

63 

Avenger System 

- 

64 

B-1B Modification 

Conventional Mission Upgrade program 
(CMUP) 

65 

B-1B Weapon System Trainer 

- 

66 

B-52 Stratofortress Modifications 

Block II 

67 

B-52 Stratofortress Modifications 

ICSMS 

68 

BGM-74 Aerial Target 

- 

69 

Brilliant Eyes (BE) Space-Based Sensors 

- 

70 

C-141 

Aircrew Training System 

71 

C-17 

Maintenance Training Devices 

72 

C/KC-135 

Air Data Computer 

73 

C/KC-135 

Autopilot 

74 

C/KC-135 

Carousel IV Inertial Navigation System 

75 

C/KC-135 

Digital Engine Pressure Ratio Transfer 

76 

C/KC-135 

Fuel Savings Advisory System 

77 

C/KC-135 

Fuel System Advisory 

78 

C/KC-135 

Standard Flight Data Recorder 

79 

CV HELO Avionics 

SH-60F/HH-60H 

80 

Carrier Air Traffic Control 

AN/SPN-42 

81 

Carrier Air Traffic Control 

AN/SPN-46 

82 

Cheyenne Mountain Complex 

Command Center Processing and Display 
System - Replacement (CCPDS-R) 

83 

Cheyenne Mountain Complex 

Communications System Segment - 
Replacement (CSSR) 

84 

Cheyenne Mountain Complex 

Granite Sentry 

85 

Cheyenne Mountain Complex 

Space Defense Operations Center (SPADOC) 

86 

Cheyenne Mountain Complex 

Survivable Communications Integration 

System (SCIS) 

87 

Combat Service Support Control System 


(CSSCS) 


88 

Communications Automations 

VMACS (V5) 




























































Table B-1, Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

89 

Communications Automations 

VMACS II 

90 

Consolidated Automated Support System 
(CASS) 

- 

91 

Countermeasures Decoy Dispensing System 
TACAIR EW 

Fleet Airborne Electronic Warfare System 

92 

DMS 

AUTODIN Switching Center (ASC) 

93 

DMS 

Message Conversion System (MCS) 

94 

DMS 

Proof of Concept Network 

95 

Dual Mode Seeker 

- 

96 

E-2C (baseline) Group II 

L-304 CP (OL-424/ASQ) 

97 

E-2C 

Mission Computer Upgrade (MCU) 

98 

E-4B 

Automated Data Processing (ADP) System 

99 

E-4B 

Message Processing System 

100 

E-4B 

Super High Frequency (SHF) System 

101 

EA-6B Prowler 

- 

102 

ES-3A 

- 

103 

Electro-Optical Targeting Sensors 

Gunship Ballistic Winds Sensor 

104 

F-16 

NMC Blocks 30 40 and 50 

105 

F-16 

Non-NMC Blocks 30 40 and 50 

106 

F-22 

Air Vehicle 

107 

FAAD C2 Engineering Development Program 

- 

108 

FAAD Command & Control Engineering 
Development 

- 

109 

FAAD Ground Based Sensor 

MPQ64 

110 

FAAD Ground Based Sensor 

Simulation Support 

111 

Fixed Distributed System (FDS) 

Shore Signal & Information Processing 

Segment 

112 

Fleet Satellite Communications (FLTSATCOM), 
now UHF SATCOM Terminals 

Common User Digital Information Exchange 
System 

113 

HARM 

Command Launch Computer (CLC) 

114 

HARM 

Missile Software 

115 

HARM 

Simulation Software 

116 

HAVE P 

Baseline 

117 

HAVEP 

Mod for PEP 

118 

HAWK Air Defense System 

HAWK IIIA 

119 

HAWK Air Defense System 

HAWK IIIA Major Mod 














































































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

120 

HAWK Air Defense System 

Phase III Hawk System 

121 

lONDS (Integrated Operational Nudets Detection 
System) 

Integrated Correlation and Display System 

122 

lONDS (Integrated Operational Nudets Detection 
System) 

Nudet Detection System (NDS) 

123 

lUSS 

SOSUS 

124 

JAVELIN 

- 

125 

Joint Direct Attack Munition 

- 

126 

Joint Services Imagery Processing Systems 
(JSIPS) 

- 

127 

Joint Services/Navy Standard Avionics 
Components & Subsystems 

GPWS CAT 1 

128 

Joint Services/Navy Standard Avionics 
Components & Subsystems 

GPWS III HE/0 

129 

Joint Standoff Weapon (JSOW) 

Baseline 

130 

Joint Surveillance Target Attack Radar System 
(Joint STARS) 

- 

131 

Joint Tactical Information Distribution System 
(JTIDS) 

- 

132 

LANTIRN 

Navigation Pod 

133 

LANTIRN 

Target Pod 

134 

Line-of-Sight Anti-Tank (LOSAT) 

- 

135 

Link-16 Joint Tactical Information Distribution 
System (JTIDS) 

- 

136 

Longbow Apache 

- 

137 

M-1 Abrams Tank 

- 

138 

M-31 FCT 

SSST 

139 

MC-130H Combat Talon II 

- 

140 

MCS VI2 Prototype, Release 2 

- 

141 

MH-53E 

Mission Planning Station (MPS) 

142 

MH-53E 

Navigation/Communication System (NCS) 

143 

MH-60G Helicopter 

VSDS 

144 

MILSTAR Satellite Communications Systems 

Mission Planning Element 

145 

MILSTAR Terminals 

SCAMP (Single Channel Antijam Manportable 
Terminal) 

146 

MILSTAR Terminals 

SMART-T (Raytheon) 

147 

MILSTAR Terminals 

SMART-T (Rockwell) 





































































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

148 

MILSTAR 

Defense Satellite Communication System 
(DSCS), Generic Telemetry Simulator (GTS) 

149 

MILSTAR 

Defense Satellite Communication System 
(DSCS), Satellite Analyst Workstation 
(SAWS) 

150 

MILSTAR 

Defense Satellite Communication System 
(DSCS), Telemetry Gathering and Archiving 
System (TGAS) 

151 

MILSTAR 

MILSTAR Space Segment 

152 

MILSTAR 

- 

153 

MIM-72G (Rosette Scan Seeker) Missile 

Chaparral 

154 

MK-15 Close-in Weapons Systems (CIWS/ 
Phalanx) 

PHALANX Block 0 & Block 1, Baselines 0,1,2 

155 

MK-15 Close-in Weapons Systems (CIWS/ 
Phalanx) 

PHALANX Block 1 Baseline 2 W/HOLC and 
beyond 

156 

MK-30 Target Development 

MK 30 MOD2 ASW Training Target System 

157 

MK-30 Target Development 

MK 30 MOD2 ASW Training Target System 

158 

MK-48 Advance Capability (ADCAP) 

ADCAP Modifications (MO-OS) 

159 

MK-48 Advance Capability (ADCAP) 

- 

160 

MLRS Launcher 

Basic System 

161 

MLRS Launcher 

Extended Range MLRS, IFCS 

162 

MLRS Product Improvement Program 

Fire Direction Data Manager 

163 

MQM-8G (EER) 

Vandal 

164 

MQM-8G (ER) 

Vandal 

165 

Marine Corp Intelligence Analysis System 

IAS 

166 

MILSTAR 

- 

167 

Mine Hunter Costal (MHC) 

- 

168 

Mine Hunting Sonar System 

A/N 374-1 

169 

Mine Hunting Sonar System 

AMNSYS 

170 

Mine Hunting Sonar System 

AQS-20 

171 

Missile Simulation 

- 

172 

Multi-Role Survivable Radar 

- 

173 

Multifunctional Information Distribution System 
(MIDS) 

- 

174 

Multiple Launch Rocket System (MLRS) 

Terminal Guidance Warhead (TGW) 

Improved Fire Control System 

175 

Multiple Launch Rocket System (MLRS) 

Extended Range MLRS, BGSR Launcher 

176 

NCCS Ashore 

OSS 





















































































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

177 

NCOS Ashore 

TSC 

178 

NTDS Software Improvements/Advanced 

Combat Direction System (ACDS) Block 1 

- 

179 

Night Vision Combat Vehicles 

Second Generation Tank Sight 

180 

Non-Cooperative Target Recognition Electronic 
Support Measures (NCTR-ESM) 

ANA/SX-2 

181 

Noncooperative Identification Subsystems 

Combat ID Program - Hughes Aircraft 

182 

Noncooperative Identification Subsystems 

Combat ID Program - Inhouse 

183 

North Warning System 

Unattended Radar 

184 

OH-58D KIOWA Warrior 

Control/Display Subsystem Operational Flight 
Program 

185 

OH-58D KIOWA Warrior 

Mast Mounted Sight 

186 

Ocean Surveillance Information System Baseline 
Upgrade (OSIS OBU) 

- 

187 

P-3 Upgrade 

AN/USQ-78 

188 

P-3 Upgrade 

AN/USQ-78A 

189 

P-3 Upgrade 

CP-2044 (System Test Program) 

190 

P-3 Upgrade 

CP-2044 (Tactical Mission Software) 

191 

P-3 Upgrade 

CP-901 (Operational Program) 

192 

P-3C Sensor Integration 

Air Common Acoustic Processing (ACAP) 

193 

Patriot Air Defense Missile System 

Patriot Advanced Capability - 3 (PAC-3) 

194 

Phoenix 

AIM-54C Missile, Tactical Software 

195 

QF-4 Full Scale Aerial Target 

Airborne System Test Set 

196 

QF-4 Full Scale Aerial Target 

Automatic Flight Control Computer 

197 

QF-4 Full Scale Aerial Target 

Ground Station Simulator 

198 

QF-4N 

Fullscale Aerial Target (FSAT) 

199 


Fullscale Aerial Target (FSAT) 

200 

RAM 

Block 1 (IRMU) 

201 

RAM 

Guided Missile Launching System, MK 144 

202 

Radar Upgrade 

F/A 18 Radar Upgrade 

203 

S-3 Viking Modification 

S-3 Co-Processor Memory Unit, AYK-23 

204 

S-3 Viking Modification 

S-3 General Purpose Digital Computer AYK- 
10 

205 

SATCOM Ship Terminals, now EHF SATCOM 
Terminals 

- 

206 

SATCOM Ship Terminals, now SHF SATCOM 
Terminals 

- 



















































































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

207 

SSN-21 Seawolf Program 

Air Firing Valve Electronic System (AFVE) 

208 

SSN-21 Seawolf Program 

ANA/VLQ-4(V)1 

209 

SSN-21 Seawolf Program 

BSY-2 Combat System 

210 

SSN-21 Seawolf Program 

Circuit-D 

211 

SSN-21 Seawolf Program 

Data Distribution System 

212 

SSN-21 Seawolf Program 

Monitoring System 

213 

SSN-21 Seawolf Program 

Periscope System 

214 

SSN-21 Seawolf Program 

Ship Control System 

215 

SSN-21 Seawolf Program 

Weapons Storage and Handling 

216 

SOF Aircrew Training System (ATS) 

- 

217 

SOF Airdrop Advanced Development 

ATD for AALC, (GPADS) Guided Parafoil 

Aerial Delivery System 

218 

SOF Airdrop Advanced Development 

Draper Labs ACT II BAA, Parafoil GN&C 

219 

SSN-688 Los Angeles 

AN/BQQ-SE 

220 

SSN-688 Los Angeles 

AN/BSY-1, ECI-010 Baseline 

221 

SSN-688 Los Angeles 

CCS MK1, Program C4.2V1 

222 

SSN-688 Los Angeles 

CCS MK2, Program DO 

223 

SSSEP 

Advanced Submarine Tactical ESM Combat 
System 

224 

SSSEP 

Photonics Mast 

225 

SURTASS (Surveillance Towed Array Sensor 
System) 

SURTASS Production 

226 

SURTASS 

Advanced Deployable System 

227 

SURTASS 

SURTASS LFA (FSED) 

228 

Seeker Advanced Development Program 

Small Diameter Imaging System 

229 

Sensor Fuzed Weapon (SFW) 

- 

230 

Sidewinder 

AIM-9X 

231 

Signal Processor Vehicle Interface 

Airborne System Test Set 

232 

Simulator for Electronic Combat Training (SECT) 

AN/FSQ-T25 Electronic Combat Trainer 

233 

Space Boosters Rocket Systems 

Delta Redundant Measurement Systems 

234 

Space Boosters Rocket Systems 

Inertial Upper Stages 

235 

Space Boosters Rocket Systems 

Medium Launch Vehicle (MLV-II), Atlas 

Launch Vehicle 

236 

Space Boosters Rocket Systems 

Redundant Inertial Flight Control Assembly 

237 

Space Experiments for Phenomenology and 
Technology Demonstrations 

- 



























































































Table B-1. Weapon Program/System Names (Continued) 


Program Name 


System Name 


238 Sparrow AIM/RIM-7R Weapon System 


239 Special Operations Aircraft 


240 Standard Missile 2 - Block IV 


241 Standard Missile Improvements 


242 Standard Missile Improvements 


242 Standard Theatre Army Command and Control 
System 


244 Standoff Land Attack Missile (SLAM) 


245 Standoff Land Attack Missile (SLAM) 


246 Stinger RPM Block 1 


247 Stinger RPM 


248 Submarine Support Equipment Program (SSEP) 


249 Submarine Tactical Communication System 


250 Surface Ship Torpedo Defense (SSTD) 


251 System Simulator/Simulations 


252 T-45TS Goshawk Trainer 


253 T-45TS Goshawk Trainer 


254 TACAIR EW 


255 TACAIR EW 


256 TACAIR EW 


257 TACAIR EW 


258 TACAIR EW 


259 TACAIR EW 


260 TACAIR EW 


261 TACAIR EW 


262 TACAIR EW 


263 TACAIR EW 


264 TACAIR EW 


265 TACAIR EW 


266 I TALD and ITALD 


267 TARTAR Support Equipment 


268 I TARTAR Support Equipment 


Integrated Avionics Subsystem 


AEGIS ER 


MHIP-SM-2 BLK NIB Infrared Seeker 
Computer 


MHIP-SM-2 BLK NIB Missile Control 
Computer 


STACCS 


Baseline 


Upgrade 



Submarine Message Buffer 


AN/SLR-24 Detection and Launched 
Countermeasures Subsystems 


Target Oriented Tracking System 


Operational Flight Trainer (OFT) 


T-45A Aircraft 


AAR-47 Missile Warning Set 


AAR-47 Missile Warning Set (Upgrade) 


ALE-47 Countermeasures Dispenser 


ALQ-126B RCVR/Jammer 


ALQ-157 IR Jammer 


ALQ-162 Tactical Simulation POD 


ALQ-167/AST-6 Tactical Simulation POD 


ALR-67 (v) 3 & 4 Radar Warning RCVR 


AN/ALE-50 


AN/ALQ-170 (V) Tactical Simulation POD 


AN/ALR-67(v)2 ECP51D Countermeasures 
Receiving Set 


AVR-2 Laser Detecting Set 


Communications Tracking Set AN/SYR-1 
EHESPA 


Missile Fire Control System MK 74 





















































































Table B-1. Weapon Program/System Names (Continued) 


No. 

Program Name 

System Name 

269 

TARTAR Support Equipment 

TARTAR Common (was MK 14) 

270 

TERPES 

TERPES Upgrade 

271 

TRI-TAC 

System Planning System Control 

272 

Tactical Electronic Reconnaissance Processing 
& Evaluation System (TERPES) 

TERPES Phase II 

273 

Tactical Electronic Surveillance Systems - AD 

Concurrent Systems Baseline, Enhanced 
Tactical Users Terminal 

274 

Tactical Electronic Surveillance Systems - AD 

SUCCESS UHF Radio 

275 

Tactical Electronic Surveillance Systems - AD 

Unix Systems Baseline, Mobile tactical 
Terminal 

276 

Tactical Electronic Surveillance Systems - AD 

Communications System Processor 

277 

Tactical Environmental Support Systems 
Engineering 

Tactical Environmental Support System 
(TESS (3)) 

278 

Tactical Satellite Communications 
(TACSATCOM) 

AN/PSC-5 Enhanced Manpack UHF Terminal 
(EMUT) 

279 

Tanker Transport Trainer System 

T-1ASIM 

280 

Tanker Transport Trainer System 

T-1ATMS 

281 

Tomahawk Modifications 

Advanced Tomahawk Weapon Control 

System (ATWCS) 

282 

Tomahawk Modifications 

Baseline Improvement Program (Block IV 
Operational Embedded Software only) 

283 

Tomahawk Modifications 

Theater Mission Planning Center/Afloat 
Planning 

284 

Tomahawk Modifications 

Enhancement to Support TBIP 

285 

Tomahawk 

Baseline Weapon Control System 

286 

Tomahawk 

TLAM-Conventional (R/UGM-109C/D) 

287 

Tomahawk 

TLAM-Nuclear (R/UGM-109A) 

288 

Training Devices/Simulators 

Marine Air Ground Task Force (MAGTF) 
Tactical Warfare Simulation (MTWS) 

289 

UHF SATCOM Terminals 

Demand Assigned Multiple Access 

290 

UHF SATCOM Terminals 

SATCOM Signal Analyzer 

291 

UHF SATCOM Terminals 

Submarine Satellite Information Exchange 
System 

292 

UHF SATCOM Terminals 

Tactical Data Information Exchange System 

293 

UHF SATCOM Terminals 

Tactical Intelligence 

294 

USQ-74 

Link-11 

295 

V-22 Osprey 

- 

296 

Wide Area Mine 

- 



B-12 


























































































B.1.2 


List of AIS Program/System Names 

Table B-2. AIS Program/System Names 


System Name 


Program Name 



GCCS 


Combat Ammunition System - Deployable 
(CAS-D) 


Combat Ammunition System - Command 
(CASE) 


Combat Ammunition System - Ammunition 
Control Point (CAS-A) 


Combat Ammunition System - Base (CAS- 

B) 


Defense Civilian Personnel Data System (DCPDS) 


Department of Army Movements Management 
System - Redesign (DAMMS-R) 


Department of Army Movements Management 
System - Redesign (DAMMS-R) 


Department of Army Movements Management 
System - Redesign (DAMMS-R) 


Depot Maintenance Standard System (DMSS) 


Depot Maintenance Standard System (DMSS) 


Depot Maintenance Standard System (DMSS) 


Depot Maintenance Standard System (DMSS) 


Distribution Standard System (DSS) 


Electronic Military Personnel Records System 
(EMPRS) 


Fuels Automated Management System (FAMS) 



Block II 





DM-HMMS 


DMMIS 


PDMSS 


TIMA - ATICTS 


Defense Personnel Records Imaging 
System (DPRIS) 


Force Augmentation Planning and 
Execution System (FAPES) 


JOPES Version 3.3.3 


LOGSAFE 283V 


Scheduling and Movement 


Joint Computer-Aided Acquisition and Logistic 
Support (JCALS) 


NALCOMIS IMA 


NALCOMIS OMA 


Primary Oceanographic Prediction System 


Requirements Data Bank (RDB) 



B-13 






















































Table B-2. AIS Program/System Names (Continued) 


No. 

Program Name 

System Name 

324 

Reserve Component Automation System (RCAS) 

- 

325 

SARSS 

SARSS-2AC/B 

326 

SARSS 

SARSS-2AD and SARSS-1 

327 

SBIS 

- 

328 

Source Data Systems 

- 

329 

Standard Installation/Division Personnel System 
(SIDPERS) 

SIDPERS-3 

330 

Stock Point ADP Program (SPAR) 

UADPS-SP 

331 

TAMM IS 

- 

332 

Transportation Operational Personal Property 
Standard System (TOPS) 

- 

333 

Unit Level Logistics System (ULLS) 

ULLS - A 

334 

Unit Level Logistics System (ULLS) 

ULLS - G 

335 

Unit Level Logistics System (ULLS) 

ULLS - S4 






B-14 







































B.2 Remaining Survey Data 

This section of the appendix provides a list of all survey responses excluding 
“Program Name” and “System Name” (which are found in Section B.l). The rows have 
been arbitrarily mixed to prevent association of survey response and program/system name. 
A number of abbreviations or codes are used in this section of the appendix: 

a. For the Service associated with the Program Name: Air Force (F), Army (A), 
Navy (N), DISA (D), Marine Corps (M). Agencies and other organizations are 
denoted by (O). 

b. For Acquisition Category: I (A), II (B), IE (C), and IV (D). 

c. For SLOC (in thousands), 1-100 (A), 100-500 (B), 500-1,000 (C), 1,000-5,000 
(D), and 5,000-h (E). 

d. For Acquisition Phase: Concept Exploration (A), DemonstrationA^alidation 
(B), Engineering and Manufacturing Development (C), Production and 
Deployment (D), and Major Modification (E). 

e. For Percent of Language Use: less than 5% (A), 5-25% (B), 25-50% (C), 50- 
75% (D), and greater than 75% (E). Note that if the survey response provided 
exact percentages, they are included in parenthesis. 

For example, the first row in Table B-3 reflects a response by an Air Force program/ 
system, acquisition category I, in the Production and Deployment acquisition phase, having 
100-500K of SLOC, with five programming languages (Assembly - <5%, Fortran pre-91/ 
92 - <5%, Jovial J73 - 5-25%, PL/I 76/87/93 - 50-75%, and ATLAS - <5%). 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages - % of Use 

336 

F 

A 

D 

B 

Assembly - A 

Fortran pre-91/92 - A 

Jovial J73 - B f 

PL/I 76/87/93 - D 

ATLAS - A 











B.2.1 Weapon System Survey Data 


Table B-3. Weapon System Survey Data 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages - % of Use 

336 

F 

A 

D 

B 

Assembly - A 

Fortran pre-91/92 - A 

Jovial J73 - B f 

PL/I 76/87/93 - D 

ATLAS - A 

337 

F 

C 

D 

A 

Assembly - C (30%) 

Ada 83 - D (60%) 
4GL-B(10%) 

338 

N 

A 

D 

A 

C89-E(100%) 

339 

N 

C 

D 

D 

C89-A(1%) 

CMS-21 - E (98%) 

Others - A (1%) 

340 

N 

A 

D 

D 

Ada - E (100%) 

341 

N 

A 

D 

A 

Ada - E (100%) 

342 

N 

A 

D 

A 

Assembly - B (10%) 

C89 - E (90%) 

343 

N 

A 

D 

B 

Assembly - A (2%) 

C89 - E (98%) 

344 

N 

C 

D 

A 

C89 - A (3%) 

CMS-2M - E (92%) 

Others - A (5%) 

345 

N 

A 

D 

A 

Assembly - A(4%) 

Ada - D (56%) 

C89 - C (40%) 

346 

N 

A 

D 

A 

Ada-E (100%) 

347 

A 

A 

E 

B 

Assembly - B 

Ada - E 

C89-E 

ATLAS - E 

348 

A 

C 

B 

A 

Assembly - A 

Ada-E 

C89-B 

349 

A 

B 

C 

B 

Machine - A 

Ada - E 

350 

A 

C 

B 

B 

Assembly - A 

Ada-E 

C89-A 

351 

N 

D 

E 

A 

Assembly - E 

C+-H-B 

Others - B 

352 

F 

D 

D 

B 

Fortran pre-91/92 - E 

353 

F 

A 

D 

B 

Ada 83-E (100%) 



B-16 
























































































Table B-3. Weapon System Survey Data (Continued) 


Service ACAT Phase SLOC I Languages - % of Use 



C89-B 

Fortran pre-91/92 - D 


Assembly - E 
ATLAS -E 


Assembly - B 
Jovial pre-J73 - E 


Assembly - B 
Ada 83 - E 


Assembly - E 


Assembly - B 
Jovial pre-J73 - E 


Assembly - E 


Ada 83 - E 


C89-B 

Fortran pre-91/92 - E 


Ada 83 - E 


Assembly - B 
C89-A 

Fortran pre-91/92 - E 


Ada 83 - E 


Assembly 
Ada 83 
C++ 

Fortran 91/92,3 

Jovial pre-J73 

Pascal pre-90 

Prolog 

4GL 

DTC 


Assembly - E (89%) 
Fortran pre-91/92 - A (6%) 
C++ - A (5%) 


Ada 83 - B (25%) 
C89 - D (75%) 


C89 - E (100%) 


Machine - A 
Jovial J73 - E 


Machine - A 
Ada 83 - E 


Machine - B 
Fortran pre-91/92 - E 


B-17 































































































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages • % of Use 

374 

N 

D 

D 

c 

Assembly - C (29%) 

Ada 83 - B (8%) 

C89 - C (29%) 

C++ - A (3%) 

CMS-2M - B (12%) 

Pascal pre-90 - C (19%) 

375 

N 

D 

D 

A 

Assembly - E 

376 

N 

B 

C 

B 

Ada 83 - E 

377 

F 

- 

E 

D 

Assembly - D 

C++-B 

378 

F 

- 

D 

A 

Assembly - E 

379 

N 

D 

C 

- 

C89- E 

380 

N 

D 

C 

B 

Assembly - B 

Ada 83 - D 

Pascal pre-90 - B 

Others - B 

(Screen Descriptor Language) 

381 

N 

D 

C 

- 

Assembly - E 

382 

N 

D 

B 

- 

Assembly 

Fortran pre-91/92 

383 

N 

D 

D 

- 

Assembly - E 

384 

N 

C 

D 

- 

PIJM (Intel) - E 

385 

N 

D 

C 

- 

Assembly - E 

386 

N 

D 

D 

- 

Assembly 

C++ 

Fortran 

387 

N 

D 

C 

- 

Assembly 

C++ 

Fortran 

388 

N 

D 

D 

- 

Assembly - E 

389 

N 

D 

C 

- 

Assembly - E 

390 

F 

A 

D 

E 

Assembly - B (15%) 

Jovial J73 - E (85%) 

391 

F 

A 

C 

E 

Assembly - A 

Ada 83 - C 

Jovial J73 - D 

ATLAS - A 

392 

A 

D 

D 

A 

Assembly - E 



B-18 





































































































Table B-3. Weapon System Survey Data (Continued) 


Languages - % of Use 


Service I ACAT I Phase I SLOC 



Ada 83 - D 

Fortran pre-91/92 - B 

Assembly - B 

C89-B 

Jovial - A 

Pascal - A 

PL/M - A 


Assembly - B (10%) 
Ada 83 - A (3%) 

Basic 87/93 - B (8%) 
C89 - B (8%) 

Fortran 91/92 - A (3%) 
Jovial J73 - D (68%) 


Assembly - A (8%) 

Ada 83-B(14%) 

Basic 87/93 - B (8%) 

C89 - B (8%) 

Fortran pre-91/92 - B (3%) 
Jovial J73 - D (66%) 


Assembly - E (100%) 


C89-E 


Assembly - E 


Ada 83 - E 


Assembly - B (24%) 
C89-B(18%) 
Others - (13%) 

4GL - A (3%) 

GPSS - A (1%) 


Ada 83 - B (6%) 

Basic 87/93 - A (1%) 

Fortran pre-91/92 - B (15%) 
Pascal pre-90 - B (6%) 

PIL -C (25%) 

VAX Macro - B (8%) 

VTL - C (39%) 


Assembly - D (51%) 

Fortran pre-91/92 - B (21%) 
PIL - C (25%) 

Vax Macro - A (3%) 


Assembly - C (35%) 

C89 - A (4%) 

Fortran pre-91/92 - D (58%) 
4GL - A (3%) 


Assembly - A (3%) 

Basic 87/93 - B (25%) 
Fortran pre-91/92 - C (49%) 
Jovial J73 - C (33%) 


B-19 






























































Table B-3. Weapon System Survey Data (Continued) 


Service ACAT Phase I SLOC 



Languages - % of Use 


Jovial J73-E(100%) 


Ada 83- E (100%) 


Ada 83- E (100%) 


C++-E (100%) 


Assembly - B 
Ada 83 - B 
C89-A 

Fortran pre-91/92 - B 
Jovial J73 - C 
Pascal pre-90 - A 
PLM-B 


Ada 83-E (100%) 


Assembly - B (22%) 

Ada 83 - D (67%) 

C89 - A (3%) 

Fortran pre-91/92 - B (7%) 
Pascal 90 - A (<1%) 


Ada 83-E (100%) 


Ada 83 - D (53.4%) 
C89 - B (7.4%) 

C++ - C (39.2%) 
Fortran pre-91/92 - A 
4GL-A 


Ada 83 - E 
VHDL-D 


Ada 83 - E 
C89-A 


Assembly - C 
Ada 83 - C 
C89-A 
C++-A 
ATLAS -C 


Ada 83 - C 
C89-E 


C89-E 


Assembly - A (4%) 
C89 - E (96%) 


Assembly - A 
Ada 83 - E 


Ada 83 - C 
C89-B 

Fortran pre-91/92 - B 
Pascal pre-90 - A 
4GL-B 


B-20 
















































































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages - % of Use 

422 

F 

A 

c 

D 

Assembly - B (10.3%) 

Ada 83 - E (89.54%) 

C89 - A (0.2%) 

423 

A 

C 

B 

A 

Assembly - A 

Ada 83 - E 

C89-B 

424 

F 

C 

C 

B 

Ada 83 - E 

C89-A 

425 

N 

A 

D 

B 

Assembly - C 

Others - C 

426 

F 

- 

D 

A 

Ada 83-E (100%) 

427 

F 

- 

D 

A 

Ada 83-E (100%) 

428 

F 

- 

D 

A 

Ada 83-E (100%) 

429 

F 


D 

D 

C89 - D (75%) 

Fortran - B (25%) 

430 

F 

- 

E 

A 

Jovial J73 - E (100%) 

431 

F 

- 

E 

A 

Jovial J73 - E (100%) 

432 

N 

C 

D 

B 

Assembly - C 

Ada 83 - B 

C89-B 

Pascal pre-90 - B 

PLM-86 - C 

433 

N 

D 

D 

B 

Assembly - E (100%) 

434 

N 

C 

C 

B 

Ada 83 - E (100%) 

435 

M 

D 

A 

B 

C++-E (100%) 

436 

M 

B 

D 

D 

Assembly - C (40%) 

C89 - B (6%) 

CMS-2M - C (50%) 

Fortran pre-91/92 - A (0.4%) 

Pascal pre-90 - A (4%) 

437 

N 

D 

B 

B 

Assembly - E 

C89-B 

438 

N 

B 

C 

B 

Assembly - D (51%) 

Ada 83 - C (44%) 

C89 - C (5%) 

439 

N 

C 

C 

A 

Ada 83 - E 

C89-B 

440 

N 

C 

C 

A 

Ada 83 - E (100%) 

































































































ACAT I Phase I SLOC 


Table B-3. Weapon System Survey Data (Continued) 


Languages - % of Use 


Assembly - B (9%) 

Ada 83 - A (3%) 

C89 - B (12%) 

Fortran pre-91/92 - D (58%) 
Pascal pre-90 - B (9%) 
Pascal 90 - B (9%) 

Others - A (0.5%) 


Ada 83 - B (10.6%) 

C89 - C (38.8%) 

Fortran pre-91/92 - C (44.8%) 
Pascal pre-90 - A (4.7%) 
Others-A (1.1%) 


Assembly - C (30%) 
Ada 83 - D (65%) 
CMS-2M - B (5%) 


Assembly - D 
Fortran pre-91/92 - B 


CMS-2M - E 
PL/I 76/87/93 - B 


Ada 83 - D 
C-H--C 


Assembly - E (100%) 


Pascal pre-90 - E (100%) 


Assembly - B (10%) 
Ada 83 - E (90%) 
ATLAS -E 


Ada 83 - C 

C89-C 

4GL-A 


Assembly - B (8.1%) 

Ada 83 - A (2.4%) 

Fortran pre-91/92 - B (19.1%) 
Jovial J73 - B (6.5%) 

Pascal pre-90 - D (63.2%) 


Ada 83 - C (39%) 

Fortran pre-91/92 - C (26%) 
Jovial J73 - C (28%) 

Pascal pre-90 - B (8%) 


Ada 83 - D (66%) 

Fortran pre-91/92 - B (22.6%) 
Jovial J73 - A (3.1%) 

Pascal pre-90 - B (8.3%) 




B-22 





























































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages - % of Use 

454 

A 

A 

c 

B 

Assembly - B (9.5%) 

Ada 83 - B (9%) 

C++ - C (29.8%) 

Fortran pr6-91/92 - C (44%) 

Others - C (7.7%) 

455 

A 

- 

- 

D 

Ada 83 - C 

C89-D 

GPSS - A 

456 

A 

B 

D 

A 

Assembly - E (100%) 

457 

M 

D 

C 

B 

Ada 83 - C (50%) 

C89 - C (50%) 

458 

F 

A 

E 

C 

Assembly - B (21.4%) 

Ada 83-B(10%) 

Jovial pre-J73 - D (53.6%) 

Jovial J73 - B (15%) 

459 

F 

C 

D 

D 

Fortran pre-91/92 - E 

Jovial J73 - A 

460 

F 

D 

D 

A 

Jovial pre-J73 - C 

Jovial J73 - C 

461 

F 

D 

D 

D 

Jovial pre-J73 - B 

Jovial J73 - E 

462 

0 

A 

B 

B 

Ada 83-E (100%) 

463 

N 

C 

D 

A 

Assembly - A 

CMS-2 M - E 

464 

N 

- 

D 

A 

Assembly - E (100%) 

465 

N 

D 

D 

B 

Machine - E (100%) 

466 

N 

D 

E 

C 

C89-E(100%) 

467 

N 

B 

D 

D 

Assembly - B 

Fortran pre-91/92 - D 

Pascal pre-90 - B 

ATLAS - C 

468 

N 

B 

D 

B 

Assembly - E (100%) 

469 

A 

- 

A 

- 

C89 - E (90%) 

Fortran 91/92 - B (10%) 

470 

N 

C 

D 

C 

Assembly - A 

Ada 83 - C 

C89-B 

CMS-2 M - C 

Pascal pre-90 - A 

4GL-A 

471 

F 

D 

B 

A 

Assembly - B (15%) 

C89 - D (67%) 

Jovial J73 - B (8%) 

Pascal pre-90 - (10%) 



























































































Table B-3. Weapon System Survey Data (Continued) 


ACAT Phase I SLOC 



Languages - % of Use 


Assembly - B (9%) 

C89 - C (37%) 

Fortran pre-91/92 - C (46%) 
Jovial J73 - B (7%) 
VHDL-A (1%) 


C89 - D (70%) 

C++ - B (10%) 

Fortran 91/92 - B (20%) 


Ada 83-E (100%) 


Assembly - E (100%) 


Assembly - C (29%) 
C++ - D (71%) 


Assembly - B (16%) 
Pascal pre-90 - E (84%) 


Machine - A 
Assembly - B 
Others - E (80%) 


Assembly - E (100%) 


Assembly - B (6%) 
Others - E (94%) 


Assembly - B 
C89-C 
C++ - B 
CDL-E 


Assembly - E (100%) 


Machine - A 
Assembly - B 
C89- E 


Assembly - B 
Ada 83 - E 


Assembly - D 
Ada 83 - D 


Assembly - E (100%) 


Assembly - B 
Fortran pre-91/92 - E 


Ada 83-E (100%) 


Assembly - C (29.4%) 
Ada 83 - C (36%) 

C89 - C (35.6%) 


Ada 83 - E (98%) 
C89 - A (2%) 



B-24 











































































































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages - % of Use 

491 

F 

A 

D 

D 

Assembly - A (3%) 

Ada 83 - D (67%) 

4GL - C (30%) 

492 

N 

B 

D 

C 

Assembly - D (55%) 

Ada 83 - C (45%) 

493 

N 

B 

D 

B 

Assembly - D (58.4%) 

CMS-2M - C (41.6%) 

494 

N 

B 

D 

A 

Assembly - C (30%) 

CMS-2M - D (70%) 

495 

N 

A 

D 

A 

Assembly - E (100%) 

496 

N 

A 

D 

A 

Assembly - D 

Ada 83 - B 

Jovial J73 - C 

497 

N 

B 

D 

C 

Assembly - C 

C89-A 

Fortran pre-91/92 - C 

498 

N 

C 

C 

D 

Ada 83 - D 

C89-C 

C++ - B 

Others - A 

4GL-B 

499 

N 

A 

C 

C 

Ada 83 - D 

C89-A 

C++-A 

Fortran 91/92 - C 

500 

N 

A 

C 

B 

Assembly - B 

Ada 83 - C 

C89-B 

Fortran 91/92 - B 

Jovial J73 - B 

501 

N 

A 

C 

D 

Ada 83 - E 

C89-A 

4GL-A 

502 

M 

D 

- 

B 

Ada 83 - E 

C89-B 

503 

A 

A 

C 

C 

Assembly - A 

Ada 83 - E 

C89-A 

Fortran pre-91/92 - E 

504 

A 

A 

D 

D 

Machine - E 

C++ - B (14%) 

505 

A 

A 

D 

D 

Fortran - C 

C89-C 








































































Table B-3. Weapon System Survey Data (Continued) 


Service 


ACAT Phase I SLOC 



Languages - % of Use 


Ada 83 - D (53%) 
C89 - B (7%) 

C++ - C (39%) 
4GL - B (5%) 


Assembly - D 
C89-C 


Assembly - A 
Ada 83 - E 
C89-A 


Machine - A 
Assembly - A 
C89- E 


Assembly - E 
C89- E 


Assembly - D 
Ada 83 - D 
C89- D 
Basic 78 - A 
C++-C 

Fortran pre-91/92 - A 
Fortran 91/92 - A 


Assembly - E 


C89-E 

4GL-B 


Assembly - B 
Ada 83 - B 
C89- E 


Ada 83 - D (60%) 
C89 - C (40%) 


Assembly - A 
Ada 83 - C 
C89-B 

Fortran pre-91/92 - A 
Jovial J73 - C 
ATLAS - A 


Assembly - B 
Ada 83 - E 
Pascal pre-90 - B 


Fortran pre-91/92 - E 
Others - B 


Machine - A 
Ada 83 - C 
C89-C 

Fortran pre-91/92 - B 


B-26 












































































Table B-3. Weapon System Survey Data (Continued) 


Languages - % of Use 


Service ACAT I Phase I SLOC 



Machine - A 
Assembly - B 
Ada 83 - A 
Fortran pre-91/92 - E 


Assembly - B (25%) 
Jovial pr6-J73 - E (75%) 


Assembly - B 
Jovial J73 - E 


Assembly - C 
Ada 83 - C 
C89-B 

Pascal pre-90 - B 


Assembly - A 
Ada 83 - E 
C89-A 


Assembly - C (40%) 
Jovial J73 - D (60%) 


C89-C 

Pascal pre-90 - C 


Assembly - A 
Ada 83 - E 
4GL-B 


Assembly - A 
Ada 83 - D 
C++-B 


Assembly - B 
Ada 83 - E 


Assembly - A (2.71%) 

C89 - A (4.58%) 

CMS-2 M - A (2.43%) 

Fortran pre-91/92 - B (8.21%) 
Others - E (82.1%) 


Assembly - D 
Ada 83 - B 
CMS-2 M - B 


Assembly - E 
Ada 83 - B 


C-H--A 

Fortran pre-91/92 - D 
Fortran 91/92 - C 
4GL-A 


Assembly - C 

C89-C 

5GL-C 






































































Service ACAT I Phase I SLOC 


Table B-3. Weapon System Survey Data (Continued) 


Languages - % of Use 


Ada 83 - D 
C++ - C 
5GL-C 


Ada 83 - E 
C89-A 


Assembly - B 
Fortran pre-91/92 - B 
Jovial J73 - B 
Pascal pre-90 - B 
4GL-A 

Special purpose - B 


Ada 83 - E 
Fortran pre-91/92 - A 


Ada 83 - E 


Assembly - C 
Fortran pre-91/92 - C 
Jovial J73 - D 


Machine - A 
Assembly - B 
Ada 83 - B 
Basic - B 
C89-B 

Fortran pre-91/92 - B 
Fortran 91/92 - B 
Special purpose - B 


Assembly - A 
C89- E 


Ada 83 - E 
C89-B 

Fortran pre-91/92 - A 
4GL-A 

Special purpose - B 


Assembly - E (90%) 
C89-B(10%) 


Assembly - B 
C89-B 

Fortran pre-91/92 - B 
Pascal pre-90 - D 


Assembly - B 
PL/I 87/93 subset - E 


Assembly 
Jovial J73 


Assembly - D 
Ada 83 - C 










































































Table B-3. Weapon System Survey Data (Continued) 


ACAT I Phase I SLOC 



Languages - % of Use 


Assembly - D 
Ada 83 - A 


Assembly - A (5%) 
Ada 83 (80%) 
Other - B (15%) 


Assembly - E (100%) 


Ada 83 - E 


CMS-2 Y - E 


Machine - C 
Assembly - C 
C89-B 

Fortran pre-91/92 - A 


Assembly - B 
Fortran pre-91/92 - D 


Assembly - E 


Ada 83 - E 


Assembly - B (22%) 
Ada 83 - B (7%) 
Jovial J73 - D (71%) 


Assembly - B (5%) 
Ada 83 - D (60%) 
Jovial J73 - C (35%) 


Assembly - A (1%) 
Ada 83 - A (2%) 
C89 - E (90%) 
Basic89 - A (3%) 


Assembly - D (57%) 
Basic89 - B (7%) 
C89 - C (36%) 


Machine - A (0.1%) 

Assembly - A (3.9%) 

Fortran pre-91/92 - D (64.3%) 
C89 - A (0.7%) 

Jovial J73 - A (4.9%) 

Ada 83 - A (4.9%) 

Others - C 


Machine - D 
Ada 83 - A 


Assembly - E 


Assembly - E 


Assembly - B (5%) 
Ada 83 - E (90%) 
Others - B (5%) 





























































































Table B-3. Weapon System Survey Data (Continued) 


Languages - % of Use 


ACAT I Phase I SLOC 



Ada 83 - D (75%) 
Others - C (25%) 


Assembly - C (40%) 
Ada 83 - D (60%) 


Ada 83 - E 


CMS-2 M - E 
Special purpose - B 


Ada 83 - D (53.4%) 
C89 - B (7.4%) 

C++ - C (39.2%) 
Fortran pre-91/92 - A 
4GL-A 


Assembly - A 
C89- E 
CMS-2 M - A 
4GL-A 


Assembly - A 
C89- E 


Ada 83 - A 
C89- E 
C++-B 


C89-E 
C++ - B 


Assembly - A 
C89-A 
Other - E 


Assembly - A 
Fortran pre-91/92 - E 


C89-A 

C++-D 

Fortran pre-91/92 - A 
4GL-C 


Assembly - A 
Other - E 


Assembly - A 

C89-D 

C++-B 

Fortran pre-91/92 - B 

Lisp - A 

4GL-A 


Assembly - A 
Ada 83 - E 
C89-A 

Fortran pre-91/92 - E 



B-30 


















































































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages • % of Use 

582 

N 

- 

E 

D 

Ada 83 - B (20.48%) 

Basic 87/93-B (10.46) 

C89 - B (8.23%) 

C++ - C (39.25%) 

CMS-2 M - B (6.7%) 

Fortran 91/92 - B (9.69%) 
Assembly - A (4.29%) 

4GL-A(0.91%) 

583 

N 

A 

D 

A 

Fortran pre-91/92 - D 

584 

N 

C 

B 

- 

C++-D 

585 

A 

C 

C 

B 

C++-E 

Others - A 

586 

N 

A 

D 

B 

Assembly - B 

Ada 83 - A 

C++-A 

Fortran pre-91/92 - E 

587 

F 

A 

C 

C 

Assembly - B (23%) 

C89-A 

C++-A 

Fortran pre-91/92 - B 

Jovial J73 - B 

Others - B (25%) 

588 

F 

A 

C 

D 

Assembly - A 

Ada 83 - E 

Fortran pre-91/92 - A 

Jovial pre-J73 - B 

Jovial J73 - B 

589 

F 

B 

D 

A 

Ada 83 - C (25%) 

C89 - D (75%) 

590 

F 

B 

D 

A 

C89 - B (5%) 

Fortran pre-91/92 - E (95%) 

591 

F 

B 

E 

B 

Assembly - B (15%) 

Fortran pre-91/92 - E (85%) 

592 

F 

A 

C 

B 

Ada 83 - E 

593 

N 

D 

B 

A 

Ada 83 - E 

C89-A 

594 

A 

- 

B 

A 

Assembly - C 

Ada 83 - B 

C++-B 

Others - C 

595 

N 

B 

C 

C 

Machine - C 

C++-A 

CMS-2 Y - D 

CMS-2 M - A 






































































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages • % of Use 

596 

N 

C 

D 

c 

Assembly - A (6%) 

Ada 83 - E (85%) 

C89 - B (9%) 

597 

N 

C 

D 

B 

Ada 83 - E 

598 

N 

c 

D 

C 

Assembly - A (15%) 

CMS-2 M - E (85%) 

599 

N 

c 

D 

D 

Assembly - E 

C89-A 

600 

N 

c 

E 

B 

Assembly - C 

Ada 83 - D 

C89-A 

4GL-A 

601 

N 

- 

D 

D 

Assembly - C (43%) 

C89 - B (18%) 

C++ - A (0.23%) 

Others - B (10%) 

SPL/1 - C (29%) 

602 

A 

- 

A 

A 

Ada 83 - D 

C89-C 

CSSL- A 

603 

N 

D 

C 

E 

Machine - A (1.71%) 

Assembly - C (29.26%) 

C89 - A (4.8%) 

CMS-2 M-C (31.34%) 

Pascal pre-90 - B (14.04%) 

PL/I 76/87/93 - A (2.06%) 
Others - B (12.45%) 

SPL/1 - A (3.29%) 

604 

N 

C 

C 

D 

Assembly - C (48.6%) 

CMS-2 M - A (4.4%) 

Others-B (16.7%) 

SPL/1 - C (30.3%) 

605 

N 

D 

D 

D 

Assembly - D 

CMS-2 Y - B 

CMS-2 M - B 

606 

N 

B 

C 

D 

Assembly - B 

Ada 83 - C 

C89- B 

CMS-2 Y - C 

CMS-2 M - B 

607 

N 

B 

C 

B 

Assembly - B (9.09%) 

Ada 83-C (42.17%) 

C++-B (21.26%) 

Fortran 91/92 - C (27.48%) 

608 

A 

B 

C 

A 

Assembly - A (4%) 

Ada 83 - D (96%) 













































































Table B-3. Weapon System Survey Data (Continued) 


ACAT Phase SLOC Languages - % of Use 



Assembly - C 
Fortran 91/92 - B 
Others - B 


C89- E 


Assembly - B 
Ada 83 - E 


Ada 83 - E 


Fortran pre-91/92 - E 


Ada 83 - E 


Machine - A 
Assembly - B 
Basic 78 - A 
C89: A 

Fortran pre-91/92 - D 
4GL-B 


Assembly - A 
Basic 78 - A 
C++ - A 

Fortran pre-91/92 - A 
Pascal pre-90 - A 
4GL-A 


Assembly - B 
Pascal pre-90 - D 
ATLAS - E 


Assembly - A 
Ada 83 - E 
C89-B 
Jovial J73 - A 


Ada 83 - B 

C89-C 

4GL-C 


Ada 83 - B (9%) 
C89 - D (67%) 
LISP-A(1%) 
4GL - B (23%) 


Ada 83 - C (40%) 

C89 - A (3%) 

Cobol pre-85 - A (3%) 
Others - A (2%) 

4GL - D (52%) 


Fortran pre-91/92 - D 
Pascal 90 - B 
C89-B 



































































Table B-3. Weapon System Survey Data (Continued) 


No. 

Service 

ACAT 

Phase 

SLOC 

Languages - % of Use 

623 

N 

A 

D 

B 

Fortran pre-91/92 - D 

Pascal 90 - B 

C89-B 

624 

N 

A 

D 

B 

Fortran pre-91/92 - D 

Pascal 90 - B 

C89-B 

625 

N 

A 

D 

C 

C89- E 

C++-B 

4GL-B 

626 

N 

- 

C 

C 

CMS-2 Y - C (30%) 

Fortran pre-91/92 - B (10%) 

Pascal pre-90 - D (60%) 

627 

N 

- 

C 

E 

Assembly - A (1%) 

Ada 83-A(1%) 

C89-A(1%) 

CMS-2 Y - E (95%) 

Fortran 91/92 - A (1%) 

Pascal 90 - A (1%) 

628 

N 

- 

D 

C 

Assembly - A 

CMS-2 Y - E 

629 

N 

C 

E 

D 

Ada 83 - B 

C89- D 

Others - B 

4GL-B 

630 

N 

C 

E 

B 

Ada 83 - B (13%) 

C89 - C (47%) 

4GL - C (40%) 


B-34 

















































B.2.2 AIS Survey Data 


Table B-4. AIS Survey Data 


ACAT I Phase I SLOC 



Languages - Percent of Use 


Fortran 91/92 - A 
Cobol pre-85 - E 
4GL-B 


4GL-E 


4GL- E 


C89 - E (82.76%) 
4GL-B (17.24%) 


C89-A 
4GL-E 


C89-B 

4GL-E 


Ada 83 - A (2%) 
C++ - B (20%) 
Cobol 85 - E (78%) 


Ada 83-A (10%) 
C++ - B (20%) 
4GL - E (70%) 


Ada 83 - D 
Cobol pre-85 - B 
4GL-B 


Ada 83 - E 
Cobol 85 - B 
4GL-A 


Ada-E 

4GL-B 


Ada-E 

4GL-B 


4GL-E 


Ada 83 - E 
4GL-A 


Ada 83 - E 
4GL-B 


Machine - B (10%) 

Cobol pre-85 - C (40%) 
Cobol 85 - B (49%) 

Fortran pre-91/92 - A (1%) 


C89-B(12.5) 
C++-A(1%) 
4GL - E (86.5%) 


B-35 

















































































Table B-4. AIS Survey Data (Continued) 


No. 

Serv 

ACAT 

Phase 

SLOC 

Languages - Percent of Use 

648 

0 

- 

D 

B 

Ada 83 - E (81%) 

C89 - B (8%) 

Cobol - B (7%) 

Assembly - A (4%) 

649 

0 

- 

D 

B 

Ada 83-B(11%) 

C89 - B (6%) 

4GL - E (83%) 

650 

0 

- 

D 

- 

Ada 83 - E (90%) 

C89 - B (7%) 

Cobol - A (3%) 

651 

0 

- 

D 

D 

Cobol - E (88%) 

Assembly - B (8%) 

Fortran - A (4%) 

652 

N 

C 

D 

D 

Cobol pre-85 - E 

653 

N 

- 

E 

C 

C89-B 

Fortran pre-91 /92 - E 

4GL-B 

654 

F 

- 

D 

D 

Assembly - A (1.6%) 

Ada 83 - B (5.4%) 

Basic 87/93 - A (0.6%) 

C89 - C (41%) 

Cobol 85-D (51.3%) 

4GL - A (0.2) 

655 

A 

c 

D 

D 

Ada 83 - B 

Basic 87/93 - D 

4GL-A 

656 

F 

B 

D,E 

B 

Ada - E 

4GL-B 

657 

F 

B 

D,E 

B 

C89-A 

4GL-E 

658 

N 

- 

A.B.C,D, 

E 

D 

Ada 83 - B 

Cobol 85 - D 

659 

A 

B 

C 

B 

Ada 83-E (100%) 

660 

A 

B 

C 

B 

Ada 83-E (100%) 

661 

A 

B 

D 

B 

Ada 83-E (100%) 

662 

A 

- 

D 

C 

Ada 83 - B 

4GL-E 

663 

A 

- 

D 

A 

C89- D 

4GL-B 

664 

A 

- 

C 

C 

Ada 83 - E 



B-36 































































































Table B-4. AIS Survey Data (Continued) 


No. 

Serv 

ACAT 

Phase 

SLOC 

Languages - Percent of Use 

665 

F 


E 

D 

Assembly - B 

Ada 83 - A 

Cobol 85 - C 

Others - D 

4GL - A 

666 

A 

- 

- 

C 

Ada 83 - C (45%) 

4GL - C (45%) 

5GL-C(10%) 

667 

0 

- 

C 

E 

Assembly - A 

C++-B 

Cobol pre-85 - B 

Fortran 91/92 - B 

4GL-D 

668 

N 

A 

D 

- 

C++ 

4GL 

669 

N 

A 

D 

- 

Cobol 85 


B-37 
































LIST OF REFERENCES 


[AF-CCIP 1973] 

[ANSI/IEEE 1990] 

[Carroll 1994] 
[DoDI 1991] 

[DoDI 1993] 
[Fisher 1974] 

[Fisher 1976] 

[Fisher 1977] 

[GSA 1973] 


Space and Missile System Organization, AFSC, Information 
ProcessingIData Automation Implications for Air Force Command 
and Control Requirements in the 1980s, Vol. IV, Technology Trends: 
Software, October 1973, AD-A919 267 L. 

American National Standards Institute and Institute for Electrical and 
Electronics Engineers, Inc., Standard 610.12-1990, ANSIIIEEE 
Standard Glossary of Software Engineering Terminology. 

Carroll Publishing Co., Defense Organization Service, Program 
Management Index, July 1994, Washington D.C., pp. 1-66. 

DoDDI Number 5000.2, “Subject: Defense Acquisition Management 
Policies and Procedures.” January 1,1991. 

DoDDI Number 8120.1, “Subject: Life-Cycle Management (LCM) 
of Automated Information Systems (AISs),” January 14,1993. 

Fisher, David A., Automatic Data Processing Costs in the Defense 
Department, IDA Paper P-1046, October 1974, Institute for Defense 
Analyses. 

Fisher, David A., A Common Programming Language for the 
Department of Defense—Background and Technical Requirements, 
IDA Paper P-1191, June 1976, Institute for Defense Analyses. 

Fisher, David A., A Common Programming Language for the 
Department of Defense-Background, History and Technical 
Requirements, IDA Paper-1263, May 1977, Institute for Defense 
Analyses. 

Inventory of Automatic Data Processing Equipment in the United 
States Government, Fiscal Year 1973, Automated Data and 


References-1 



Telecommunications Service, General Services Administration, FSN 
7610-181-7284. 


[Jones 1991] 

[OASD 1994] 

[STSC 1994] 

[Whitaker 1993] 


Jones, Capers, Applied Software Measurement, McGiaw-HiU: New 
York, 1991. 

Office of the Secretary of Defense Memorandum for Distribution, 
Subject: “Designation of Major Automated Information Systems and 
Quarterly Reporting Requirements,” August 5, 1994. 

Software Technology Support Center, Guidelines for Successful 
Acquisition and Management of Software Intensive Systems: 
Weapons Systems, Command and Control Systems, Management 
Information Systems, Volume 1, September 1994. 

Whitaker, William A. “Ada the Project—DoD High Order Language 
Working Group,” ACM SIGPLAN Notices, Vol. 28, No. 3, March 
1993, pp. 299-331. 




LIST OF ACRONYMS 


IGL 

First Generation Language 

2GL 

Second Generation Language 

3GL 

Third Generation Language 

4GL 

Fourth Generation Language 

5GL 

Fifth Generation Language 

ACAT 

Acquisition Category 

ADP 

Automatic Data Processing 

AIS 

Automated Information System 

C2 

Command and Control 

C3 

Command, Control and Communications 

C3I 

Command, Control, Communications and Intelligence 

COTS 

Commercial off the Shelf 

DARPA 

Defense Advanced Research Projects Agency 

DDR&E 

Director, Defense Research and Engineering 

DoD 

Department of Defense 

FIPS 

Federal Information Processing Standards 

HOLWG 

High Order Language Working Group 

IDA 

Institute for Defense Analyses 

IEEE 

Institute for Electrical and Electronics Engineers 

O&M 

Operations and Maintenance 

OSD 

Office of the Secretary of Defense 

PMI 

Program Management Index 

RDT&E 

Research, Development, Test & Evaluation 

SLAM 

Standoff Land Attack Missile 

SLOC 

Source Lines of Code 


Acronyms-1 



REPORT DOCUMENTATION PAGE 


Form Approved 
0MB No. 0704-0188 


Public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, 
gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspea of this 
colleaion of information, including suggestions for reducing this burden, to Washington Headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson 
Davis Highway, Suite 1204, Arlington, VA 22202-4302, and to the Office of Management and Budget, Paperwork Reduction Project (0704-0188), Washington, DC 20503. 


1. AGENCY USE ONLY (Leave blank) 


4. TITLE AND SUBTITLE 


2. REPORT DATE 

January 1995 


3. REPORT TYPE AND DATES COVERED 

Final 


A Survey of Computer Programming Languages Currently Used in 
the Department of Defense 


6. AUTHOR(S) 

Audrey A. Hook, Bill Brykczynski, Catherine W. McDonald, Sarah 
H. Nash, Christine Youngblut 


5. FUNDING NUMBERS 

DASW01-94-C-0054 


Task Order T-S5-306 


7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 

Institute for Defense Analyses (IDA) 

1801 N. Beauregard St. 

Alexandria, VA 22311-1772 


8. PERFORMING ORGANIZATION REPORT 
NUMBER 


IDA Paper P-3054 


9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES) 

Defense Information Systems Agency 

Center for Software, DoD Software Initiatives Dept. 

5600 Columbia Pike 

Falls Church, VA 22041 


10. SPONSORING/MONITORING AGENCY 
REPORT NUMBER 



12a. DISTRIBUTION/AVAILABILITY STATEMENT 

Approved for public release, unlimited distribution: March 10, 
1995. 


I2b. DISTRIBUTION CODE 

2A 


13. ABSTRACT (Maximum 200 words) 

This study reports on a programming language survey commissioned by the Assistant Secretary of 
Defense for C3I to determine how many programming languages are being used in the DoD today as 
compared to 20 years ago when the DoD began development of the Ada language. The sample 
population for this survey consisted of weapons systems taken from the 1994 Presidential Budget 
requests for RDT&E programs exceeding $15 million and Procurement budgets exceeding $25 
million. The current DoD list of major Automated Information Systems was used as the survey 
sample for non-weapons systems. The survey found that over 80% of the applications in the sample 
were written in third generation languages. Moreover, it identified 37 third generation languages in 
contrast to an estimate of at least 450 general purpose languages and dialects in 1974. In weapons 
systems modernization, Ada is the most commonly used language. 


14. SUBJECT TERMS ~ 15. NUMBER OF PAGES 

Projrami^g Languages, Surveys, AISs, Weapon Systems Software, Ada, 110 

C, Third Generation Languages. le. price code- 


20. LIMITATION OF ABSTRACT 

uf* KbPUKl OF THIS PAGE OF ABSTRACT 

Unclassified _ Unclassified _ Unclassified _ SAR 

NSN 7540-01-280-5500 Standard Form 298 (Rev. 2-89) 

Prescribed by ANSI Std. Z39-18 
298-102 

















