NAVAL POSTGRADUATE SCHOOL 
Monterey, California 



THESIS 


AGENT-BASED SIMULATION 

OF A MARINE INFANTRY SQUAD 

IN AN URBAN ENVIRONMENT 

by 


Arthur R. Aragon 


September 2001 


Thesis Advisor: 

Neil Rowe 

Seeond Reader: 

Chris Eagle 


Approved for public release; distribution is unlimited. 





Report Documentation Page 


Report Date Report Type Dates Covered (from... to) 

30 Sep 2001 N/A 

Title and Subtitle Contract Number 

Agent-Based Simulation of a Marine Infantry Squad in 

an Urban Environment Grant Number 

Program Element Number 

Author(s) Project Number 

Aragon 

Task Number 
Work Unit Number 

Performing Organization Name(s) and Address(es) Performing Organization Report Number 

Research Office Naval Postgraduate School Monterey, 

Ca 93943-5138 

Sponsoring/Monitoring Agency Name(s) and Sponsor/Monitor’s Acronym(s) 

Address(es) 

Sponsor/Monitor’s Report Number(s) 

Distribution/Availability Statement 

Approved for public release, distribution unlimited 

Supplementary Notes 
Abstract 


Subject Terms 



Number of Pages 

162 






REPORT DOCUMENTATION PAGE 


Form Approved OMB No. 0704-0188 
Public reporting burden for this collection of information is estimated to average 1 hour per response, including 
the time for reviewing instruction, searching existing data sources, gathering and maintaining the data needed, and 
completing and reviewing the collection of information. Send comments regarding this burden estimate or any 
other aspect of this collection of information, including suggestions for reducing this burden, to Washington 
headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson Davis Highway, Suite 
1204, Arlington, VA 22202-4302, and to the Office of Management and Budget, Paperwork Reduction Project 

(0704-0188) Washington DC 20503. _ 

2. REPORT DATE 
September 2001 


6. AUTHOR(S) 

Aragon, Arthur R. 


11. SUPPLEMENTARY NOTES The views expressed in this thesis are those of the author and do not reflect the official 
policy or position of the Department of Defense or the U.S. Government. 


13. ABSTRACT (maximum 200 words) 

This thesis research focused on the design, development, and implementation of an agent-based simulation of a 
Marine infantry squad in an urban environment. The goal was to design an autonomous-agent framework that could model a 
combatant’s decision cycle. A squad entity comprised of these agents was created to explore the idea of team dynamics and the 
balance between meeting individual goals and team goals. The agents were placed in a two-dimensional, discrete-state, 
simulation world with a simple model of urban infrastructure. The squad goal was to patrol through the environment using 
checkpoints. The individual agent goals were to move to a destination and maintain the squad formation. The critical issues of 
agent movement were collision detection/avoidance, goal managing and forward planning. Distinguishing the agents by their 
role in the squad allowed a single agent to act as the squad leader. This agent was given the ability to plan a path to accomplish 
the squad’s overall goal as a series of sub-goals, which was successful in getting the majority of the agents to their checkpoints 
in squad formation. The design of the simulation program facilitates further research in using autonomous agents to model 
small-units in an urban environment. 


16. PRICE CODE 


NSN 7540-01-280-5500 Standard Form 298 (Rev. 2-89) 

Prescribed by ANSI Std. 239-18 


20. LIMITATION 
OE ABSTRACT 

UL 


15. NUMBER OE 
PAGES 

161 


14. SUBJECT TERMS 

Autonomous agents, Computer Simulation, Urban Combat, Military Operations in Urban Terrain, 
Java, Software Engineering, Model-View-Controller Architecture 

18. SECURITY 
CLASSIEICATION OE THIS 
PAGE 

Unclassified 


19. SECURITY 
CLASSIEICATION OE 
ABSTRACT 

Unclassified 


17. SECURITY 
CLASSIEICATION OE 
REPORT 

Unclassified 


12b. DISTRIBUTION CODE 


12a. DISTRIBUTION / AVAILABILITY STATEMENT 

Approved for public release; distribution is unlimited. 


7. PEREORMING ORGANIZATION NAME(S) AND ADDRESS(ES) 

Naval Postgraduate School 
Monterey, CA 93943-5000 

9. SPONSORING / MONITORING AGENCY NAME(S) AND ADDRESS(ES) 

N/A 


5. LENDING NUMBERS 


8. PEREORMING 
ORGANIZATION REPORT 

NUMBER _ 

10. SPONSORING / MONITORING 
AGENCY REPORT NUMBER 


4. TITLE AND SUBTITLE: Title (Mix case letters) 
kgent-Based Simulation of a Marine Infantry Squad in an Urban Environment 


3. REPORT TYPE AND DATES COVERED 

Master’s Thesis 


1. AGENCY USE ONLY (Leave blank) 


1 




























THIS PAGE INTENTIONALLY LEET BLANK 


11 



Approved for public release; distribution is unlimited. 


AGENT-BASED SIMULATION 
OF A MARINE INFANTRY SQUAD 
IN AN URBAN ENURONMENT 

Arthur R. Aragon 

Captain, United States Marine Corps 
B.S.M.E., United States Naval Academy, 1996 


Submitted in partial fulfillment of the 
requirements for die degree of 


MASTER OF SCIENCE IN COMPUTER SCIENCE 


fi'omdie 


NAVAL POSTGRADUATE SCHOOL 
September 2001 


Author: 


Approved by: 






Department of Computer Science 




THIS PAGE INTENTIONALLY LEET BLANK 


IV 



ABSTRACT 


This thesis research focused on the design, development and implementation of an 
agent based simulation of a Marine infantry squad in an urban environment. The goal 
was to design an autonomous-agent framework that could model a combatant’s decision 
cycle. A squad entity comprised of these agents was created to explore the idea of team 
dynamics and the balance between meeting individual goals and team goals. The agents 
were placed in a two-dimensional, discrete-state, simulation world with a simple model 
of urban infrastructure. The squad goal was to patrol through the environment using 
checkpoints. The individual agent goals were to move to a destination and maintain the 
squad formation. The critical issues of agent movement were collision 
detection/avoidance, goal managing and forward planning. Distinguishing the agents by 
their role in the squad allowed a single agent to act as the squad leader. This agent was 
given the ability to plan a path to accomplish the squad’s overall goal as a series of sub¬ 
goals, which was successful in getting the majority of the agents to their checkpoints in 
squad formation. The design of the simulation program facilitates further research in 
using autonomous agents to model small-units in an urban environment. 


V 



THIS PAGE INTENTIONALLY LEET BLANK 


VI 



TABLE OF CONTENTS 


1. INTRODUCTION.1 

A, THESIS STATEMENT.1 

B, PURPOSE.1 

C, THESIS GOALS.1 

D, THESIS ORGANIZATION.2 

IL BACKGROUND.3 

A. GLOBAL URBANIZATION AND MILITARY OPERATIONS.3 

B. THE CHALLENGES OF URBAN WARFARE.4 

C. TRAINING FOR URBAN WARFARE.5 

D. MODELING, SIMULATION AND AUTONOMOUS AGENTS.6 

E. ISAAC.8 

F. ARCHIMEDES.9 

III. SIMULATION DEVELOPMENT.11 

A, STATEMENT OF REQUIREMENTS.11 

B, REQUIREMENTS SPECIFICATIONS.11 

C, SOFTWARE ARCHITECTURE.12 

1, Models.13 

2, View.14 

3, Controller.16 

D, SIMULATION ENVIRONMENT.16 

IV. AGENT DEVELOPMENT.19 

A. AGENT FRAMEWORK.19 

B. STATE VARIABLES.20 

C. GOALS AND GOAL MANAGING.21 

D. AGENT ACTION.22 

1. Basic Movement.22 

2 Collision Detection/Avoidance.23 

3, Path Planning.24 

E. SQUAD RELATIONSHIP.28 

F. SQUAD VS. INDIVIDUAL GOALS.29 

V. SIMULATION ANALYSIS.31 

A RUNNING THE SIMULATION.31 

B, SIMULATION RESULTS.31 

1. The Scenario.31 

2. Squad and Individual Agent Interaction.31 

VI. FUTURE WORK AND CONCLUSIONS.35 

A. FUTURE WORK.35 

1. Develop Agent Personalities.35 

2, Develop Agent Actions.35 

vii 










































3, Develop different agent types.35 

4, Develop the infrastructure.35 

5, Develop the User Interface.35 

6, Create Smarter Agents.35 

B, CONCLUSIONS.36 

APPENDIX A, JAVA SOURCE CODE.37 

LIST OF REFERENCES.141 

BIBLIOGRAPHY.143 

INITIAL DISTRIBUTION LIST.145 


viii 












LIST OF FIGURES 


Figure 1. Model-View-Controller Architecture.12 

Figure 2. Class Diagram of Model Objects.13 

Figure 3. Infrastructure Class Hierarchy.14 

Figure 4. The View Component’s Display.15 

Figure 5. Agent Framework.19 

Figure 6. Agent Movement Constraints.23 

Figure 7. Path Search Node Network.25 

Figure 8. Best-First Search (Shortest Path).26 

Figure 9. Best-First Search (Cover and Concealment Benefit).27 

Figure 10. Squad-Marine Agents’ Class Relationship.28 

Figure 11. Squad Moving to Third Checkpoint.33 














THIS PAGE INTENTIONALLY LEET BLANK 


X 



DISCLAIMER 


The computer program developed in this research was exploratory in nature. It 
cannot be considered verified or validated. Any application of this program outside of 
experimental research is not recommended and is done at the risk of the user. 



THIS PAGE INTENTIONALLY LEET BLANK 



EXECUTIVE SUMMARY 


U.S. military operations in urban terrain have been directly affected by global 
urbanization. The level of training and research in urban tactics must correspond to its 
growing relevance on the global scene. Simulation can provide great benefits to the 
study of urban tactics at the small-unit level. 

This thesis research focused on the design, development and implementation of an 
agent based simulation of a Marine infantry squad in an urban environment. The primary 
goal was to design an autonomous-agent framework that could model a combatant’s 
decision cycle and create a squad of these agents working to accomplish both individual 
and team goals. The agents were placed in a two-dimensional, discrete-state, simulation 
world with a simple model of urban infrastructure. The squad goal was to patrol through 
the environment using checkpoints. The individual agent goals were to move to a 
destination and maintain the squad formation. 

The critical issues of agent movement were collision detection, collision 
avoidance, goal managing, and forward planning. Distinguishing the agents by their 
role in the squad allowed a single agent to act as the squad leader. This agent was given 
the ability to plan a path to accomplish the squad’s overall goal as a series of sub-goals, 
which was successful in getting the majority of the agents to their checkpoints in squad 
formation. 

The design of the simulation program facilitates further research in using 
autonomous-agents to model small-units in an urban environment to analyze the 
efficiency of current tactics and to experiment with new ones. 



THIS PAGE INTENTIONALLY LEET BLANK 


XIV 



ACKNOWLEDGMENT 


I would like to thank my advisor, Dr. Neil Rowe, for his guidance and patience 
during this research. 


XV 



THIS PAGE INTENTIONALLY LEET BLANK 


XVI 



I. INTRODUCTION 


A. THESIS STATEMENT 

A constructive agent-based simulation of a Marine infantry squad in an urban 
environment can serve as a useful tool for the warfighter. It can be used to study the 
dynamics between the individual Marine and the squad to help define the boundaries 
between self-preservation and teamwork. It ean be used to analyze the efficiency of 
current tactics, techniques, and procedures used in urban combat. It can provide the 
repeatability and statistical data that live simulations lack. Finally, it can be used to 
experiment with new and innovative tactics against the potential threats of the future. 


B, PURPOSE 


The purpose of this thesis is to take the first step in ereating such an agent-based 
simulation. The primary effort will be to create an abstract model of a Marine infantry 
squad in an urban environment. Engineering autonomous agents in a eonstructive, 
discrete-state simulation program using the Java object-oriented programming language 
is how this will be aecomplished. The simulation will focus on the motions of the squad 
and its individual Marine agents in order to study the team dynamics and performance of 
the squad in aecomplishing the simple task of patrolling through an urban area. 


C. THESIS GOALS 


The overall goals of this thesis are: 

• To engineer an autonomous Marine agent with individual goals and an 
individual personality; 

• To model a Marine infantry squad eomprised of these autonomous Marine 
agents; 

• To engineer an objeet-oriented discrete-state simulation with a 2D display 
to depict the actions of the agents in the simulation; 


1 



To study the balance between individual agent goals and squad goals; 
To model simple squad tactics; and 

To identify emergent behavior of the agents in the simulation. 


D, THESIS ORGANIZATION 


This thesis is organized into the following chapters: 

• Chapter II: Background. Identifies the root of the problem being 
addressed and how a simulation tool that models urban operations at the 
squad level can assist in evaluating current tactics and experimenting with 
new ones. Explains the proposed approach in developing the simulation 
and the benefits behind that approach 

• Chapter III: Simulation Development. Describes the software engineering 
process from requirements to software architecture. 

• Chapter IV: Agent Development. Describes the development of the 
autonomous agents from a high-level framework to the software 
mechanisms that allow the agent to assess their environment, make 
decisions and act on those decisions. 

• Chapter V: Simulation Analysis. Describes the current simulation status 
and analysis of squad and individual agent behavior. 

• Chapter VI: Future Work and Conclusions. 


2 



II. BACKGROUND 


A. GLOBAL URBANIZATION AND MUT T ARY OPERATIONS 


One of the most significant global trends characterizing the last century is the 
urbanization of the world’s population. According to recent UN reports, an estimated 
150,000 people are added to the urban population of developing countries every day. 
Within the next decade, more than 50 percent of the world’s population will live in urban 
areas (UN, 1994); this figure is expected to increase to over 60 percent by the year 2025. 

Some areas of the world have seen phenomenal population increases in very short 
periods of time. Japan, Mongolia, and the continent of Africa have all seen their urban 
population increase by more than 25% in less than a 50-year period. (United Nations 
Population Division 1997). China has gone from 192 million people living in urban 
environments to 377 million in a 16-year period from 1980 to 1996. The most dramatic 
increase in urban population occurred in the Democratic People's Republic of Korea, 
which saw an increase from 17.7 percent to 61.2 percent from the years 1953 to 
1995(United Nations Population Division 1997). 

In more cases than not, rapid urbanization greatly exceeds the growth rate of 
urban infrastructures. This will lead to an eventual lack of energy resources, housing, 
and job opportunities for those immigrating to urban centers. The end result is an 
increase in poverty and crime, which sets the stage for regional instability and potential 
crises. 

U.S. military operations in urban terrain have been directly affected by urban 
population growth over the last 50 years. From the landing at Inchon, the battle for 
Seoul, and Hue city, to operations in Beirut, Panama, Haiti, Somalia, and Bosnia, the 
U.S. military has seen a shift from operations in open country to operations in urban 
centers ranging from small villages and towns to major metropolitan cities. 


3 



B, 


THE CHALLENGES OF URBAN WARFARE 


Up through World War II there were generally two ways to deal with urban areas. 
The first was to outright avoid them. Bypassing a eity and eontrolling its external nodes 
was an inexpensive way of eontrolling the eity itself. Controlling these external nodes 
allowed a military foree to out supply and oommunioation lines to that eity without 
having to enter it. The seoond method was to reduoe the eity by aerial or artillery 
bombardment and then enter and destroy it with little or no regard for oollateral damage 
or oivilian oasualties. 

There were genuinely good reasons why military leaders ohose to deal with urban 
areas in these two ways. Urban warfare, sinoe the Middle Ages, has always been more 
expensive and oomplex than warfare in open oountry. It is very resouroe and man¬ 
intensive, oasualty rates are high, and operations are usually painstaking and very time- 
oonsuming. Today’s urban environment adds many more unique ohallenges. 

First, urban environments provide a three-dimensional ground threat not seen in 
eonventional non-urban settings. Where eontrol of the ground in non-urban terrain is 
defined by surfaee area, eontrol of the ground in an urban environment must be defined in 
terms of volume. Multi-level buildings, basements, sewer systems, subway systems, all 
provide a third dimension. For a military foree to truly “eontrol” an area in an urban 
environment, it must eontrol this third dimension. 

Seeondly, a teehnologieal advantage in weaponry is neutralized in an urban 
environment. The military has used teehnology to gain the advantages of inereased range 
and lethality in weapon systems. These advantages are not only neutralized in urban 
environments but may serve as disadvantages. One eharaeteristie eommon to platforms 
with inereased ranges is a minimum target distanee. In the elose-quarter eonditions of 
urban warfare, a military foree is not likely to have the minimum distanee between itself 
and the enemy to take advantage of these long-range weapons. Additionally, the 
advantage of inereased lethality of eertain weapons equates to an inerease in the effeetive 
easualty radius of its munitions. With the elose-quarter eonditions of the urban 
environment, using these weapons ean lead to fratrieide or undesired eollateral damage. 

4 



Third, the close-quarter conditions themselves serve as a challenge. Close-quarter 
conditions reduce a military unit’s ability to disperse itself, making it more vulnerable to 
high casualty rates when area-target weapons like grenades, mortar rounds, or other 
explosives are used against it. Close-quarter conditions increase the risk of fratricide, as 
friendly units will operate much closer together and in more chaotic conditions. Close- 
quarter conditions increase the challenge of locating and targeting the enemy, and reduce 
the frontal coverage of a single unit, creating the need for more forces in the area of 
operation. 

Finally, the urban environment has obstacles not encountered in non-urban 
settings. Buildings, rubble, cars, fences, windows, doors, walls, and furniture are just a 
few. Environmental factors to be noted are electrical hazards from power lines and 
generators, natural gas hazards from gas lines and heating systems, and gasoline hazards 
from gas stations and automobiles. In addition to the obstacles themselves, the material 
of which they are made can affect the tactics a military unit practices. For example, some 
building materials may preclude the use of specific weapons due to fire hazard or the risk 
of fratricide. 

These are a few of the many challenges a military force is faced with in urban 
combat. Armed conflict is no longer defined solely by full-scale wars, but by a spectrum 
of operations ranging from peacekeeping and other low-intensity conflict to high- 
intensity combat operations. In recent military operations urban centers could not be 
avoided. In addition, global opinion has become less tolerant of excessive collateral 
damage and non-combatant casualties. Leveling an urban center to rubble has become 
unacceptable as a military course of action. New methods must be developed. 


C. TRAINING FOR URBAN WARFARE 


The level of training in Military Operations in Urban Terrain (MOUT) must 
correspond to its growing relevance on the global scene. The two greatest challenges in 
training in MOUT are realism and constancy. 


5 



In order for any combat training to be effective it must be realistic. Military units 
must see and experience the unique challenges associated with the urban environment in 
realistic combat settings. In order for troops to learn which tactics are effective, they 
must train in realistic scenarios where casualties are assessed. Obviously, live-fire 
exercises are not an option. However, the reasonable alternatives like MILES gear (laser- 
tag) or paint-ball guns are either poor in achieving realism or too expensive to conduct on 
a regular basis. 

MOUT training must also be continuous. The tactics, techniques and procedures 
for urban warfare are more complex than those associated with operations in non-urban 
terrain. Therefore, training in an urban environment must be done on a more regular 
basis and should be the focus of Marine combat training. The problem in today’s military 
is that the training sites for this specific kind of training are few in relation to the number 
of units needing them; frequency of training is limited to 4 to 5 training exercises a year. 
MOUT training demands much more attention. 

D, MODELING, SIMULATION AND AUTONOMOUS AGENTS 


Although there is no substitution for realistic training, computer modeling and 
simulation (M&S) may greatly help urban warfare training problems. Modeling can be 
defined as representing reality in a simplified manner such that some lesser details are 
avoided, but the integrity of dependencies and relationships are maintained. A model is 
characterized by three attributes. The first is the Reference or what the model refers to or 
represents. The second attribute is the Purpose or the intended cognitive reason for the 
model with respect to its referent. The last attribute is the Cost-effectiveness or the 
benefit of using the model instead of the referent itself (Rothenberg, 1989) 

Computer simulation is defined as the translation of a model from a mathematical 
or logical form into a working computer program. There are two approaches to 
simulation: analytical and discrete-state. Analytical simulation uses mathematical 
analysis to describe the referent. Its limitation is that not everything can be described in 
terms of mathematical equations. The discrete-state approach attempts to define the 

6 



referent in terms of unique states connected to another by events or other low level 
interactions, which cause transitions from one unique state to another, (Rothenberg, 
1989). 

Simulation can provide great benefits to the study of MOUT. It can provide 
vantage points not feasible in live training or real combat because of the limitation of 
real-life perspective. It can graphically depict the relationships between the agents in the 
squad and their interaction with the simulation environment. Other benefits include 
repeatability of scenarios and control over time. 

Simulating MOUT at the small-unit level with a focus on close-quarter battle 
techniques can also serve as a useful tool for small unit leaders. It will allow leaders to 
determine the effectiveness of existing tactics, techniques and procedures, to learn about 
the special challenges associated with operating in the urban environment, and to study 
the team dynamics of a small unit in such an environment. Simulation could also prove 
to be an inexpensive solution to experimenting with new and innovative tactics. 

For this thesis, a Marine infantry squad in an urban combat scenario will be 
modeled using autonomous agents in a discrete-state simulation. Autonomous agents are 
encapsulated software objects that take input from their environment, process that input, 
and then output specific actions that in turn affect and change the environment, (Weiss, 
1999). A software agent is capable of autonomous processing and autonomous action in 
order to meet its design objectives. Using autonomous agents to represent each Marine 
will facilitate the modeling of difficult cognitive and reactive responses not captured by 
other modeling techniques, they will make decisions and act independent of the user. 
This will provide a more realistic perspective in studying the performance of the squad 
and each Marine in a decentralized setting. Additionally, it will help depict the cause- 
and-effect relationships between the individual agents and their environment and how the 
relationships effect the operation of the squad. The real-life details of an infantry squad 
in a combat scenario will not and cannot be modeled. However, all the important 
relationships and dependencies between all the components of the overall simulation 
model will be represented. 


7 



Using C++ or Java, the model and its relationships will be implemented as an 
object-oriented simulation program. It will include a graphical user interface which will 
allow the user to view the model and the interaction of the components within the model 
in a graphical representation instead of raw, incomprehensible data. Some of the benefits 
of using an object-oriented approach to simulation are the comprehensibility of the 
design, encapsulation of information, extensibility of the program for future 
development, and modularization of the design, all of which will help make the program 
easier to test and program errors easier to identify. 


E. ISAAC 


Irreducible Semi-Autonomous Adaptive Combat (ISAAC) is an agent-based 
simulation developed by Andrew Ilachinski for the U.S. Marine Corps’ Combat 
Development Command (MCCDC), (Ilachinski, 1997). The focus of Ilachinski’s work 
was to approach ground combat as a Complex Adaptive System of individual 
autonomous agents. The ISAAC agents, ISAACA’s, represent low-level combatants 
with the ability to adapt to the environment by responding to local information and, based 
on adjustable “personality” vectors, making decisions advancing them towards a single 
overall goal to capture the opponent’s flag. 

Conventional combat models are primarily based on the Lanchester Equations 
created by F.W. Lanchester in 1914. These equations provided a simple way to adjudicate 
attrition style combat based only on attrition rates and the sizes of the forces involved but 
cannot capture the dynamic, non-linear characteristics of real combat or the adaptive 
behavior of combatant forces. ISAAC’S approach provides a higher level of resolution to 
combat modeling. 

The intent behind this thesis is to build on Ilachinski’s approach to modeling 
ground combat with autonomous agents modeling combatants; however, the focus will be 
on simultaneously modeling the unit to which these combatants belong to explore the 
relationship between the individual agent and the team. The individual agents will also 


8 



have the ability to manage and address individual goals while attempting to aeeomplish 
the team’s overall goal. 

Another aspeet to the ISAAC simulation that this thesis will foeus on is the idea 
of agent personalities. Eaeh agent has a “personality” veetor of weights assigned to 
speeifie environmental information; alive friendly agents, alive enemy agents, injured 
friendly, injured enemy, own flag, and enemy flag. A numerieal weight is assigned to 
eaeh eorresponding information type; the larger the weight, the higher the propensity of 
the agent is to move towards that type of object. For example, an aggressive agent would 
have high weights for alive enemy agents, injured enemy, and enemy flag, and would be 
more interested in moving towards enemy agents than towards friendly agents. For our 
application, personality attributes should be based more on real-life skills and attributes 
such as physical fitness, marksmanship, leadership, etc. 


F. ARCHIMEDES 


In the tradition of ISAAC, ARCHIMEDES is the Marine Corps’ current project in 
combat modeling and simulation. Its primary purpose is to provide a fast-running, 
flexible simulation architecture that provided variable resolution, variable scenario input, 
and behavior driven autonomous agents. The ARCHIMEDES platform was more a 
modeling environment than a model, with an emphasis on allowing the user to tailor the 
environment and the rules governing agent behavior for a wide range of scenarios. 
However, the focus of ARCHIMEDES is the development of a modeling tool while the 
focus of this is the development of the agent model and the relationship between the 
individual agent and the unit to which it belongs. 


9 



THIS PAGE INTENTIONALLY LEET BLANK 


10 



III. SIMULATION DEVELOPMENT 


A. STATEMENT OF REQUIREMENTS 


The product of this thesis is a Java application. A modified software engineering 
approach has been taken to compensate for the time limitations. 

The goal of this thesis is to model a Marine infantry squad with individual 
autonomous agents. Each agent will have individual attributes and goals. The squad 
itself will be represented as an agent with attributes and goals of its own. This will allow 
the team dynamics and dependencies to be qualitatively assessed and the effectiveness of 
tactics, techniques and procedures to be studied. The simulation, known henceforth as 
the Marine Squad Combat Simulation or MSCS, will be engineered according to the 
object-oriented programming paradigm in the Java programming language. 

B. REQUIREMENTS SPECIFICATIONS 


The basic requirements for the Marine Squad Combat Simulation are: 

• MSCS will be object-oriented. 

• MSCS will utilize autonomous agents to model actors in the simulation 

• Marine agents will be autonomous 

• Enemy agents and noncombatant agents will be autonomous. 

• Marine agents will have at least the following attributes: 

• X position; 

• Y position; 

• Heading; 

• Role; 

• Rate of movement; 

• Active goal; and 

• Goal manager. 


11 




• All Marine agents will be organized into one squad 

• Agents will have goals and decision-making mechanisms 

• MSCS will be implemented in the Java programming language 

• MSCS will provide a two dimensional interface 

• MSCS will be a closed-form, constructive simulation 

• MSCS will be engineered for extensibility to allow for the future 
enhancements 

C. SOFTWARE ARCHITECTURE 


The architecture of the Marine Squad Combat Simulation is described using only 
the Conceptual View of the four-view paradigm presented in (Hofmeister, Nord and Soni, 
2000). The requirements of the MSCS can be met in a single executable application built 
using a component-based architecture like the Model-View-Controller. This architecture 
was chosen because it facilitates the extensibility needed for future enhancements of the 
program and provides modularity that separates the models from both the interface and 
the simulation controller, (Burbeck, 1987). It is easy to add, remove, or alter the models 
without affecting the simulation environment. 





Figure 1. Model-View-Controller Architecture. 


12 







1 . 


Models 


The model eomponent of the simulation architecture is actually a component of 
components. It represents all the models in the simulation world. These models will 
have no association with the View component other than providing information to 
facilitate the graphical representation of the model. 

Every model in the simulation is derived from a single abstract class, SimObject 
(short for simulation object). Each subclass of SimObject contains at least an X and Y 
position value and a type attribute, which classifies the type of model created. Currently 
the models that can be created are SimpleAgents and BuildingComponents. Erom these, 
more specific objects like Marine agents, walls and doors can be created with attributes 
and methods tailored to those specific models. The Unified Modeling Eanguage, UML, 
class diagram in Eigure 2 shows the hierarchy of objects that represent the models in the 
simulation, (Eriksson and Penker, 1998). 



Eigure 2. Class Diagram of Model Objects. 


13 



























These basic models were then encapsulated into larger collections of the models. 
For example, an abstract base class, Building, was created which contains Wall and Door 
objects. Derivations of the Building class, Buildingl and Building!, combine different 
numbers of walls and doors to create different building structures. Furthermore, a class 
named Infrastructure contains a collection of Building derivatives; Figure 3 shows its 
class relationships. 



Figure 3. Infrastructure Class Hierarchy. 


2, View 

The view component is the direct interface between the user and the controller. It 
is responsible for displaying graphics and data provided by the models and the controller. 
For MSCS the view component is encapsulated in the paintQ function of the Java Applet 

14 




























controlling the simulation. The view eomponent communieates with eaeh of the models 
through the eontroller. Each model eontains its own paintQ funetion, which 
communicates to the view eomponent the information needed to graphieally display eaeh 
model on the two-dimensional display. Figure 4 shows the display provided by the 
view eomponent, whieh graphieally depiets the simulation world and models. 

The environment for the simulation program is modeled as a two dimensional 
system of grid squares. The grid squares have dimensions of 5 x 5 pixels. Agents are 
represented by eyan (light blue) squares. Walls are represented as several gray squares. 
Doors are represented by gray-outlined squares. Only one SimObject ean oecupy each 
grid square at a time. Orange squares represent checkpoints. 



Figure 4. 


The View Component’s Display. 
15 











3. 


Controller 


The controller component controls the running of the application. It does so 
through the SimController class, which extends the Applet class. The SimController class 
has three main functions. The first function is to maintain a global “blackboard” of 
information by which the View and Model components can retrieve information about 
the simulation environment. The blackboard function is accomplished with an 
instantiation of the class Parameters. The Parameters class contains all of the simulation 
parameters and global constants of the simulation environment. It provides the common 
language for all 3 components of the simulation architecture. 

The second function of the SimController class is to retrieve user input from 
external devices, i.e. mouse, keyboard, etc. This input is processed and translated into 
commands. These commands are then sent to the Model and View components in order 
to trigger their state changes. 

The third function of the SimController class is to run the simulation iteration by 
iteration. In the case of the agents, the controller component will act as the system 
“referee” as the agents interact with each other and the environment. The resulting 
architecture provides for extensibility and modularity. In addition, it facilitates rapid 
prototyping of the system that allows functionality to be added incrementally. 

Earlier attempts to use an independent thread to execute the simulation made it 
difficult to test and debug the program. To facilitate testability in MSCS, the controller 
uses a lockstep-timestep to run the simulation. 


D, SIMULATION ENVIRONMENT 


The Parameters class holds all the necessary information about the environment. 
It maintains a data structure SIM_ENV (short for Simulation Environment), which knows 
what type of SimObject occupies each grid square. SIM_ENV is updated after each 
simulation iteration to keep up with agent movement. The information provided by 


16 



SIM_ENV is critical for collision detection and avoidance in eonneetion with agent 
movement during the simulation. This issue is discussed further in Chapter IV. 


17 



THIS PAGE INTENTIONALLY LEET BLANK 


18 



IV. AGENT DEVELOPMENT 


A, AGENT FRAMEWORK 


One of the key design issues of this program is that of the agent. Autonomous 
agents take input from their environment, process that input, and then execute actions that 
in turn affect the environment, (Weiss, 1999). Like an object in object-oriented 
programming, an agent is acted upon by its environment. However, unlike an object, the 
agent has sole direct control over its behavior and actions. As an object encapsulates its 
state and behaviors, so too will the agent’s state and behaviors be encapsulated, along 
with its data processing and decision-making functions. 



Figure 5. Agent Framework. 


Figure 5 graphically depicts the high-level decision-cycle framework for the 
Marine agent or OODA loop. The agent observes the environment through its sensor 


19 
























functions. The information received may or may not affeet the agent’s state. If the state 
has changed, the agent’s new state will affect the status of its individual goals. The agent 
orients itself using its own state revision function to adjust its state variables. The goal 
managing mechanism of the agent will then adjust the status of its goals based on the 
agent’s new state. The agent then decides using its goal managing mechanism which 
goal is the most eritieal and should be addressed. The goal manager assigns this goal as 
the active goal. Finally, the agent acts on the environment based on its active goal. The 
agent executes this decision cycle each iteration of the simulation. 


B, STATE VARIABLES 


Referring back to Figure 2, the SimpleAgent has an X and Y position, type, 
heading, and health attributes. An instantiation of the Marine agent contains these 
attributes and several more, the most important of whieh are the role attribute, the rate 
attribute and activeGoal attribute. 

The role attribute is assigned to each agent at the moment of instantiation. It 
defines the Marine agent’s job in the squad. It affects the actions of the agent and serves 
as a heuristic for its movement algorithm. Currently, the role attribute is not explored 
much by our implementation for lack of time. For future enhaneement of the program 
changing the role attribute of an agent ean help model delegation of authority if a senior 
agent is destroyed. 

The rate attribute describes the rate of movement for the agent. Currently, in the 
Parameters class, there are 5 rates of movement defined as distances in pixel length per 
time step that the agent can to move. This translates to a range of movement of 0 to 2 
grid squares per time step. 

The activeGoal attribute is the goal that the agent deems eritieal to address. The 
activeGoal dictates the aetion that the agent will execute at the end of its decision cycle. 
The agent’s goal-managing mechanism, a derivative of the GoalManager class described 
later in the chapter, determines this 


20 



c 


GOALS AND GOAL MANAGING 


The agent’s behavior is dietated by its goals represented by Goal objeets, which 
describe a desired state the agent works toward. At this stage of the simulation 
development, the Goal objects created for Marine agents are MoveGoal, FormationGoal, 
and the SurvivalGoal. MoveGoal means to move to a desired location in the simulation 
environment. FormationGoal means to assume a position in the squad formation based 
on its role attribute. The SurvivalGoal, not yet implemented, means to get out of the line 
of fire and find a place of cover to regenerate its health value. 

Goal objects can hold one of three states. Using a traffic-light analogy, goals that 
become critical have a RED status; those goals that are satisfied hold a GREEN status; 
otherwise goals are in a YELLOW status. In the cases of the MoveGoal and 
EormationGoal, the current distance between the agent and its desired destination 
determines the status thresholds. For example, if the distance from the agent to its 
desired MoveGoal destination is greater than 100, then the agent’s move goal would be 
assigned a RED status; if the distance is less than 5, the MoveGoal status would be 
GREEN, and if the distance is between 5 and 100, the MoveGoal status is YELLOW. 
The assessment of the FormationGoal status is similar, except it is based on the agent’s 
distance from its current position to the desired location with respect to the squad leader 
position and heading. This ensures that the agents move in some semblance of a tactical 
formation. The assessment of the SurvivalGoal would be based on the health attribute of 
the agent or whether the agent is under fire. 

The agent’s overall goal managing is handled by a software mechanism simply 
called the GoalManager class. The MarineGoalManager, which extends the 
GoalManager class, holds the agent’s Goal objects, assesses the status of these Goal 
objects after each state change, and then determines which goal is the most critical and 
should be addressed by the agent. It is in the MarineGoalManager that the priorities and 
decision-making aspects of the agent are created. For example, after assessing the status 
of its goals, the MarineGoalManager can assign the active goal by this algorithm: 


21 



IF SurvivalGoal.status = RED , THEN activeGoal = SurvivalGoal 
ELSE IE FormationGoal.status = RED, THEN activeGoa\= EormationGoal 
ELSE activeGoal = MoveGoal. 


This algorithm would make survival the agent’s highest priority, followed by 
staying in formation, and then moving towards the agent’s final destination. This is a 
general solution for an average agent. There are other ways to give eaeh agent a unique 
set of deeision-making rules based on personality attributes like experience, leadership, 
bravery, ete. Eor example, some agents eould hold the MoveGoal as a higher priority 
than staying in formation, or other agents eould hold the MoveGoal as the highest priority 
overall. Similarly, varying the goal-status thresholds could create cautious agents whose 
SurvivalGoal becomes critical when their health attribute is 60 or less, aggressive agents 
whose SurvivalGoal becomes critical when their health attribute is 40 or less, or 
“kamikaze” (suicide) agents whose SurvivalGoal never becomes critical. 


D, AGENT ACTION 

1, Basic Movement 

Once the agent’s active goal has been assigned, the agent executes an action that 
will advance the agent further in the accomplishment of that goal. Presently, the agents 
are restricted to one type of action: movement. The agents will move toward a desired 
checkpoint or a position in the squad formation. Eigure 6 depicts the agent’s movement 
constraints. The grid layout of the simulation environment constrains agent movement to 
8 possible directions shown by the arrows. The aspect of movement rate constrains the 
agent to move 0, 1 or 2 grid squares in any of the 8 directions. The squares in yellow 
represent movement at the fastest rate; the squares in green represent movement at the 
slow and medium rates; and the blue square represents the agent’s position. 


22 




Figure 6. Agent Movement Constraints. 

2 Collision Detection/Avoidance 

Which of the 8 directions is the best for the agent to head in to reach a desired 
location is a straightforward evaluation. Flowever, collision detection and avoidance 
become the critical issues for agent movement in the modeled urban infrastructure. The 
individual agent’s movement is confined to 16 possible moves, so a simple and 
inexpensive algorithm was developed to check the viability of each of these moves by 
retrieving information about the corresponding grid squares from the SIM_ENV array. 
Knowing the agent’s rate and preferred direction of travel, the agent’s list of moves is cut 
down to 4, the last one being to stay in place. These moves are ordered by distance to the 
desired location. For example, if the agent needed to move down and right, but was 
unable to, his next set of moves would be to move down or move right. If neither is 
viable then the agent stays put for that time-step. 

Although this collision detection algorithm works at the local level, it can fail at 

the global level. It has the tendency to get agents stuck in corners or areas with many 

obstacles. It also limits the agent movement to direct routes to the desired location, 

which is not always the smartest approach by human standards. These problems led to an 

attempt to give the agent some global obstacle sensing by a density evaluating function. 

In this context density describes the presence of obstacles and their proximity to the 

23 





















agent. For a specified number of grid squares in each of the possible directions of 
movement, an integer value representing the type of object that occupies the grid square 
was retrieved from the SIM_ENV array. Values other than zero represent obstacles. 
Each value was then multiplied by a proximity factor; the closer the obstacle was to the 
agent, the higher the proximity factor. The results were summed together for a total 
density value for that direction. However, this approach still failed to give the agent a 
reliably viable route to its final destination; Agents were still getting stuck in corners or 
inside buildings. This led to the decision to incorporate path planning, at least for the 
squad leader. 

3, Path Planning 

Path planning gives the squad leader global planning ability to find a truly viable 
path from the starting point to the squad’s desired destination. Only the agent whose role 
attribute was that of the squad leader would be given the ability to plan a path. This was 
done to visualize the difference in mission between the squad leader and the rest of the 
squad. 

The cornerstone of path planning is a search algorithm. The search algorithm 
would need a search space of nodes to serve as a search graph. The nodes would have to 
correspond to trafficable areas in the environment. One simplification was to associate 
nodes with each entrance of the buildings in the environment and then connect the nodes 
that are within a clear line of sight of each other. The first step was to create a class of 
nodes called PathNode and a search-graph class, PathSearchGraph, to hold the nodes. 
Next, the Door class was reengineered to create two objects of the PathNode class upon 
instantiation of a Door object, one corresponding to the external side of the Door object 
and one corresponding to the internal side. These nodes are added to the 
PathSearchGraph, which then calls on a method to link all the nodes that are within a 
clear line of sight of each other. This creates the network of nodes. When the squad 
leader agent begins his path planning, he creates two additional PathNodes, 
corresponding to his starting position and his desired destination, and links them to the 
existing search graph. 


24 



Figure 7 shows an example of the search graph created from a sample 
infrastructure (wall and doors). The PathNodes are shown as the white colored squares 
associated with the doors of the gray buildings. The red lines are the edges that connect 
the nodes by line of sight. The squad members are the cyan squares. 



Figure 7. Path Search Node Network. 


Once there is a network of nodes including the start and destination nodes, the 
squad leader agent can use one of four algorithms to choose a path to the destination 
node. Breadth-first and Depth-first search algorithms were programmed for this purpose; 
however, they are not practical as tactical path planning algorithms. 

So, two best-first search algorithms were created. The first was based on distance 
from the node to the destination node. The algorithm finds the path of shortest distance 
from the start node to the destination node. The second best-first search algorithm was 
based on a cover and concealment benefit instead of a cost; nodes internal to the 
buildings were given a cover and concealment value of 10, and all others were given a 
cover and concealment value of 0. The algorithm searches for the most covered and 
concealed route to the destination node. 


25 


















Once the seareh algorithm is able to loeate the destination node a list of nodes 
from the start node to the destination node is eompiled. Next, a path is construeted for 
each successive pair of nodes, providing a list of sub-destinations that the agent moves 
toward in order to reaeh its final destination. Figures 8 and 9 show the resulting paths 
(yellow squares) for the best-first search shortest path algorithm and the best-first seareh 
eover and concealment algorithm, respectively. 



Figure 8. 


Best-First Seareh (Shortest Path). 
26 






































Figure 9. Best-First Seareh (Cover and Concealment Benefit). 


27 












Path planning solved the collision detection/avoidance problem and provided a 
way of modeling the common tactical dilemma of speed vs. security. In some situations 
a leader will choose to take the quickest or shortest route. In other situations, it is more 
important to find a secure route, characterized by cover and concealment. This and the 
variety of search algorithms provide ways to create unique tactical decision-making 
personalities. 

E. SQUAD RELATIONSHIP 


The relationship between the squad and its individual agents is a major issue in 
the development of this simulation. The intent was to engineer a software structure that 
could act as an agent while at the same time serve as the cohesive container for the 
individual Marine agents. The Squad entity would have to be transparent to the 
simulation environment. The Squad object, therefore, would not be derived from the 
SimpleAgent class, but would contain the same framework as the Marine agent. 

The Squad entity would sense the environment and contain its own goals and goal 
manager like the individual agents. Its state would be dependent on the status of its goals 
and the states of the agents in the squad. It would use the personality attributes of the 
Marine whose role attribute is Squad Leader to influence its decision-making process. 
However, its main function would be to keep the agents focused on the squad’s overall 
goal. Figure 10 shows the class relationship between the Squad agent and the Marine 
agents. 


Squad 


Marine 

^squadVector: Vector 

a ri n e Attri b u te s 


1 13 


^squadOps() 

^nnarineOps() 


Figure 10. Squad-Marine Agents’ Class Relationship. 


28 









F. SQUAD VS. INDIVIDUAL GOALS 


Presently, the Squad manages only one goal; to eonduet a patrol using 
predetermined eheekpoints. This PatrolGoal direets the individual agents to move 
through these eheekpoints by eatalyzing the ereation of sueeessive MoveGoals for the 
squad leader agent. The rest of the agents in the squad have highest priority on their 
FormationGoal, whieh direets the agents to maintain their position in the squad 
formation. The SquadGoalManager assesses the progress of the PatrolGoal and the 
simulation ends when the PatrolGoal status is GREEN. 


29 



THIS PAGE INTENTIONALLY LEET BLANK 


30 



V. SIMULATION ANALYSIS 


A RUNNING THE SIMULATION 


Opening the SimController applet instantiates the simulation world and all the 
models in the world. The infrastrueture is ereated. The squad and its agents are ereated 
and positioned at a predetermined starting point. The simulation advanees eaeh time- 
step with eaeh eliek of the mouse button. With eaeh time-step of the simulation, the 
agents in the squad exeeute their deeision eyele with the ultimate intent of aeeomplishing 
the squad’s overall goal and their individual goals. The simulation as a whole is 
eomprised of 22 Java elasses and the SimController.html applet. The program runs using 
the Java Development Kit version 1.3, or using the JBuilder 4 IDE and oeeupies 70 
kilobytes of souree data. 

B, SIMULATION RESULTS 

1. The Scenario 

At this stage of development, the simulation program models an infantry squad 
eontaining 13 autonomous Marine agents. The squad has a single goal: to patrol the 
simulation environment, using predetermined eheekpoints. There were three eheekpoints 
in the seenario. The patrol mission is translated to the squad leader agent as sueeessive 
movement goals. The squad leader agent reeeives the first destination from the Squad 
entity and ereates a movement goal to that destination. Upon reaehing the first 
eheekpoint, the squad leader reeeives the seeond eheekpoint and again ereates a 
movement goal to that destination. This eyele repeats until the third eheekpoint has been 
translated to the squad leader agent. 

2, Squad and Individual Agent Interaction 

The squad leader agent uses its path-planning ability to find a viable route to eaeh 
eheekpoint and then moves along the resulting path. The other agents in the squad use a 
loeal eollision deteetion/avoidanee algorithm to pursue their FormationGoal, essentially 


31 



leaving the navigation responsibilities to the squad leader. Their main eoneern is to 
maintain a eolurnn formation as they move from eheekpoint to eheekpoint. This was 
done to model a eommand and eontrol strueture within the squad. The Squad entity keeps 
traek of the all the agents in the squad in order to assess the progress of meeting the 
Squad's PatrolGoal. 

The results on this simple seenario were mixed. The proeess of getting the squad 
through all three eheekpoints was sueeessful. The squad leader was able to move 
unhindered, while the rest of the squad guided their movement off of the squad leader. 
The majority of the squad reaehes eaeh eheekpoint as a eohesive unit. However, 
members of the squad seem to aet like “lost sheep” following a shepherd beeause only 
the shepherd knows where to go. In faet, beeause of the limitations in the eollision 
deteetion and avoidanee algorithm and laek of global planning strategies in the Marine 
agents, some ended getting stuek. It was eommon to see I or 2 agents getting stuek in 
eomers while the rest of the squad eontinued on to the next eheekpoint. Figure 11 shows 
the squad moving to the third and final eheekpoint. 


32 




Figure 11. Squad Moving to Third Checkpoint. 


33 

























































































































































































































































































































































THIS PAGE INTENTIONALLY LEET BLANK 


34 



VI. FUTURE WORK AND CONCLUSIONS 


A. FUTURE WORK 


Many potential enhancements of this program are apparent. 

1. Develop Agent Personalities 

• Develop the agents’ personalities by adding tangible skills like 
marksmanship and physical fitness which would affect their shooting 
accuracy and movement rates. 

• Add intangible qualities like experience, leadership, and courage, which 
would affect the agents’ decision-making ability and goal prioritization. 

• Refine the agent models by studying actual human performance. 

2. Develop Agent Actions 

• Add randomness to action choice and execution. 

• Develop the agents’ ability to act by adding target acquisition ability. 

• Add the ability to engage enemy targets. 

• Allow agents to die. 

3. Develop different agent types 

• Introduce enemy agents with opposing goals and non-combatant agents. 

4. Develop the infrastructure 

• Make the simulation terrain affect the agents’ movement rates. 

• Add more complexity to the infrastructure, water supplies, religious 
centers, etc, with cause-and-effect relationships with how the enemy and 
non-combatants act when these are affected by Marine agent actions. 

5. Develop the User Interface 

Add functionality to the graphical user interface in order to allow the user to: 

• Change the simulation parameters; 

• Alter the personalities of the agents; 

• Analyze the current state of the agents; 

• Add agents dynamically; and 

• Analyze elements of the infrastructure. 

6. Create Smarter Agents 


35 




Develop the intelligenee of the agents in the simulation by: 

• Creating more goals for the individual agent. 

• Creating more goals for the squad. 

• Using genetie algorithms to allow the agents to adapt and learn from their 

environment. 

B, CONCLUSIONS 


Developing autonomous agents is a eomplex and evolutionary undertaking. 
Detailed software engineering preparation is needed to produee intelligent meehanisms 
within the agent. The potential of autonomous agents in research and analysis in a 
simulation program remains promising for military applications. They provide a 
controllable and inexpensive test environment for a wide variety of processes. Using 
such a versatile tool to evaluate small-unit operations in an urban environment is an 
advantage over our future adversaries that we cannot afford to ignore. 


36 



APPENDIX A. JAVA SOURCE CODE 


This appendix contains the Java source code for the Marine Squad Combat 


Simulation. 


* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.MenuBar; 
import java.awt.event. *; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang. *; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 


public class SimController extends Applet implements ActionListener { 
boolean isStandalone = false; 


//simulation attributes 
int iteration=0; 

Squad simSquad; 

Marine tempMarine; 

Vector targetVector; 
Infrastructure siminfrastructure; 
Parameters simParameters; 


//graphics 

Image offScreenImage = null; 
Graphics offScreenGraphics = null; 
Dimension offScreenSize = null; 


37 




//interface components 
BorderLayout borderLayoutl; 

Panel controlPanel; 

Choice searchAlgorithm; 

String algorithms[] = {"BestFirst (Cover & Concealment)", 
"BestFirst(Shortest Distance)", "BreadthFirstSearch", 
"DepthFirstSearch"}; 

Button simStep, reset, showNode, showPath; 


/**Get a parameter value*/ 

public String getParameter(String key. String del) { 
return isStandalone ? System.getProperty(key, del) : 
(getParameter(key) != null ? getParameter(key): del); 

} 


/**Constmct the applet*/ 
public SimController() { 

addMouseListener( new MouseAdapter() { 

public void mouseReleased( MouseEvent me) { 
simSquad.ooda(); 
repaint(); 

Parameters.simIteration++; 


}); 


/**Initiahze the applet*/ 
public void init() { 
try { 
jblnitO; 

} 

catch(Exception e) { 
e .print StackTrac e(); 

} 

} 

/**Component initialization*/ 
private void jblnit() throws Exception { 
this. setBackground(Color. lightGray); 
borderLayoutl = new BorderLayout(); 
this. setLayout(borderLayout 1); 

controlPanel = new Panel(); 
searchAlgorithm = new Choice(); 
for (int ik = 0; ik < algorithms.length; ik++){ 
searchAlgorithm.addItem(algorithms[ik]); 

} 

searchAlgorithm.addItemListener( 
new ItemListenerO { 


38 



public void itemStateChanged(ItemEvent e) 

{ 

String mystring = (String)e.getltem(); 
if("BreadthFirstSearch".equals(mystring)){ 

Parameters.PathSearch = Parameters.BFSEARCH; 

} 

else if("DepthFirstSearch".equals(mystriiig)){ 
Parameters.PathSearch = Parameters.DFSEARCFl; 

} 

else{ 

if("BestFirst(Shortest Distance)".equals(mystring)){ 
Parameters.PathSearch = Parameters.SHORTDISTSEARCFl; 

} 

else if ( 

"BestFirst (Cover & Concealment)".equals(mystring)){ 
Parameters.PathSearch = Parameters.COVERSEARCFl; 

} 

} 

} 

}); 

simStep = new Button("STEP"); 
reset = new Button("RESET"); 
showNode = new Button("SHOW NODES"); 
showPath = new Button("SHOW PATH"); 

controlPanel. setLayout(new GridLayout( 1,5)); 
controlPanel. add(simStep); 
simStep.addActionListener(this); 
controlPanel. add(reset); 
reset.addActionListener(this); 
controlPanel. add(showNode); 
showNode.addActionListener(this); 
controlPanel. add(showPath); 
showPath. addActionListener(this); 
controlPanel.add(searchAlgorithm); 

simParameters = new Parameters(); 
simParameters. initEnvO; 
siminfrastmcture = new Infrastructure(); 
simSquad = new Squad(); 
simParameters.pathGraph.setLinksO; 
this.add(controlPanel, borderLayoutl .NORTH); 


}//end init() 


public void actionPerformed(ActionEvent e) { 
String arg = e.getActionCommand(); 

if("STEP".equals(arg)){ 

startStopO; 

} 

else if("RESET".equals(arg)){ 
reset(); 


39 



else{ 

ifC'SHOW NODES".equals(arg)) { 
toggleNodesQ; 

} 

else ifC'SHOW PATH".equals(arg)){ 
togglePathO; 

} 


}//end aetionPerformed 

publie void startStop() { 
simSquad.ooda(); 
repaintQ; 

Parameters. simIteration++; 

} 


publie void reset() { 
simParameters = new Parameters(); 
simParameters.initEnvO; 
siminffastrueture = new Infrastrueture(); 
simSquad = new Squad(); 
simParameters.pathGraph.setLinksO; 
Parameters, simiteration = 0; 
repaintQ; 

} 


publie void toggleNodesQ { 
if(!Parameters.ShowNodes) { 
Parameters. ShowNodes = true; 

} 

else{ 

Parameters.ShowNodes = false; 

} 

repaintQ; 

}//end toggleNodes 


publie void togglePathQ { 
if(! Parameters. ShowPath) { 
Parameters. ShowPath = true; 

} 

else{ 

Parameters. ShowPath = false; 

} 

repaintQ; 

}//end togglePath 


publie void paint(Graphies g) { 

//draw baekground world 
g.setColor(Color.blaek); 

40 



g.fillRect(0,0,Parameters.WIDTH, Parameters.HEIGHT); 
g.setColor(Color.darkGray); 
for(iiit ix =0; ix <= Parameters.COLUMNS; ix++){ 
g. drawLine (ix * Parameters. CELL_ WIDTH, 0, 
ix*Parameters.CELL_WIDTH,Parameters.HEIGHT); 

} 

for(iiit iy=0; iy<= Parameters.ROWS; iy++){ 
g.drawLine(0,iy*Parameters.CELL_HEIGHT, 
Parameters.WIDTH, iy*Parameters.CELL_HEIGHT); 

} 


//draw start pt 
g. setColor(Color. orange); 

g.fdlReet(Parameters.STARTING_POINT[0],Parameters.STARTING_POINT[l], 

Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 

//draw eheekPoints 

g.fdlReet(Parameters.CHECK_PTS [0] [0],Parameters.CHECK_PTS [0] [ 1 ], 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 
g.fdlReet(Parameters.CHECK_PTS [ 1 ] [0],Parameters.CHECK_PTS [ 1 ] [ 1 ], 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 
g.fdlReet(Parameters.CHECK_PTS [2] [0],Parameters.CHECK_PTS [2] [ 1 ], 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 

//draw infrastrueture 
siminfrastrueture .paint(g); 

//draw squad 
simSquad.paint(g); 

//draw nodes 

if(Parameters. ShowNodes) { 

Parameters.pathGraph.paint(g); 

} 

}//end paint 


publie final void update(Graphies g) { 

//implements no-fiieker graphies 
Dimension dim = getSize(); 

if((offSereenImage==null) || 

(dim.width != offSereenSize.width) || 

(dim.height != offSereenSize.height))) 

offSereenImage = ereatelmage(dim.width, dim.height); 
offSereenSize = dim; 

offSereenGraphies = offSereenImage.getGraphies(); 


} 

oftSereenGraphies.elearReet(0,0,offSereenSize.width,offSereenSize.height); 

paint(offSereenGraphies); 
g. drawImage(o ffScreenImage, 0,0 ,null); 


41 



}//end update 


/** Start the applet*/ 
public void start() { 

} 

/**Stop the applet*/ 
public void stop() { 

} 

/**Destroy the applet*/ 
public void destroy() { 

} 

/**Get Applet information*/ 
public String getAppletInfo() { 
return "Applet Information"; 

} 

/**Get parameter info*/ 
public String[][] getParameterInfo() { 
return null; 

} 

} 


42 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

* class Parameters holds all the simulation parameters and 

* constants. 

*/ 

public class Parameters { 

//simulation environment 
final static int CELL WIDTH = 5; 
final static int CELL_HEIGHT= 5; 
final static int COLUMNS = 150; 
final static int ROWS = 120; 

final static int WIDTH = CELL WIDTH * COLUMNS; 
final static int HEIGHT = CELL HEIGHT * ROWS; 

//environment array 

//tracks what object occupies a grid in the environment 
public static int SIM_ENV[][] = new int[120][150]; 


//simObject types 
final static int DOOR = -1; 
final static int MARINE =5; 
final static int WALL =15; 

//simulation parameters 

final static int NUM MARINES = 13; 

public static boolean ShowPath = false; 

public static boolean ShowNodes = false; 

public static int PathSearch = 0; 

public static boolean PatrolMission = false; 

//goal status 

final static int RED = -1; 
final static int YELLOW = 0; 
final static int GREEN = 1; 

final static int [] STARTING_POINT = {80,140}; 

final static int [][] CHECK PTS = {{520,280},{650,500},{100,480}}; 

//rates of movement 
final static int STOP =0; 
final static int VERY SLOW =1 ; 
final static int SLOW = 2; 
final static int MEDIUM = 5; 


43 



final static int FAST =10; 

//simulation iteration counter 
public static int simiteration = 0; 

//headings 

final static int NORTH = 0; 
final static int SOUTH = 1; 
final static int EAST = 2; 
final static int WEST = 3; 
final static int NORTH EAST = 4; 
final static int NORTH WEST = 5; 
final static int SOUTH EAST = 6; 
final static int SOUTH WEST = 7; 

//move actions 
final static int UP =0; 
final static int DOWN =1; 
final static int RIGHT = 2; 
final static int LEFT =3; 
final static int UPRIGHT =4; 
final static int UPLEFT = 5; 
final static int DOWNRIGHT = 6; 
final static int DOWNLEFT = 7; 
final static int STAY = 8; 

//pathsearchgraph 

public static PathSearchGraph pathGraph = new PathSearchGraph("Pathgraph"); 

final static int LOS DIST = 180; //Line of sight range 

final static int COVER SEARCH = 0;//Bestfirst w/cover 

final static int SHORTDIST SEARCH = 1;//=1 for depthfirst w/distance 

final static int BFSEARCH = 2; //breadth first search 

final static int DFSEARCH = 3;//depth first search 


//squad settings 

public static int SQD FORMATION = 2; 
public static int DISPERSION = 2; 

//formations 

final static int LINE = 1; 
final static int COLUMN = 2; 

//goals 

final static int MOVE GOAL = 1; 
final static int FORMATION GOAL = 2; 
final static int PATROL GOAL = 3; 

//squad roles 

final static int SQD LDR = 0; 

//wall sizes 

final static int WALL XS = 5; 
final static int WALL S = 10; 
final static int WALL M = 20; 


44 



//door sizes 

final static int DOOR S = 4; 
final static int DOOR M = 6; 
//wall and door orientations 
final static int VERTICAL = 1; 
final static int HORIZONTAL = 2; 


* setEnv(r,c,t) 

* sets SIM_ENV[r][c] to type t 

*/ 

public void setEnv(int r, int c, int t) { 
SIM_ENV[r][c] = t; 

}//end setEnv 

* initEnvO initializes the SIM ENV array 

*/ 

public void initEnv() { 
for(int ix = 0; ix < ROWS; ix++){ 
for(int iy =0; iy < COLUMNS; iy++){ 
SIM_ENV[ix][iy] = 0; 

}//end for 
}//end for 
}//end initEnv 

* getEnVal(r, c) returns type value contained 

* in SIM_ENV[r][c] 

*/ 

public int getEnVal(int r, int c){ 
return SIM_ENV[r][c]; 

}//end getEnVal 

}//end Parameters 


45 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 

* class Squad creates an autonomous agent entity 

* that contains the Marine agents in the simulation 

* A transparent entity: has no discrete position in the 

* simulation environment. Not a child of the SimObject class 

*/ 

public class Squad { 

int direction = Parameters.RIGHT; 

int movementRate= Parameters.STOP; 

int squadActiveGoal = Parameters.PATROL GOAL; 

Marine tempMarine; 

Vector squadVector; 

SquadGoalManager sqdGoalManager; 


public Squad() { 

squadVector = new Vector(); 

//create marines and place them in squad vector 
//position Marine agents in column formation on screen 
int baseX = Parameters. STARTING_POINT[0]; 
int baseY = Parameters. STARTING_POINT[l]; 
int destH = Parameters.EAST; 
int destX = 0; 
int destY = 0; 

for(int ix = 0; ix < Parameters.NUM MARINES; ix++){ 
switch(ix) { 
case 0: 

destX = baseX; 


46 





destY = baseY; 
break; 
case 1: 

destX = baseX + (1 * Parameters.CELL WIDTH); 
destY = baseY + (2 * Parameters.CELL WIDTH); 
break; 

case 2: 

destX = baseX + (3 * Parameters.CELL WIDTH); 
destY = baseY + (4 * Parameters.CELL WIDTH); 
break; 

case 3: 

destX = baseX + (5 * Parameters.CELL WIDTH); 
destY = baseY + (4 * Parameters.CELL WIDTH); 
break; 

case 4: 

destX = baseX + (3 * Parameters.CELL WIDTH); 
destY = baseY + (2 * Parameters.CELL WIDTH); 
break; 

case 5: 

destX = baseX - (3 * Parameters.CELL WIDTH); 
destY = baseY - (I * Parameters.CELL WIDTH); 
break; 

case 6: 

destX = baseX - (5 * Parameters.CELL WIDTH); 
destY = baseY - (4 * Parameters.CELL WIDTH); 
break; 

case 7: 

destX = baseX - (I* Parameters.CELL HEIGHT); 
destY = baseY-(2 * Parameters.CELL HEIGHT); 

break; 

case 8: 

destX = baseX -(3* Parameters.CELL HEIGHT); 
destY = baseY-(4 * Parameters.CELL HEIGHT); 
break; 

case 9: 

destX = baseX - (6 * Parameters.CELL WIDTH); 
destY = baseY - (5 * Parameters.CELL HEIGHT); 
break; 

case 10: 

destX = baseX-(8 * Parameters.CELL HEIGHT); 
destY = baseY - (7 * Parameters.CELL WIDTH); 
break; 

case II: 

destX = baseX- (5 * Parameters.CELL HEIGHT); 
destY = baseY - (5 * Parameters.CELL WIDTH); 

47 



break; 


case 12: 

destX = baseX - (6 * Parameters.CELL WIDTH); 
destY = baseY - (7 * Parameters.CELL HEIGHT); 
break; 

}//end switch(ix) 

//set Marine values 

tempMarine = new Marine(ix,destX,destY,destH); 

//add newly created Marine to squadVector 
squad V ector. addElement(tempMarine); 

}//end for 

sqdGoalManager = new SquadGoalManager(squadVector); 
}//end constructor 


* ooda() runs each Marine agent in the squad 

* through their ooda loop cycle 

*/ 

public void ooda() { 

sqdGoalManager.checkGoalStatus(squadVector); 
squadActiveGoal = sqdGoalManager.getActiveGoal(); 
for(int ix = 0; ix < Parameters.NUM MARINES; ix++){ 
tempMarine = (Marine)squadVector.elementAt(ix); 
tempMarine .oodaLoop(squadV ector); 

} 

}//end ooda 


* paint() paints the Squad object 

*/ 

public void paint(Graphics g) { 
for(int ix=0; ix < Parameters.NUM MARINES; ix++){ 
tempMarine = (Marine)squadVector.elementAt(ix); 
tempMarine.paint(g); 

}//end for 
}//end paint 


* getMarineAt(x) returns Marine at index x 

*/ 

public Marine getMarineAt(int x) { 
tempMarine = (Marine)squadVector.elementAt(x); 
return tempMarine; 

}//end getMarineAt 


}//end squad 


48 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 

public class Marine extends SimpleAgent { 

//attributes 
int rate; 
int role; 

int personality []; 

int nextAgentMove = Parameters. STAY; 
int activeGoal; 

int SENSOR_RANGE = 10; 

int density Range = 50; 

int density = 0; 

int density Threshold = 25; 

int moveDensity[] = {0,0,0,0,0,0,0,0}; 

int health; 


boolean[] moves = {true,true,true,true,true,true,true,true}; 
Color agentColor = Color.blue; 

Marine tempMarine; 

Vector pathVector; 

PathElement tempElement; 

MarineGoalManager goalManager; 


public Marine(int r, int x, int y, int h) { 
setXpos(x); 
setYpos(y); 
setHeading(h); 

setType(Parameters.MARINE); 
Parameters.SIM_ENV[y/Parameters.CELL_HEIGHT] 

[x/Parameters.CELL_WIDTH]=Parameters.MARINE; 

49 





role = r; 

rate = Parameters. SLOW; 
health =100; 

path Vector = new Vector(); 
goalManager = new ]VlarineGoal]Vlanager(x,y,r,h, 
Parameters.STARTING_POINT[0], 
Parameters. STARTING_POINT[ 1 ]); 
}//end constructor 


// methods 

!** 

* void setRate(int x) 

* sets Marines rate of movement 

*/ 

public void setRate(int x) { 
rate = x; 

} 


* void setRole(int x) 

* sets Marines role within the squad 

*/ 

public void setRole(int x) { 
role = x; 

} 


public void setNewMoveGoal(int x, int y) { 
goalManager.newMoveGoal(x,y, this); 

}//end setNewMoveGoal 

public void setNewFormationGoal(int h,int bx,int by) { 
goalManager.newFormationGoal(h,bx,by); 

}//end setNewFormatiouGoal 

public void checkGoals() { 
goalManager.checkGoalStatus(getX(), 
getYO); 

}//end checkGoals 


public void paint(Graphics g) { 
if(role == 0) { 
g. setColor(Co lor. cyan); 

g.drawRect((getX()/Parameters.CELL_WIDTH)*Parameters.CELL_WIDTH, 
(getY()/Parameters.CELL_HEIGHT)*Parameters.CELL_HEIGHT, 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 
if(Parameters. ShowPath) { 
g. setColor(Color.yellow); 

for(Enumeration e = pathVector.elements(); e.hasMoreElements();){ 
tempElement = (PathElement)e.nextElement(); 
g.drawRect((int)tempElement.getX(), 

(int)tempElement.getY (), 

Parameters.CELL WIDTH, Parameters.CELL HEIGHT); 

} 


50 



}//end if 


}//end if 

g.setColor(Color.cyan); 

g.fillRect((getX()/Parameters.CELL_WIDTH)*Parameters.CELL_WIDTH, 

(getY()/Parameters.CELL_HEIGHT)*Parameters.CELL_HEIGHT, 

Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 


}//end paint 


public void oodaLoop(Vector sqdVector){ 

tempMarine =(Marine)sqdVector.elementAt(0); 
int baseX = tempMarine.getX(); 
int baseY = tempMarine.getY(); 
int baseHeading = tempMarine.getHeading(); 
if(role != 0){ 

setNewFormationGoal(baseHeading,baseX,baseY); 

} 


goalManager.checkGoalStatus(getX(),getY()); 
activeGoal = goalManager.getActiveGoal(); 


switch(activeGoal) { 

case Parameters.MOVE GOAL: 

moveAction(); 

break; 

case Parameters.FORMATION GOAL: 

formationAction(); 
break; 

}//end switch 


}//end OODA loop 


* int distance(cx,cy,gx,gy) returns the distance 

* between the points(cx,cy) and (gx,gy) 

* @retum distance distance between two points 

*/ 

public int distance(int ex, int cy, int gx, int gy) { 
int distance=0; 
double delX = (cx-gx); 
double delY = (cy-gy); 

distance = (int)Math.sqrt(delX*delX + delY*delY); 
return distance; 


51 



}//end distance 


* boolean lineOfSight(cx,cy,gx,gy) determines 

* if there is a clear line of sight between the two points 

* (cx,cy) and (gx,gy) 

* @retum isLOS true if Line of Sight is clear 

*/ 

public boolean hneOfSight(int ex, int cy, int gx, int gy) { 
boolean isLOS = true; 
double delX = (cx-gx); 
double delY = (cy-gy); 
double iy; 
if(delX — 0){ 

for( double ix = 5; ix <= Math.abs(delY); ix+=l){ 

iy= ix; 
if(delY<0){ 

if(Parameters.SIM_ENV[(int)(cy +iy)/5][(int)cx/5]>10) { 
isLOS = false; 

}//end if 


} 

else{ 

if(Parameters.SIM_ENV[(int)(cy-iy)/5][(int)cx/5] >10) { 
isLOS = false; 

}//end if 

}//end if/else 

}//end for 


} 

else{ 

double slope = delY/defX; 

for( double ix = 5; ix <= Math.abs(defX); ix+=l){ 

iy= (slope*ix); 
if(delX<0){ 

if(Parameters.SIM_ENV[(int)(cy+iy)/5][(int)(cx+ix)/5] >10) { 
isLOS = false; 

} 


} 

else) 

if(Parameters.SIM_ENV[(int)(cy-iy)/5][(int)(cx-ix)/5] >10){ 
isLOS = false; 

} 


52 



}//end if/else 
}//end for 
}//endif/else 
return isLOS; 
}//lineOfSight 


* moveAction() executes the agent's action 

* to address the MoveGoal 

*/ 

public void moveAction() { 

int goalX=0; 
int goalY=0; 
int currentX = getX(); 
int currentY = getY(); 
int distance = 0; 
int status^ 0; 

goalX = goalManager.movegoal.getDestX(); 
goalY = goalManager.movegoal.getDestY(); 
distance = (int)Math.sqrt(Math.abs(goalX-currentX)* 

Math.abs(goalX-currentX) + Math.abs(goalY -currentY) * 
Math.abs(goalY -currentY)); 
if(distance <= 2)rate = Parameters.STOP; 

if(distance < 2 && distance <=40) rate = Parameters. VERY SLOW; 
if(distance >40 && distance <=100)rate = Parameters. SLOW; 
if(distance >100) rate = Parameters.MEDIUM; 

setMoves(currentX,currentY); 
setMoveDensity(currentX, currentY); 

//make first move in path 
Enumeration e = pathVector.elements(); 
if(e.hasMoreElements()) { 

tempElement = (PathElement) pathVector.elementAt(O); 
double pathX = tempElement. getX(); 
double pathY = tempElement. getY(); 

double deltaPos = Math.sqrt((pathX-currentX)*(pathX-currentX) -l- 
(pathY-currentY)*(pathY-current Y)); 
if(deltaPos <10){ pathVector.removeElementAt(O);} 

int statusX = currentX < pathX ? 1 : (currentX > pathX ? 3 : 2); 
int statusY = currentY < pathY ? 1 : (currentY > pathY ? 3 : 2); 
status = 10 * statusX -I- statusY; 

} 

else{ 

status = 22; 

} 


53 




int nextMoveX= getX(); 
int nextMoveY = getY(); 


switch(status){ 
case 11: 

nextMoveX =getX()+rate; 
nextMoveY =getY()+rate; 
setHeading(Parameters.SOUTH_EAST); 
nextAgentMove = Parameters. SOUTHEAST; 
break; 

case 12: 

nextMoveX = getX()+rate; 
nextMoveY = getY(); 
setHeading(Parameters.EAST); 
nextAgentMove=Parameters.EAST; 
break; 

case 13: 

nextMoveX =getX()+rate; 
nextMoveY =getY()-rate; 
setHeading(Parameters .NORTHE AST); 
nextAgentMove=Parameters.NORTH_EAST; 
break; 

case 21: 

nextMoveX = getX(); 
nextMoveY = getY()+rate; 
setHeading(Parameters. SOUTH); 
nextAgentMove=Parameters. SOUTH; 
break; 

case 22: 

nextMoveX =getX(); 
nextMoveY =getY(); 
setHeading(getHeading()); 
nextAgentMove=Parameters.STAY; 
break; 

case 23: 

nextMoveX = getX(); 
nextMoveY = getY()-rate; 
setHeading(Parameters.NORTH); 
nextAgentMove=Parameters. N ORTH; 
break; 

case 31: 

nextMoveX =getX()-rate; 

nextMoveY =getY()+rate; 

setHeading(Parameters.SOUTH_WEST); 

nextAgentMove=Parameters.SOUTH_WEST; 

break; 

case 32: 

nextMoveX = getX()-rate; 


54 



nextMoveY = getY(); 
setHeading(Parameters .WE ST); 
nextAgentMove=Parameters.WEST; 
break; 


case 33: 

nextMoveX =getX()-rate; 
nextMoveY =getY()-rate; 
setHeading(Parameters.NORTH_WEST); 
next AgentMove=Parameters. NORTH_ WE ST; 
break; 


default: 

break; 

}//end switch() 

setMoves(getX(),getY ()); 
if(nextAgentMove ==Parameters.STAY) { 


} 

else{ 

if(getX()/5 == nextMoveX/5 && getY()/5 == nextMoveY/5){ 

//don't change SIM Env 

} 

else{ 

Parameters. SIM_ENV[getY()/5][getX()/5] = 0; 

Parameters. SIM_ENV[nextMoveY/5][nextMoveX/5] = Parameters.MARINE; 

} 

setXpos(nextMoveX); 
setY pos(nextMove Y); 

} 

}//end action 


* formationAction() executes the agent's action 

* to address its FormationGoal 

*/ 

public void formationAction() { 
int goalX=0; 
int goalY=0; 
int currentX = getX(); 
int currentY = getY (); 
int distance = 0; 

goalX = goalManager.formationgoal.getDestX(); 
goalY = goalManager.formationgoal.getDestY(); 
distance = (int)Math.sqrt(Math.abs(goalX-currentX)* 

Math.abs(goalX-currentX) + Math.abs(goalY -currentY) * 
Math.abs(goalY -currentY)); 
if(distance <= 2) rate = Parameters. STOP; 

if (distance >2 && distance <=10) rate= Parameters. VERY SLOW; 
if(distance >10 && distance <=20) rate = Parameters.SLOW; 

55 




if(distance > 20 && distance <=30) rate = Parameters.MEDIUM; 
if(distance >30) rate = Parameters.FAST; 

setMoves(currentX,currentY); 
setMoveDensity(currentX, currentY); 


int statusX = goalX > currentX ? 1 : (goalX < currentX ? 2 : 3); 
int statusY = goalY > currentY ? 1 : (goalY < currentY ? 2 : 3); 
int status = 10*statusX + statusY; 

int ix = Parameters.STAY; 
boolean loop = true; 
uextAgentMove = Parameters.STAY; 
switch(statusX) { 

//agent should move right 
case 1: 

switch(statusY) { 

//agent should move down 
case 1: 

uextAgentMove = Parameters.DOWNRIGHT; 
loop = true; 

while(loop && !moves[nextAgentMove] && 

(moveDensity[nextAgentMove] > density Threshold)) { 
switch(nextAgentMove) { 
case Parameters.DOWNRIGHT: 
uextAgentMove = Parameters.RIGHT; 
break; 

case Parameters.RIGHT: 
uextAgentMove = Parameters.DOWN; 
break; 

case Parameters.DOWN: 

uextAgentMove = Parameters.DO WNLEFT; 

break; 

case Parameters.DO WNLEFT: 
uextAgentMove = Parameters.UPRIGHT; 
break; 


case Parameters.UPRIGHT: 
uextAgentMove = Parameters. STAY; 
loop = false; 
break; 

}//end switch(ix) 

}//end while loop 
break; 


//agent should move up 
case 2: 

ix = Parameters.UPRIGHT; 


56 



loop = true; 

while(loop && ! moves [ix] && 

moveDensity[ix] > density Threshold) { 
switch(ix) { 

case Parameters.UPRIGHT: 
ix = Parameters. RIGHT; 
break; 

case Parameters.RIGHT: 
ix = Parameters.UP; 
break; 

case Parameters.UP: 
ix = Parameters.UPLEFT; 
break; 

case Parameters.UPLEFT: 
ix = Parameters.DOWNRIGHT; 
break; 

case Parameters.DOWNRIGHT: 
loop = false; 
ix = Parameters. STAY; 
break; 

}//end switch(ix) 

} 

nextAgentMove = ix; 
break; 

//agent should MOVE right 
case 3: 

ix = Parameters. RIGHT; 
loop = true; 

while(Ioop && !moves[ix] && 

moveDensity[ix] > density Threshold) { 
switch(ix) { 

case Parameters.RIGHT: 
ix = Parameters.UPRIGHT; 
break; 

case Parameters.UPRIGHT: 
ix = Parameters.DOWNRIGHT; 
break; 

case Parameters.DOWNRIGHT: 

ix = Parameters.UP; 

break; 

case Parameters.UP: 
ix = Parameters.DOWN; 
break; 

case Parameters.DOWN: 
loop = false; 
ix = Parameters. STAY; 
break; 


57 



}//end switch(ix) 

} 

nextAgentMove = ix; 
break; 


}//end switch(statusY) 
break; 


//agent should move left 
ease 2: 

switeh(status Y) { 

//agent should move up 
ease 2: 

ix = Parameters.UPLEFT; 
loop = true; 

while(loop &&!moves[ix] && 

moveDensity[ix] > density Threshold) { 
switeh(ix) { 

ease Parameters.UPLEFT: 
ix = Parameters.LEFT; 
break; 

ease Parameters.LEFT: 
ix = Parameters.UP; 
break; 

ease Parameters.UP: 

ix = Parameters.UPRlGHT; 

break; 

ease Parameters.UPRlGHT: 
ix = Parameters.DOWNLEFT; 
break; 

ease Parameters.DOWNLEFT: 
loop = false; 
ix = Parameters. STAY; 
break; 

}//end switeh(ix) 

}//end while 
nextAgentMove = ix; 
break; 

//agent should move left 
ease 3: 

ix = Parameters.LEFT; 
loop = true; 

while(loop && ! moves [ix] && 

moveDensity[ix] > density Threshold) { 
switeh(ix) { 

ease Parameters.LEFT: 


58 



ix = Parameters.UPLEFT; 
break; 

case Parameters.UPLEFT: 
ix = Parameters.DOWNLEFT; 
break; 

case Parameters.DOWNLEFT: 

ix = Parameters .UP; 

break; 

case Parameters.UP: 
ix = Parameters.DOWN; 
break; 

case Parameters.DOWN: 
loop = false; 
ix = Parameters. STAY; 
break; 

}//end switch(ix) 

} 

nextAgentMove = ix; 
break; 

//agent should move down 
case 1: 

ix = Parameters.DOWNLEFT; 
loop = true; 

while(loop && !moves[ix] && 

moveDensity[ix] > density Threshold) { 
switch(ix) { 

case Parameters.DOWNLEFT: 
ix = Parameters.LEFT; 
break; 

case Parameters.LEFT: 
ix = Parameters.DOWN; 
break; 

case Parameters.DOWN: 
ix = Parameters.UPLEFT; 
break; 

case Parameters.UPLEFT: 
ix = Parameters.DOWNRIGFIT; 
break; 

case Parameters.DOWNRIGFIT: 
loop = false; 
ix = Parameters. STAY; 
break; 

}//end switch(ix) 

} 

nextAgentMove = ix; 
break; 


59 



}//end switch(statusY) 
break; 

//agent moves up or down 
case 3: 

switch(status Y) { 

//agent should move up 
case 2: 

ix = Parameters.UP; 
loop = true; 

while(loop && !moves[ix] && 

moveDensity[ix] > density Threshold) { 
switch(ix) { 
case Parameters.UP: 
ix = Parameters.UPLEFT; 
break; 

case Parameters.UPLEFT: 
ix = Parameters.UPRIGFlT; 
break; 

case Parameters.UPRIGFlT: 
ix = Parameters.LEFT; 
break; 

case Parameters.LEFT: 
ix = Parameters. RIGHT; 
break; 

case Parameters.RIGHT: 
loop = false; 
ix = Parameters. STAY; 
break; 

}//end switch(ix) 

} 

nextAgentMove = ix; 
break; 

//agent should stay 
case 3: 

nextAgentMove = Parameters.STAY; 
break; 

//agent should move down 
case 1: 

ix = Parameters. DOWN; 
loop = true; 

while(loop && !moves[ix] && 

moveDensity[ix] > densityThreshold) { 
switch(ix) { 

case Parameters.DOWN: 

ix = Parameters.DOWNRIGHT; 

break; 


case Parameters.DOWNRIGHT: 

60 



ix = Parameters.DOWNLEFT; 
break; 


ease Parameters.DOWNLEFT: 
ix = Parameters. RIGHT; 
break; 

ease Parameters.RIGHT: 
ix = Parameters.LEFT; 
break; 

ease Parameters.LEFT: 
loop = false; 
ix = Parameters. STAY; 
break; 

}//end switeh(ix) 

} 

nextAgentMove = ix; 
break; 

}//end switeh(statusY) 
break; 

}//end switeh(status) 


int nextAgentMoveX = getX(); 
int nextAgentMoveY = getY(); 
switeh(nextAgent]Vlove) { 

ease Parameters.STAY: 

nextAgentMoveX =getX(); 
nextAgentMoveY =getY(); 
super. setHeading(getHeading()); 

break; 

ease Parameters.UP: 

nextAgentMoveX = getX(); 
nextAgentMoveY = getY()-rate; 
super. setHeading(Parameters.N ORTH); 

break; 

ease Parameters.DOWN: 
nextAgentMoveX = getX(); 
nextAgentMoveY = getY()+rate; 
super. setHeading(Parameters. SOUTH); 

break; 

ease Parameters.RIGHT: 

nextAgentMoveX = getX()+rate; 
nextAgentMoveY = getY(); 
setHeading(Parameters.EAST); 

break; 

ease Parameters.LEFT: 

nextAgentMoveX = getX()-rate; 


61 



nextAgentMoveY = getY(); 
super.setHeading(Parameters.WEST); 
break; 

case Parameters.UP RIGHT: 

nextAgentMoveX =getX()+rate; 
nextAgentMoveY =getY()-rate; 
super.setHeading(Parameters.NORTH_EAST); 
break; 

case Parameters.UPLEFT: 

nextAgentMoveX =getX()-rate; 
nextAgentMoveY =getY()-rate; 
super. setHeading(Parameters.N ORTHWE ST); 
break; 

case Parameters.DOWNRIGHT: 
nextAgentMoveX =getX()+rate; 
nextAgentMoveY =getY()+rate; 
super. setHeading(Parameters. SOUTHE AST); 
break; 

case Parameters.DOWNLEFT: 
nextAgentMoveX =getX()-rate; 
nextAgentMoveY =getY()+rate; 
super. setHeading(Parameters.SOUTH_WEST); 
break; 

default: 

break; 

}//end switch 


if(getX()/5 == nextAgentMoveX/5 && getY()/5 == nextAgentMoveY/5){ 
//don't change SIM Env 

} 

else) 

Parameters. SIM_ENV[getY()/5][getX()/5] = 0; 

Parameters. SIM_ENV[nextAgentMoveY/5][nextAgentMoveX/5] = 
Parameters.MARINE; 

} 

setXpos(nextAgentMoveX); 
set Y pos(nextAgentMove Y); 


}//end formationaction 

* findPath(cx,cy,gx,gy) finds a path from point(cx,cy) to 

* (gx,gy) 

*/ 


62 



public void fmdPath(int cx, int cy, int gx, int gy){ 
setMoves(cx,cy); 

PathElement newElement; 
double delX = (cx-gx); 
double delY = (cy-gy); 
double iy; 
if(delX — 0){ 

for( double ix = 5; ix <= Math.abs(delY); ix+=5){ 

iy= ix; 
if(delY<0){ 

if(Parameters.SIM_ENV[(int)(cy +iy)/5][(int)cx/5]<10) { 
newElement = new PathElement((double)cx,(double)cy + iy); 
pathV ector. addElement(newElement); 

}//end if 

} 

else{ 

if(Parameters.SIM_ENV[(int)(cy-iy)/5][(int)cx/5] <10) { 
newElement = new PathElement((double)cx,(double)cy - iy); 
path V ector. addElement(newElement); 

}//end if 
}//end if/else 

}//end for 

} 

else) 

double slope = delY/delX; 

for( double ix = 5; ix <= Math.abs(defX); ix+=5){ 

iy= (slope*ix); 
if(delX<0){ 

if(Parameters.SIM_ENV[(int)(cy+iy)/5][(int)(cx+ix)/5] <10) { 
newElement = new PathElement((double)cx + ix,(double)cy + iy); 
pathV ector. addElement(newElement); 

}//end if 


} 

else) 

if(Parameters.SIM_ENV[(int)(cy-iy)/5][(int)(cx-ix)/5] <10)) 
newElement = new PathElement((double)cx - ix,(double)cy - iy); 
pathV ector. addElement(newElement); 

}//end if 

}//end if/else 

}//end for 

}//endif/else 
}//end fmdPath() 




63 



* int getDensityO calculates the density 

* around the agent's current position 

*/ 

public int getDensityO { 

//reset density value 
int newDensity = 0; 

int minX = getX()/Parameters.CELL_WIDTH - SENSOR_RANGE; 
minX = minX <=0 ? 0 : minX; 


int maxX = getX()/Parameters.CELL_HEIGHT + SENSOR_RANGE; 

maxX = maxX >= Parameters.COLUMNS - 1 ? Parameters.COLUMNS : maxX; 

int minY = getY()/Parameters.CELL_HEIGHT - SENSOR_RANGE; 
minY = minY<=0 ? 0 : minY; 

int maxY = getY()/Parameters.CELL_HEIGHT + SENSOR_RANGE; 
maxY = maxY >= Parameters.ROWS -1 ? Parameters.ROWS : maxY; 

for(int iy = minY; iy < maxY; iy++) { 
for(int ix = minX; ix < maxX; ix++) { 
newDensity += Parameters.SIM_ENV[iy][ix]; 

} 

} 


return newDensity; 
}//end getDensity 


* setMoves(x,y) determines whether the 8 

* moves from point (x,y) are accessible, 

* i.e. no obstacles or other agents occupy the 8 grid squares 

* around the agent's current position 

*/ 

public void setMoves(int x, int y) { 
int currentX = x; 
int currentY = y; 

//reset moves 

for(int ix = 0; ix < moves.length; ix++){ 
moves[ix] = true; 

} 


//check upmoves 
if(currentY <= 10 || 

Parameters.SIM_ENV[currentY/Parameters.CELL_HEIGHT - 1] 
[currentX/Parameters.CELL WIDTH] > 10 || 

(rate == Parameters.FAST && 

Parameters.SIM_ENV[currentY/Parameters.CELL HEIGFlT - 2] 
[currentX/Parameters.CELL WIDTH] > 10 )) 
moves[Parameters.UP] = false; 

// checkdownMoves 


64 



if(currentY >= (Parameters.HEIGHT - 10)|| 

Parameters.SIM_ENV[eurrentY/Parameters.CELL_HEIGHT + 1] 
[eurrentX/Parameters.CELL WIDTH] > 10 || 

(rate == Parameters.FAST && 

Parameters.SIM_ENV[eurrentY/Parameters.CELL_HEIGHT + 2] 
[eurrentX/Parameters.CELL WIDTH] > 10 )) 
moves[Parameters.DOWN] = false; 

//eheek leftmoves 
if(eurrentX <= 10 || 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT] 
[eurrentX/Parameters.CELL WIDTH - 1] > 10 || 

(rate == Parameters.FAST && 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT] 
[eurrentX/Parameters.CELL WIDTH - 2] > 10)) 
moves[Parameters.LEFT] = false; 

//eheek rightmoves 

if(eurrentX >= (Parameters.WIDTH - 10) || 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT] 
[eurrentX/Parameters.CELL WIDTH + 1] >10 || 

(rate == Parameters.FAST && 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT] 
[eurrentX/Parameters.CELL WIDTH + 2] >10 )) 
moves[Parameters.RIGHT] = false; 

//eheek upright/downright/upleft/downleft moves 

if(! moves [Parameters. UP] 11! mo ve s [Parameters. RIGHT] 11 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-l] 
[eurrentX/Parameters.CELL WIDTH + 1] > 10 || 

(rate == Parameters.FAST && 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-2] 
[eurrentX/Parameters.CELL WIDTH + 2] > 10)) 
moves[Parameters.UPRIGHT] = false; 

if(!moves[Parameters.UP] 11!moves[Parameters.LEFT]11 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-l] 
[eurrentX/Parameters.CELL WIDTH- 1] > 10 || 

(rate == Parameters.FAST && 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-2] 
[eurrentX/Parameters.CELL WIDTH- 2] > 10 )) 
moves[Parameters.UPLEFT] = false; 

if(!moves[Parameters.DOWN] || !moves[Parameters.RIGHT]|| 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-l-l] 
[eurrentX/Parameters.CELL WIDTH -I- 1] > 10 || 

(rate == Parameters.FAST && 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-l-2] 
[eurrentX/Parameters.CELL WIDTH -I- 2] > 10)) 
moves[Parameters.DOWNRIGHT] = false; 

if(! moves [Parameters. DOWN] 11! moves[Parameters.LEFT] 11 

Parameters.SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-l-l] 
[eurrentX/Parameters.CELL WIDTH -1] > 10 || 

(rate == Parameters.FAST && 

Parameters. SIM_ENV[eurrentY/Parameters.CELL_HEIGHT-l-2] 

65 



[currentX/Parameters.CELL WIDTH -2] > 10)) 
moves[Parameters.DOWNLEFT] = false; 

}//end setMovesQ 


* setMoveDensity(cx,cy) calculates the density 

* in each of the agent's directions of movement from its 

* position at (cx,cy) and places the value in the moveDensity array 

*/ 

public void set]VloveDensity(int ex, int cy) { 
int currentX = ex; 
int currentY = cy; 

//reset moveDensity array 
for(int ik =0; ik < moveDensitydength; ik++){ 
mo veDensity [ik] =0; 

} 

int count = 0; 
int range = 0; 

//up density 

range = currentY/Parameters.CELL HEIGHT - densityRange; 
range = range <= 0 ? 0 : range; 

for(int X = currentY/Parameters.CELL HEIGHT - 1; x >= range; x—){ 
count++; 

moveDensity[Parameters.UP] += 
density Range/count * 

Parameters. SIMEN V [x] [currentX/Parameters. CELLWIDTH]; 

} 


//down density 
count = 0; 

range = currentY/Parameters.CELLHEIGHT +density Range; 
range = range >= Parameters.ROWS - 1 ? Parameters.ROWS - 1 : range; 
for(int X = currentY/Parameters.CELL HEIGHT +1; x <= range; x++){ 
count++; 

moveDensity[Parameters.DOWN] += 
density Range/count * 

Parameters. SIM_ENV[x] [currentX/Parameters.CELLWIDTH]; 

} 

//right density 
count = 0; 

range = currentX/Parameters.CELLHEIGHT + densityRange; 
range = range >= Parameters.COLUMNS - 1 ? Parameters.COLUMNS - 1 : range 
for(int X = currentX/Parameters.CELL HEIGHT +1; x <= range; x++){ 
count++; 

moveDensity[Parameters.RIGHT] += 
density Range/count * 

Parameters.SIM_ENV[currentY/Parameters.CELL_HEIGHT][x]; 

} 


//left density 


66 



count =0; 

range = currentX/Parameters.CELLHEIGHT - density Range; 
range = range <= 0 ? 0 : range; 

for(int X = currentX/Parameters.CELL HEIGHT -1; x >= range; x—){ 
count++; 

moveDensity[Parameters.LEFT] += 
density Range/count * 

Parameters. SIM_ENV[currentY/Parameters.CELL_HEIGHT] [x]; 


//up right 
count = 0; 

int upRange = currentY/Parameters.CELL HEIGHT - densityRange; 
upRange = upRange <= 0 ? 0 : upRange; 

int delUp = (int)Math.abs(currentY/Parameters.CELL_HEIGHT - upRange); 

int rightRange=currentX/Parameters.CELL_HEIGHT + densityRange; 
rightRange = rightRange >= Parameters.COLUMNS - 1 ? 

Parameters.COLUMNS - 1 : rightRange; 
int delRight = (int)Math.abs(currentX/Parameters.CELL_WIDTH - rightRange); 

range = delUp < delRight ? delUp : delRight; 

for(int X = 1; x < range; x++){ 
count++; 

moveDensity[Parameters.UPRIGHT]+= 
densityRange/count * 

Parameters.SIM_ENV[currentY/Parameters.CELL_HEIGHT - x] 
[currentX/Parameters.CELLWIDTH + x]; 

} 


//up left 
count =0; 

upRange = currentY/Parameters.CELL HEIGHT - densityRange; 
upRange = upRange <= 0 ? 0 : upRange; 

delUp = (int)Math.abs(currentY/Parameters.CELL_HEIGHT - upRange); 

int leftRange=currentX/Parameters.CELL_HEIGHT - densityRange; 
leftRange = leftRange <= 0 ? 0 : leftRange; 

int delLeft = (int)Math.abs(currentX/Parameters.CELL_WIDTH - leftRange); 
range = delUp < delLeft ? delUp : delLeft; 


for(int X = 1; x < range; x++){ 
count++; 

moveDensity[Parameters.UPLEFT]+= 
densityRange/count * 

Parameters.SIM_ENV[currentY/Parameters.CELL_HEIGHT - x] 
[currentX/Parameters.CELL WIDTH - x]; 


//down right 
count = 0; 

int downRange = currentY/Parameters.CELL HEIGHT + densityRange; 

67 



downRange = downRange >= Parameters.ROWS -1 ? 

Parameters.ROWS -1 : downRange; 

int delDown = (int)Math.abs(eurrentY/Parameters.CELL_HEIGHT - downRange); 

rightRange=currentX/Parameters.CELL_HEIGHT + density Range; 
rightRange = rightRange >= Parameters.COLUMNS - 1 ? 

Parameters.COLUMNS - 1 : rightRange; 
delRight = (int)Math.abs(eurrentX/Parameters.CELL_WIDTH - rightRange); 

range = delDown < delRight ? delDown : delRight; 

for(int X = 1; x < range; x++){ 
eount++; 

moveDensity[Parameters.DOWNRIGHT] += 
densityRange/eount * 

Parameters.SIM_ENV[eurrentY/Parameters.CELL_HEIGHT + x] 
[eurrentX/Parameters.CELLWIDTH + x]; 

} 


//down left 
eount = 0; 

downRange = eurrentY/Parameters.CELLHEIGHT + density Range; 
downRange = downRange >= Parameters.ROWS -1 ? 

Parameters.ROWS -1 : downRange; 

delDown = (int)Math.abs(currentY/Parameters.CELL_HEIGHT - downRange); 

leftRange=eurrentX/Parameters.CELL_HEIGHT - density Range; 
leflRange = leftRange <= 0 ? 0 : leftRange; 

delLeft = (int)Math.abs(currentX/Parameters.CELL_WIDTH - leftRange); 

range = delDown < delLeft ? delDown : delLeft; 

for(int X = 1; x < range; x++){ 
eount++; 

moveDensity [Parameters.DO WNLEFT]+= 
densityRange/eount * 

Parameters.SIM_ENV[eurrentY/Parameters.CELL_HEIGHT + x] 
[eurrentX/Parameters.CELL WIDTH - x]; 

[//end for loop 
[//end setmoveDensity 


[//end Marine 


68 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

!** 

* class SimpleAgent 

* Description: child class of SimObject, parent class of all agents 

*/ 

public class SimpleAgent extends SimObject { 

//attributes 

int heading; //int between 0 and 359 
int health; //value between 0 and 100 


public SimpleAgent() { 
health =100; 
setType(O); 

} 


//set methods 


* void setHeading(int hd) 

* sets agent's heading to hd 

*/ 

public void setHeading(int hd) { 
heading = hd; 

} 


* void setHealth(int hi) 

* sets agent's health to hi 

*/ 

public void setHealth(int hl){ 
health = hi; 

} 


//get methods 


* int getHeadingO 


69 



* returns agent's heading 

*/ 

public int getHeading() { 
return heading; 

} 


* int getHealth() 

* returns agent's health 

*/ 

public int getHealth() { 
return health; 

} 


}//end simpleAgent 


70 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 
import java.util.*; 

* SquadGoalManager manages the squads goal 

* Currently squad has a single goal: PatrolGoal 

*/ 

public class SquadGoalManager { 

PatrolGoal pgoal; 


public SquadGoalManager(Vector squadVector) { 
pgoal = new PatrolGoal(squadVector); 

}// 

public void checkGoalStatus(Vector squadVector) { 
//check patrol goal status 
pgoal.checkGoalStatus(squadVector); 

}//end checkGoalStatus 


public int getActiveGoal() { 
int squadActiveGoaU Parameters.PATROL GOAL; 
return squadActiveGoal; 

}//end getActiveGoal 

}//end SquadGoalManager 


71 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 
import java.util.*; 

* MarineGoalManager manages the Marine agents' goals 

*/ 

public class MarineGoalManager { 
int agentRole; 

MoveGoal movegoal; 

FormationGoal formationgoal; 

!** 

* MarineGoalManager constructor creates 

* MoveGoal and FormationGoal objects 

* @param x move destination x-coord 

* @param y move destnation y-coord 

* @param r role of agent 

* @param h heading of squad leader 

* @param bX x-coord of base of movement(sqd leader) 

* @param bY y-coord of base of movement(sqd leader) 

*/ 

public MarineGoalManager(int x, int y, int r, int h, int bX, int bY) { 
if(r==0){ 

movegoal = new MoveGoal(x,y); 

} 

else) 

formationgoal = new FormationGoal(r,h,bX,bY); 

} 

agentRole = r; 

}//end constructor 

* newMoveGoal(int x, int y, Marine m) 

* creates a newMoveGoal for Marine m 

* for a destination of (x,y) 

* @param x x-coord of goal destination 

* @param y y-coord of goal destination 

* @param m Marine to receive to new move goal 
*/ 

public void newMoveGoal(int x, int y, Marine m) { 
movegoal = new MoveGoal(x,y); 

PathNode startNode = new PathNode(m.getX(),m.getY(),0); 
PathNode endNode = new PathNode(x, y, 0); 

72 



Parameters.pathGraph.reset(); 

Parameters.pathGraph.put(startNode); 

Parameters.pathGraph.put(endNode); 

Parameters .pathGraph. setLinks(); 

Vector waypoints = new Vector(); 
switch(Parameters.PathSearch) { 

case Parameters.COVER SEARCH: 

waypoints = (Vector)Parameters.pathGraph.coverFirstSearch(startNode, 
endNode); 

break; 

case Parameters.SHORTDIST SEARCH: 

waypoints = (Vector)Parameters.pathGraph.bestFirstSearch(startNode, 
endNode); 

break; 

case Parameters.BFSEARCFi: 

waypoints = (Vector)Parameters.pathGraph.breadthFirstSearch(startNode, 
endNode); 

break; 

case Parameters.DFSEARCFi: 

waypoints = (Vector)Parameters.pathGraph.depthFirstSearch(startNode, 
endNode); 

break; 

}//end switch 

for(int ij = waypoints.size()-l; ij > 0; ij—){ 

PathNode tipNode = (PathNode)waypoints.elementAt(ij); 

PathNode tailNode = (PathNode)waypoints.elementAt(ij-l); 

m.fmdPath(tipNode.getX(),tipNode.getY(), 

tailNode.getX(),tailNode.getY()); 

}//end for 

}//end newMoveGoal 

* newFormationGoal(int h, int bX, int bY) 

* sets new FormationGoal 

* @param h squad leader's heading 

* @param bX squad leader's x-coord 

* @param bY squad leader's y-coord 
*/ 

public void newFormationGoal(int h, int bX, int bY) { 
formationgoal. setFormation(h,bX,b Y); 

} 


* checkGoalStatus(int ax, int ay) 

* checks goal status based on the agent's current position 

* currently squad leader moves 

* while squad focuses on staying in formation 

* @param ax agent's current x-coord 


73 



* @param ay agent's current y-coord 

*/ 

public void checkGoalStatus(int ax, int ay) { 
if(agentRole == Parameters. SQD_LDR){ 
movegoal.checkGoalStatus(ax,ay); 

} 

else{ 

formationgoal.checkGoalStatus(ax,ay); 

} 

}//end checkGoalStatus 


* getActiveGoal() returns agent's active goal 

* currently squad leader moves 

* while squad focuses on staying in formation 

* @retum activeGoal agent's active goal 

*/ 

public int getActiveGoal() { 
int activeGoal; 

if(agentRole ==Parameters. SQDLDR) { 
int moveStatus = movegoal.getStatus(); 
activeGoal^ Parameters.MOVE GOAL; 

} 

else{ 

int formationStatus = formationgoal.getStatus(); 
activeGoal = Parameters.FORMATIONGOAL; 

} 

return activeGoal; 

}//end getActiveGoal() 

}//end marineGoalManager 


74 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 
import java.util.*; 

public class PatrolGoal extends Goal{ 
boolean checkpoint 1 = false; 
boolean checkPoint2 = false; 
boolean checkPoint3 = false; 

int currentCheckPointX = Parameters.CHECK_PTS[0][0]; 
int currentCheckPointY = Parameters.CHECK_PTS[0][l]; 
int cpVicinity =15; 

!** 

* PatrolGoal constructor creates the squad's patrol goal 

* using 3 predetermined checkpoints 

* @param squadVector vector holding Marine agents 

*/ 

public PatrolGoal(Vector squadVector) { 

Marine tempMarine = (Marine)squadVector.firstElement(); 
tempMarine. setN ewMoveGoal(currentCheckPointX, 
currentCheckPointY); 

}//end constructor 

* checkGoalStatus(Vector squadVector) 

* checks the PatrolGoal status based on current position of 

* squad leader 

* @param squadVector Vector of Marine agents in squad 

*/ 

public void checkGoalStatus(Vector squadVector)) 

Marine sqdldr = (Marine)squadVector.firstElement(); 

int distance = (int)Math.sqrt( Math.abs(sqdldr.getX()-currentCheckPointX) * 
Math.abs(sqdldr.getX()-currentCheckPointX) + 
Math.abs(sqdldr.getY()-currentCheckPointY) * 
Math.abs(sqdldr.getY()-currentCheckPointY) 

); 


if(!checkPointl){ 

if(distance <=cpVicinity) { 
checkpoint 1 = true; 

currentCheckPointX = Parameters.CHECK_PTS[1][0]; 
currentCheckPointY = Parameters.CHECK_PTS[1][1]; 
sqdldr. setNewMoveGoal(currentCheckPointX, 
currentCheckPo int Y); 


}//end if 


75 



} 

else{ 

if(!checkPoiiit2){ 

if(distaiice <=cpViciiiity) { 
checkPoiiit2 = true; 

currentCheckPointX = Parameters.CHECK_PTS[2][0]; 
eurrentCheekPointY = Parameters.CHECK_PTS[2][1]; 
sqdldr.setNewMoveGoal(eurrentCheekPointX,eurrentCheekPointY); 

}//end if 


} 

else{ 

if(distanee <=epVieiiiity) { 
eheekPointS = true; 

Parameters.PatrolMission = true; 
}//end if 
}//end if/else 
}//end if/else 
}//end eheekGoalStatus 


}//end patrolGoal 


76 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
**! 

package thesis; 

!** 

* class MoveGoal creates the agents' goal to move 

* to a desired location 

* Description: child class of Goal 

*/ 

public class MoveGoal extends Goal { 

int destX; 
int destY; 

!** 

* MoveGoal constructor 

* @param x goal destination x-coord 

* @param y goal destination y-coord 

*/ 

public MoveGoal(int x, int y) { 
destX = x; 
destY = y; 

} 


* getDestXQ returns goal x-coord 

* @retum destX goal x-coord 

*/ 

public int getDestXQ { 
return destX; 

} 


* getDestYQ returns goal y-coord 

* @retum destY goal y-coord 

*/ 

public int getDestY0{ 
return destY; 

} 


* void checkGoalStatus(int x, int y) 

* determines goal criticality and sets status 

* @param x agent's current x position 

* @param y agent's current y position 

*/ 


77 



public void checkGoalStatus(int x, int y) { 
int xDist = (int)(Math.abs(x-destX)); 
int yDist = (int)(Math.abs(y-destY)); 
int newDist = (int)(Math.sqrt(xDist*xDist + yDist*yDist)); 

if (newDist > 25) { 
set Status(Parameters .RED); 

} 

else if (newDist <=!){ 
setStatus(Parameters.GREEN); 

} 

else) 

setStatus(Parameters. YELLOW); 

} 

}//end checkGoalStatus 


}//end MoveGoal 


78 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 


* class FormationGoal 

* Description: child class of Goal 

* creates the agent goal to stay in the prescribed 

* squad formation 

*/ 

public class FormationGoal extends Goal { 

private int destX;//goal destination x-coord 

private int destY;//goal destination y-coord 

int heading; //heading of agent calling on FormationGoal 

int role; //role of agent who is calling on formationGoal 

!** 

* FormationGoal constructor 

* @param r role of agent creating FormationGoal 

* @param h heading of agent 

* @param baseX x-coordinate of the base of movement 

* @param baseY y-coordinate of the base of movement 

*/ 

public FormationGoal(int r,int h, int baseX, int baseY) { 
role = r; 
heading = h; 

switch(Parameters. SQDFORMATION) { 

case Parameters.COLUMN: 

setColumn(heading,baseX,base Y); 
break; 

//case Parameters.WEDGE: 

case Parameters.LINE: 

setLine(heading,baseX,baseY); 
break; 

}//end switch 
}//end constructor 

* setFormation() sets the squad formation based 

* on the position (baseX, baseY) and heading (h) 

* of squad leader agent and the squad formation: Parameters. SQD FORMATION 

* @param h squad leader heading 


79 



* @param baseX x-coord of squad leader 

* @param baseY y-coord of squad leader 

*/ 

publie void setFormation(int h, int baseX, int baseY) { 

switch(Parameters. SQDFORMATION) { 
case Parameters.COLUMN: 

setColumn(li,baseX,base Y); 
break; 

//case Parameters.WEDGE: 

case Parameters.LINE: 

setLine(li,baseX,baseY); 
break; 

}//end switch 
}//end setFormation 

* getDestXQ returns goal destination x-coord 

* @retum destX 

*/ 

public int getDestX() { 
return destX; 

}//end getDestX 

* getDestY() returns goal destination y-coord 

* @retum destY 

*/ 

public int getDestY(){ 
return destY; 

}//end getDestY 

!** 

* void checkGoalStatus(int x, int y) 

* determines goal criticality and sets status 

* @param x agent's current x position 

* @param y agent's current y position 

*/ 

public void checkGoalStatus(int x, int y) { 
int xDist = (int)(Math.abs(x-destX)); 
int yDist = (int)(Math.abs(y-destY)); 
int newDist = (int)(Math.sqrt(xDist*xDist -I- yDist*yDist)); 

if (newDist > 15){ 
set Status(Parameters .RED); 

} 

else if (newDist <= 1){ 
setStatus(Parameters.GREEN); 

} 

else) 

set Status(Parameters .YELLOW); 

} 

}//end checkGoalStatus 


80 



//public void setWedge(int h, int x, int y) 


* setLineO sets the destination coordinates 

* (destX, destY) of the calling agent based on role in squad 

* to achieve a squad line formation 

* @param h squad leader's heading 

* @param x x-coord of squad leader's position 

* @param y y-coord of squad leader's position 
*/ 

public void setLine(int h, int x, int y) { 
int baseX = x; 
int baseY = y; 
switch(role) { 
case 0: 

destX = baseX; 
destY = baseY; 
break; 

case 1: 
switch(h) { 

case Parameters.NORTH: 
destX = baseX; 

destY = baseY - (Parameters.DISPERSION * 

1 * Parameters.CELL WIDTH); 

break; 

case Parameters.SOUTH: 
destX = baseX; 

destY = baseY + (Parameters.DISPERSION * 

2 * Parameters.CELL WIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION * 

2 * Parameters.CELL WIDTH); 
destY = baseY; 
break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION * 

2 * Parameters.CELL WIDTH); 
destY = baseY; 
break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 



destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 2: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 

82 



Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 


case 3: 
switch(h) { 

case Parameters.NORTH: 
destX = baseX; 

destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 
destX = baseX; 

destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION*4 * 
Parameters.CELLWIDTH); 
destY = baseY; 
break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY; 
break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

83 



destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

}//end switeh 
break; 

ease 4: 

switeh(Ii) { 

ease Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 


84 



case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = bascY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 


case 5: 

switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 

85 



Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 6: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 

86 



break; 


case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

destY = baseY + (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

destY = baseY - (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

destY = baseY + (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 7: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 


87 



destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH EAST: 
destX = baseX; 

destY = baseY - (Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 
destY = baseY; 
break; 

ease Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 
destY = baseY; 
break; 

ease Parameters.SOUTH WEST: 
destX = baseX; 

destY = baseY + (Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 

break; 

}//end switeh 
break; 

ease 8: 
switeh(h) { 

ease Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.EAST: 


88 



destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH EAST: 
destX = baseX; 

destY = baseY - (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 
destY = baseY; 
break; 

ease Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 
destY = baseY; 
break; 

ease Parameters.SOUTH WEST: 
destX = baseX; 

destY = baseY + (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 

break; 

}//end switeh 
break; 

ease 9: 
switeh(h) { 

ease Parameters.NORTH: 

destX = baseX +(Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH: 

destX = baseX -(Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY -l- (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.EAST: 


89 



destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH WEST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters. SOUTH WE ST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLHEIGHT); 

break; 

}//end switeh 
break; 

ease 10: 
switeh(h) { 

ease Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

destY = baseY + (Parameters.DISPERSION *3 * 

90 



Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY; 
break; 

case Parameters.NORTH WEST: 
destX = baseX; 

destY = baseY - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 
destX = baseX; 

destY = baseY + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 


case Parameters. SOUTH WE ST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY; 
break; 

}//end switch 
break; 

case II: 

switch(h) { 

case Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX - (Parameters.DISPERSION *4 * 

91 



Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH EAST: 

destX = baseX -l- (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY; 
break; 

ease Parameters.NORTH WEST: 
destX = baseX; 

destY = baseY - (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH EAST: 
destX = baseX; 

destY = baseY -l- (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters. SOUTH WE ST: 

destX = baseX - (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY; 
break; 

}//end switeh 
break; 

ease 12: 
switeh(h) { 

ease Parameters.NORTH: 

destX = baseX -l- (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH: 

destX = baseX - (Parameters.DISPERSION *5 * 

92 



Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH WEST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters. SOUTH WE ST: 

destX = baseX - (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLHEIGHT); 

break; 

}//end switch 
break; 

}//end switch 
}//end setLineO 


* setCoIumnO sets the destination coordinates 

93 



* (destX, destY) of the calling agent based on role in squad 

* to achieve a squad column formation 

* @param h squad leader's heading 

* @param x x-coord of squad leader's position 

* @param y y-coord of squad leader's position 
*/ 

public void setColumn(int h, int x, int y) { 
int baseX = x; 
int baseY = y; 

switch(role) { 

case 0: 

destX = baseX; 
destY = baseY; 
break; 

case 1: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX +(Parameters.DISPERSION * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX-(Parameters.DISPERSION * 
Parameters.CELLWIDTH); 
destY = baseY +(Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY+(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION * 1 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

94 



destX = baseX - (Parameters.DISPERSION * 1 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 2: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX-(Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY +(Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY+ (Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *5* 
Parameters.CELLWIDTH); 
destY = baseY-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 

95 



Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 


case 3: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *6* 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY -l-(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 


96 



case Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = bascY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3* 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 4: 

switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2* 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 

97 



Parameters.CELLWIDTH); 
destY = baseY +(Parameters.DISPERSION *1 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.NORTH EAST: 

destX = baseX + (Parameters.DISPERSION *1 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.NORTH WEST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH EAST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH WEST: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

}//end switeh 
break; 


ease 5: 

switeh(h) { 

ease Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.SOUTH: 

destX = baseX-(Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY-l-(Parameters.DISPERSION *1* 

98 



Parameters.CELLWIDTH); 


break; 

case Parameters.WEST: 

destX = baseX+ (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 6: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX-(Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 


99 



case Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY+(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX + (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX + (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 

break; 

case Parameters. SOUTH WE ST: 

destX = baseX + (Parameters.DISPERSION *3 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 7: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

100 



destY = baseY - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.WEST: 

destX = baseX -l- (Parameters.DISPERSION *2 * 
Parameters.CELLWIDTH); 
destY = baseY -l-(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

ease Parameters.NORTH EAST: 

destX = baseX -(Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 
destY = baseY -l- (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.NORTH WEST: 

destX = baseX -l- (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 
destY = baseY-l-(Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION * I * 
Parameters.CELLHEIGHT); 
destY = baseY-(Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 

break; 

ease Parameters. SOUTH WE ST: 

destX = baseX-l- (Parameters.DISPERSION *I * 
Parameters.CELLHEIGHT); 
destY = baseY - (Parameters.DISPERSION *1* 
Parameters.CELLHEIGHT); 

break; 

}//end switeh 
break; 

ease 8: 
switeh(h) { 

ease Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY -l- (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 

break; 


101 



case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX -l- (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY -l-(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX- (Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 
destY = baseY -l- (Parameters.DISPERSION *2 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH WEST: 

destX = baseX -l- (Parameters.DISPERSION *2 * 
Parameters.CELLHEIGHT); 
destY = baseY-l-(Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX -(Parameters.DISPERSION *2* 
Parameters.CELLHEIGHT); 
destY = baseY-(Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 

break; 


case Parameters.SOUTH WEST: 

destX = baseX-l- (Parameters.DISPERSION *3 * 
Parameters.CELLHEIGHT); 
destY = baseY - (Parameters.DISPERSION *2* 
Parameters.CELLHEIGHT); 

break; 

}//end switch 
break; 

case 9: 
switch(h) { 

case Parameters.NORTH: 


102 



destX = baseX + (Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *9 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *9 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *9 * 
Parameters.CELLWIDTH); 
destY = baseY-l-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX -l- (Parameters.DISPERSION *9 * 
Parameters.CELLWIDTH); 
destY = baseY-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY -l- (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.NORTH WEST: 

destX = baseX -l- (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY -l- (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX -l- (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *6 * 
Parameters.CELLHEIGHT); 

break; 

}//end switch 
break; 


103 



case 10: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX + (Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *12 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX-(Parameters.DISPERSION * I * 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *12 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *12 * 
Parameters.CELLWIDTH); 
destY = baseY-l-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX -l- (Parameters.DISPERSION *12 * 
Parameters.CELLWIDTH); 
destY = baseY-(Parameters.DISPERSION *1* 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *7 * 
Parameters.CELLWIDTH); 
destY = baseY-l- (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX-l-(Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 
destY = baseY -l- (Parameters.DISPERSION *7* 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX-(Parameters.DISPERSION *8 * 
Parameters.CELLHEIGHT); 
destY = baseY - (Parameters.DISPERSION *7 * 
Parameters.CELLWIDTH); 

break; 


case Parameters. SOUTH WE ST: 

destX = baseX -l- (Parameters.DISPERSION *7 * 

104 



Parameters.CELLWIDTH); 
destY = baseY- (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

}//end switch 
break; 

case 11: 

switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION * 1 * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *1 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *8* 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *1 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX -l- (Parameters.DISPERSION *8 * 
Parameters.CELLWIDTH); 
destY = baseY -l-(Parameters.DISPERSION *1 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 
destY = baseY-l- (Parameters.DISPERSION *4 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX-l-(Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 
destY = baseY -l-(Parameters.DISPERSION *5 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH EAST: 

destX = baseX-(Parameters.DISPERSION *4 * 
Parameters.CELLHEIGHT); 
destY = baseY - (Parameters.DISPERSION *5 * 

105 



Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX+ (Parameters.DISPERSION *5 * 
Parameters.CELLHEIGHT); 
destY = baseY - (Parameters.DISPERSION *4* 
Parameters.CELLHEIGHT); 

break; 

}//end switch 
break; 

case 12: 
switch(h) { 

case Parameters.NORTH: 

destX = baseX - (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY + (Parameters.DISPERSION *11 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.SOUTH: 

destX = baseX + (Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *11 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.EAST: 

destX = baseX - (Parameters.DISPERSION *11* 
Parameters.CELLWIDTH); 
destY = baseY -(Parameters.DISPERSION *I * 
Parameters.CELLWIDTH); 

break; 

case Parameters.WEST: 

destX = baseX -l- (Parameters.DISPERSION *11* 
Parameters.CELLWIDTH); 
destY = baseY -l-(Parameters.DISPERSION *1 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH EAST: 

destX = baseX - (Parameters.DISPERSION *7 * 
Parameters.CELLWIDTH); 
destY = baseY-l- (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 

break; 

case Parameters.NORTH WEST: 

destX = baseX -l- (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY -l- (Parameters.DISPERSION *7 * 
Parameters.CELLHEIGHT); 

break; 


106 



case Parameters.SOUTH EAST: 

destX = baseX - (Parameters.DISPERSION *6 * 
Parameters.CELLWIDTH); 
destY = baseY - (Parameters.DISPERSION *7 * 
Parameters.CELLHEIGHT); 

break; 

case Parameters.SOUTH WEST: 

destX = baseX+ (Parameters.DISPERSION *7 * 
Parameters.CELLHEIGHT); 
destY = baseY - (Parameters.DISPERSION *6* 
Parameters.CELLHEIGHT); 

break; 

}//end switch 
break; 

}//end switch 
}//end setColumn() 

}//end FormationGoal 


107 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

* class Goal 

* Description: class Goal 

* parent class for agent goal objects 

*/ 

public class Goal { 

int status; //goal status 
int type; //type of goal 

//Goal constructor 
public Goal() { 

} 


* void setStatus(int x) 

* @param x status of goal 

*/ 

public void setStatus(int x) { 
status = x; 

}//end setStatus 

!** 

* void setGoalType(int t) 

* @param t type of goal 

*/ 

public void setGoalType(int t) { 
type = t; 

}//end setGoalType 


* int getStatusQ 

* @retum status of goal 

*/ 

public int getStatus(){ 
return status; 

}//end getStatus 

* int getGoalTypeO 

* @retum type goal type 

*/ 


108 



public int getGoalType(){ 
return type; 

}//end getGoalType 


}//end Goal 


109 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import java.util.*; 
import j ava.awt. *; 

* class PathSearchGraph creates a searchgraph of PathNodes 

* for agent path-planning 

*/ 

public class PathSearchGraph extends Hashtable { 

String name; 

public PathSearchGraph(String n) { 
name = n; 

} 


//reset each PathNode in graph 
voidreset() { 

Enumeration e = this.elements(); 
while(e.hasMoreElements()){ 

PathNode nextNode = (PathNode)e.nextElement(); 
nextNode.reset(); 

}//end while 
}//end reset 


//add node to hashtable using nodelD as key 
void put(PathNode node) { 
put(node.getNodeID(), node); 

}//end put 


* setLinksO establishes links between 

* nodes that have a clear line of sight and 

* are within los distance 

*/ 

public void setLinks() { 

Enumeration e = this.elements(); 
while(e.hasMoreElements()) { 

PathNode nextNode = (PathNode)e.nextElement(); 

Enumeration e2 = this.elements(); 
while(e2.hasMoreElements()) { 

no 



PathNode linkNode = (PathNode)e2.nextElement(); 
if( linkNode.getNodelDO != nextNode.getNodelDQ && 
lineOfSight(nextNode.getX(),nextNode.getY(), 
linkNode.getXQ, linkNode.getYQ) && 
distance(nextNode.getX(),nextNode.getY(), 

linkNode.getXQ, linkNode.getYQ) < Parameters.LOS DIST) { 
nextNode.addLink(linkNode); 

} 

}//end while 
}//end while 
}//end setLinks 


* setDistaneeCost(PathNode goalNode) ealeulates 

* the distanee eost to the goalNode from eaeh Node in 

* the seareh graph 

*/ 

publie void setDistaneeCost(PathNode goalNode) { 

Enumeration e = this.elementsQ; 

while(e.hasMoreElementsQ) { 

PathNode nextNode = (PathNode)e.nextElementQ; 
nextNode.setDistaneeCost( distanee(nextNode.getXQ, 
nextNode.getYQ, 
goalNode.getXQ, 
goalNode.getYQ)); 

}// 

}//end setDistaneeCost 


* int distanee(ex,ey,gx,gy) returns the distanee 

* between the points(ex,ey) and (gx,gy) 

* @retum distanee distanee between two points 

*/ 

publie int distanee(int ex, int ey, int gx, int gy) { 
int distanee=0; 
double delX = (ex-gx); 
double delY = (ey-gy); 

distanee = (int)]Vtath.sqrt(delX*delX + delY*delY); 
return distanee; 

}//end distanee 


* boolean hneOfSight(ex,ey,gx,gy) determines 

* if there is a elear line of sight between the two points 

* (ex,ey) and (gx,gy) 

* @retum isLOS true if Line of Sight is elear 

*/ 

publie boolean hneOfSight(int ex, int ey, int gx, int gy) { 
boolean isLOS = true; 
double defX = (ex-gx); 
double delY = (ey-gy); 


111 



double iy; 
if(delX — 0){ 

for( double ix = 5; ix <= Math.abs(delY); ix+=l){ 

iy= ix; 

if(delY<0){ 

if(Parameters.SIM_ENV[(int)(cy +iy)/5][(int)ex/5]>10) { 
isLOS = false; 

}//end if 

} 

else{ 

if(Parameters.SIM_ENV[(int)(cy-iy)/5][(int)cx/5] >10) { 
isLOS = false; 

}//end if 
}//end if/else 
}//end for 
} 

else{ 

double slope = delY/defX; 
for( double ix = 5; ix <= Math.abs(defX); ix+=l){ 
iy= (slope*ix); 
if(delX<0){ 

if(Parameters.SIM_ENV[(int)(cy+iy)/5][(int)(cx+ix)/5] >10) { 
isLOS = false; 


else) 

if(Parameters.SIM_ENV[(int)(cy-iy)/5][(int)(cx-ix)/5] >10) { 
isLOS = false; 

} 

}//end if/else 
}//end for 
}//endif/else 

return isLOS; 

}//lineOfSight 

!** 

* Vector breadthFirstSearch(startNode, endNode) 

* conducts a BPS from startNode to endNode 

* and returns a vector containing the nodes that lead from 

* the startNode to endNode 

* @param startNode agent's starting node 

* @param endNode agent's desired location 

* @retum pathToGoal Vector containing the list of nodes leading to endNode 

*/ 

public Vector breadthFirstSearch(PathNode startNode, PathNode endNode)) 
Vector temp = new Vector)); 

Vector pathToGoal = new Vector)); 

Vector queue = new Vector)); 
queue.addElement)startNode); 

StartNode.setTested)true); 

while)queue.size))>0)) 

PathNode testNode = )PathNode)queue.firstElement)); 
queue .removeElementAt)0); 
temp.addElement)testNode); 


112 



if(testNode.getNodeID() == endNode.getNodeID()){ 
pathToGoal.addElemeiit(testNode); 

PathNode backNode = (PathNode)testNode.getBackTrace(); 
pathToGoal.addElemeiit(backNode); 
while(backNode.getBackTrace()! = null) { 
backNode = (PathNode )backNode.getBackTrace(); 
pathToGoal.addElement(backNode); 

}// 

return pathToGoal; 

} 


if(!testNode.expanded) { 
testNode.expand(queue,PathNode.BACK); 

} 

}//end while 

return null; 

}//end bfs 


* Vector depthFirstSearch(startNode, endNode) 

* conducts a DFS from startNode to endNode 

* and returns a vector containing the nodes that lead from 

* the startNode to endNode 

* @param startNode agent's starting node 

* @param endNode agent's desired location 

* @retum pathToGoal Vector containing the list of nodes leading to endNode 

*/ 

public Vector depthFirstSearch(PathNode startNode, PathNode endNode)) 

Vector temp = new Vector(); 

Vector pathToGoal = new Vector(); 

Vector queue = new Vector(); 
queue.addElement(startNode); 

StartNode.setTested(true); 

while(queue.size()>0) { 

PathNode testNode = (PathNode)queue.firstElement(); 
queue .remo veElementAt(O); 
temp. addElement(testNode); 

if(testNode.getNodeID() == endNode.getNodeID()){ 
pathToGoal.addElement(testNode); 

PathNode backNode = (PathNode)testNode.getBackTrace(); 
pathToGoal.addElement(backNode); 
while(backNode.getBackTrace()!= null) { 
backNode = (PathNode )backNode.getBackTrace(); 
pathToGoal.addElement(backNode); 

}// 

return pathToGoal; 

} 


113 



if(!testNode.expanded) { 
testNode.expand(queue,PathNode.FRONT); 

} 

}//end while 
return null; 

}//end dfs 


* Vector bestFirstSearch(startNode, endNode) 

* conducts a BestFS (Shortest Distance) from startNode to endNode 

* and returns a vector containing the nodes that lead from 

* the startNode to endNode 

* @param startNode agent's starting node 

* @param endNode agent's desired location 

* @retum pathToGoal Vector containing the list of nodes leading to endNode 

*/ 

public Vector bestFirstSearch(PathNode startNode, PathNode endNode)) 

Vector temp = new Vector(); 

Vector pathToGoal = new Vector(); 

Vector queue = new Vector(); 

setDistanceCost(endNode); 

queue. addElement(startN ode); 
startN ode .setTested(true); 

while(queue.size()>0) { 

PathNode testNode = (PathNode)queue.firstElement(); 
queue .remo veElementAt(O); 
temp.addElement(testNode); 

if(testNode.getNodeID() == endNode.getNodeID()){ 
pathToGoal.addElement(testNode); 

PathNode backNode = (PathNode)testNode.getBackTrace(); 
pathToGoal.addElement(backNode); 
while(backNode.getBackTrace()!= null)) 
backNode = (PathNode )backNode.getBackTrace(); 
pathToGoal.addElement(backNode); 

}// 

return pathToGoal; 

} 


if(!testNode.expanded)) 

testNode.expand(queue,PathNode.INSERT_DIST); 

} 


}//end while 
return null; 

114 



}//end bestfs 


* Vector coverFirstSearch(startNode, endNode) 

* conducts a BestFS (highest cover value) from startNode to endNode 

* and returns a vector containing the nodes that lead from 

* the startNode to endNode 

* @param startNode agent's starting node 

* @param endNode agent's desired location 

* @retum pathToGoal Vector containing the list of nodes leading to endNode 

*/ 

public Vector coverFirstSearch(PathNode startNode, PathNode endNode)) 

Vector temp = new Vector(); 

Vector pathToGoal = new Vector(); 

Vector queue = new Vector(); 

setDistanceCost(endNode); 

queue.addElement(startNode); 

StartNode.setTested(true); 

while(queue.size()>0) { 

PathNode testNode = (PathNode)queue.firstElement(); 
queue .removeElementAt(O); 
temp.addElement(testNode); 

if(testNode.getNodeID() == endNode.getNodeID()){ 
pathToGoal.addElement(testNode); 

PathNode backNode = (PathNode)testNode.getBackTrace(); 
pathToGoal.addElement(backNode); 
while(backNode.getBackTrace()!= null)) 
backNode = (PathNode)backNode.getBackTrace(); 
pathToGoal.addElement(backNode); 

}// 

return pathToGoal; 

} 

if(!testNode.expanded)) 

testNode.expand(queue,PathNode.INSERT_COVER); 

} 


}//end while 
return null; 
}//end coverfs 


* paint() paints the searchgraph node by node 

*/ 


115 



public void paint(Graphics g) { 

Enumeration e = this.elements(); 
while(e.hasMoreElements()){ 

PathNode nextNode = (PathNode)e.nextElement(); 
nextNode.paint(g); 

}//end while 
}//end paint 


}//end PathSearchGraph 


116 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 


!** 

* class PathNodes creates nodes used to 

* establish a search graph network for the agent's 

* path planning 

*/ 

public class PathNode extends Object { 


Vector links; // holds links to other nodes 


int depth; //depth in a tree from start node 

boolean expanded; // indicates if node has been expanded 

boolean tested; //indicates if node was ever tested 

int xPosition; // x-coord of node 

int yPosition; //y-coord of node 

String nodelD; //string ID 

float distanceCost = 0; 

float coverBenefit = 0; 

PathNode backTrace = null; 


public static final int FRONT = 0; 
public static final int BACK = 1; 
public static final int INSERT DIST = 2; 
public static final int INSERT COVER = 3; 

public PathNode(int x, int y, float c) { 
xPosition = x; 
yPosition = y; 

nodeID = "" + (1000*x + y); 
coverBenefit = c; 
depth = 0; 

links = new Vector(); 
expanded = false; 
tested = false; 


117 




}//end constructor 


public int getX(){ return xPosition;} 
public int getY(){ return yPosition;} 
public String getNodeID(){ return nodelD;} 
public float getCoverQ { return coverBenefit;} 
public float getDistanceO { return distanceCost; } 
public boolean isleaf() { return (links.size() ==0) ; } 
public PathNode getBackTrace() { return backTrace;} 

public void setDistanceCost(float d) { distanceCost = d; } 
public void setDepth(int d) { depth = d; } 
public void setExpanded(boolean state) { expanded = state;} 
public void setXested (boolean state) {tested = state; } 

public void reset() { 
depth = 0; 
distanceCost = 0; 
expanded = false; 
tested = false; 
backTrace = null; 

}//end reset 

public void setBackTrace(PathNode pn){ 
backTrace = pn; 

} 


public void addLink(PathNode pn) { 
links.addElement(pn); 

}//end addLink 


public void expand(Vector queue, int position)} 
setExpanded(true); 
for(int j = 0;j < links.size(); j++) { 

PathNode uextNode = (PathNode)links.elementAt(j); 
if(!nextNode.tested) { 

uextNode. setT ested(true); 
uextNode.setBackTrace(this); 
uextNode.setDepth(depth + 1); 

switch(position) { 

case FRONT: queue.insertElementAt(nextNode,0); 
break; 

case BACK: queue.addElement(nextNode); 
break; 

case INSERT DIST: 
boolean inserted = false; 

float uextDistanceCost = uextNode.getDistance(); 


118 



for(int k = 0; k < queue.size(); k++){ 

//find where to insert node 

if(nextDistanceCost < ((PathNode)queue.elementAt(k)).getDistance()) { 
queue .insertElementAt(nextNode, k); 
inserted = true; 
break; //exit for loop 
}//end if 

}//end for 

//couldn't find place to insert, so add to end of queue 
if(!inserted) queue.addElement(nextNode); 
break; 

case INSERT COVER: 
boolean isinserted = false; 
float nextCover = nextNode.getCover(); 


for(int k = 0; k < queue.size(); k++){ 

//find where to insert node 

if(nextCover > ((PathNode)queue.elementAt(k)).getCover()){ 
queue .insertElementAt(nextNode, k); 
isinserted = true; 
break; //exit for loop 
}//end if 

}//end for 

//couldn't find place to insert, so add to end of queue 
if(!isinserted) queue.addElement(nextNode); 
break; 


}//end switch(position) 

} 

}//end for 
}//end expand 


public void paint(Graphics g) { 
g.setColor(Color. white); 

g.fillRect((getX()/Parameters.CELL_WIDTH)*Parameters.CELL_WIDTH, 

(getY()/Parameters.CELL_HEIGHT)*Parameters.CELL_HEIGHT, 

Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 

g.setColor(Color.red); 

Enumeration e = links.elements(); 
while(e.hasMoreElements()) { 

PathNode linkNode = (PathNode)e.nextElement(); 
g.drawLine(getX(),getY (),linkNode.getX(),linkNode.getY ()); 

} 

}//end paint 


}//end PathNode 


119 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 


package thesis; 

* class PathElement creates path objects that are 

* created to serve as navigation points for the agents to follow 

*/ 

public class PathElement { 
double xVal = -1; 
double yVal = -1; 
int direction = -1; 

public PathElement(double x, double y) { 
xVal = x; 
yVal = y; 

} 


public double getX() { 
return xVal; 

} 


public double getY(){ 
return yVal; 

} 


public int getD() { 
return direction; 

} 

}//end PathElement 


120 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 


* class Infrastructure creates a series of building objects 

* that serve as the infrastructure for the urban environment 

* 

*/ 

public class Infrastructure { 

Building 1 bla,blb,blc,bld,ble; 

Building2 b2a,b2b,b2c; 

!** 

* Infrastucture constructor 

*/ 

public InfrastructureO { 
bla = new Buildingl(50,250); 
bib = new Buildingl(45,400); 
blc = new Buildingl(200,400); 
bid = new Building 1(355,400); 

b2a = new Building2(200,75); 
b2b = new Building2(475,75); 
b2c = new Building2(475,240); 

}//end constructor 


* paint() 

* paints the infrastructure building by building 

*/ 

public void paint(Graphics g) { 

//draw buildings 

bla. paint(g); 

blb. paint(g); 

blc. paint(g); 


121 




bld.paint(g); 

b2a.paiiit(g); 

b2b.paiiit(g); 

b2c.paiiit(g); 

}//end paint 

}//end infrastructure 


122 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 

* 


package thesis; 


!** 

* class Building 

* Description: Parent class to building types 

*/ 


public class Building { 


int xPosition = 0; //x coordinate of building 
int yPosition = 0; //y coordinate of building 

int hWall; //size of horizontal walls in environment grid squares 
int vWall; //size of vertical walls 

int hDoor; //size of horizontal doors 
int vDoor; //size of vertical doors 


* BuildingO constructor 

*/ 

public BuildingO { 
hWall = Parameters.WALLS; 
vWall = Parameters.WALLS; 
hDoor = Parameters.DOORS; 
vDoor = Parameters.DOORS; 

} 


* set() methods 

* sets attribute to parameter value 

*/ 

//sets X coordinate of building to x 
public void setX(int x) { 
xPosition = x; 

} 


//sets y coordinate of building to y 
public void setY(int y){ 
yPosition = y; 

} 


123 




//sets horizontal wall size to hw 
publie void setHWall(int hw){ 
hWall = hw; 

} 


//sets vertical wall size to vw 
public void setVWall(int vw){ 
vWall = vw; 

} 


//sets horizontal door size to hd 
public void setHDoor(int hd) { 
hDoor = hd; 

} 


//sets vertical door size to vd 
public void setVDoor(int vd) { 
vDoor = vd; 

} 


* get() methods 

*/ 

//returns x coordinate 
public int getX() { 
return xPosition; 

} 


//returns y coordinate 
public int getY(){ 
return yPosition; 

} 


//returns horizontal wall size 
public int getHWall(){ 
return hWall; 

} 


//returns vertical wall size 
public int getVWall(){ 
return vWall; 

} 


//returns horizontal door size 
public int getHDoor() { 
return hDoor; 

} 


//returns vertical door size 
public int getVDoor() { 
return vDoor; 

} 


}//end building 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 


* class Building 1 

* Description: child class of Building 

* Creates a simple 4 wall building with 4 doors 

*/ 

public class Building 1 extends Building { 

Vector buildingComponents; //holds building components: doors and walls 
Wall temp Wall; 

Door tempDoor; 

!** 

* Building 1 constructor creates Wall and Door objects 

* and adds them to buildingComponent Vector 

* @param x x-coordinate of upper left comer of building 

* @param y y-coordinate of upper left comer of building 

*/ 

public Building l(int x, int y) { 
super.setX(x); 
super.setY(y); 

buildingComponents = new Vector(); 

//north wall 

tempWall = new Wall(getX(), 
getY(), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX() +Parameters.CELL_WIDTH*(getHWall()), 
getY(), 
getHDoorO, 


125 




Parameters. HORIZONT AL, 

Parameters. DOWN); 

buildingComponents.addElement(tempDoor); 

temp Wall = new Wall(getX() + 

Parameters.CELL WIDTH *(getHWall() + getHDoor()), 
getY(), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 


//south wall 

tempWall = new Wall(getX(), 

getY()+ Parameters.CELLHEIGHT* 

(2*getVWall() + getVDoor()+l), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX() + Parameters.CELL WIDTH * getHWall(), 
getY()+ Parameters.CELLHEIGHT* 

(2*getVWall() + getVDoor()+l), 
getHDoor(), 

Parameters. HORIZONT AL,Parameters .UP); 
buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getX() + Parameters.CELL WIDTH * 

(getHWallO + getHDoorO), 
getY0+ Parameters.CELLHEIGHT* 

(2*getVWallO + getVDoorO+1), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 


//west wall 

tempWall = new Wall(getXO, 

getY0+ Parameters.CELL HEIGHT *(1), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX0, 

getY0+ Parameters.CELL HEIGHT * 
(getVWallO + 1), 
getVDoorO, 

Parameters. VERTICAL,Parameters. RIGHT); 
buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getXO, 

getY0+ Parameters.CELL HEIGHT * 
(getVWallO + 1 + getVDoorO), 
getVWallO, 

Parameters. VERTICAL); 


126 



buildingComponents.addElement(tempWall); 


//east wall 

tempWall = new Wall(getX()+ Parameters.CELL HEIGHT * 
(2*getHWall() + getHDoor()-l), 
getY()+ Parameters.CELL HEIGHT *(1), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX()+ Parameters.CELL HEIGHT * 
(2*getHWall() + getHDoorQ - 1), 
getY()+ Parameters.CELL HEIGHT * 
(getVWallO + 1), 
getVDoorO, 

Parameters. VERTICAL,Parameters.LEFT); 
buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getX()+ Parameters.CELL HEIGHT * 
(2*getHWall() + getHDoor() - 1), 
getY()+ Parameters.CELL HEIGHT * 
(getVWallO + 1 + getVDoorO), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

}//end eonstruetor 


* paintO paints the instantiation of Building 1 

* by eall eaeh Wall and Door objeets' paintO funetion 

*/ 

publie void paint(Graphies g) { 

BuildingComponent tempComponent; 
for(Enumeration e = buildingComponents.elementsO; 
e.hasMoreElementsO;){ 

tempComponent = (BuildingComponent) e.nextElement(); 
tempComponent.paint(g); 

}//end for loop 
}//end paint 

}//endbuildingl 


127 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import java.awt.*; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import j ava. lang. *; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 

!** 

* class Building2 

* Description: child class of Building 

* creates a 2-room building with 4 horizontal doors 

* and 3 vertical doors 

*/ 

public class Building2 extends Building { 

Vector buildingComponents; //holds building components: doors and walls 
Wall temp Wall; 

Door tempDoor; 


* Building2 constructor creates Wall and Door objects 

* and adds them to buildingComponent Vector 

* @param x x-coordinate of upper left comer of building 

* @param y y-coordinate of upper left comer of building 

*/ 

public Building2(int x, int y) { 
super.setX(x); 
super.setY(y); 

buildingComponents = new Vector(); 

//north wall 

tempWall = new Wall(getX(), 
getY(), 
getHWallO, 

Parameters. HORIZONT AL); 
bn ildingComponents. addElement(temp W all); 

tempDoor = new Door(getX() -l-Parameters.CELL_WIDTH*getHWall(), 
getY(), 
getHDoorO, 

Parameters.HORIZONTAL, 

128 




Parameters. DOWN); 

buildingComponents.addElement(tempDoor); 


temp Wall = new Wall(getX() + 

Parameters.CELL WIDTH *(getHWall() + getHDoor()), 
getY(), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 


//north wall#2 

tempWall = new Wall(getX()+ Parameters.CELL HEIGHT * 
(2*getHWall() + getHDoor()), 

getY(), 

getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX0+ Parameters.CELL HEIGHT * 
(3*getHWallO + getHDoorQ ), 

getY(), 

getHDoorO, 

Parameters.HORIZONTAL, 

Parameters. DOWN); 

buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getX()+ Parameters.CELL HEIGHT * 
(3*getHWallO + 2*getHDoorO ), 

getY(), 

getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 


//south wall 

tempWall = new Wall(getXO, 

getY0+ Parameters.CELLHEIGHT* 

(2*vWall + getVDoorO+1), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX0 + Parameters.CELL WIDTH * getHWallO, 
getY0+ Parameters.CELLHEIGHT* 

(2*getVWallO + getVDoorO+1), 
getHDoorO, 

Parameters. HORIZONT AL,Parameters .UP); 
buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getXO + Parameters.CELL WIDTH * 

(getHWallO + getHDoorO), 
getY0+ Parameters.CELLHEIGHT* 

(2*getVWallO + getVDoorO+1), 
getHWallO, 

Parameters. HORIZONT AL); 

129 



buildingComponents.addElement(tempWall); 


//south wall #2 

tempWall = new Wall(getX()+ Parameters.CELLHEIGHT 
(2*getHWall() + getHDoor()), 
getY()+ Parameters.CELLHEIGHT* 
(2*getVWall() + getVDoor()+l), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX()+ Parameters.CELL HEIGHT 
(3*getHWall() + getHDoorQ ), 
getY()+ Parameters.CELLHEIGHT* 
(2*getVWall() + getVDoor()+l), 
getHDoor(), 

Parameters. HORIZONT AL,Parameters .UP); 
buildingComponents.addElement(tempDoor); 


tempWall = new Wall(getX()+ Parameters.CELLHEIGHT 
(3*getHWall() + 2*getHDoor()), 
getY()+ Parameters.CELLHEIGHT* 
(2*getVWall() + getVDoor()+l), 
getHWallO, 

Parameters. HORIZONT AL); 
buildingComponents.addElement(tempWall); 

//west wall 

tempWall = new Wall(getX(), 

getY()+ Parameters.CELL HEIGHT *(1), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

tempDoor = new Door(getX0, 

getY()+ Parameters.CELL HEIGHT * 
(getVWallO + 1), 
getVDoor(), 

Parameters. VERTICAL,Parameters.RIGHT); 
buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getX(), 

getY()+ Parameters.CELL HEIGHT * 
(getVWallO + 1 + getVDoorO), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

//mid wall 

tempWall = new Wall(getXO+ Parameters.CELLHEIGHT 
(2*getHWallO + getHDoorO - 1), 
getY0+ Parameters.CELL HEIGHT *(1^ 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

130 



tempDoor = new Door(getX()+ Parameters.CELL HEIGHT * 
(2*getHWall() + getHDoor() - 1), 
getY()+ Parameters.CELL HEIGHT * 
(getVWallO + 1), 
getVDoor(), 

Parameters. VERTICAL,Parameters.RIGHT); 
buildingComponents.addEIement(tempDoor); 

tempWall = new WaII(getX()+ Parameters.CELL HEIGHT * 
(2*getHWaIl() + getHDoorQ - I), 
getY()+ Parameters.CELL HEIGHT * 
(getVWallO + I + getVDoorO), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addEIement(tempWall); 

//eastwall 

tempWall = new WaII(getX()+ Parameters.CELL HEIGHT * 
(4*getHWaII() + 2*getHDoor() - I), 
getY()+ Parameters.CELL HEIGHT *(I), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addEIement(tempWall); 

tempDoor = new Door(getX()+ Parameters.CELL HEIGHT * 
(4*getHWaI10 + 2*getHDoorO - 1), 
getY()+ Parameters.CELL HEIGHT * 
(getVWallO + 1), 
getVDoorO, 

Parameters. VERTICAL,Parameters.LEFT); 
buildingComponents.addElement(tempDoor); 

tempWall = new Wall(getXO+ Parameters.CELL HEIGHT * 
(4*getHWallO + 2*getHDoorO - 1), 
getY0+ Parameters.CELL HEIGHT * 
(getVWallO + 1 + getVDoorO), 
getVWallO, 

Parameters. VERTICAL); 
buildingComponents.addElement(tempWall); 

}//end constructor 

* paint() paints the instantiation of Building2 

* by call each Wall and Door objects' paint() function 

*/ 

public void paint(Graphics g) { 

BuildingComponent tempComponent; 
for(Enumeration e = buildingComponents.elements(); 
e.hasMoreElementsO;){ 

tempComponent = (BuildingComponent) e.nextElement(); 
tempComponent.paint(g); 

}//end for loop 
}//end paint 
}//end building2 


131 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 


* class BuildingComponent 

* Description: parent class of objects 

* used to create buildings: Walls and Doors 

*/ 

public class BuildingComponent extends SimObjectj 

//orientation of building component: 
//Parameters.HORIZONTAL or Parameters.VERTICAL 
int orientation = 0; 

//component size in grid squares 
int size = 0; 

//constmctor 

public BuildingComponent() { 

} 


* set() methods 

*/ 

//sets size of component to s 
public final void setSize(int s){ 
size = s; 

} 


//sets orientation to o 
public final void setOrientation(int o) { 
orientation = o; 




* get() methods 

*/ 

//returns component size 
public final int getSize() { 
return size; 

} 


//returns component orientation 
public final int getOrientation() { 
return orientation; 

} 


* paintQ function 

* paints component to screen 

*/ 

public void paint(Graphics g) { 
g.fillRect(getX(XgetY (), 

Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 
}//end paint 


}//end BuildingComponent 


133 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang.*; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 

!** 

* class Door 

* Description: child class of BuildingComponent 

* creates a door 

*/ 

public class Door extends BuildingComponent { 
int iuDirection = 0; 

* Door constructor 

* @param x x-coordinate 

* @param y y-coordinate 

* @param s size of door 

* @param o orientation of door 

* @param i entrance direction 
*/ 

public Door(int x, int y, int s, int o, int i) { 

super.setType(Parameters.DOOR); 

super.setXpos(x); 

super.setYpos(y); 

super.setSize(s); 

super. setOrientation(o); 

iuDirection = i; 

int cover 1, cover2; 

if(getOrientation() == Parameters.HORIZONTAL) { 

//inserts a type value of Parameters.Door 

//in the SIM ENV array for each grid square the door 

//occupies 


134 




for(iiit ix = 0; ix < getSizeQ; ix ++){ 
Parameters.SIM_ENV[y/Parameters.CELL_HEIGHT] 

[x/Parameters.CELL_WIDTH + ix] = Parameters.DOOR; 

} 


//ereates a eover attribute 
//lO for inside the door; 0 for outside 
if(inDireetion == Parameters. DOWN)] 
eoverl = 10; 
eover2 = 0; 

} 

else] 

eoverl =0; 
eover2=10; 

} 


//ereates 2 nodes assoeiated with the door 
//one node for inside the door 
//one node for outside the door 

PathNode newNode = new PathNode(x+s/2*Parameters.CELL_WIDTH, 
y+30, eoverl); 

Parameters.pathGraph.put(newNode); 

newNode = new PathNode(x+s/2*Parameters.CELL_WIDTH, y-30, eover2); 
Parameters.pathGraph.put(newNode); 

} 

else] 

//inserts a type value of Parameters.Door 

//in the SIM ENV array for eaeh grid square the door 

//oeeupies 

for(int ix = 0; ix < getSizeQ; ix ++)] 

Parameters.SIM_ENV[y/Parameters.CELL_WIDTH + ix] 

[x/Parameters.CELL_HEIGHT] = Parameters.DOOR; 

} 


//ereates a eover attribute 
//lO for inside the door; 0 for outside 
if(inDireetion == Parameters.RIGHT)] 
eoverl = 10; 
eover2 = 0; 

} 

else] 

eoverl =0; 
eover2=10; 

} 


//ereates 2 nodes assoeiated with the door 
//one node for inside the door 
//one node for outside the door 
PathNode newNode = new PathNode(x+30, 

y+s/2 * Parameters .CELLWIDTH, eover 1); 

Parameters.pathGraph.put(newNode); 

newNode = new PathNode(x-30, y+s/2*Parameters.CELL_WIDTH, eover2); 
Parameters.pathGraph.put(newNode); 

} 


135 



}//end constructor 


* getInDirection() returns the Door object's entrance direction 

* @retum inDirection 

*/ 

public int getInDirection(){ 
return inDirection; 

} 


* paintQ paints the door in gray 

*/ 

public void paint(Graphics g) { 
g. setColor(Color. gray); 
for(int ix = 0; ix < size; ix ++){ 

if(orientation == Parameters.HORIZONTAL)) 
g.drawRect(getX()+(ix*Parameters.CELL_WIDTH),getY(), 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 

} 

else) 

g.drawRect(getX(),getY ()+ (ix*Parameters.CELL_HEIGHT), 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 
}//end if/else 
}//end for 
}//end paint 


}//end Door 


136 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 

import j ava.awt. *; 
import java.awt.event.*; 
import java.applet.*; 
import java.util.*; 
import java.awt.image. *; 
import java.lang. *; 
import java.io.*; 
importjava.net.*; 
import javax.swing.*; 

!** 

* class Wall 

* Description: child of BuildingComponent 

* creates a wall 
*/ 

public class Wall extends BuildingComponent { 


!** 

* Wall constructor 

* creates a wall at (x,y) 

* with a size s and orientation o 

* @param x Wall object x-coord 

* @param y Wall object y-coord 
*/ 

public Wall(int x, int y, int s, int o) { 
super. setType(Parameters. WALL); 
super.setXpos(x); 
super.setYpos(y); 
size = s; 
orientation = o; 

if(getOrientation() == Parameters.HORIZONTAL)) 
for(int ix = 0; ix < getSizeQ; ix ++){ 
Parameters.SIM_ENV[y/Parameters.CELL_HEIGHT] 

[x/Parameters.CELLWIDTH + ix] = Parameters.WALL; 


for(int ix = 0; ix < getSizeQ; ix ++){ 

Parameters.SIM_ENV[y/Parameters.CELL_WIDTH + ix] 

[x/Parameters.CELLHEIGHT] = Parameters.WALL; 


}//end constructor 


137 




* paintQ paints the Wall object 

*/ 

public void paint(Graphics g) { 
g. setColor(Color. gray); 
for(int ix = 0; ix < size; ix ++){ 

if(orientation == Parameters.HORIZONTAL)) 
g.fillRect(getX()+(ix*Parameters.CELL_WIDTH),getY(), 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 

} 

else) 

g.fillRect(getX(),getY ()+ (ix*Parameters.CELL_HEIGHT), 
Parameters.CELL_WIDTH,Parameters.CELL_HEIGHT); 
}//end if/else 
}//end for 
}//end paint 


}//end Wall 


138 



* Title: Urban Combat Simulation 

* Description: An intelligent agent simulation of a squad 

* in an urban environment 

* Copyright: Copyright (c) 2001 

* Company: USMC 

* @author Capt Arthur R. Aragon 

* @version 1.0 
*/ 

package thesis; 
import j ava.awt. *; 

!** 

* class SimObject 

* Description: parent class of all simulation objects 

*/ 

public class SimObject { 

int xPosition; //int between 0 and maxX 
int yPosition; //int between 0 and maxY 
int type; 

//constructor 
public SimObject() { 

} 


* void setXpos(int x) 

* sets agent's xPosition to x 

*/ 

public final void setXpos(int x) { 
xPosition = x; 

} 


* void setYpos(int y) 

* sets agent's yPosition to y 

*/ 

public final void setYpos(int y){ 
yPosition = y; 

} 


* void setType(int t) 

*/ 

public final void setType(int t){ 
type = t; 

} 


* int getX() 

* returns agent's xPosition 

*/ 

public final int getX() { 
return xPosition; 


139 



* int getY() 

* returns agent's yPosition 

*/ 

public final int getY(){ 
return yPosition; 

} 


* int getTypeO 

*/ 

public final int getType(){ 
return type; 

} 


}//end SimObject 



LIST OF REFERENCES 


Borland®, Learning Java ® with JBuilder™: JBuilder 4, Computer software. Inprise 
Corporation. 2000 

Burbeek, Steve. “Applieations Programming in Smalltalk-80™: How to use Model- 
View-Controller (MVC)”. Copyright 1987 

Bigus, Joseph P, and Jennifer Bigus. Construeting Intelligent Agents with Java™ . John 
Wiley & Sons, Ine. 1998. 

Cormen, Thomas H., Charles E. Leiserson, and Ronald L. Rivest. Introduction to 
Algorithms. The MIT Press. McGraw-Hill Book Company. 1990. 

Dietel, H.M. and P.J. Dietel. Java™ How To Program. Third Edition . Prentice Hall. 
1999. 

Eriksson, Hans-Erik and Magnus Penker. UME Toolkit . John Wiley & Sons, INC. 
1998. 

Hofmeister, Christine, Robert Nord, and Dilip Soni. Applied Software Architecture . 
Addison Wesley Eongman, Inc. 2000. 

Ilachinski, A., Irreducible Semi-Autonomous Adaptive Combat (ISAAC): An Artificial- 
Eife Approach to Eand Warfare (U), (Center for Naval Analyses Research Memorandum 
CRM 97-61.10), Alexandria, VA: Center for Naval Analyses, 1997. 

Koosis, Donald and David Koosis. Java™ Programming Eor Dummies,. 3^^^ Edition . 
IDG Books Worldwide, Inc. 1998. 

Rothenberg, Jeff. “Object-Oriented Simulation: Where Do We Go from Here?” A 
RAND NOTE . The Rand Corporation. October 1989. 

Rothenberg, Jeff “The Nature of Modeling.” A RAND NOTE . The Rand Corporation. 
November 1989. 

UNEP United Nations Population Division “GEO- 2000 Global Environment Outlook”, 
Chapter Two: The State of the Environment. Geneva 1997. 

United Nations Population Division, “World Urbanization Prospects: The 1994 
Revision”, UN New York, 1995. 

Weiss, Gerhard. Multiagent Systems: A Modern Approach to Distributed Artificial 
Intelligence . The MIT Press. Cambridge, Massachusetts. 1999 


I4I 



THIS PAGE INTENTIONALLY LEET BLANK 


142 



BIBLIOGRAPHY 


Cellier, Francois E. Progress in Modeling and Simulation . Academic Press. 1982. 

Luger, George F., and William A. Stubblefield. 

Artificial Intelligence: Structures and Strategies for Complex Problem Solving . Addison 
Wesley Longman, Inc. 1998. 

Milton, T.R. Jr., "Urban Operations: Future War," Military Review, 1 February 1994. 

Neelamkavil, Francis. Computer Simulation and Modeling . 

John Wiley & Sons Ltd. 1987. 

Negoita, Constantin V. and Dan Ralescu. Simulation, Knowledge-Based Computing, and 
Fuzzy Statistics . Van Nostrand Reinhold Company Inc. 1987. 

Peters, James F. and Witold Pedrycz. Software Engineering: An Engineering Approach. 
John Wiley & Sons, Inc. 2000. 

Spriet Jan A. and Ghislain C. Vansteenkiste. Computer-aided Modeling and Simulation . 
Academic Press Inc. 1982. 

Ripley, Brian D. Stochastic Simulation . John Wiley & Sons Ltd. 1987. 

United Nations Environmental Program (UNEP), The Global Environmental Outlook 
(draft), Nairobi, 1996 

United States Army, Field Manual 90-10-1: An Infantryman's Guide To Urban Combat 
(Washington D.C.: Department of Defense, 1979). 

Uttamsingh, Ranjeet J. and A. Martin Wildberger. Artificial Intelligence and Simulation . 
Simulation Series. Volume 23 Number 4. Simulation Councils, INC. 1991. 

Zobrist, George W. and James V. Leonard. Object-Oriented Simulation: Reusability, 
Adaptability, Maintainability . IEEE PRESS. 1997. 


143 




THIS PAGE INTENTIONALLY LEET BLANK 


144 



INITIAL DISTRIBUTION LIST 


1. Defense Technical Information Center 
Fort Belvoir, Virginia 

2. Dudley Knox Library 
Naval Postgraduate School 
Monterey, California 

3. Marine Corps Representative 
Naval Postgraduate School 
Monterey, California 


4. Director, Training and Education, MCCDC, Code C46 
Quantico, Virginia 


5. Director, Marine Corps Research Center, MCCDC, Code C40RC 
Quantico, Virginia 


6. Marine Corps Tactical Systems Support Activity (Attn; Operations Officer) 
Camp Pendleton, California 


7. Director, Studies and Analysis Division, MCCDC, Code C45 
Quantico, Virginia 


8 Dr. Neil Rowe, Code32 

Computer Science Department 
Naval Postgraduate School 


9. CDR Chris Eagle, Code32 

Military Instructor, Computer Science Department 
Naval Postgraduate School 


145 












